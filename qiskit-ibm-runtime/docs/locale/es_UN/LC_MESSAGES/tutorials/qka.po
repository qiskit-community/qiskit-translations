msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-10 16:30+0000\n"
"PO-Revision-Date: 2022-11-10 17:12\n"
"Last-Translator: \n"
"Language-Team: Spanish (United)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: es-un\n"
"X-Crowdin-File: /master/qiskit-ibm-runtime/docs/locale/en/LC_MESSAGES/tutorials/qka.po\n"
"X-Crowdin-File-ID: 9822\n"
"Language: es_UN\n"

#: ../../tutorials/qka.ipynb:9
msgid "This page was generated from `docs/tutorials/qka.ipynb`__."
msgstr "Esta página fue generada a partir de `docs/tutorials/qka.ipynb`__."

#: ../../tutorials/qka.ipynb:9
msgid "Quantum Kernel Alignment with Qiskit Runtime"
msgstr "Alineación del Kernel Cuántico con Qiskit Runtime"

#: ../../tutorials/qka.ipynb:11
msgid "**Classification with Support Vector Machines**\\  Classification problems are widespread in machine learning applications. Examples include credit card risk, handwriting recognition, and medical diagnosis. One approach to tackling classification problems is the support vector machine (SVM) [1,2]. This supervised learning algorithm uses labeled data samples to train a model that can predict to which class a test sample belongs. It does this by finding a separating hyperplane maximizing the margin between data classes. Often, data is not linearly separable in the original space. In these cases, the kernel trick is used to implicitly encode a transformation of the data into a higher-dimensional feature space, through the inner product between pairs of data points, where the data may become separable."
msgstr "**Clasificación con Máquinas de Vectores de Soporte**\\ Los problemas de clasificación están muy extendidos en las aplicaciones de machine learning. Los ejemplos incluyen riesgo de tarjeta de crédito, reconocimiento de escritura a mano y diagnóstico médico. Un enfoque para abordar los problemas de clasificación es la máquina de vectores de soporte (support vector machine, SVM) [1,2]. Este algoritmo de aprendizaje supervisado utiliza muestras de datos etiquetados para entrenar un modelo que puede predecir a qué clase pertenece una muestra de prueba. Lo hace encontrando un hiperplano de separación que maximiza el margen entre las clases de datos. A menudo, los datos no se pueden separar linealmente en el espacio original. En estos casos, el truco del kernel se usa para codificar implícitamente una transformación de los datos en un espacio de características de mayor dimensión, a través del producto interno entre pares de puntos de datos, donde los datos pueden volverse separables."

#: ../../tutorials/qka.ipynb:14
msgid "**Quantum Kernels**\\  Quantum computers can be used to encode classical data in a quantum-enhanced feature space. In 2019, IBM introduced an algorithm called the quantum kernel estimator (QKE) for computing quantum kernels [3]. This algorithm uses quantum circuits with data provided classically and offers an efficient way to evaluate inner products between data in a quantum feature space. For two data samples :math:`\\theta` and :math:`\\theta'`, the kernel matrix is given as"
msgstr "**Kernels Cuánticos**\\ Las computadoras cuánticas se pueden usar para codificar datos clásicos en un espacio de funciones mejoradas cuánticamente. En 2019, IBM introdujo un algoritmo llamado estimador de kernel cuántico (quantum kernel estimator, QKE) para calcular kernels cuánticos [3]. Este algoritmo utiliza circuitos cuánticos con datos proporcionados de forma clásica y ofrece una forma eficiente de evaluar productos internos entre datos en un espacio cuántico de características. Para dos muestras de datos :math:`\\theta` y :math:`\\theta'`, la matriz del kernel está dada como"

#: ../../tutorials/qka.ipynb:16
msgid "K(\\theta, \\theta') = \\lvert\\langle 0^n \\rvert U^\\dagger(\\theta) U(\\theta') \\lvert 0^n \\rangle \\rvert^2,"
msgstr "K(\\theta, \\theta') = \\lvert\\langle 0^n \\rvert U^\\dagger(\\theta) U(\\theta') \\lvert 0^n \\rangle \\rvert^2,"

#: ../../tutorials/qka.ipynb:21
msgid "where :math:`U(\\theta)` prepares the quantum feature state. Quantum kernels used in a classification framework inherit the convex optimization program of the SVM and avoid common limitations of variational quantum classifiers. A key observation of this paper was that a necessary condition for a computational advantage requires quantum circuits for the kernel that are hard to simulate classically. More recently, IBM proved that quantum kernels can offer superpolynomial speedups over any classical learner on a learning problem based on the hardness of the discrete logarithm problem [4]. This means that quantum kernels can someday offer quantum advantage on suitable problems."
msgstr "donde :math:`U(\\theta)` prepara el estado cuántico de la característica. Los kernels cuánticos utilizados en un framework de clasificación heredan el programa de optimización convexa de SVM y evitan las limitaciones comunes de los clasificadores cuánticos variacionales. Una observación clave de este artículo fue que una condición necesaria para una ventaja computacional requiere circuitos cuánticos para el kernel que son difíciles de simular de forma clásica. Más recientemente, IBM demostró que los kernels cuánticos pueden ofrecer aceleraciones superpolinómicas sobre cualquier aprendiz clásico en un problema de aprendizaje basado en la dificultad del problema del logaritmo discreto [4]. Esto significa que los kernels cuánticos algún día pueden ofrecer una ventaja cuántica en los problemas adecuados."

#: ../../tutorials/qka.ipynb:24
msgid "**Quantum Kernels that Exploit Structure in Data**\\  An important approach in the search for practical quantum advantage in machine learning is to identify quantum kernels for learning problems that have underlying structure in the data. We’ve taken a step in this direction in our recent paper [5], where we introduced a broad class of quantum kernels that exploit group structure in data. Examples of learning problems for data with group structure could include learning permutations or classifying translations. We call this new class of kernels *covariant quantum kernels* as they are related to covariant quantum measurements. The quantum feature map is defined by a unitary representation :math:`D(\\theta)` of a group :math:`G` for some element :math:`\\theta \\in G`, and a fiducial reference state :math:`\\lvert\\psi\\rangle = V\\lvert0^n\\rangle` prepared by a unitary circuit :math:`V`. The kernel matrix is given as"
msgstr "**Kernels Cuánticos que Explotan la Estructura de los Datos**\\ Un enfoque importante en la búsqueda de una ventaja cuántica práctica en el machine learning es identificar los kernels cuánticos para problemas de aprendizaje que tienen una estructura subyacente en los datos. Hemos dado un paso en esta dirección en nuestro artículo reciente [5], donde presentamos una amplia clase de kernels cuánticos que explotan la estructura de grupo en los datos. Los ejemplos de problemas de aprendizaje para datos con estructura de grupo podrían incluir el aprendizaje de permutaciones o la clasificación de traducciones. Llamamos a esta nueva clase de núcleos *kernels cuánticos covariantes* ya que están relacionados con mediciones cuánticas covariantes. El mapa cuántico de características está definido por una representación unitaria :math:`D(\\theta)` de un grupo :math:`G` para algún elemento :math:`\\theta \\in G`, y un estado de referencia fiducial :math:`\\lvert\\psi\\rangle = V\\lvert0^n\\rangle` preparado por un circuito unitario :math:`V`. La matriz del kernel está dada como"

#: ../../tutorials/qka.ipynb:27
msgid "K(\\theta, \\theta') = \\vert\\langle 0^n \\rvert V^\\dagger D^\\dagger(\\theta) D(\\theta') V \\lvert 0^n \\rangle \\rvert^2. \\qquad (1)"
msgstr "K(\\theta, \\theta') = \\vert\\langle 0^n \\rvert V^\\dagger D^\\dagger(\\theta) D(\\theta') V \\lvert 0^n \\rangle \\rvert^2. \\qquad (1)"

#: ../../tutorials/qka.ipynb:32
msgid "In general, the choice of the fiducial state is not known *a priori* and can significantly impact the performance of the classifier. Here, we use a method called quantum kernel alignment (QKA) to find a good fiducial state for a given group."
msgstr "En general, la elección del estado fiducial no se conoce *a priori* y puede afectar significativamente el rendimiento del clasificador. Aquí, usamos un método llamado alineación del kernel cuántico (quantum kernel alignment, QKA) para encontrar un buen estado fiducial para un grupo determinado."

#: ../../tutorials/qka.ipynb:34
msgid "**Aligning Quantum Kernels on a Dataset**\\  In practice, SVMs require a choice of the kernel function. Sometimes, symmetries in the data can inform this selection, other times it is chosen in an ad hoc manner. Kernel alignment is one approach to learning a kernel on a given dataset by iteratively adapting it to have high similarity to a target kernel informed from the underlying data distribution [6]. As a result, the SVM with an aligned kernel will likely generalize better to new data than with an unaligned kernel. Using this concept, we introduced in [5] an algorithm for quantum kernel alignment, which provides a way to learn a quantum kernel from a family of kernels. Specifically, the algorithm optimizes the parameters in a quantum circuit to maximize the alignment of a kernel while converging to the maximum SVM margin. In the context of covariant quantum kernels, we extend Eq. :math:`(1)` to"
msgstr "**Alineación de Kernels Cuánticos en un Conjunto de Datos**\\ En la práctica, las SVMs requieren una elección de la función del kernel. A veces, las simetrías en los datos pueden informar esta selección, otras veces se elige de manera ad hoc. La alineación del kernel es un enfoque para aprender un kernel en un conjunto de datos determinado al adaptarlo iterativamente para que tenga una gran similitud con un kernel objetivo informado a partir de la distribución de datos subyacente [6]. Como resultado, la SVM con un kernel alineado probablemente generalizará mejor los datos nuevos que con un kernel no alineado. Usando este concepto, presentamos en [5] un algoritmo para la alineación del kernel cuántico, que proporciona una forma de aprender un kernel cuántico de una familia de kernels. Específicamente, el algoritmo optimiza los parámetros en un circuito cuántico para maximizar la alineación de un kernel mientras converge al margen máximo de la SVM. En el contexto de los kernels cuánticos covariantes, extendemos la ecuación :math:`(1)` a"

#: ../../tutorials/qka.ipynb:37
msgid "K_\\lambda(\\theta,\\theta') = \\lvert\\langle 0^n \\rvert V^\\dagger_\\lambda D^\\dagger(\\theta) D(\\theta') V_\\lambda \\lvert 0^n \\rangle \\rvert^2, \\qquad (2)"
msgstr "K_\\lambda(\\theta,\\theta') = \\lvert\\langle 0^n \\rvert V^\\dagger_\\lambda D^\\dagger(\\theta) D(\\theta') V_\\lambda \\lvert 0^n \\rangle \\rvert^2, \\qquad (2)"

#: ../../tutorials/qka.ipynb:42
msgid "and use QKA to learn a good fiducial state parametrized by :math:`\\lambda` for a given group."
msgstr "y usamos QKA para aprender un buen estado fiducial parametrizado por :math:`\\lambda` para un grupo determinado."

#: ../../tutorials/qka.ipynb:44
msgid "**Covariant Quantum Kernels on a Specific Learning Problem**\\  Let’s try out QKA on a learning problem. In the following, we’ll consider a binary classification problem we call *labeling cosets with error* [5]. In this problem, we will use a group and a subgroup to form two cosets, which will represent our data classes. We take the group :math:`G = SU(2)^{\\otimes n}` for :math:`n` qubits, which is the special unitary group of :math:`2\\times2` matrices and has wide applicability in nature, for example, the Standard Model of particle physics and in many condensed matter systems. We take the graph-stabilizer subgroup :math:`S_{\\mathrm{graph}} \\in G` with :math:`S_{\\mathrm{graph}} = \\langle \\{ X_i \\otimes_{k:(k,i) \\in \\mathcal{E}} Z_k \\}_{i \\in \\mathcal{V}} \\rangle` for a graph :math:`(\\mathcal{E},\\mathcal{V})` with edges :math:`\\mathcal{E}` and vertices :math:`\\mathcal{V}`. Note that the stabilizers fix a stabilizer state such that :math:`D_s \\lvert \\psi\\rangle = \\lvert \\psi\\rangle`. This observation will be useful a bit later."
msgstr "**Kernels Cuánticos Covariantes en un Problema de Aprendizaje Específico**\\ Probemos QKA en un problema de aprendizaje. A continuación, consideraremos un problema de clasificación binaria que llamamos *etiquetado de clases laterales con error* [5]. En este problema, usaremos un grupo y un subgrupo para formar dos clases laterales, que representarán nuestras clases de datos. Tomamos el grupo :math:`G = SU(2)^{\\otimes n}` para :math:`n` qubits, que es el grupo unitario especial de :math:`2\\times2` matrices y tiene una amplia aplicabilidad en la naturaleza, por ejemplo, el Modelo Estándar de física de partículas y en muchos sistemas de materia condensada. Tomamos el subgrupo estabilizador de grafos :math:`S_{\\mathrm{graph}} \\in G` con :math:`S_{\\mathrm{graph}} = \\langle \\{ X_i \\otimes_{k:(k,i) \\in \\mathcal{E}} Z_k \\}_{i \\in \\mathcal{V}} \\rangle` para un grafo :math:`(\\mathcal{E},\\mathcal{V})` con aristas :math:`\\mathcal{E}` y vértices :math:`\\mathcal{V}`. Ten en cuenta que los estabilizadores fijan un estado estabilizador tal que :math:`D_s \\lvert \\psi\\rangle = \\lvert \\psi\\rangle`. Esta observación será útil un poco más adelante."

#: ../../tutorials/qka.ipynb:48
msgid "To generate the dataset, we write the rotations of the group as :math:`D(\\theta_1, \\theta_2, 0)=\\exp(i \\theta_1 X) \\exp(i \\theta_2 Z) \\in SU(2)`, so that each qubit is parametrized by the first two Euler angles (the third we set to zero). Then, we draw randomly two sets of angles :math:`\\mathbf{\\theta}_\\pm \\in [-\\pi/4, \\pi/4]^{2n}` for the :math:`n`-qubit problem. From these two sets, we construct a binary classification problem by forming two left-cosets (representing the two classes) with those angles, :math:`C_\\pm = D(\\mathbf{\\theta}_\\pm) S_{\\mathrm{graph}}` where :math:`D(\\mathbf{\\theta}_\\pm) = \\otimes_{k=1}^n D(\\theta_\\pm^{2k-1}, \\theta_\\pm^{2k}, 0)`. Note that the elements of the cosets can again be written in terms of Euler angles. We build training and testing sets by randomly drawing elements from :math:`C_\\pm` such that the dataset has samples :math:`i=1,...,m` containing the first two Euler angles for each qubit :math:`\\mathbf{\\theta}_{y_i} = (\\theta_{y_i}^{1}, \\theta_{y_i}^{2}, \\theta_{y_i}^{3}, \\theta_{y_i}^{4}, ..., \\theta_{y_i}^{2n-1}, \\theta_{y_i}^{2n})` and labels :math:`y_i \\in \\{-1,1\\}` that indicate to which coset a sample belongs."
msgstr "Para generar el conjunto de datos, escribimos las rotaciones del grupo como :math:`D(\\theta_1, \\theta_2, 0)=\\exp(i \\theta_1 X) \\exp(i \\theta_2 Z) \\in SU(2)`, de modo que cada qubit esté parametrizado por los dos primeros ángulos de Euler (el tercero lo ponemos en cero). Luego, dibujamos aleatoriamente dos conjuntos de ángulos :math:`\\mathbf{\\theta}_\\pm \\in [-\\pi/4, \\pi/4]^{2n}` para el problema de :math:`n` qubits A partir de estos dos conjuntos, construimos un problema de clasificación binaria formando dos clases laterales izquierdas (que representan las dos clases) con esos ángulos, :math:`C_\\pm = D(\\mathbf{\\theta}_\\pm) S_{\\mathrm{graph}}` donde :math:`D(\\mathbf{\\theta}_\\pm) = \\otimes_{k=1}^n D(\\theta_\\pm^{2k-1}, \\theta_\\pm^{2k}, 0)`. Ten en cuenta que los elementos de las clases laterales se pueden escribir nuevamente en términos de los ángulos de Euler. Construimos conjuntos de entrenamiento y prueba dibujando elementos al azar de :math:`C_\\pm` de modo que el conjunto de datos tenga muestras :math:`i=1,...,m` que contengan los dos primeros ángulos de Euler para cada qubit :math:`\\mathbf{\\theta}_{y_i} = (\\theta_{y_i}^{1}, \\theta_{y_i}^{2}, \\theta_{y_i}^{3}, \\theta_{y_i}^{4}, ..., \\theta_{y_i}^{2n-1}, \\theta_{y_i}^{2n})` y etiquetas :math:`y_i \\in \\{-1,1\\}` que indican a qué clase lateral pertenece una muestra."

#: ../../tutorials/qka.ipynb:52
msgid "Next, we select a fiducial state. A natural candidate is the stabilizer state we encountered above. Why? Because this is a subgroup invariant state, :math:`D_s\\lvert\\psi\\rangle = \\lvert\\psi\\rangle`, which causes the data for a given coset to be mapped to a unique state: :math:`D(\\mathbf{\\theta}_\\pm)D_s \\lvert\\psi\\rangle = D(\\mathbf{\\theta}_\\pm) \\lvert\\psi\\rangle`. This means the classifier only needs to distinguish the *two* states :math:`D(\\mathbf{\\theta}_\\pm) \\lvert\\psi\\rangle \\langle \\psi\\rvert D^\\dagger(\\mathbf{\\theta}_\\pm)` for every element of the coset. In this tutorial, we will add a small Gaussian error with variance :math:`0.01` to the Euler angles of the dataset. This noise will perturb these two states, but if the variance is sufficiently small, we expect the states will still be classified correctly. Let’s consider a parametrized version of the stabilizer state, associated with the coupling graph :math:`(\\mathcal{E},\\mathcal{V})` given by the device connectivity, as our fiducial state and then use kernel alignment to find its optimal parameters. Specifically, we’ll replace the initial layers of Hadamards in the graph state with :math:`y`-rotations by an angle :math:`\\lambda`,"
msgstr "A continuación, seleccionamos un estado fiducial. Un candidato natural es el estado estabilizador que encontramos arriba. ¿Por qué? Debido a que este es un estado invariable de subgrupo, :math:`D_s\\lvert\\psi\\rangle = \\lvert\\psi\\rangle`, lo que hace que los datos de una clase lateral determinada se mapeen a un estado único: :math:`D(\\mathbf{\\theta}_\\pm)D_s \\lvert\\psi\\rangle = D(\\mathbf{\\theta}_\\pm) \\lvert\\psi\\rangle`. Esto significa que el clasificador solo necesita distinguir los *dos* estados :math:`D(\\mathbf{\\theta}_\\pm) \\lvert\\psi\\rangle \\langle \\psi\\rvert D^\\dagger(\\mathbf{\\theta}_\\pm)` para cada elemento de la clase lateral. En este tutorial, agregaremos un pequeño error Gaussiano con varianza :math:`0.01` a los ángulos de Euler del conjunto de datos. Este ruido perturbará estos dos estados, pero si la varianza es lo suficientemente pequeña, esperamos que los estados se clasifiquen correctamente. Consideremos una versión parametrizada del estado estabilizador, asociado con el grafo de acoplamiento :math:`(\\mathcal{E},\\mathcal{V})` dado por la conectividad del dispositivo, como nuestro estado fiducial y luego usemos la alineación del kernel para encontrar sus parámetros óptimos. Específicamente, reemplazaremos las capas iniciales de Hadamards en el estado del grafo con rotaciones :math:`y` por un ángulo :math:`\\lambda`,"

#: ../../tutorials/qka.ipynb:56
msgid "\\lvert \\psi_\\lambda\\rangle = V_\\lambda \\lvert 0^n\\rangle = \\prod_{(k,t) \\in \\mathcal{E}} CZ_{k,t} \\prod_{k \\in \\mathcal{V}} \\exp\\left(i \\frac{\\lambda}{2} Y_k\\right)\\lvert 0^n\\rangle,"
msgstr "\\lvert \\psi_\\lambda\\rangle = V_\\lambda \\lvert 0^n\\rangle = \\prod_{(k,t) \\in \\mathcal{E}} CZ_{k,t} \\prod_{k \\in \\mathcal{V}} \\exp\\left(i \\frac{\\lambda}{2} Y_k\\right)\\lvert 0^n\\rangle,"

#: ../../tutorials/qka.ipynb:61
msgid "where :math:`CZ=\\mathrm{diag}(1,1,1,-1)`. Then, given two samples from our dataset, :math:`\\mathbf{\\theta}` and :math:`\\mathbf{\\theta}'`, the kernel matrix is evaluated as in Eq. :math:`(2)`. If we initialize the kernel with :math:`\\lambda \\approx 0`, we expect the quantum kernel alignment algorithm to converge towards the optimal :math:`\\lambda = \\pi/2` and the classifier to yield 100% test accuracy."
msgstr "donde :math:`CZ=\\mathrm{diag}(1,1,1,-1)`. Luego, dadas dos muestras de nuestro conjunto de datos, :math:`\\mathbf{\\theta}` y :math:`\\mathbf{\\theta}'`, la matriz del kernel se evalúa como en la ecuación :math:`(2)`. Si inicializamos el kernel con :math:`\\lambda \\approx 0`, esperamos que el algoritmo de alineación del kernel cuántico converja hacia :math:`\\lambda = \\pi/2` óptima y el clasificador produzca una precisión de prueba del 100%."

#: ../../tutorials/qka.ipynb:63
msgid "Let’s define two specific problem instances to test these ideas out. We’ll be using the quantum device ``ibmq_montreal``, with coupling map shown below:"
msgstr "Definamos dos instancias de problemas específicos para probar estas ideas. Usaremos el dispositivo cuántico ``ibmq_montreal``, con el mapa de acoplamiento que se muestra a continuación:"

#: ../../tutorials/qka.ipynb:65
msgid "|090cf64fc85b4dc99a24a68babdd4126|"
msgstr ""

#: ../../tutorials/qka.ipynb:78
msgid "090cf64fc85b4dc99a24a68babdd4126"
msgstr ""

#: ../../tutorials/qka.ipynb:67
msgid "We’ll pick two different subgraphs, one for 7 qubits and one for 10, to define our problem instances. Using these subgraphs, we’ll generate the corresponding datasets as described above, and then align the quantum kernel with QKA to learn a good fiducial state."
msgstr "Elegiremos dos subgrafos diferentes, uno para 7 qubits y otro para 10, para definir nuestras instancias de problemas. Usando estos subgrafos, generaremos los conjuntos de datos correspondientes como se describió arriba y luego alinearemos el kernel cuántico con QKA para aprender un buen estado fiducial."

#: ../../tutorials/qka.ipynb:69
msgid "|67b5892f46a94f8280f74f67331cbe37|"
msgstr ""

#: ../../tutorials/qka.ipynb:81
msgid "67b5892f46a94f8280f74f67331cbe37"
msgstr ""

#: ../../tutorials/qka.ipynb:71
msgid "**Speeding up Algorithms with Qiskit Runtime**\\  QKA is an iterative quantum-classical algorithm, in which quantum hardware is used to execute parametrized quantum circuits for evaluating the quantum kernel matrices with QKE, while a classical optimizer tunes the parameters of those circuits to maximize the alignment. Iterative algorithms of this type can be slow due to latency between the quantum and classical calculations. Qiskit Runtime is a new architecture that can speed up iterative algorithms like QKA by co-locating classical computations with the quantum hardware executions. In this tutorial, we’ll use QKA with Qiskit Runtime to learn a good quantum kernel for the *labeling cosets with error* problem defined above."
msgstr "**Algoritmos de Aceleración con Qiskit Runtime**\\ QKA es un algoritmo iterativo cuántico-clásico, en el que se utiliza hardware cuántico para ejecutar circuitos cuánticos parametrizados para evaluar las matrices del kernel cuántico con QKE, mientras que un optimizador clásico ajusta los parámetros de esos circuitos para maximizar la alineación. Los algoritmos iterativos de este tipo pueden ser lentos debido a la latencia entre los cálculos cuánticos y clásicos. Qiskit Runtime es una nueva arquitectura que puede acelerar los algoritmos iterativos como QKA al ubicar los cálculos clásicos junto con las ejecuciones de hardware cuántico. En este tutorial, usaremos QKA con Qiskit Runtime para aprender un buen kernel cuántico para el problema de *etiquetado de clases laterales con error* definido anteriormente."

#: ../../tutorials/qka.ipynb:74
msgid "**References**\\  [1] B. E. Boser, I. M. Guyon, and V. N. Vapnik, Proceedings of the Fifth Annual Workshop on Computational Learning Theory, COLT ’92 (Association for Computing Machinery, New York, NY, USA, 1992) pp. 144-152 `link <https://doi.org/10.1145/130385.130401>`__ [2] V. Vapnik, The Nature of Statistical Learning Theory, Information Science and Statistics (Springer New York, 2013) `link <https://books.google.com/books?id=EqgACAAAQBAJ>`__ [3] V. Havlíček, A. D. Córcoles, K. Temme, A. W. Harrow, A. Kandala, J. M. Chow, and J. M. Gambetta, Nature 567, 209-212 (2019) `link <https://doi.org/10.1038/s41586-019-0980-2>`__ [4] Y. Liu, S. Arunachalam, and K. Temme, arXiv:2010.02174 (2020) `link <https://arxiv.org/abs/2010.02174>`__ [5] J. R. Glick, T. P. Gujarati, A. D. Córcoles, Y. Kim, A. Kandala, J. M. Gambetta, K. Temme, arXiv:2105.03406 (2021) `link <https://arxiv.org/abs/2105.03406>`__\\  [6] N. Cristianini, J. Shawe-taylor, A. Elisseeff, and J. Kandola, Advances in Neural Information Processing Systems 14 (2001) `link <https://proceedings.neurips.cc/paper/2001/file/1f71e393b3809197ed66df836fe833e5-Paper.pdf>`__"
msgstr "**References**\\  [1] B. E. Boser, I. M. Guyon, and V. N. Vapnik, Proceedings of the Fifth Annual Workshop on Computational Learning Theory, COLT ’92 (Association for Computing Machinery, New York, NY, USA, 1992) pp. 144-152 `enlace <https://doi.org/10.1145/130385.130401>`__ [2] V. Vapnik, The Nature of Statistical Learning Theory, Information Science and Statistics (Springer New York, 2013) `enlace <https://books.google.com/books?id=EqgACAAAQBAJ>`__ [3] V. Havlíček, A. D. Córcoles, K. Temme, A. W. Harrow, A. Kandala, J. M. Chow, and J. M. Gambetta, Nature 567, 209-212 (2019) `enlace <https://doi.org/10.1038/s41586-019-0980-2>`__ [4] Y. Liu, S. Arunachalam, and K. Temme, arXiv:2010.02174 (2020) `enlace <https://arxiv.org/abs/2010.02174>`__ [5] J. R. Glick, T. P. Gujarati, A. D. Córcoles, Y. Kim, A. Kandala, J. M. Gambetta, K. Temme, arXiv:2105.03406 (2021) `enlace <https://arxiv.org/abs/2105.03406>`__\\  [6] N. Cristianini, J. Shawe-taylor, A. Elisseeff, and J. Kandola, Advances in Neural Information Processing Systems 14 (2001) `enlace <https://proceedings.neurips.cc/paper/2001/file/1f71e393b3809197ed66df836fe833e5-Paper.pdf>`__"

#: ../../tutorials/qka.ipynb:93
msgid "Load your account and get the quantum backend"
msgstr "Carga tu cuenta y obtén el backend cuántico"

#: ../../tutorials/qka.ipynb:95
msgid "We’ll be using the 27-qubit device ``ibmq_montreal`` for this tutorial in Qiskit Runtime on IBM Quantum."
msgstr "Usaremos el dispositivo de 27 qubits ``ibmq_montreal`` para este tutorial en Qiskit Runtime en IBM Quantum."

#: ../../tutorials/qka.ipynb:124
msgid "Invoke the Quantum Kernel Alignment program"
msgstr "Invocar el programa de Alineación de Kernel Cuántico"

#: ../../tutorials/qka.ipynb:126
msgid "Before executing the runtime program for QKA, we need to prepare the dataset and configure the input parameters for the algorithm."
msgstr "Antes de ejecutar el programa runtime para QKA, debemos preparar el conjunto de datos y configurar los parámetros de entrada para el algoritmo."

#: ../../tutorials/qka.ipynb:129
msgid "1. Prepare the dataset"
msgstr "1. Preparar el conjunto de datos"

#: ../../tutorials/qka.ipynb:131
msgid "First, we load the dataset from the ``csv`` file and then extract the labeled training and test samples. Here, we’ll look at the 7-qubit problem, shown above in subfigure a). A second dataset is also available for the 10-qubit problem in b)."
msgstr "Primero, cargamos el conjunto de datos desde el archivo ``csv`` y luego extraemos las muestras de entrenamiento y prueba etiquetadas. Aquí, veremos el problema de 7 qubits, que se muestra arriba en la subfigura a). También está disponible un segundo conjunto de datos para el problema de 10 qubits en b)."

#: ../../tutorials/qka.ipynb:157
msgid "Let’s take a look at the data to see how it’s formatted. Each row of the dataset contains a list of Euler angles, followed by the class label :math:`\\pm1` in the last column. For an :math:`n`-qubit problem, there are :math:`2n` features corresponding to the first two Euler angles for each qubit (recall discussion above). The rows alternate between class labels."
msgstr "Echemos un vistazo a los datos para ver cómo están formateados. Cada fila del conjunto de datos contiene una lista de ángulos de Euler, seguida de la etiqueta de clase :math:`\\pm1` en la última columna. Para un problema de :math:`n` qubits, hay :math:`2n` características correspondientes a los dos primeros ángulos de Euler para cada qubit (recuerda la discusión anterior). Las filas alternan entre etiquetas de clase."

#: ../../tutorials/qka.ipynb:232
msgid "Now, let’s explicitly construct the training and test samples (denoted ``x``) and their labels (denoted ``y``)."
msgstr "Ahora, construyamos explícitamente las muestras de entrenamiento y prueba (denotadas con ``x``) y sus etiquetas (denotadas con ``y``)."

#: ../../tutorials/qka.ipynb:270
msgid "2. Configure the QKA algorithm"
msgstr "2. Configurar el algoritmo QKA"

#: ../../tutorials/qka.ipynb:272
msgid "The first task is to set up the feature map and its entangler map, which specifies the arrangement of :math:`CZ` gates in the fiducial state. We will choose this to match the connectivity of the problem subgraph, pictured above. We also initialize the fiducial state parameter :math:`\\lambda` with ``initial_point``."
msgstr "La primera tarea es configurar el mapa de características y su mapa entrelazador, que especifica la disposición de las compuertas :math:`CZ` en el estado fiducial. Elegiremos esto para que coincida con la conectividad del subgrafo del problema, que se muestra arriba. También inicializamos el parámetro del estado fiducial :math:`\\lambda` con ``initial_point``."

#: ../../tutorials/qka.ipynb:308
msgid "Let’s print out the circuit for the feature map (the circuit for the kernel will be a feature map for one data sample composed with an inverse feature map for a second sample). The first part of the feature map is the fiducial state, which is prepared with a layer of :math:`y` rotations followed by :math:`CZ`\\ s. Then, the last two layers of :math:`z` and :math:`x` rotations in the circuit denote the group representation :math:`D(\\theta)` for a data sample :math:`\\theta`. Note that a single-qubit rotation is defined as :math:`RP(\\phi) = \\exp(- i [\\phi/2] P)` for :math:`P \\in {X, Y, Z}`."
msgstr "Imprimamos el circuito para el mapa de características (el circuito para el kernel será un mapa de características para una muestra de datos compuesta por un mapa de características inversas para una segunda muestra). La primera parte del mapa de características es el estado fiducial, que se prepara con una capa de rotaciones :math:`y` seguidas de :math:`CZ`\\ s. Luego, las dos últimas capas de rotaciones :math:`z` y :math:`x` en el circuito denotan la representación del grupo :math:`D(\\theta)` para una muestra de datos :math:`\\theta`. Ten en cuenta que una rotación de un solo qubit se define como :math:`RP(\\phi) = \\exp(- i [\\phi/2] P)` para :math:`P \\in {X, Y, Z}`."

#: ../../tutorials/qka.ipynb:430
msgid "Next, we set the values for the SVM soft-margin penalty ``C`` and the number of SPSA iterations ``maxiters`` we use to align the quantum kernel."
msgstr "A continuación, establecemos los valores para la penalización del margen suave de la SVM ``C`` y el número de iteraciones de SPSA ``maxiters`` que usamos para alinear el kernel cuántico."

#: ../../tutorials/qka.ipynb:452
msgid "Finally, we decide how to map the virtual qubits of our problem graph to the physical qubits of the hardware. For example, in the 7-qubit problem, we can directly map the virtual qubits ``[0, 1, 2, 3, 4, 5, 6]`` to the physical qubits ``[10, 11, 12, 13, 14, 15, 16]`` of the device. This allows us to avoid introducing SWAP gates for qubits that are not connected, which can increase the circuit depth."
msgstr "Finalmente, decidimos cómo mapear los qubits virtuales de nuestro grafo del problema a los qubits físicos del hardware. Por ejemplo, en el problema de 7 qubits, podemos asignar directamente los qubits virtuales ``[0, 1, 2, 3, 4, 5, 6]`` a los qubits físicos ``[10, 11, 12, 13, 14, 15, 16]`` del dispositivo. Esto nos permite evitar la introducción de compuertas SWAP para qubits que no están conectados, lo que puede aumentar la profundidad del circuito."

#: ../../tutorials/qka.ipynb:475
msgid "3. Set up and run the program"
msgstr "3. Configurar y ejecutar el programa"

#: ../../tutorials/qka.ipynb:477
msgid "We’re almost ready to run the program. First, let’s take a look at the program metadata, which includes a description of the input parameters and their default values."
msgstr "Estamos casi listos para ejecutar el programa. Primero, echemos un vistazo a los metadatos del programa, que incluyen una descripción de los parámetros de entrada y sus valores predeterminados."

#: ../../tutorials/qka.ipynb:672
msgid "We see that this program has several input parameters, which we’ll configure below. To run the program, we’ll set up its two main components: ``inputs`` (the input parameters from the program metadata) and ``options`` (the quantum backend). We’ll also define a callback function so that the intermediate results of the algorithm will be printed as the program runs. Note that each step of the algorithm for the settings we’ve selected here takes approximately 11 minutes."
msgstr "Vemos que este programa tiene varios parámetros de entrada, que configuraremos a continuación. Para ejecutar el programa, configuraremos sus dos componentes principales: ``inputs`` (los parámetros de entrada de los metadatos del programa) y ``options`` (el backend cuántico). También definiremos una función de devolución de llamada para que los resultados intermedios del algoritmo se impriman a medida que se ejecuta el programa. Ten en cuenta que cada paso del algoritmo para la configuración que hemos seleccionado aquí toma aproximadamente 11 minutos."

#: ../../tutorials/qka.ipynb:809
msgid "4. Retrieve the results of the program"
msgstr "4. Recuperar los resultados del programa"

#: ../../tutorials/qka.ipynb:811
msgid "Now that we’ve run the program, we can retrieve the output, which is the aligned kernel parameter and the aligned kernel matrix. Let’s also plot this kernel matrix (we’ll subtract off the diagonal to show the contrast between the remaining entries). The kernel matrix is expected to have a block-diagonal structure. This reflects the fact that the kernel maps the input data effectively to just two states (modulo the small noise we added to the data; recall the discussion above). That is, data in the same coset (same class label) have a larger overlap than do data from different cosets."
msgstr "Ahora que hemos ejecutado el programa, podemos recuperar la salida, que es el parámetro del kernel alineado y la matriz del kernel alineado. Grafiquemos también esta matriz del kernel (restaremos la diagonal para mostrar el contraste entre las entradas restantes). Se espera que la matriz del kernel tenga una estructura de bloque diagonal. Esto refleja el hecho de que el núcleo mapea los datos de entrada de manera efectiva a solo dos estados (módulo al pequeño ruido que agregamos a los datos; recuerda la discusión anterior). Es decir, los datos en la misma clase lateral (misma etiqueta de clase) tienen una superposición mayor que los datos de diferentes clases laterales."

