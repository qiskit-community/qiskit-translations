msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-10 16:30+0000\n"
"PO-Revision-Date: 2022-11-10 16:44\n"
"Last-Translator: \n"
"Language-Team: Japanese\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ja\n"
"X-Crowdin-File: /master/qiskit-ibm-runtime/docs/locale/en/LC_MESSAGES/tutorials/qka.po\n"
"X-Crowdin-File-ID: 9822\n"
"Language: ja_JP\n"

#: ../../tutorials/qka.ipynb:9
msgid "This page was generated from `docs/tutorials/qka.ipynb`__."
msgstr "このページは `docs/tutorials/qka.ipynb`__ から生成されました。"

#: ../../tutorials/qka.ipynb:9
msgid "Quantum Kernel Alignment with Qiskit Runtime"
msgstr "Qiskit Runtime による量子カーネルアラインメント"

#: ../../tutorials/qka.ipynb:11
msgid "**Classification with Support Vector Machines**\\  Classification problems are widespread in machine learning applications. Examples include credit card risk, handwriting recognition, and medical diagnosis. One approach to tackling classification problems is the support vector machine (SVM) [1,2]. This supervised learning algorithm uses labeled data samples to train a model that can predict to which class a test sample belongs. It does this by finding a separating hyperplane maximizing the margin between data classes. Often, data is not linearly separable in the original space. In these cases, the kernel trick is used to implicitly encode a transformation of the data into a higher-dimensional feature space, through the inner product between pairs of data points, where the data may become separable."
msgstr "**サポート・ベクトル・マシンによる分類**\\ 分類の問題は、機械学習アプリケーションに広く適用されています。 例えば、クレジット・カードのリスク、手書き文字認識、医療診断などが挙げられます。 分類問題に対処するための 1 つのアプローチは、サポートベクターマシン ( SVM) [1,2] です。 この教師あり学習アルゴリズムは、ラベル付きデータ・サンプルを使用して、テスト・サンプルがどのクラスに属するかを予測できるモデルをトレーニングします。 これは、データクラス間のマージンを最大にする分離超平面を見つけることによって行われます。 多くの場合、データは元の空間では線形分離可能ではありません。 このような場合、カーネル・トリックは、データが分離できるようになるデータ・ポイントのペア間の内積を通して、データをより高次元の特徴空間に変換することを暗黙的に符号化するために使用されます。"

#: ../../tutorials/qka.ipynb:14
msgid "**Quantum Kernels**\\  Quantum computers can be used to encode classical data in a quantum-enhanced feature space. In 2019, IBM introduced an algorithm called the quantum kernel estimator (QKE) for computing quantum kernels [3]. This algorithm uses quantum circuits with data provided classically and offers an efficient way to evaluate inner products between data in a quantum feature space. For two data samples :math:`\\theta` and :math:`\\theta'`, the kernel matrix is given as"
msgstr "**Quantum Kernels**\\  量子コンピューターは、古典データを量子的に拡張された特徴空間に符号化するために使用することができます。 2019年に IBM は量子カーネルを計算するための量子カーネル推定器 (quantum kernel estimator、QKE ) と呼ばれるアルゴリズムを発表しました [3] 。 このアルゴリズムは、古典的に提供されたデータを持つ量子回路を使用し、量子特徴空間におけるデータ間の内積を効率的に評価する方法を提供します。  :math:`\\theta`  と  :math:`\\theta'` の 2 つのデータサンプルについて、カーネル行列は以下のように与えられます。"

#: ../../tutorials/qka.ipynb:16
msgid "K(\\theta, \\theta') = \\lvert\\langle 0^n \\rvert U^\\dagger(\\theta) U(\\theta') \\lvert 0^n \\rangle \\rvert^2,"
msgstr "K(\\theta, \\theta') = \\lvert\\langle 0^n \\rvert U^\\dagger(\\theta) U(\\theta') \\lvert 0^n \\rangle \\rvert^2,"

#: ../../tutorials/qka.ipynb:21
msgid "where :math:`U(\\theta)` prepares the quantum feature state. Quantum kernels used in a classification framework inherit the convex optimization program of the SVM and avoid common limitations of variational quantum classifiers. A key observation of this paper was that a necessary condition for a computational advantage requires quantum circuits for the kernel that are hard to simulate classically. More recently, IBM proved that quantum kernels can offer superpolynomial speedups over any classical learner on a learning problem based on the hardness of the discrete logarithm problem [4]. This means that quantum kernels can someday offer quantum advantage on suitable problems."
msgstr "ここで、 :math:`U(\\theta)` は量子特徴量の状態を表します。 分類フレームワークで使用される量子カーネルは、 SVM の凸最適化プログラムを継承し、変分量子分類器に共通する制約を回避します。 この論文では、量子カーネルが計算量的に優位に立つための条件として、古典的にシミュレートするのが難しい量子回路が必要であることが示されています。 さらに最近では、IBMは量子カーネルが、離散対数問題の困難さに基づいた学習問題に関して、古典な学習器よりも超多項式高速化を実現できることを証明しました [4] 。 このことは、量子カーネルがいつか、適切な問題に量子的な利点を提供することを意味しています。"

#: ../../tutorials/qka.ipynb:24
msgid "**Quantum Kernels that Exploit Structure in Data**\\  An important approach in the search for practical quantum advantage in machine learning is to identify quantum kernels for learning problems that have underlying structure in the data. We’ve taken a step in this direction in our recent paper [5], where we introduced a broad class of quantum kernels that exploit group structure in data. Examples of learning problems for data with group structure could include learning permutations or classifying translations. We call this new class of kernels *covariant quantum kernels* as they are related to covariant quantum measurements. The quantum feature map is defined by a unitary representation :math:`D(\\theta)` of a group :math:`G` for some element :math:`\\theta \\in G`, and a fiducial reference state :math:`\\lvert\\psi\\rangle = V\\lvert0^n\\rangle` prepared by a unitary circuit :math:`V`. The kernel matrix is given as"
msgstr "**データの構造を利用する量子カーネル**\\ 機械学習で実用的な量子の利点を探すための重要なアプローチは、データの基礎となる構造を持つ問題を学習するための量子カーネルを特定することです。私たちは、最近の論文 [5] でこの方向に一歩踏み出しました。そこでは、データの群構造を利用する幅広いクラスの量子カーネルを紹介しました。 群構造を持つデータの学習問題の例には、順列の学習や翻訳の分類が含まれます。 この新しいクラスのカーネルは、共変量子測定に関連しているため、*共変量子カーネル* と呼ばれます。量子特徴マップは、ある要素 :math:`\\theta \\in G`  のグループ :math:`G`  のユニタリー表現  :math:`D(\\theta)` と、ユニタリー回路  :math:`V` によって作成された基準参照状態 :math:`\\lvert\\psi\\rangle = V\\lvert0^n\\rangle`  によって定義されます。カーネル行列は次のように与えられます。"

#: ../../tutorials/qka.ipynb:27
msgid "K(\\theta, \\theta') = \\vert\\langle 0^n \\rvert V^\\dagger D^\\dagger(\\theta) D(\\theta') V \\lvert 0^n \\rangle \\rvert^2. \\qquad (1)"
msgstr "K(\\theta, \\theta') = \\vert\\langle 0^n \\rvert V^\\dagger D^\\dagger(\\theta) D(\\theta') V \\lvert 0^n \\rangle \\rvert^2. \\qquad (1)"

#: ../../tutorials/qka.ipynb:32
msgid "In general, the choice of the fiducial state is not known *a priori* and can significantly impact the performance of the classifier. Here, we use a method called quantum kernel alignment (QKA) to find a good fiducial state for a given group."
msgstr "基準状態に何を選ぶかが分類器のパフォーマンスに大きな影響を与えることがありますが、*先験的*に何を選ぶべきかは一般に知られていません。ここでは、量子カーネルアライメント (quantum kernel alignment、QKA) と呼ばれる手法を使用して、与えられたグループに適した基準の状態を探します。"

#: ../../tutorials/qka.ipynb:34
msgid "**Aligning Quantum Kernels on a Dataset**\\  In practice, SVMs require a choice of the kernel function. Sometimes, symmetries in the data can inform this selection, other times it is chosen in an ad hoc manner. Kernel alignment is one approach to learning a kernel on a given dataset by iteratively adapting it to have high similarity to a target kernel informed from the underlying data distribution [6]. As a result, the SVM with an aligned kernel will likely generalize better to new data than with an unaligned kernel. Using this concept, we introduced in [5] an algorithm for quantum kernel alignment, which provides a way to learn a quantum kernel from a family of kernels. Specifically, the algorithm optimizes the parameters in a quantum circuit to maximize the alignment of a kernel while converging to the maximum SVM margin. In the context of covariant quantum kernels, we extend Eq. :math:`(1)` to"
msgstr "**データセットでの量子カーネルのアライン**\\ 実際に、SVMではカーネル関数を選択する必要があります。 データの対称性により選ぶ場合もあれば、アドホックな方法で選択する場合もあります。 カーネルアラインメントは、与えらえれたデータセットでカーネルを学習するためのアプローチでの一つで、元になるデータ分布から得られる目標のカーネルとの類似性が高くなるように繰り返し適応させる手法です [6] 。 その結果、アラインされたカーネルを使用したSVMは、アラインされていないカーネルを使用した場合よりも、新しいデータに対してより良く汎化される可能性が高くなります。 この概念を使用して、[5] で、カーネルのファミリーから量子カーネルを学習する方法を提供する、量子カーネルアライメントのアルゴリズムを導入しました。 具体的には、アルゴリズムは量子回路のパラメーターを最適化して、SVMマージンを最大に収束しながらカーネルのアライメントを最大化します。共変量子カーネルのコンテキストでは、式  :math:`(1)` を次のように拡張します。"

#: ../../tutorials/qka.ipynb:37
msgid "K_\\lambda(\\theta,\\theta') = \\lvert\\langle 0^n \\rvert V^\\dagger_\\lambda D^\\dagger(\\theta) D(\\theta') V_\\lambda \\lvert 0^n \\rangle \\rvert^2, \\qquad (2)"
msgstr "K_\\lambda(\\theta,\\theta') = \\lvert\\langle 0^n \\rvert V^\\dagger_\\lambda D^\\dagger(\\theta) D(\\theta') V_\\lambda \\lvert 0^n \\rangle \\rvert^2, \\qquad (2)"

#: ../../tutorials/qka.ipynb:42
msgid "and use QKA to learn a good fiducial state parametrized by :math:`\\lambda` for a given group."
msgstr "QKA を使用して、与えられた所定のグループに対して、 :math:`\\lambda` をパラメーターとする適切な基準状態を把握することができます。"

#: ../../tutorials/qka.ipynb:44
msgid "**Covariant Quantum Kernels on a Specific Learning Problem**\\  Let’s try out QKA on a learning problem. In the following, we’ll consider a binary classification problem we call *labeling cosets with error* [5]. In this problem, we will use a group and a subgroup to form two cosets, which will represent our data classes. We take the group :math:`G = SU(2)^{\\otimes n}` for :math:`n` qubits, which is the special unitary group of :math:`2\\times2` matrices and has wide applicability in nature, for example, the Standard Model of particle physics and in many condensed matter systems. We take the graph-stabilizer subgroup :math:`S_{\\mathrm{graph}} \\in G` with :math:`S_{\\mathrm{graph}} = \\langle \\{ X_i \\otimes_{k:(k,i) \\in \\mathcal{E}} Z_k \\}_{i \\in \\mathcal{V}} \\rangle` for a graph :math:`(\\mathcal{E},\\mathcal{V})` with edges :math:`\\mathcal{E}` and vertices :math:`\\mathcal{V}`. Note that the stabilizers fix a stabilizer state such that :math:`D_s \\lvert \\psi\\rangle = \\lvert \\psi\\rangle`. This observation will be useful a bit later."
msgstr "**特定の学習問題に関する共変量子カーネル**\\ 学習問題に関するQKAを試してみましょう。 以下では、*剰余類へのエラーラベル付け* [5]と呼ばれるバイナリ分類の問題について検討します。 この問題では、群と部分群を使用して、データクラスを表す2つの剰余類を形成します。 グループ :math:`G = SU(2)^{\\otimes n}`  を :math:`n` 量子ビットと見なします。これは、  :math:`2\\times2` 行列の特殊ユニタリー群であり、素粒子物理学の標準モデルや多くの凝縮系など、自然界で幅広い適用されてます。 ここでは、辺  :math:`\\mathcal{E}`  と頂点 :math:`\\mathcal{V}`  を持つグラフ :math:`(\\mathcal{E},\\mathcal{V})` を :math:`S_{\\mathrm{graph}} = \\langle \\{ X_i \\otimes_{k:(k,i) \\in \\mathcal{E}} Z_k \\}_{i \\in \\mathcal{V}} \\rangle`   として持つグラフスタビライザー部分群 :math:`S_{\\mathrm{graph}} \\in G`   を取ります。スタビライザーは  :math:`D_s \\lvert \\psi\\rangle = \\lvert \\psi\\rangle` のようにスタビライザー状態を固定することに注意してください。 この観察は少し後で役に立ちます。"

#: ../../tutorials/qka.ipynb:48
msgid "To generate the dataset, we write the rotations of the group as :math:`D(\\theta_1, \\theta_2, 0)=\\exp(i \\theta_1 X) \\exp(i \\theta_2 Z) \\in SU(2)`, so that each qubit is parametrized by the first two Euler angles (the third we set to zero). Then, we draw randomly two sets of angles :math:`\\mathbf{\\theta}_\\pm \\in [-\\pi/4, \\pi/4]^{2n}` for the :math:`n`-qubit problem. From these two sets, we construct a binary classification problem by forming two left-cosets (representing the two classes) with those angles, :math:`C_\\pm = D(\\mathbf{\\theta}_\\pm) S_{\\mathrm{graph}}` where :math:`D(\\mathbf{\\theta}_\\pm) = \\otimes_{k=1}^n D(\\theta_\\pm^{2k-1}, \\theta_\\pm^{2k}, 0)`. Note that the elements of the cosets can again be written in terms of Euler angles. We build training and testing sets by randomly drawing elements from :math:`C_\\pm` such that the dataset has samples :math:`i=1,...,m` containing the first two Euler angles for each qubit :math:`\\mathbf{\\theta}_{y_i} = (\\theta_{y_i}^{1}, \\theta_{y_i}^{2}, \\theta_{y_i}^{3}, \\theta_{y_i}^{4}, ..., \\theta_{y_i}^{2n-1}, \\theta_{y_i}^{2n})` and labels :math:`y_i \\in \\{-1,1\\}` that indicate to which coset a sample belongs."
msgstr "データセットを生成するために、グループの回転を :math:`D(\\theta_1, \\theta_2, 0)=\\exp(i \\theta_1 X) \\exp(i \\theta_2 Z) \\in SU(2)` として記述し、各量子ビットが最初の2つのオイラー角（3番目はゼロに設定）によってパラメーター化されるようにします。 次に、 :math:`n` 量子ビット問題に対して2セットの角度 :math:`\\mathbf{\\theta}_\\pm \\in [-\\pi/4, \\pi/4]^{2n}` をランダムに描画します。 これらの2つのセットから、これらの角度 :math:`C_\\pm = D(\\mathbf{\\theta}_\\pm) S_{\\mathrm{graph}}` （ :math:`D(\\mathbf{\\theta}_\\pm) = \\otimes_{k=1}^n D(\\theta_\\pm^{2k-1}` ）で2つの左剰余類（2つのクラスを表す）を形成することにより、二項分類問題を構築します。剰余類の要素は、オイラー角で表すことができます。 データセットに各量子ビット :math:`\\mathbf{\\theta}_{y_i} = (\\theta_{y_i}^{1}, \\theta_{y_i}^{2}, \\theta_{y_i}^{3}, \\theta_{y_i}^{4}, ..., \\theta_{y_i}^{2n-1}, \\theta_{y_i}^{2n})` の最初の2つのオイラー角とどの剰余類を示すラベル :math:`y_i \\in \\{-1,1\\}` を含むサンプル :math:`i=1,...,m` が含まれるように、 :math:`C_\\pm` から要素をランダムに描画することにより、トレーニングセットとテストセットを構築します。 "

#: ../../tutorials/qka.ipynb:52
msgid "Next, we select a fiducial state. A natural candidate is the stabilizer state we encountered above. Why? Because this is a subgroup invariant state, :math:`D_s\\lvert\\psi\\rangle = \\lvert\\psi\\rangle`, which causes the data for a given coset to be mapped to a unique state: :math:`D(\\mathbf{\\theta}_\\pm)D_s \\lvert\\psi\\rangle = D(\\mathbf{\\theta}_\\pm) \\lvert\\psi\\rangle`. This means the classifier only needs to distinguish the *two* states :math:`D(\\mathbf{\\theta}_\\pm) \\lvert\\psi\\rangle \\langle \\psi\\rvert D^\\dagger(\\mathbf{\\theta}_\\pm)` for every element of the coset. In this tutorial, we will add a small Gaussian error with variance :math:`0.01` to the Euler angles of the dataset. This noise will perturb these two states, but if the variance is sufficiently small, we expect the states will still be classified correctly. Let’s consider a parametrized version of the stabilizer state, associated with the coupling graph :math:`(\\mathcal{E},\\mathcal{V})` given by the device connectivity, as our fiducial state and then use kernel alignment to find its optimal parameters. Specifically, we’ll replace the initial layers of Hadamards in the graph state with :math:`y`-rotations by an angle :math:`\\lambda`,"
msgstr "次に、基準状態を選択します。 自然な候補は、上記で遭遇したスタビライザー状態です。 なぜ？ これはサブグループ不変状態 :math:`D_s\\lvert\\psi\\rangle = \\lvert\\psi\\rangle` であるため、特定の剰余類のデータが一意の状態 :math:`D(\\mathbf{\\theta}_\\pm)D_s \\lvert\\psi\\rangle = D(\\mathbf{\\theta}_\\pm) \\lvert\\psi\\rangle` にマップされるからです。これは、分類器が剰余類のすべての要素の *2* 状態 :math:`D(\\mathbf{\\theta}_\\pm) \\lvert\\psi\\rangle \\langle \\psi\\rvert D^\\dagger(\\mathbf{\\theta}_\\pm)` を区別するだけでよいことを意味します。 このチュートリアルでは、分散 :math:`0.01` の小さなガウス誤差をデータセットのオイラー角に追加します。 このノイズはこれらの2つの状態を摂動させますが、分散が十分に小さい場合、状態は正しく分類されると予想されます。 デバイスの接続性によって与えられる結合グラフ :math:`(\\mathcal{E},\\mathcal{V})` に関連付けられたスタビライザー状態のパラメーター化されたバージョンを基準状態と見なし、カーネルアライメントを使用して最適なパラメーターを見つけましょう。 具体的には、グラフ状態のアダマールの初期レイヤーを :math:`y` 角度による回転 :math:`\\lambda` に置き換えます。"

#: ../../tutorials/qka.ipynb:56
msgid "\\lvert \\psi_\\lambda\\rangle = V_\\lambda \\lvert 0^n\\rangle = \\prod_{(k,t) \\in \\mathcal{E}} CZ_{k,t} \\prod_{k \\in \\mathcal{V}} \\exp\\left(i \\frac{\\lambda}{2} Y_k\\right)\\lvert 0^n\\rangle,"
msgstr "\\lvert \\psi_\\lambda\\rangle = V_\\lambda \\lvert 0^n\\rangle = \\prod_{(k,t) \\in \\mathcal{E}} CZ_{k,t} \\prod_{k \\in \\mathcal{V}} \\exp\\left(i \\frac{\\lambda}{2} Y_k\\right)\\lvert 0^n\\rangle,"

#: ../../tutorials/qka.ipynb:61
msgid "where :math:`CZ=\\mathrm{diag}(1,1,1,-1)`. Then, given two samples from our dataset, :math:`\\mathbf{\\theta}` and :math:`\\mathbf{\\theta}'`, the kernel matrix is evaluated as in Eq. :math:`(2)`. If we initialize the kernel with :math:`\\lambda \\approx 0`, we expect the quantum kernel alignment algorithm to converge towards the optimal :math:`\\lambda = \\pi/2` and the classifier to yield 100% test accuracy."
msgstr "ここで、 :math:`CZ=\\mathrm{diag}(1,1,1,-1)` です。 次に、データセットからの2つのサンプル :math:`\\mathbf{\\theta}` と :math:`\\mathbf{\\theta}'` が与えられると、カーネル行列は式 :math:`(2)` のように評価されます。 カーネルを :math:`\\lambda \\approx 0` で初期化すると、量子カーネルアライメントアルゴリズムが最適な :math:`\\lambda = \\pi/2` に収束し、分類器が100％のテスト精度をもたらすことが期待されます。"

#: ../../tutorials/qka.ipynb:63
msgid "Let’s define two specific problem instances to test these ideas out. We’ll be using the quantum device ``ibmq_montreal``, with coupling map shown below:"
msgstr "これらのアイデアをテストする 2 つの特定の問題インスタンスを定義します。 量子デバイスの ``ibmq_montreal`` を使い、次のようなカップリング・マップを使用します。"

#: ../../tutorials/qka.ipynb:65
msgid "|090cf64fc85b4dc99a24a68babdd4126|"
msgstr ""

#: ../../tutorials/qka.ipynb:78
msgid "090cf64fc85b4dc99a24a68babdd4126"
msgstr ""

#: ../../tutorials/qka.ipynb:67
msgid "We’ll pick two different subgraphs, one for 7 qubits and one for 10, to define our problem instances. Using these subgraphs, we’ll generate the corresponding datasets as described above, and then align the quantum kernel with QKA to learn a good fiducial state."
msgstr "2 つの異なるサブグラフを選択します。 ひとつは 7 量子ビット、 もうひとつは 10量子ビットで、問題のあるインスタンスを定義します。 これらのサブグラフを使って、前述のように対応するデータセットを生成し、量子カーネルを QKA でアラインして、良い基準状態を学習します。"

#: ../../tutorials/qka.ipynb:69
msgid "|67b5892f46a94f8280f74f67331cbe37|"
msgstr ""

#: ../../tutorials/qka.ipynb:81
msgid "67b5892f46a94f8280f74f67331cbe37"
msgstr ""

#: ../../tutorials/qka.ipynb:71
msgid "**Speeding up Algorithms with Qiskit Runtime**\\  QKA is an iterative quantum-classical algorithm, in which quantum hardware is used to execute parametrized quantum circuits for evaluating the quantum kernel matrices with QKE, while a classical optimizer tunes the parameters of those circuits to maximize the alignment. Iterative algorithms of this type can be slow due to latency between the quantum and classical calculations. Qiskit Runtime is a new architecture that can speed up iterative algorithms like QKA by co-locating classical computations with the quantum hardware executions. In this tutorial, we’ll use QKA with Qiskit Runtime to learn a good quantum kernel for the *labeling cosets with error* problem defined above."
msgstr "**Qiskit Runtime によるアルゴリズムの高速化**\\ QKAは反復量子古典アルゴリズムであり、量子ハードウェアを使用してパラメーター化された量子回路を実行し、QKEで量子カーネル行列を評価します。一方、古典的オプティマイザーはこれらの回路のパラメーターを調整し、アライメントを最大化します。 このタイプの反復アルゴリズムは、量子計算と従来の計算の間の待ち時間のために遅くなる可能性があります。 Qiskit Runtime は、古典的な計算と量子ハードウェアの実行を同じ場所に配置することで、QKAのような反復アルゴリズムを高速化できる新しいアーキテクチャです。 このチュートリアルでは、QKAとQiskit Runtime を使用して、上記で定義した *エラーのある剰余類のラベル付け* 問題に適した量子カーネルを学習します。"

#: ../../tutorials/qka.ipynb:74
msgid "**References**\\  [1] B. E. Boser, I. M. Guyon, and V. N. Vapnik, Proceedings of the Fifth Annual Workshop on Computational Learning Theory, COLT ’92 (Association for Computing Machinery, New York, NY, USA, 1992) pp. 144-152 `link <https://doi.org/10.1145/130385.130401>`__ [2] V. Vapnik, The Nature of Statistical Learning Theory, Information Science and Statistics (Springer New York, 2013) `link <https://books.google.com/books?id=EqgACAAAQBAJ>`__ [3] V. Havlíček, A. D. Córcoles, K. Temme, A. W. Harrow, A. Kandala, J. M. Chow, and J. M. Gambetta, Nature 567, 209-212 (2019) `link <https://doi.org/10.1038/s41586-019-0980-2>`__ [4] Y. Liu, S. Arunachalam, and K. Temme, arXiv:2010.02174 (2020) `link <https://arxiv.org/abs/2010.02174>`__ [5] J. R. Glick, T. P. Gujarati, A. D. Córcoles, Y. Kim, A. Kandala, J. M. Gambetta, K. Temme, arXiv:2105.03406 (2021) `link <https://arxiv.org/abs/2105.03406>`__\\  [6] N. Cristianini, J. Shawe-taylor, A. Elisseeff, and J. Kandola, Advances in Neural Information Processing Systems 14 (2001) `link <https://proceedings.neurips.cc/paper/2001/file/1f71e393b3809197ed66df836fe833e5-Paper.pdf>`__"
msgstr "**参考文献**\\  [1] B. E. Boser, I. M. Guyon, and V. N. Vapnik, Proceedings of the Fifth Annual Workshop on Computational Learning Theory, COLT ’92 (Association for Computing Machinery, New York, NY, USA, 1992) pp. 144-152 `link <https://doi.org/10.1145/130385.130401>`__ [2] V. Vapnik, The Nature of Statistical Learning Theory, Information Science and Statistics (Springer New York, 2013) `link <https://books.google.com/books?id=EqgACAAAQBAJ>`__ [3] V. Havlíček, A. D. Córcoles, K. Temme, A. W. Harrow, A. Kandala, J. M. Chow, and J. M. Gambetta, Nature 567, 209-212 (2019) `link <https://doi.org/10.1038/s41586-019-0980-2>`__ [4] Y. Liu, S. Arunachalam, and K. Temme, arXiv:2010.02174 (2020) `link <https://arxiv.org/abs/2010.02174>`__ [5] J. R. Glick, T. P. Gujarati, A. D. Córcoles, Y. Kim, A. Kandala, J. M. Gambetta, K. Temme, arXiv:2105.03406 (2021) `link <https://arxiv.org/abs/2105.03406>`__\\  [6] N. Cristianini, J. Shawe-taylor, A. Elisseeff, and J. Kandola, Advances in Neural Information Processing Systems 14 (2001) `link <https://proceedings.neurips.cc/paper/2001/file/1f71e393b3809197ed66df836fe833e5-Paper.pdf>`__"

#: ../../tutorials/qka.ipynb:93
msgid "Load your account and get the quantum backend"
msgstr "アカウントを読み込んで量子バックエンドを取得する"

#: ../../tutorials/qka.ipynb:95
msgid "We’ll be using the 27-qubit device ``ibmq_montreal`` for this tutorial in Qiskit Runtime on IBM Quantum."
msgstr "IBM Quantum の Qiskit Runtime で行うこのチュートリアルには、27 量子ビットデバイス ``ibmq_montreal`` を使用します。"

#: ../../tutorials/qka.ipynb:124
msgid "Invoke the Quantum Kernel Alignment program"
msgstr "量子カーネルアラインメントプログラムの呼び出し"

#: ../../tutorials/qka.ipynb:126
msgid "Before executing the runtime program for QKA, we need to prepare the dataset and configure the input parameters for the algorithm."
msgstr "QKAのrumtimeプログラムを実行する前に、データ・セットを準備し、アルゴリズムの入力パラメーターを構成する必要があります。"

#: ../../tutorials/qka.ipynb:129
msgid "1. Prepare the dataset"
msgstr "1. データセットの準備"

#: ../../tutorials/qka.ipynb:131
msgid "First, we load the dataset from the ``csv`` file and then extract the labeled training and test samples. Here, we’ll look at the 7-qubit problem, shown above in subfigure a). A second dataset is also available for the 10-qubit problem in b)."
msgstr "最初に、``csv`` ファイルからデータセットを読み込み、次にラベル付けされたトレーニングとテストサンプルを抽出します。 ここでは、上の図 a) に示す7量子ビット問題を見ていきます。b) の10量子ビット問題については、二つ目のデータセットが利用可能です。"

#: ../../tutorials/qka.ipynb:157
msgid "Let’s take a look at the data to see how it’s formatted. Each row of the dataset contains a list of Euler angles, followed by the class label :math:`\\pm1` in the last column. For an :math:`n`-qubit problem, there are :math:`2n` features corresponding to the first two Euler angles for each qubit (recall discussion above). The rows alternate between class labels."
msgstr "データを見て、どのようにフォーマットされているかを見てみましょう。 データセットの各行には、オイラー角のリストが含まれ、最後の列にクラスラベル :math:`\\pm1` が続きます。 :math:`n` 量子ビット問題の場合、各量子ビットの最初の2つのオイラー角に対応する :math:`2n` 個の特徴量があります（上記の説明を思い出してください）。 行はクラスラベル間で交互になります。"

#: ../../tutorials/qka.ipynb:232
msgid "Now, let’s explicitly construct the training and test samples (denoted ``x``) and their labels (denoted ``y``)."
msgstr "次に、トレーニングとテストサンプル（ ``x`` と表記）とそのラベル（ ``y`` と表記）を明示的に構築しましょう。"

#: ../../tutorials/qka.ipynb:270
msgid "2. Configure the QKA algorithm"
msgstr "2. QKA アルゴリズムの構成"

#: ../../tutorials/qka.ipynb:272
msgid "The first task is to set up the feature map and its entangler map, which specifies the arrangement of :math:`CZ` gates in the fiducial state. We will choose this to match the connectivity of the problem subgraph, pictured above. We also initialize the fiducial state parameter :math:`\\lambda` with ``initial_point``."
msgstr "最初のタスクは、基準状態での :math:`CZ` ゲートの配置を指定する特徴量マップとそのエンタングラー・マップを設定することです。 上に示した問題のサブグラフの接続性に一致するようにこれを選択します。 また、基準状態パラメーター :math:`\\lambda` を ``initial_point`` で初期化します。"

#: ../../tutorials/qka.ipynb:308
msgid "Let’s print out the circuit for the feature map (the circuit for the kernel will be a feature map for one data sample composed with an inverse feature map for a second sample). The first part of the feature map is the fiducial state, which is prepared with a layer of :math:`y` rotations followed by :math:`CZ`\\ s. Then, the last two layers of :math:`z` and :math:`x` rotations in the circuit denote the group representation :math:`D(\\theta)` for a data sample :math:`\\theta`. Note that a single-qubit rotation is defined as :math:`RP(\\phi) = \\exp(- i [\\phi/2] P)` for :math:`P \\in {X, Y, Z}`."
msgstr "特徴量マップの回路を表示してみましょう（カーネル回路は、1つ目のデータサンプルの特徴量マップと2番目のサンプルの逆特徴量マップを掛け合わせたものになります）。 特徴量マップの最初の部分は基準状態であり、 :math:`y` 回転の層と :math:`CZ` です。 回路の最後の :math:`z` と :math:`x` 回転の層は、データサンプル :math:`\\theta` の群表現 :math:`D(\\theta)` を示します。 単一量子ビットの回転は、 :math:`P \\in {X, Y, Z}` に対して :math:`RP(\\phi) = \\exp(- i [\\phi/2] P)` として定義されることに注意してください。"

#: ../../tutorials/qka.ipynb:430
msgid "Next, we set the values for the SVM soft-margin penalty ``C`` and the number of SPSA iterations ``maxiters`` we use to align the quantum kernel."
msgstr "次に、SVMソフトマージンペナルティ ``C`` の値と、量子カーネルをアラインさせるために使用するSPSA反復回数 ``maxiters`` を設定します。"

#: ../../tutorials/qka.ipynb:452
msgid "Finally, we decide how to map the virtual qubits of our problem graph to the physical qubits of the hardware. For example, in the 7-qubit problem, we can directly map the virtual qubits ``[0, 1, 2, 3, 4, 5, 6]`` to the physical qubits ``[10, 11, 12, 13, 14, 15, 16]`` of the device. This allows us to avoid introducing SWAP gates for qubits that are not connected, which can increase the circuit depth."
msgstr "最後に、問題グラフの仮想量子ビットをハードウェアの物理量子ビットにマッピングする方法を決定します。 たとえば、7量子ビットの問題では、仮想量子ビット ``[0, 1, 2, 3, 4, 5, 6]`` をデバイスの物理量子ビット ``[10, 11, 12, 13, 14, 15, 16]`` に直接マッピングできます。 これにより、接続されていない量子ビットにSWAPゲートを導入し、回路の深さを増加させることを避けることができます。"

#: ../../tutorials/qka.ipynb:475
msgid "3. Set up and run the program"
msgstr "3. プログラムのセットアップおよび実行"

#: ../../tutorials/qka.ipynb:477
msgid "We’re almost ready to run the program. First, let’s take a look at the program metadata, which includes a description of the input parameters and their default values."
msgstr "プログラムを実行する準備がほぼ整いました。 まず、入力パラメータとそのデフォルト値の説明を含むプログラムメタデータを見てみましょう。"

#: ../../tutorials/qka.ipynb:672
msgid "We see that this program has several input parameters, which we’ll configure below. To run the program, we’ll set up its two main components: ``inputs`` (the input parameters from the program metadata) and ``options`` (the quantum backend). We’ll also define a callback function so that the intermediate results of the algorithm will be printed as the program runs. Note that each step of the algorithm for the settings we’ve selected here takes approximately 11 minutes."
msgstr "このプログラムにはいくつかの入力パラメータがあり、以下で構成します。 プログラムを実行するために、 ``inputs`` （プログラムメタデータからの入力パラメータ）と ``options`` （量子バックエンド）の2つの主要コンポーネントを設定します。 また、プログラムの実行時にアルゴリズムの中間結果が出力されるように、コールバック関数を定義します。 ここで選択した設定のアルゴリズムの各ステップには、約11分かかることに注意してください。"

#: ../../tutorials/qka.ipynb:809
msgid "4. Retrieve the results of the program"
msgstr "4. プログラムの結果を取得する"

#: ../../tutorials/qka.ipynb:811
msgid "Now that we’ve run the program, we can retrieve the output, which is the aligned kernel parameter and the aligned kernel matrix. Let’s also plot this kernel matrix (we’ll subtract off the diagonal to show the contrast between the remaining entries). The kernel matrix is expected to have a block-diagonal structure. This reflects the fact that the kernel maps the input data effectively to just two states (modulo the small noise we added to the data; recall the discussion above). That is, data in the same coset (same class label) have a larger overlap than do data from different cosets."
msgstr "プログラムを実行したので、出力であるアラインされたカーネル・パラメーターとアラインされたカーネル行列を取得できます。このカーネル行列もプロットしてみましょう（残りのエントリー間のコントラストを示すために対角線の値から減算します）。 カーネル行列は、ブロック対角構造を持つことが期待されます。 これは、カーネルが入力データを2つの状態に効果的にマッピングするという事実を反映しています（データに追加した小さなノイズを除いたもの。上記の説明を思い出してください）。 つまり、同じ剰余類（同じクラスラベル）のデータは、異なる剰余類のデータよりもオーバーラップが大きくなります。"

