# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, Qiskit Development Team
# This file is distributed under the same license as the Qiskit Runtime IBM
# Client package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Qiskit Runtime IBM Client \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-10 16:30+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"

#: ../../tutorials/qka.ipynb:9
msgid "This page was generated from `docs/tutorials/qka.ipynb`__."
msgstr ""

#: ../../tutorials/qka.ipynb:9
msgid "Quantum Kernel Alignment with Qiskit Runtime"
msgstr ""

#: ../../tutorials/qka.ipynb:11
msgid ""
"**Classification with Support Vector Machines**\\  Classification "
"problems are widespread in machine learning applications. Examples "
"include credit card risk, handwriting recognition, and medical diagnosis."
" One approach to tackling classification problems is the support vector "
"machine (SVM) [1,2]. This supervised learning algorithm uses labeled data"
" samples to train a model that can predict to which class a test sample "
"belongs. It does this by finding a separating hyperplane maximizing the "
"margin between data classes. Often, data is not linearly separable in the"
" original space. In these cases, the kernel trick is used to implicitly "
"encode a transformation of the data into a higher-dimensional feature "
"space, through the inner product between pairs of data points, where the "
"data may become separable."
msgstr ""

#: ../../tutorials/qka.ipynb:14
msgid ""
"**Quantum Kernels**\\  Quantum computers can be used to encode classical "
"data in a quantum-enhanced feature space. In 2019, IBM introduced an "
"algorithm called the quantum kernel estimator (QKE) for computing quantum"
" kernels [3]. This algorithm uses quantum circuits with data provided "
"classically and offers an efficient way to evaluate inner products "
"between data in a quantum feature space. For two data samples "
":math:`\\theta` and :math:`\\theta'`, the kernel matrix is given as"
msgstr ""

#: ../../tutorials/qka.ipynb:16
msgid ""
"K(\\theta, \\theta') = \\lvert\\langle 0^n \\rvert U^\\dagger(\\theta) "
"U(\\theta') \\lvert 0^n \\rangle \\rvert^2,"
msgstr ""

#: ../../tutorials/qka.ipynb:21
msgid ""
"where :math:`U(\\theta)` prepares the quantum feature state. Quantum "
"kernels used in a classification framework inherit the convex "
"optimization program of the SVM and avoid common limitations of "
"variational quantum classifiers. A key observation of this paper was that"
" a necessary condition for a computational advantage requires quantum "
"circuits for the kernel that are hard to simulate classically. More "
"recently, IBM proved that quantum kernels can offer superpolynomial "
"speedups over any classical learner on a learning problem based on the "
"hardness of the discrete logarithm problem [4]. This means that quantum "
"kernels can someday offer quantum advantage on suitable problems."
msgstr ""

#: ../../tutorials/qka.ipynb:24
msgid ""
"**Quantum Kernels that Exploit Structure in Data**\\  An important "
"approach in the search for practical quantum advantage in machine "
"learning is to identify quantum kernels for learning problems that have "
"underlying structure in the data. We’ve taken a step in this direction in"
" our recent paper [5], where we introduced a broad class of quantum "
"kernels that exploit group structure in data. Examples of learning "
"problems for data with group structure could include learning "
"permutations or classifying translations. We call this new class of "
"kernels *covariant quantum kernels* as they are related to covariant "
"quantum measurements. The quantum feature map is defined by a unitary "
"representation :math:`D(\\theta)` of a group :math:`G` for some element "
":math:`\\theta \\in G`, and a fiducial reference state "
":math:`\\lvert\\psi\\rangle = V\\lvert0^n\\rangle` prepared by a unitary "
"circuit :math:`V`. The kernel matrix is given as"
msgstr ""

#: ../../tutorials/qka.ipynb:27
msgid ""
"K(\\theta, \\theta') = \\vert\\langle 0^n \\rvert V^\\dagger "
"D^\\dagger(\\theta) D(\\theta') V \\lvert 0^n \\rangle \\rvert^2. \\qquad"
" (1)"
msgstr ""

#: ../../tutorials/qka.ipynb:32
msgid ""
"In general, the choice of the fiducial state is not known *a priori* and "
"can significantly impact the performance of the classifier. Here, we use "
"a method called quantum kernel alignment (QKA) to find a good fiducial "
"state for a given group."
msgstr ""

#: ../../tutorials/qka.ipynb:34
msgid ""
"**Aligning Quantum Kernels on a Dataset**\\  In practice, SVMs require a "
"choice of the kernel function. Sometimes, symmetries in the data can "
"inform this selection, other times it is chosen in an ad hoc manner. "
"Kernel alignment is one approach to learning a kernel on a given dataset "
"by iteratively adapting it to have high similarity to a target kernel "
"informed from the underlying data distribution [6]. As a result, the SVM "
"with an aligned kernel will likely generalize better to new data than "
"with an unaligned kernel. Using this concept, we introduced in [5] an "
"algorithm for quantum kernel alignment, which provides a way to learn a "
"quantum kernel from a family of kernels. Specifically, the algorithm "
"optimizes the parameters in a quantum circuit to maximize the alignment "
"of a kernel while converging to the maximum SVM margin. In the context of"
" covariant quantum kernels, we extend Eq. :math:`(1)` to"
msgstr ""

#: ../../tutorials/qka.ipynb:37
msgid ""
"K_\\lambda(\\theta,\\theta') = \\lvert\\langle 0^n \\rvert "
"V^\\dagger_\\lambda D^\\dagger(\\theta) D(\\theta') V_\\lambda \\lvert "
"0^n \\rangle \\rvert^2, \\qquad (2)"
msgstr ""

#: ../../tutorials/qka.ipynb:42
msgid ""
"and use QKA to learn a good fiducial state parametrized by "
":math:`\\lambda` for a given group."
msgstr ""

#: ../../tutorials/qka.ipynb:44
msgid ""
"**Covariant Quantum Kernels on a Specific Learning Problem**\\  Let’s try"
" out QKA on a learning problem. In the following, we’ll consider a binary"
" classification problem we call *labeling cosets with error* [5]. In this"
" problem, we will use a group and a subgroup to form two cosets, which "
"will represent our data classes. We take the group :math:`G = "
"SU(2)^{\\otimes n}` for :math:`n` qubits, which is the special unitary "
"group of :math:`2\\times2` matrices and has wide applicability in nature,"
" for example, the Standard Model of particle physics and in many "
"condensed matter systems. We take the graph-stabilizer subgroup "
":math:`S_{\\mathrm{graph}} \\in G` with :math:`S_{\\mathrm{graph}} = "
"\\langle \\{ X_i \\otimes_{k:(k,i) \\in \\mathcal{E}} Z_k \\}_{i \\in "
"\\mathcal{V}} \\rangle` for a graph :math:`(\\mathcal{E},\\mathcal{V})` "
"with edges :math:`\\mathcal{E}` and vertices :math:`\\mathcal{V}`. Note "
"that the stabilizers fix a stabilizer state such that :math:`D_s \\lvert "
"\\psi\\rangle = \\lvert \\psi\\rangle`. This observation will be useful a"
" bit later."
msgstr ""

#: ../../tutorials/qka.ipynb:48
msgid ""
"To generate the dataset, we write the rotations of the group as "
":math:`D(\\theta_1, \\theta_2, 0)=\\exp(i \\theta_1 X) \\exp(i \\theta_2 "
"Z) \\in SU(2)`, so that each qubit is parametrized by the first two Euler"
" angles (the third we set to zero). Then, we draw randomly two sets of "
"angles :math:`\\mathbf{\\theta}_\\pm \\in [-\\pi/4, \\pi/4]^{2n}` for the"
" :math:`n`-qubit problem. From these two sets, we construct a binary "
"classification problem by forming two left-cosets (representing the two "
"classes) with those angles, :math:`C_\\pm = D(\\mathbf{\\theta}_\\pm) "
"S_{\\mathrm{graph}}` where :math:`D(\\mathbf{\\theta}_\\pm) = "
"\\otimes_{k=1}^n D(\\theta_\\pm^{2k-1}, \\theta_\\pm^{2k}, 0)`. Note that"
" the elements of the cosets can again be written in terms of Euler "
"angles. We build training and testing sets by randomly drawing elements "
"from :math:`C_\\pm` such that the dataset has samples :math:`i=1,...,m` "
"containing the first two Euler angles for each qubit "
":math:`\\mathbf{\\theta}_{y_i} = (\\theta_{y_i}^{1}, \\theta_{y_i}^{2}, "
"\\theta_{y_i}^{3}, \\theta_{y_i}^{4}, ..., \\theta_{y_i}^{2n-1}, "
"\\theta_{y_i}^{2n})` and labels :math:`y_i \\in \\{-1,1\\}` that indicate"
" to which coset a sample belongs."
msgstr ""

#: ../../tutorials/qka.ipynb:52
msgid ""
"Next, we select a fiducial state. A natural candidate is the stabilizer "
"state we encountered above. Why? Because this is a subgroup invariant "
"state, :math:`D_s\\lvert\\psi\\rangle = \\lvert\\psi\\rangle`, which "
"causes the data for a given coset to be mapped to a unique state: "
":math:`D(\\mathbf{\\theta}_\\pm)D_s \\lvert\\psi\\rangle = "
"D(\\mathbf{\\theta}_\\pm) \\lvert\\psi\\rangle`. This means the "
"classifier only needs to distinguish the *two* states "
":math:`D(\\mathbf{\\theta}_\\pm) \\lvert\\psi\\rangle \\langle "
"\\psi\\rvert D^\\dagger(\\mathbf{\\theta}_\\pm)` for every element of the"
" coset. In this tutorial, we will add a small Gaussian error with "
"variance :math:`0.01` to the Euler angles of the dataset. This noise will"
" perturb these two states, but if the variance is sufficiently small, we "
"expect the states will still be classified correctly. Let’s consider a "
"parametrized version of the stabilizer state, associated with the "
"coupling graph :math:`(\\mathcal{E},\\mathcal{V})` given by the device "
"connectivity, as our fiducial state and then use kernel alignment to find"
" its optimal parameters. Specifically, we’ll replace the initial layers "
"of Hadamards in the graph state with :math:`y`-rotations by an angle "
":math:`\\lambda`,"
msgstr ""

#: ../../tutorials/qka.ipynb:56
msgid ""
"\\lvert \\psi_\\lambda\\rangle = V_\\lambda \\lvert 0^n\\rangle = "
"\\prod_{(k,t) \\in \\mathcal{E}} CZ_{k,t} \\prod_{k \\in \\mathcal{V}} "
"\\exp\\left(i \\frac{\\lambda}{2} Y_k\\right)\\lvert 0^n\\rangle,"
msgstr ""

#: ../../tutorials/qka.ipynb:61
msgid ""
"where :math:`CZ=\\mathrm{diag}(1,1,1,-1)`. Then, given two samples from "
"our dataset, :math:`\\mathbf{\\theta}` and :math:`\\mathbf{\\theta}'`, "
"the kernel matrix is evaluated as in Eq. :math:`(2)`. If we initialize "
"the kernel with :math:`\\lambda \\approx 0`, we expect the quantum kernel"
" alignment algorithm to converge towards the optimal :math:`\\lambda = "
"\\pi/2` and the classifier to yield 100% test accuracy."
msgstr ""

#: ../../tutorials/qka.ipynb:63
msgid ""
"Let’s define two specific problem instances to test these ideas out. "
"We’ll be using the quantum device ``ibmq_montreal``, with coupling map "
"shown below:"
msgstr ""

#: ../../tutorials/qka.ipynb:65
msgid "|090cf64fc85b4dc99a24a68babdd4126|"
msgstr ""

#: ../../tutorials/qka.ipynb:78
msgid "090cf64fc85b4dc99a24a68babdd4126"
msgstr ""

#: ../../tutorials/qka.ipynb:67
msgid ""
"We’ll pick two different subgraphs, one for 7 qubits and one for 10, to "
"define our problem instances. Using these subgraphs, we’ll generate the "
"corresponding datasets as described above, and then align the quantum "
"kernel with QKA to learn a good fiducial state."
msgstr ""

#: ../../tutorials/qka.ipynb:69
msgid "|67b5892f46a94f8280f74f67331cbe37|"
msgstr ""

#: ../../tutorials/qka.ipynb:81
msgid "67b5892f46a94f8280f74f67331cbe37"
msgstr ""

#: ../../tutorials/qka.ipynb:71
msgid ""
"**Speeding up Algorithms with Qiskit Runtime**\\  QKA is an iterative "
"quantum-classical algorithm, in which quantum hardware is used to execute"
" parametrized quantum circuits for evaluating the quantum kernel matrices"
" with QKE, while a classical optimizer tunes the parameters of those "
"circuits to maximize the alignment. Iterative algorithms of this type can"
" be slow due to latency between the quantum and classical calculations. "
"Qiskit Runtime is a new architecture that can speed up iterative "
"algorithms like QKA by co-locating classical computations with the "
"quantum hardware executions. In this tutorial, we’ll use QKA with Qiskit "
"Runtime to learn a good quantum kernel for the *labeling cosets with "
"error* problem defined above."
msgstr ""

#: ../../tutorials/qka.ipynb:74
msgid ""
"**References**\\  [1] B. E. Boser, I. M. Guyon, and V. N. Vapnik, "
"Proceedings of the Fifth Annual Workshop on Computational Learning "
"Theory, COLT ’92 (Association for Computing Machinery, New York, NY, USA,"
" 1992) pp. 144-152 `link <https://doi.org/10.1145/130385.130401>`__ [2] "
"V. Vapnik, The Nature of Statistical Learning Theory, Information Science"
" and Statistics (Springer New York, 2013) `link "
"<https://books.google.com/books?id=EqgACAAAQBAJ>`__ [3] V. Havlíček, A. "
"D. Córcoles, K. Temme, A. W. Harrow, A. Kandala, J. M. Chow, and J. M. "
"Gambetta, Nature 567, 209-212 (2019) `link "
"<https://doi.org/10.1038/s41586-019-0980-2>`__ [4] Y. Liu, S. "
"Arunachalam, and K. Temme, arXiv:2010.02174 (2020) `link "
"<https://arxiv.org/abs/2010.02174>`__ [5] J. R. Glick, T. P. Gujarati, A."
" D. Córcoles, Y. Kim, A. Kandala, J. M. Gambetta, K. Temme, "
"arXiv:2105.03406 (2021) `link <https://arxiv.org/abs/2105.03406>`__\\  "
"[6] N. Cristianini, J. Shawe-taylor, A. Elisseeff, and J. Kandola, "
"Advances in Neural Information Processing Systems 14 (2001) `link "
"<https://proceedings.neurips.cc/paper/2001/file/1f71e393b3809197ed66df836fe833e5-Paper.pdf>`__"
msgstr ""

#: ../../tutorials/qka.ipynb:93
msgid "Load your account and get the quantum backend"
msgstr ""

#: ../../tutorials/qka.ipynb:95
msgid ""
"We’ll be using the 27-qubit device ``ibmq_montreal`` for this tutorial in"
" Qiskit Runtime on IBM Quantum."
msgstr ""

#: ../../tutorials/qka.ipynb:124
msgid "Invoke the Quantum Kernel Alignment program"
msgstr ""

#: ../../tutorials/qka.ipynb:126
msgid ""
"Before executing the runtime program for QKA, we need to prepare the "
"dataset and configure the input parameters for the algorithm."
msgstr ""

#: ../../tutorials/qka.ipynb:129
msgid "1. Prepare the dataset"
msgstr ""

#: ../../tutorials/qka.ipynb:131
msgid ""
"First, we load the dataset from the ``csv`` file and then extract the "
"labeled training and test samples. Here, we’ll look at the 7-qubit "
"problem, shown above in subfigure a). A second dataset is also available "
"for the 10-qubit problem in b)."
msgstr ""

#: ../../tutorials/qka.ipynb:157
msgid ""
"Let’s take a look at the data to see how it’s formatted. Each row of the "
"dataset contains a list of Euler angles, followed by the class label "
":math:`\\pm1` in the last column. For an :math:`n`-qubit problem, there "
"are :math:`2n` features corresponding to the first two Euler angles for "
"each qubit (recall discussion above). The rows alternate between class "
"labels."
msgstr ""

#: ../../tutorials/qka.ipynb:232
msgid ""
"Now, let’s explicitly construct the training and test samples (denoted "
"``x``) and their labels (denoted ``y``)."
msgstr ""

#: ../../tutorials/qka.ipynb:270
msgid "2. Configure the QKA algorithm"
msgstr ""

#: ../../tutorials/qka.ipynb:272
msgid ""
"The first task is to set up the feature map and its entangler map, which "
"specifies the arrangement of :math:`CZ` gates in the fiducial state. We "
"will choose this to match the connectivity of the problem subgraph, "
"pictured above. We also initialize the fiducial state parameter "
":math:`\\lambda` with ``initial_point``."
msgstr ""

#: ../../tutorials/qka.ipynb:308
msgid ""
"Let’s print out the circuit for the feature map (the circuit for the "
"kernel will be a feature map for one data sample composed with an inverse"
" feature map for a second sample). The first part of the feature map is "
"the fiducial state, which is prepared with a layer of :math:`y` rotations"
" followed by :math:`CZ`\\ s. Then, the last two layers of :math:`z` and "
":math:`x` rotations in the circuit denote the group representation "
":math:`D(\\theta)` for a data sample :math:`\\theta`. Note that a single-"
"qubit rotation is defined as :math:`RP(\\phi) = \\exp(- i [\\phi/2] P)` "
"for :math:`P \\in {X, Y, Z}`."
msgstr ""

#: ../../tutorials/qka.ipynb:430
msgid ""
"Next, we set the values for the SVM soft-margin penalty ``C`` and the "
"number of SPSA iterations ``maxiters`` we use to align the quantum "
"kernel."
msgstr ""

#: ../../tutorials/qka.ipynb:452
msgid ""
"Finally, we decide how to map the virtual qubits of our problem graph to "
"the physical qubits of the hardware. For example, in the 7-qubit problem,"
" we can directly map the virtual qubits ``[0, 1, 2, 3, 4, 5, 6]`` to the "
"physical qubits ``[10, 11, 12, 13, 14, 15, 16]`` of the device. This "
"allows us to avoid introducing SWAP gates for qubits that are not "
"connected, which can increase the circuit depth."
msgstr ""

#: ../../tutorials/qka.ipynb:475
msgid "3. Set up and run the program"
msgstr ""

#: ../../tutorials/qka.ipynb:477
msgid ""
"We’re almost ready to run the program. First, let’s take a look at the "
"program metadata, which includes a description of the input parameters "
"and their default values."
msgstr ""

#: ../../tutorials/qka.ipynb:672
msgid ""
"We see that this program has several input parameters, which we’ll "
"configure below. To run the program, we’ll set up its two main "
"components: ``inputs`` (the input parameters from the program metadata) "
"and ``options`` (the quantum backend). We’ll also define a callback "
"function so that the intermediate results of the algorithm will be "
"printed as the program runs. Note that each step of the algorithm for the"
" settings we’ve selected here takes approximately 11 minutes."
msgstr ""

#: ../../tutorials/qka.ipynb:809
msgid "4. Retrieve the results of the program"
msgstr ""

#: ../../tutorials/qka.ipynb:811
msgid ""
"Now that we’ve run the program, we can retrieve the output, which is the "
"aligned kernel parameter and the aligned kernel matrix. Let’s also plot "
"this kernel matrix (we’ll subtract off the diagonal to show the contrast "
"between the remaining entries). The kernel matrix is expected to have a "
"block-diagonal structure. This reflects the fact that the kernel maps the"
" input data effectively to just two states (modulo the small noise we "
"added to the data; recall the discussion above). That is, data in the "
"same coset (same class label) have a larger overlap than do data from "
"different cosets."
msgstr ""

