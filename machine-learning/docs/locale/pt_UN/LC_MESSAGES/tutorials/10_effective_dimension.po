msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-06-29 18:01+0000\n"
"PO-Revision-Date: 2022-06-29 18:33\n"
"Last-Translator: \n"
"Language-Team: Portuguese (United)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.10.3\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: pr\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/10_effective_dimension.po\n"
"X-Crowdin-File-ID: 9730\n"
"Language: pt_UN\n"

#: ../../tutorials/10_effective_dimension.ipynb:9
msgid "This page was generated from `docs/tutorials/10_effective_dimension.ipynb`__."
msgstr "Esta página foi gerada a partir de `docs/tutorials/10_effective_dimension.ipynb`__."

#: ../../tutorials/10_effective_dimension.ipynb:9
msgid "Effective Dimension of Qiskit Neural Networks"
msgstr "Dimensão efetiva das redes neurais Qiskit"

#: ../../tutorials/10_effective_dimension.ipynb:11
msgid "In this tutorial, we will take advantage of the ``EffectiveDimension`` and ``LocalEffectiveDimension`` classes to evaluate the power of Quantum Neural Network models. These are metrics based on information geometry that connect to notions such as trainability, expressibility or ability to generalize."
msgstr "Neste tutorial, vamos aproveitar as classes ``EffectiveDimension`` e ``LocalEffectiveDimension`` para avaliar o poder dos modelos de Rede Neural Quântica. São métricas baseadas na geometria da informação que se conectam a noções como treinabilidade, expressibilidade ou capacidade de generalização."

#: ../../tutorials/10_effective_dimension.ipynb:13
msgid "Before diving into the code example, we will briefly explain what is the difference between these two metrics, and why are they relevant to the study of Quantum Neural Networks. More information about global effective dimension can be found in `this paper <https://arxiv.org/pdf/2011.00027.pdf>`__, while the local effective dimension was introduced in a `later work <https://arxiv.org/abs/2112.04807>`__."
msgstr "Antes de mergulhar no exemplo de código, explicaremos brevemente qual é a diferença entre essas duas métricas e por que elas são relevantes para o estudo de Redes Neurais Quânticas. Mais informações sobre a dimensão efetiva global podem ser encontradas neste artigo <https://arxiv.org/pdf/2011.00027.pdf>`__, enquanto a dimensão efetiva local foi introduzida em um trabalho posterior <https://arxiv. org/abs/2112.04807>`__."

#: ../../tutorials/10_effective_dimension.ipynb:25
msgid "1. Global vs. Local Effective Dimension"
msgstr "1. Dimensão Efetiva Global vs. Local"

#: ../../tutorials/10_effective_dimension.ipynb:27
msgid "Both classical and quantum machine learning models share a common goal: being good at **generalizing**, i.e. learning insights from data and applying them on unseen data."
msgstr "Os modelos de machine learning clássico e quântico compartilham um objetivo comum: ser bom em **generalizar**, i.e. aprender insights de dados e aplicá-los em dados não vistos."

#: ../../tutorials/10_effective_dimension.ipynb:29
msgid "Finding a good metric to assess this ability is a non-trivial matter. In `The Power of Quantum Neural Networks <https://arxiv.org/pdf/2011.00027.pdf>`__, the authors introduce the **global** effective dimension as a useful indicator of how well a particular model will be able to perform on new data. In `Effective Dimension of Machine Learning Models <https://arxiv.org/pdf/2112.04807.pdf>`__, the **local** effective dimension is proposed as a new capacity measure that bounds the generalization error of machine learning models."
msgstr "Encontrar uma boa métrica para avaliar essa capacidade não é uma questão trivial. Em `The Power of Quantum Neural Networks <https://arxiv.org/pdf/2011.00027.pdf>`__, os autores apresentam a dimensão efetiva **global** como um indicador útil de quão bem um modelo específico será capaz de performar em novos dados. Em `Dimensão efetiva de modelos de aprendizado de máquina <https://arxiv.org/pdf/2112.04807.pdf>`__, a dimensão efetiva **local** é proposta como uma nova medida de capacidade que limita o erro de generalização de modelos de machine learning."

#: ../../tutorials/10_effective_dimension.ipynb:32
msgid "The key difference between global (``EffectiveDimension`` class) and **local** effective dimension (``LocalEffectiveDimension`` class) is actually not in the way they are computed, but in the nature of the parameter space that is analyzed. The global effective dimension incorporates the **full parameter space** of the model, and is calculated from a **large number of parameter (weight) sets**. On the other hand, the local effective dimension focuses on how well the **trained** model can generalize to new data, and how **expressive** it can be. Therefore, the local effective dimension is calculated from **a single** set of weight samples (training result). This difference is small in terms of practical implementation, but quite relevant at a conceptual level."
msgstr "A principal diferença entre a dimensão efetiva global (classe ``EffectiveDimension``) e a dimensão efetiva **local** (classe ``LocalEffectiveDimension``) não está na forma como são calculadas, mas na natureza do espaço de parâmetros que é analisado. A dimensão efetiva global incorpora o **espaço de parâmetro completo** do modelo e é calculada a partir de um **grande número de conjuntos de parâmetros (peso)**. Por outro lado, a dimensão efetiva local se concentra em quão bem o modelo **treinado** pode generalizar para novos dados e quão **expressivo** pode ser. Portanto, a dimensão efetiva local é calculada a partir de **um único** conjunto de amostras de peso (resultado do treinamento). Essa diferença é pequena em termos de implementação prática, mas bastante relevante em nível conceitual."

#: ../../tutorials/10_effective_dimension.ipynb:45
msgid "2. The Effective Dimension Algorithm"
msgstr "2. O Algoritmo de Dimensão Efetiva"

#: ../../tutorials/10_effective_dimension.ipynb:47
msgid "Both the global and local effective dimension algorithms use the Fisher Information matrix to provide a measure of complexity. The details on how this matrix is calculated are provided in the `reference paper <https://arxiv.org/pdf/2011.00027.pdf>`__, but in general terms, this matrix captures how sensitive a neural network’s output is to changes in the network’s parameter space."
msgstr "Os algoritmos de dimensão efetiva global e local usam a matriz informação Fisher para fornecer uma medida de complexidade. Os detalhes sobre como essa matriz é calculada são fornecidos no `documento de referência <https://arxiv.org/pdf/2011.00027.pdf>`__, mas em termos gerais, essa matriz captura a sensibilidade da saída de uma rede neural às alterações no espaço de parâmetros da rede."

#: ../../tutorials/10_effective_dimension.ipynb:49
msgid "In particular, this algorithm follows 4 main steps:"
msgstr "Em particular, este algoritmo segue 4 passos principais:"

#: ../../tutorials/10_effective_dimension.ipynb:51
msgid "**Monte Carlo simulation:** the forward and backward passes (gradients) of the neural network are computed for each pair of input and weight samples."
msgstr "**Simulação de Monte Carlo:** os passos para frente e para trás (gradientes) da rede neural são calculadas para cada par de amostras de entrada e peso."

#: ../../tutorials/10_effective_dimension.ipynb:52
msgid "**Fisher Matrix Computation:** these outputs and gradients are used to compute the Fisher Information Matrix."
msgstr "**Computação da Matriz de Fisher:** essas saídas e gradientes são usados para calcular a Matriz de Informações de Fisher."

#: ../../tutorials/10_effective_dimension.ipynb:53
msgid "**Fisher Matrix Normalization:** averaging over all input samples and dividing by the matrix trace"
msgstr "**Normalização da matriz de Fisher:** calcular a média de todas as amostras de entrada e dividir pelo traço da matriz"

#: ../../tutorials/10_effective_dimension.ipynb:54
msgid "**Effective Dimension Calculation:** according to the formula from `Abbas et al. <https://arxiv.org/pdf/2011.00027.pdf>`__"
msgstr "**Cálculo da Dimensão Efetiva:** de acordo com a fórmula de `Abbas et al. <https://arxiv.org/pdf/2011.00027.pdf>`__"

#: ../../tutorials/10_effective_dimension.ipynb:66
msgid "3. Basic Example (CircuitQNN)"
msgstr "3. Exemplo Básico (CircuitQNN)"

#: ../../tutorials/10_effective_dimension.ipynb:68
msgid "This example shows how to set up a QNN model problem and run the global effective dimension algorithm. Both Qiskit ``CircuitQNN`` (shown in this example) and ``OpflowQNN`` (shown in a later example) can be used with the ``EffectiveDimension`` class."
msgstr "Este exemplo mostra como configurar um problema de modelo QNN e executar o algoritmo de dimensão efetiva global. Ambos, Qiskit ``CircuitQNN`` (mostrado neste exemplo) e ``OpflowQNN`` (mostrado em um exemplo posterior), podem ser usados com a classe ``EffectiveDimension``."

#: ../../tutorials/10_effective_dimension.ipynb:70
msgid "We start off from the required imports and a fixed seed for the random number generator for reproducibility purposes."
msgstr "Partimos das importações necessárias e uma semente fixa para o gerador de números aleatórios para fins de reprodutibilidade."

#: ../../tutorials/10_effective_dimension.ipynb:109
msgid "3.1 Define QNN"
msgstr "3.1 Definir QNN"

#: ../../tutorials/10_effective_dimension.ipynb:111
msgid "The first step to create a ``CircuitQNN`` is to define a parametrized feature map and ansatz. In this toy example, we will use 3 qubits, and we will define the circuit used in the ``TwoLayerQNN`` class."
msgstr "O primeiro passo para criar um ``CircuitQNN`` é definir um mapa de características parametrizado e ansatz. Neste exemplo simplório, usaremos 3 qubits e definiremos o circuito usado na classe ``TwoLayerQNN``."

#: ../../tutorials/10_effective_dimension.ipynb:151
msgid "The parametrized circuit can then be sent together with an optional interpret map (parity in this case) to the ``CircuitQNN`` constructor."
msgstr "O circuito parametrizado pode então ser enviado junto com um mapa de interpretação opcional (paridade neste caso) para o construtor ``CircuitQNN``."

#: ../../tutorials/10_effective_dimension.ipynb:200
msgid "3.2 Set up Effective Dimension calculation"
msgstr "3.2 Configure o cálculo da Dimensão Efetiva"

#: ../../tutorials/10_effective_dimension.ipynb:202
msgid "In order to compute the effective dimension of our QNN using the ``EffectiveDimension`` class, we need a series of sets of input samples and weights, as well as the total number of data samples available in a dataset. The ``input_samples`` and ``weight_samples`` are set in the class constructor, while the number of data samples is given during the call to the effective dimension computation, to be able to test and compare how this measure changes with different dataset sizes."
msgstr "Para calcular a dimensão efetiva de nosso QNN usando a classe ``EffectiveDimension``, precisamos de uma série de conjuntos de amostras e pesos de entrada, bem como o número total de amostras de dados disponíveis em um conjunto de dados. O ``input_samples`` e o ``weight_samples`` são definidos no construtor da classe, enquanto o número de amostras de dados é dado durante a chamada para o cálculo da dimensão efetiva, para poder testar e comparar como esta medida muda com diferentes conjuntos de dados tamanhos."

#: ../../tutorials/10_effective_dimension.ipynb:213
msgid "We can define the number of input samples and weight samples and the class will randomly sample a corresponding array from a normal (for ``input_samples``) or a uniform (for ``weight_samples``) distribution. Instead of passing a number of samples we can pass an array, sampled manually."
msgstr "Podemos definir o número de amostras de entrada e amostras de peso e a classe irá amostrar aleatoriamente um array correspondente de uma distribuição normal (para ``input_samples``) ou uma distribuição uniforme (para ``weight_samples``). Em vez de passar um número de amostras, podemos passar um array, amostrado manualmente."

#: ../../tutorials/10_effective_dimension.ipynb:240
msgid "If we want to test a specific set of input samples and weight samples, we can provide it directly to the ``EffectiveDimension`` class as shown in the following snippet:"
msgstr "Se quisermos testar um conjunto específico de amostras de entrada e amostras de peso, podemos fornecê-lo diretamente à classe ``EffectiveDimension``, conforme mostrado no trecho a seguir:"

#: ../../tutorials/10_effective_dimension.ipynb:265
msgid "The effective dimension algorithm also requires a dataset size. In this example, we will define an array of sizes to later see how this input affects the result."
msgstr "O algoritmo de dimensão efetiva também requer um tamanho de conjunto de dados. Neste exemplo, definiremos uma matriz de tamanhos para ver posteriormente como essa entrada afeta o resultado."

#: ../../tutorials/10_effective_dimension.ipynb:288
msgid "3.3 Compute Global Effective Dimension"
msgstr "3.3 Calcular Dimensão Efetiva Global"

#: ../../tutorials/10_effective_dimension.ipynb:290
msgid "Let’s now calculate the effective dimension of our network for the previously defined set of input samples, weights, and a dataset size of 5000."
msgstr "Vamos agora calcular a dimensão efetiva de nossa rede para o conjunto previamente definido de amostras de entrada, pesos e um tamanho de conjunto de dados de 5.000."

#: ../../tutorials/10_effective_dimension.ipynb:311
msgid "The effective dimension values will range between 0 and ``d``, where ``d`` represents the dimension of the model, and it’s practically obtained from the number of weights of the QNN. By dividing the result by ``d``, we can obtain the normalized effective dimension, which correlates directly with the capacity of the model."
msgstr "Os valores de dimensão efetiva irão variar entre 0 e ``d``, onde ``d`` representa a dimensão do modelo, e é praticamente obtido a partir do número de pesos do QNN. Ao dividir o resultado por ``d``, podemos obter a dimensão efetiva normalizada, que se correlaciona diretamente com a capacidade do modelo."

#: ../../tutorials/10_effective_dimension.ipynb:364
msgid "By calling the ``EffectiveDimension`` class with an array if input sizes ``n``, we can monitor how the effective dimension changes with the dataset size."
msgstr "Ao chamar a classe ``Effective Dimension`` com um array se os tamanhos de entrada forem ``n``, podemos monitorar como a dimensão efetiva muda com o tamanho do conjunto de dados."

#: ../../tutorials/10_effective_dimension.ipynb:449
msgid "4. Local Effective Dimension Example"
msgstr "4. Exemplo de dimensão local efetiva"

#: ../../tutorials/10_effective_dimension.ipynb:451
msgid "As explained in the introduction, the local effective dimension algorithm only uses **one** set of weights, and it can be used to monitor how training affects the expressiveness of a neural network. The ``LocalEffectiveDimension`` class enforces this constraint to ensure that these calculations are conceptually separate, but the rest of the implementation is shared with ``EffectiveDimension``."
msgstr "Conforme explicado na introdução, o algoritmo de dimensão efetiva local usa apenas **um** conjunto de pesos e pode ser usado para monitorar como o treinamento afeta a expressividade de uma rede neural. A classe ``LocalEffectiveDimension`` impõe essa restrição para garantir que esses cálculos sejam conceitualmente separados, mas o resto da implementação é compartilhada com ``EffectiveDimension``."

#: ../../tutorials/10_effective_dimension.ipynb:453
msgid "This example shows how to leverage the ``LocalEffectiveDimension`` class to analyze the effect of training on QNN expressiveness."
msgstr "Este exemplo mostra como aproveitar a classe ``LocalEffectiveDimension`` para analisar o efeito do treinamento na expressividade do QNN."

#: ../../tutorials/10_effective_dimension.ipynb:465
msgid "4.1 Define Dataset and QNN"
msgstr "4.1 Defina o Conjunto de Dados e QNN"

#: ../../tutorials/10_effective_dimension.ipynb:467
msgid "We start by creating a 3D binary classification dataset:"
msgstr "Começamos criando um conjunto de dados de classificação binária 3D:"

#: ../../tutorials/10_effective_dimension.ipynb:493
msgid "The next step is to create a QNN, an instance of ``TwoLayerQNN`` in our case. Since we pass only the number of inputs, the network will continue with the default values for feature map and ansatz."
msgstr "O próximo passo é criar um QNN, uma instância de ``TwoLayerQNN`` no nosso caso. Como passamos apenas o número de entradas, a rede continuará com os valores padrão para mapa de recursos e ansatz."

#: ../../tutorials/10_effective_dimension.ipynb:515
msgid "4.2 Train QNN"
msgstr "4.2 Treine o QNN"

#: ../../tutorials/10_effective_dimension.ipynb:517
msgid "We can now proceed to train the QNN. The training step may take some time, be patient. You can pass a callback to the classifier to observe how the training process is going on. We fix ``initial_point`` for reproducibility purposes as usual."
msgstr "Agora podemos prosseguir para treinar o QNN. A etapa de treinamento pode levar algum tempo, seja paciente. Você pode passar um callback para o classificador para observar como o processo de treinamento está acontecendo. Corrigimos o ``initial_point`` para fins de reprodutibilidade, como de costume."

#: ../../tutorials/10_effective_dimension.ipynb:590
msgid "The classifier can now differentiate between classes with an accuracy of:"
msgstr "O classificador agora pode diferenciar entre classes com uma precisão de:"

#: ../../tutorials/10_effective_dimension.ipynb:638
msgid "4.3 Compute Local Effective Dimension of trained QNN"
msgstr "4.3 Calcular Dimensão Efetiva Local do QNN treinado"

#: ../../tutorials/10_effective_dimension.ipynb:640
msgid "Now that we have trained our network, let’s evaluate the local effective dimension based on the trained weights. To do that we access the trained weights directly from the classifier."
msgstr "Agora que treinamos nossa rede, vamos avaliar a dimensão efetiva local com base nos pesos treinados. Para isso, acessamos os pesos treinados diretamente do classificador."

#: ../../tutorials/10_effective_dimension.ipynb:701
msgid "4.4 Compute Local Effective Dimension of untrained QNN"
msgstr "4.4 Calcular Dimensão Efetiva Local de QNN não treinado"

#: ../../tutorials/10_effective_dimension.ipynb:703
msgid "We can compare this result with the effective dimension of the untrained network, using the ``initial_point`` as our weight sample:"
msgstr "Podemos comparar este resultado com a dimensão efetiva da rede não treinada, usando o ``initial_point`` como nossa amostra de peso:"

#: ../../tutorials/10_effective_dimension.ipynb:762
msgid "4.5 Plot and analyze results"
msgstr "4.5 Plote e analise os resultados"

#: ../../tutorials/10_effective_dimension.ipynb:764
msgid "If we plot the effective dimension values before and after training, we can see the following result:"
msgstr "Se plotarmos os valores de dimensão efetivos antes e depois do treinamento, podemos ver o seguinte resultado:"

#: ../../tutorials/10_effective_dimension.ipynb:800
msgid "In general, we should expect the value of the local effective dimension to decrease after training. This can be understood by looking back into the main goal of machine learning, which is to pick a model that is expressive enough to fit your data, but not too expressive that it overfits and performs badly on new data samples."
msgstr "Em geral, devemos esperar que o valor da dimensão efetiva local diminua após o treinamento. Isso pode ser entendido olhando para o objetivo principal de machine learning, que é escolher um modelo que seja expressivo o suficiente para ajustar seus dados, mas não tão expressivo que se ajuste demais e tenha um desempenho ruim em novas amostras de dados."

#: ../../tutorials/10_effective_dimension.ipynb:802
msgid "Certain optimizers help regularize the overfitting of a model by learning parameters, and this action of learning inherently reduces a model’s expressiveness, as measured by the local effective dimension. Following this logic, a randomly initialized parameter set will most likely produce a higher effective dimension that the final set of trained weights, because that model with that particular parameterization is “using more parameters” unnecessarily to fit the data. After training (with the implicit regularization), a trained model will not need to use so many parameters and thus have more “inactive parameters” and a lower effective dimension."
msgstr "Certos otimizadores ajudam a regularizar o overfitting de um modelo por meio de parâmetros de aprendizado, e essa ação de aprendizado reduz inerentemente a expressividade de um modelo, medida pela dimensão efetiva local. Seguindo essa lógica, um conjunto de parâmetros inicializado aleatoriamente provavelmente produzirá uma dimensão efetiva mais alta que o conjunto final de pesos treinados, porque esse modelo com essa parametrização específica está “usando mais parâmetros” desnecessariamente para ajustar os dados. Após o treinamento (com a regularização implícita), um modelo treinado não precisará usar tantos parâmetros e, portanto, terá mais “parâmetros inativos” e uma dimensão efetiva menor."

#: ../../tutorials/10_effective_dimension.ipynb:805
msgid "We must keep in mind though that this is the general intuition, and there might be cases where a randomly selected set of weights happens to provide a lower effective dimension than the trained weights for a specific model."
msgstr "Devemos ter em mente que esta é a intuição geral, e pode haver casos em que um conjunto de pesos selecionados aleatoriamente forneça uma dimensão efetiva menor do que os pesos treinados para um modelo específico."

