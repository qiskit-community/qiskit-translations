msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-05-09 10:21+0000\n"
"PO-Revision-Date: 2023-08-14 19:37\n"
"Last-Translator: \n"
"Language: de\n"
"Language-Team: German\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: de\n"
"X-Crowdin-File: /main/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/09_saving_and_loading_models.po\n"
"X-Crowdin-File-ID: 9887\n"

#: ../../tutorials/09_saving_and_loading_models.ipynb:9
msgid "This page was generated from `docs/tutorials/09_saving_and_loading_models.ipynb`__."
msgstr "Diese Seite wurde aus `docs/tutorials/09_saving_and_loading_models.ipynb`__ generiert."

#: ../../tutorials/09_saving_and_loading_models.ipynb:9
msgid "Saving, Loading Qiskit Machine Learning Models and Continuous Training"
msgstr "Speichern, Laden von Qiskit Machine Learning Modellen und kontinuierliches Training"

#: ../../tutorials/09_saving_and_loading_models.ipynb:11
msgid "In this tutorial we will show how to save and load Qiskit machine learning models. Ability to save a model is very important, especially when a significant amount of time is invested in training a model on a real hardware. Also, we will show how to resume training of the previously saved model."
msgstr "In diesem Tutorial werden wir zeigen, wie man Qiskit-Maschine-Lerning-Modelle speichert und lädt. Die Möglichkeit, ein Modell zu speichern, ist sehr wichtig, insbesondere wenn ein beträchtlicher Zeitaufwand in das Training eines Modells auf einer realen Hardware investiert wird. Außerdem werden wir zeigen, wie das Training des zuvor gespeicherten Modells wieder aufgenommen werden kann."

#: ../../tutorials/09_saving_and_loading_models.ipynb:13
msgid "In this tutorial we will cover how to:"
msgstr "In diesem Tutorial schauen wir uns Folgendes an:"

#: ../../tutorials/09_saving_and_loading_models.ipynb:15
msgid "Generate a simple dataset, split it into training/test datasets and plot them"
msgstr "Erstelle einen einfachen Datensatz, teile ihn in Trainings-/Test-Datensätze und gib ihn aus"

#: ../../tutorials/09_saving_and_loading_models.ipynb:16
msgid "Train and save a model"
msgstr "Ein Modell trainieren und speichern"

#: ../../tutorials/09_saving_and_loading_models.ipynb:17
msgid "Load a saved model and resume training"
msgstr "Ein gespeichertes Modell laden und das Training fortsetzen"

#: ../../tutorials/09_saving_and_loading_models.ipynb:18
msgid "Evaluate performance of models"
msgstr "Leistung von Modellen bewerten"

#: ../../tutorials/09_saving_and_loading_models.ipynb:19
msgid "PyTorch hybrid models"
msgstr "PyTorch-Hybridmodelle"

#: ../../tutorials/09_saving_and_loading_models.ipynb:30
msgid "First off, we start from the required imports. We'll heavily use SciKit-Learn on the data preparation step. In the next cell we also fix a random seed for reproducibility purposes."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:64
msgid "We will be using two quantum simulators, in particular, two instances of the ``Sampler`` primitive. We'll start training on the first one, then will resume training on the second one. The approach shown in this tutorial can be used to train a model on a real hardware available on the cloud and then re-use the model for inference on a local simulator."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:88
msgid "1. Prepare a dataset"
msgstr "1. Datensatz vorbereiten"

#: ../../tutorials/09_saving_and_loading_models.ipynb:90
msgid "Next step is to prepare a dataset. Here, we generate some data in the same way as in other tutorials. The difference is that we apply some transformations to the generated data. We generates ``40`` samples, each sample has ``2`` features, so our features is an array of shape ``(40, 2)``. Labels are obtained by summing up features by columns and if the sum is more than ``1`` then this sample is labeled as ``1`` and ``0`` otherwise."
msgstr "Der nächste Schritt besteht darin, einen Datensatz vorzubereiten. Hier erzeugen wir einige Daten auf die gleiche Weise wie in anderen Tutorials. Der Unterschied besteht darin, dass wir einige Transformationen auf die erzeugten Daten anwenden. Wir generieren ``40`` Proben, jedes Beispiel hat ``2`` Features, also sind unsere Features ein Array der Form ``(40, 2)``. Labels werden durch das Summieren von Features in Spalten erhalten und wenn die Summe mehr als ``1`` ist, wird dieses Sample mit ``1`` gelabelt und ``0`` andernfalls."

#: ../../tutorials/09_saving_and_loading_models.ipynb:114
msgid "Then, we scale down our features into a range of ``[0, 1]`` by applying ``MinMaxScaler`` from SciKit-Learn. Model training convergence is better when this transformation is applied."
msgstr "Dann reduzieren wir unsere Funktionen auf einen Bereich von ``[0, 1]`` indem wir ``MinMaxScaler`` von SciKit-Learn anwenden. Die Konvergenz der Trainingsmodelle ist besser, wenn diese Transformation angewandt wird."

#: ../../tutorials/09_saving_and_loading_models.ipynb:161
msgid "Let's take a look at the features of the first ``5`` samples of our dataset after the transformation."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:219
msgid "We choose ``VQC`` or Variational Quantum Classifier as a model we will train. This model, by default, takes one-hot encoded labels, so we have to transform the labels that are in the set of ``{0, 1}`` into one-hot representation. We employ SciKit-Learn for this transformation as well. Please note that the input array must be reshaped to ``(num_samples, 1)`` first. The ``OneHotEncoder`` encoder does not work with 1D arrays and our labels is a 1D array. In this case a user must decide either an array has only one feature(our case!) or has one sample. Also, by default the encoder returns sparse arrays, but for dataset plotting it is easier to have dense arrays, so we set ``sparse`` to ``False``."
msgstr "Wir wählen ``VQC`` oder Variational Quantum Classifier als Modell, das wir trainieren. Dieses Modell nimmt standardmäßig eine one-hot Kodierte-Bezeichnung auf, also müssen wir die Labels, die im Satz ``{0, 1}`` sind, in eine one-hot Repräsentation umwandeln. Wir verwenden auch SciKit-Learn für diese Transformation. Bitte beachte, dass das Eingabearray zuerst in ``(num_samples, 1)`` umgestaltet werden muss. Der ``OneHotEncoder`` funktioniert nicht mit 1D Arrays und unsere Labels sind ein 1D Array. In diesem Fall muss ein Benutzer entscheiden, ob ein Array nur ein Feature hat (unser Fall!) oder ein Sample. Außerdem gibt der Encoder standardmäßig sparse Arrays zurück, aber für das Plotten von Datensätzen ist es einfacher, dichte Arrays zu haben. Daher setzen wir ``sparse`` auf ``False``."

#: ../../tutorials/09_saving_and_loading_models.ipynb:296
msgid "Let's take a look at the labels of the first ``5`` labels of the dataset. The labels should be one-hot encoded."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:354
#, python-format
msgid "Now we split our dataset into two parts: a training dataset and a test one. As a rule of thumb, 80% of a full dataset should go into a training part and 20% into a test one. Our training dataset has ``30`` samples. The test dataset should be used only once, when a model is trained to verify how well the model behaves on unseen data. We employ ``train_test_split`` from SciKit-Learn."
msgstr "Jetzt haben wir unseren Datensatz in zwei Teile aufgeteilt: einen Trainingsdatensatz und einen Testdatensatz. Als Faustregel gilt, dass 80 % des gesamten Datensatzes in einen Trainingsteil und 20 % in einen Testteil gehen sollten. Unser Trainingsdatensatz enthält ``30`` Beispiele. Der Testdatensatz sollte nur einmal verwendet werden, wenn ein Modell trainiert wird, um zu überprüfen, wie gut sich das Modell bei noch nicht gesehenen Daten verhält. Wir verwenden ``train_test_split`` von SciKit-Learn."

#: ../../tutorials/09_saving_and_loading_models.ipynb:403
msgid "Now it is time to see how our dataset looks like. Let's plot it."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:470
msgid "On the plot above we see:"
msgstr "Auf dem Diagramm oben sehen wir:"

#: ../../tutorials/09_saving_and_loading_models.ipynb:472
msgid "Solid blue dots are the samples from the training dataset labeled as ``0``"
msgstr "Ausgefüllte blaue Punkte beschreiben die Proben aus dem Trainingsdatensatz, welche mit ``0`` gelabelt sind"

#: ../../tutorials/09_saving_and_loading_models.ipynb:473
msgid "Empty blue dots are the samples from the test dataset labeled as ``0``"
msgstr "Leere blaue Punkte beschreiben die Proben aus dem Testdatensatz, welche mit ``0`` gelabelt sind"

#: ../../tutorials/09_saving_and_loading_models.ipynb:474
msgid "Solid green dots are the samples from the training dataset labeled as ``1``"
msgstr "Ausgefüllte grüne Punkte beschreiben die Proben aus dem Trainingsdatensatz, welche mit ``1`` gelabelt sind"

#: ../../tutorials/09_saving_and_loading_models.ipynb:475
msgid "Empty green dots are the samples from the test dataset labeled as ``1``"
msgstr "Leere grüne Punkte beschreiben die Proben aus dem Testdatensatz, welche mit ``1`` gelabelt sind"

#: ../../tutorials/09_saving_and_loading_models.ipynb:477
msgid "We'll train our model using solid dots and verify it using empty dots."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:489
msgid "2. Train a model and save it"
msgstr "2. Trainiere ein Modell und speicher es"

#: ../../tutorials/09_saving_and_loading_models.ipynb:491
msgid "We'll train our model in two steps. On the first step we train our model in ``20`` iterations."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:512
msgid "Create an empty array for callback to store values of the objective function."
msgstr "Erstelle ein leeres Array für das Callback, um Werte der Zielfunktion zu speichern."

#: ../../tutorials/09_saving_and_loading_models.ipynb:533
msgid "We re-use a callback function from the Neural Network Classifier & Regressor tutorial to plot iteration versus objective function value with some minor tweaks to plot objective values at each step."
msgstr "Wir verwenden eine Callback-Funktion aus dem Tutorial \"Neural Network Classifier & Regressor\", um mit einigen kleineren Anpassungen ein Diagramm mit Iteration gegenüber dem Zielfunktionswert zu erstellen, um Diagramme der Zielwerte bei jedem Schritt zu erstellen."

#: ../../tutorials/09_saving_and_loading_models.ipynb:576
msgid "As mentioned above we train a ``VQC`` model and set ``COBYLA`` as an optimizer with a chosen value of the ``maxiter`` parameter. Then we evaluate performance of the model to see how well it was trained. Then we save this model for a file. On the second step we load this model and will continue to work with it."
msgstr "Wie oben erwähnt, trainieren wir ein ``VQC`` Modell und setzen ``COBYLA`` als Optimierer mit einem ausgewählten Wert des ``maxiter`` Parameters. Dann bewerten wir die Leistung des Modells, um zu sehen, wie gut es trainiert wurde, und speichern dieses Modell für eine Datei. Im zweiten Schritt werden wir dieses Modell laden und weiter daran arbeiten."

#: ../../tutorials/09_saving_and_loading_models.ipynb:578
msgid "Here, we manually construct an ansatz to fix an initial point where to start optimization from."
msgstr "Hier erstellen wir manuell einen Ansatz, um einen Anfangspunkt zu fixieren, von dem aus mit der Optimierung begonnen werden soll."

#: ../../tutorials/09_saving_and_loading_models.ipynb:602
msgid "We create a model and set a sampler to the first sampler we created earlier."
msgstr "Wir erstellen ein Modell und setzen einen Sampler auf den ersten Sampler, den wir früher erstellt haben."

#: ../../tutorials/09_saving_and_loading_models.ipynb:625
msgid "Now it is time to train the model."
msgstr "Nun ist es an der Zeit, das Modell zu trainieren."

#: ../../tutorials/09_saving_and_loading_models.ipynb:680
msgid "Let's see how well our model performs after the first step of training."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:729
msgid "Next, we save the model. You may choose any file name you want. Please note that the ``save`` method does not append an extension if it is not specified in the file name."
msgstr "Als Nächstes speichern wir das Modell. Du kannst einen beliebigen Dateinamen auswählen. Bitte beachte, dass die ``save`` Methode keine Erweiterung anhängt, wenn sie nicht im Dateinamen angegeben ist."

#: ../../tutorials/09_saving_and_loading_models.ipynb:751
msgid "3. Load a model and continue training"
msgstr "3. Ein Modell laden und das Training fortsetzen"

#: ../../tutorials/09_saving_and_loading_models.ipynb:753
msgid "To load a model a user have to call a class method ``load`` of the corresponding model class. In our case it is ``VQC``. We pass the same file name we used in the previous section where we saved our model."
msgstr "Um ein Modell zu laden, muss ein Benutzer eine Klassenmethode ``load`` der entsprechenden Modellklasse aufrufen. In unserem Fall ist es ``VQC``. Wir übergeben den gleichen Dateinamen wie im vorherigen Abschnitt, wo wir unser Modell gespeichert haben."

#: ../../tutorials/09_saving_and_loading_models.ipynb:774
msgid "Next, we want to alter the model in a way it can be trained further and on another simulator. To do so, we set the ``warm_start`` property. When it is set to ``True`` and ``fit()`` is called again the model uses weights from previous fit to start a new fit. We also set the ``sampler`` property of the underlying network to the second instance of the ``Sampler`` primitive we created in the beginning of the tutorial. Finally, we create and set a new optimizer with ``maxiter`` is set to ``80``, so the total number of iterations is ``100``."
msgstr "Als nächstes wollen wir das Modell so ändern, dass es auf einem anderen Simulator weiter trainiert werden kann. Dazu setzen wir die ``warm_start`` Eigenschaft. Wenn es auf ``True`` gesetzt ist und ``fit()`` erneut aufgerufen wird, verwendet das Modell Gewichte aus dem vorherigen Fit, um einen neuen Fit zu starten. Wir haben auch die ``sampler`` Eigenschaft des zugrunde liegenden Netzwerkes auf die zweite Instanz des ``Sampler`` gesetzt, das wir zu Beginn des Tutorials erstellt haben. Schließlich erstellen und setzen wir einen neuen Optimierer mit ``maxiter`` auf ``80``, so dass die Gesamtzahl der Iterationen ``100`` ist."

#: ../../tutorials/09_saving_and_loading_models.ipynb:798
msgid "Now we continue training our model from the state we finished in the previous section."
msgstr "Jetzt trainieren wir unser Modell aus dem Zustand, den wir im vorherigen Abschnitt fertig gestellt haben."

#: ../../tutorials/09_saving_and_loading_models.ipynb:891
msgid "Let's see which data points were misclassified. First, we call ``predict`` to infer predicted values from the training and test features."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:913
msgid "Plot the whole dataset and the highlight the points that were classified incorrectly."
msgstr "Zeichne den gesamten Datensatz und hebe die Punkte hervor, die falsch eingestuft wurden."

#: ../../tutorials/09_saving_and_loading_models.ipynb:989
msgid "So, if you have a large dataset or a large model you can train it in multiple steps as shown in this tutorial."
msgstr "Wenn du also einen großen Datensatz oder ein großes Modell hast, kannst du ihn in mehreren Schritten trainieren, wie in diesem Tutorial gezeigt."

#: ../../tutorials/09_saving_and_loading_models.ipynb:1001
msgid "4. PyTorch hybrid models"
msgstr "4. PyTorch Hybridmodelle"

#: ../../tutorials/09_saving_and_loading_models.ipynb:1003
msgid "To save and load hybrid models, when using the TorchConnector, follow the PyTorch recommendations of saving and loading the models. For more details please refer to the PyTorch Connector tutorial `here <https://qiskit.org/documentation/machine-learning/tutorials/05_torch_connector.html>`__ where a short snippet shows how to do it."
msgstr "Um Hybrid-Modelle zu speichern und zu laden, folge den PyTorchConnector-Empfehlungen zum Speichern und Laden der Modelle. Weitere Details findest du im Tutorial `hier <https://qiskit.org/documentation/machine-learning/tutorials/05_torch_connector.html>`__ des PyTorch-Connector, in dem ein kurzes Snippet zeigt, wie man es macht."

#: ../../tutorials/09_saving_and_loading_models.ipynb:1005
msgid "Take a look at this pseudo-like code to get the idea:"
msgstr "Wirf einen Blick auf diesen pseudo-artigen Code, um eine Idee davon zu bekommen:"

