msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-02-07 03:44+0000\n"
"PO-Revision-Date: 2023-03-27 11:45\n"
"Last-Translator: \n"
"Language: de\n"
"Language-Team: German\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: de\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/01_neural_networks.po\n"
"X-Crowdin-File-ID: 9628\n"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/01_neural_networks.ipynb`__."
msgstr "Diese Seite wurde aus ` docs/tutorials/01_neural_networks.ipynb ` __ generiert."

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "Neuronale Quantennetze"

#: ../../tutorials/01_neural_networks.ipynb:12
msgid "Overview"
msgstr "Überblick"

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "This notebook demonstrates different quantum neural network (QNN) implementations provided in ``qiskit-machine-learning``, and how they can be integrated into basic quantum machine learning (QML) workflows."
msgstr "Dieses Notebook zeigt verschiedene neuronale Quantennetze (im Englischen Quantum Neural Network: QNN), die in ``qiskit-machine-learning`` zur Verfügung gestellt werden, und wie diese in grundlegende Quantenmaschinenlernprozesse (QML) integriert werden können."

#: ../../tutorials/01_neural_networks.ipynb:16
msgid "The tutorial is structured as follows:"
msgstr "Das Tutorial ist wie folgt strukturiert:"

#: ../../tutorials/01_neural_networks.ipynb:18
msgid "`Introduction <#1.-Introduction>`__"
msgstr "`Einführung <#1.-Einführung>`__"

#: ../../tutorials/01_neural_networks.ipynb:19
msgid "`How to Instantiate QNNs <#2.-How-to-Instantiate-QNNs>`__"
msgstr "`Wie man QNNs instanziiert <#2.-Wie-man-QNNs-instanzieiiert>`__"

#: ../../tutorials/01_neural_networks.ipynb:20
msgid "`How to Run a Forward Pass <#3.-How-to-Run-a-Forward-Pass>`__"
msgstr "`Wie führt man einen Vorwärts-Pass durch <#3.-Wie-führt-man-einen-Vorwärts-Pass>`__"

#: ../../tutorials/01_neural_networks.ipynb:21
msgid "`How to Run a Backward Pass <#4.-How-to-Run-a-Backward-Pass>`__"
msgstr "`Wie führt man einen Rückwärts-Pass durch <#4. Wie-führt-man-einen-Rückwärts-Pass>`__"

#: ../../tutorials/01_neural_networks.ipynb:22
msgid "`Advanced Functionality <#5.-Advanced-Functionality>`__"
msgstr "`Erweiterte Funktionalität <#5.-Erweiterte-Funktionalität>`__"

#: ../../tutorials/01_neural_networks.ipynb:23
msgid "`Conclusion <#6.-Conclusion>`__"
msgstr "' Fazit <#6.-Fazit > ` __"

#: ../../tutorials/01_neural_networks.ipynb:35
msgid "1. Introduction"
msgstr "1. Einführung"

#: ../../tutorials/01_neural_networks.ipynb:38
msgid "1.1. Quantum vs. Classical Neural Networks"
msgstr "1.1. Quantum vs. Klassische Neuronale Netzwerke"

#: ../../tutorials/01_neural_networks.ipynb:40
msgid "Classical neural networks are algorithmic models inspired by the human brain that can be trained to recognize patterns in data and learn to solve complex problems. They are based on a series of interconnected nodes, or *neurons*, organized in a layered structure, with parameters that can be learned by applying machine or deep learning training strategies."
msgstr "Klassische neuronale Netzwerke sind algorithmische Modelle, die vom menschlichen Gehirn inspiriert sind. Sie können dazu trainiert werden, Muster in Daten zu erkennen und komplexe Probleme zu lösen. Sie basieren auf einer Reihe von miteinander verbundenen Knoten, oder *Neuronen*, die in einer schichtigen Struktur organisiert sind. Dazu gehören ebenfalls Parametern, die durch Anwendung maschineller oder tiefer Lernstrategien erlernt werden können."

#: ../../tutorials/01_neural_networks.ipynb:42
msgid "The motivation behind quantum machine learning (QML) is to integrate notions from quantum computing and classical machine learning to open the way for new and improved learning schemes. QNNs apply this generic principle by combining classical neural networks and parametrized quantum circuits. Because they lie at an intersection between two fields, QNNs can be viewed from two perspectives:"
msgstr "Die Motivation hinter Quantum Machine Learning (QML) liegt in der Integration von Konzepten aus Quantencomputer und klassischem Maschinellen Lernen, um den Weg für neue und verbesserte Lernprogramme zu öffnen. QNNs wenden dieses generische Prinzip an, indem sie klassische neuronale Netzwerke und parametrisierte Quantenschaltkreise kombinieren. Da sie an einem Schnittpunkt zwischen zwei Feldern liegen, können QNNs aus zwei Perspektiven betrachtet werden:"

#: ../../tutorials/01_neural_networks.ipynb:44
msgid "From a **machine learning perspective**, QNNs are, once again, algorithmic models that can be trained to find hidden patterns in data in a similar manner to their classical counterparts. These models can **load** classical data (**inputs**) into a quantum state, and later **process** it with quantum gates parametrized by **trainable weights**. Figure 1 shows a generic QNN example including the data loading and processing steps. The output from measuring this state can then be plugged into a loss function to train the weights through backpropagation."
msgstr "Aus der traditionellen Perspektive von **Machien Learning** sind QNNs wiederum algorithmische Modelle, die trainiert werden können, versteckte Muster in Daten ähnlich wie ihre klassischen Gegenstücke zu finden. Diese Modelle können klassische Daten (**Eingaben**) in einen Quantenzustand **laden** und später mit Quantengattern **verarbeiten**, die durch **trainierbare Gewichte** parametrisiert sind. Abbildung 1 zeigt ein generisches QNN-Beispiel, das die Schritte zum Laden und Verarbeiten von Daten aufzeigt. Die Ausgabe aus der Messung dieses Zustands kann dann in eine Verlustfunktion gesteckt werden, um die Gewichte durch Rückpropagierung zu trainieren."

#: ../../tutorials/01_neural_networks.ipynb:47
msgid "From a **quantum computing perspective**, QNNs are quantum algorithms based on parametrized quantum circuits that can be trained in a variational manner using classical optimizers. These circuits contain a **feature map** (with input parameters) and an **ansatz** (with trainable weights), as seen in Figure 1."
msgstr "Aus einer ** Quanten-Computing-Perspektive ** sind QNNs Quantenalgorithmen, die auf parametrisierten Quantenschaltungen basieren, die mit klassischen Optimierungsmethoden variationsweise trainiert werden können. Diese Schaltkreise enthalten eine **Feature Map** (mit Eingabeparametern) und eine **Ansatz** (mit trainierbaren Gewichten), wie in Abbildung 1 zu sehen."

#: ../../tutorials/01_neural_networks.ipynb:49
msgid "|new_qnn-3.jpg|"
msgstr "|new_qnn-3.jpg|"

#: ../../tutorials/01_neural_networks.ipynb:53
msgid "new_qnn-3.jpg"
msgstr "new_qnn-3.jpg"

#: ../../tutorials/01_neural_networks.ipynb:51
msgid "*Figure 1. Generic quantum neural network (QNN) structure.*"
msgstr "*Abbildung 1. Generische Struktur eines neuronalen Quantennetzwerks (QNN).*"

#: ../../tutorials/01_neural_networks.ipynb:64
msgid "As you can see, these two perspectives are complementary, and do not necessarily rely on strict definitions of concepts such as “quantum neuron” or what constitutes a QNN’s “layer”."
msgstr "Wie man sieht, ergänzen sich diese beiden Perspektiven gegenseitig und verlassen sich nicht unbedingt auf strenge Definitionen von Konzepten wie „Quantenneuron“ oder was die „Schicht“ einer QNN ausmacht."

#: ../../tutorials/01_neural_networks.ipynb:67
msgid "1.2. Implementation in ``qiskit-machine-learning``"
msgstr "1.2. Implementierung in ``qiskit-machine-learning``"

#: ../../tutorials/01_neural_networks.ipynb:69
msgid "The QNNs in ``qiskit-machine-learning`` are meant as application-agnostic computational units that can be used for different use cases, and their setup will depend on the application they are needed for. The module contains an interface for the QNNs and two specific implementations:"
msgstr "Die QNNs in ``qiskit-machine-learning`` sind als anwendungsagnostische Recheneinheiten gedacht, die für unterschiedliche Anwendungsfälle verwendet werden können, und ihr Setup hängt von der Anwendung ab, für die sie benötigt werden. Das Modul enthält eine Schnittstelle für die QNNs und zwei spezifische Implementierungen:"

#: ../../tutorials/01_neural_networks.ipynb:71
msgid "`NeuralNetwork <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.NeuralNetwork.html>`__: The interface for neural networks. This is an abstract class all QNNs inherit from."
msgstr "`NeuralNetwork <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.NeuralNetwork.html>`__: Die Schnittstelle für neuronale Netzwerke. Dies ist eine abstrakte Klasse, von der alle QNN geerbt werden."

#: ../../tutorials/01_neural_networks.ipynb:72
msgid "`EstimatorQNN <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.EstimatorQNN.html>`__: A network based on the evaluation of quantum mechanical observables."
msgstr "`EstimatorQNN <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.EstimatorQNN.html>`__: Ein Netzwerk, das auf der Auswertung von quantenmechanischen Observablen basiert."

#: ../../tutorials/01_neural_networks.ipynb:73
msgid "`SamplerQNN <https://qiskit.org/documentation/machine-learning/locale/fr_FR/stubs/qiskit_machine_learning.neural_networks.SamplerQNN.html>`__: A network based on the samples resulting from measuring a quantum circuit."
msgstr "`SamplerQNN <https://qiskit.org/documentation/machine-learning/locale/fr_FR/stubs/qiskit_machine_learning.neural_networks.SamplerQNN.html>`__: Ein Netzwerk, das auf den Proben basiert, die sich aus der Messung einer Quantenschaltung ergeben."

#: ../../tutorials/01_neural_networks.ipynb:75
msgid "These implementations are based on the `qiskit primitives <https://qiskit.org/documentation/apidoc/primitives.html>`__. The primitives are the entry point to run QNNs on either a simulator or real quantum hardware. Each implementation, ``EstimatorQNN`` and ``SamplerQNN``, takes in an optional instance of its corresponding primitive, which can be any subclass of ``BaseEstimator`` and ``BaseSampler``, respectively."
msgstr "Diese Implementierungen basieren auf den `qiskit primitives <https://qiskit.org/documentation/apidoc/primitives.html>`__. Die 'Primitiven' sind der Einstiegspunkt, um QNNs entweder auf einem Simulator oder echter Quantenhardware zu betreiben. Jede Implementierung, ``EstimatorQNN`` und ``SamplerQNN``, nimmt eine optionale Instanz ihrer zugehörigen Primitive auf, die jede Unterklasse von ``BaseEstimator`` bzw. ``BaseSampler`` sein kann."

#: ../../tutorials/01_neural_networks.ipynb:77
msgid "The ``qiskit.primitives`` module provides a reference implementation for the ``Sampler`` and ``Estimator`` classes to run statevector simulations. By default, if no instance is passed to a QNN class, an instance of the corresponding reference primitive (``Sampler`` or ``Estimator``) is created automatically by the network. For more information about primitives please refer to the `primitives documentation <https://qiskit.org/documentation/apidoc/primitives.html>`__."
msgstr "Das ``qiskit.primitives`` Modul stellt eine Referenzimplementierung für die ``Sampler`` und ``Estimator`` Klassen bereit, um Statevector Simulationen auszuführen. Standardmäßig wird keine Instanz an eine QNN Klasse übergeben, eine Instanz der zugehörigen Primitive (``Sampler`` oder ``Estimator``) wird automatisch vom Netzwerk erstellt. Weitere Informationen über Primitive findet man in der `Dokumentation von primitives <https://qiskit.org/documentation/apidoc/primitives.html>`__."

#: ../../tutorials/01_neural_networks.ipynb:79
msgid "The ``NeuralNetwork`` class is the interface for all QNNs available in ``qiskit-machine-learning``. It exposes a forward and a backward pass that take data samples and trainable weights as input."
msgstr "Die ``NeuralNetwork`` Klasse ist die Schnittstelle für alle QNNs, die in ``qiskit-machine-learning`` verfügbar sind. Es stellt einen vorwärtsgerichteten und rückwärtsgerichteten Pass dar, der Datenproben und trainierbare Gewichte als Input nimmt."

#: ../../tutorials/01_neural_networks.ipynb:81
msgid "It’s important to note that ``NeuralNetwork``\\ s are “stateless”. They do not contain any training capabilities (these are pushed to the actual algorithms or applications: `classifiers <https://qiskit.org/documentation/machine-learning/apidocs/qiskit_machine_learning.algorithms.html#classifiers>`__, `regressors <https://qiskit.org/documentation/machine-learning/apidocs/qiskit_machine_learning.algorithms.html#regressors>`__, etc), nor do they store the values for trainable weights."
msgstr "Es ist wichtig zu beachten, dass ``NeuralNetwork``\\ s „zustandslose“ sind. Sie enthalten weder Trainingskapazitäten (diese werden an die eigentlichen Algorithmen oder Anwendungen weitergegeben: `classifiers <https://qiskit.org/documentation/machine-learning/apidocs/qiskit_machine_learning.algorithms.html#classifiers>`__, `regressors <https://qiskit.org/documentation/machine-learning/apidocs/qiskit_machine_learning.algorithms.html#regressors>`__, etc), noch speichern sie die Werte für trainierbare Gewichte."

#: ../../tutorials/01_neural_networks.ipynb:94
msgid "Let’s now look into specific examples for the two ``NeuralNetwork`` implementations. But first, let’s set the algorithmic seed to ensure that the results don’t change between runs."
msgstr "Schauen wir uns nun spezifische Beispiele für die beiden ``NeuralNetwork`` Implementierungen an. Aber zuerst stellen wir den algorithmischen Seed ein, um sicherzustellen, dass die Ergebnisse nicht während des Prozesses wechseln."

#: ../../tutorials/01_neural_networks.ipynb:118
msgid "2. How to Instantiate QNNs"
msgstr "2. Wie man QNNs instanziiert"

#: ../../tutorials/01_neural_networks.ipynb:121
msgid "2.1. ``EstimatorQNN``"
msgstr "2.1. ``EstimatorQNN``"

#: ../../tutorials/01_neural_networks.ipynb:123
msgid "The ``EstimatorQNN`` takes in a parametrized quantum circuit as input, as well as an optional quantum mechanical observable, and outputs expectation value computations for the forward pass. The ``EstimatorQNN`` also accepts lists of observables to construct more complex QNNs."
msgstr "Der ``EstimatorQNN`` nimmt eine parametrisierte Quantenschaltung als Eingabe, sowie eine optionale quantenmechanische Observable, und gibt als Ausgabe Erwartungswertberechnungen für den Vorwärts-Pass. Der ``EstimatorQNN`` akzeptiert auch Listen von Observablen, um komplexere QNN zu erstellen."

#: ../../tutorials/01_neural_networks.ipynb:125
msgid "Let’s see an ``EstimatorQNN`` in action with a simple example. We start by constructing the parametrized circuit. This quantum circuit has two parameters, one represents a QNN input and the other represents a trainable weight:"
msgstr "Schauen wir uns nun ein ``EstimatorQNN`` in Aktion mit einem einfachen Beispiel an. Wir beginnen mit der Konstruktion der parametrisierten Schaltung. Diese Quantenschaltung hat zwei Parameter, einer stellt eine QNN-Eingabe dar und der andere ein trainierbares Gewicht:"

#: ../../tutorials/01_neural_networks.ipynb:163
msgid "We can now create an observable to define the expectation value computation. If not set, then the ``EstimatorQNN`` will automatically create the default observable :math:`Z^{\\otimes n}`. Here, :math:`n` is the number of qubits of the quantum circuit."
msgstr "Wir können nun eine Observable erstellen, um die Erwartungswert-Berechnung zu definieren. Falls nicht gesetzt, wird der ``EstimatorQNN`` automatisch die Standard-Observable :math:`Z^{\\otimes n}` erstellen. Hier ist :math:`n` die Anzahl der Qubits der Quantenschaltung."

#: ../../tutorials/01_neural_networks.ipynb:165
msgid "In this example, we will change things up and use the :math:`Y^{\\otimes n}` observable:"
msgstr "In diesem Beispiel werden wir die Dinge ein bisschen ändern und die :math:`Y^{\\otimes n}` Observable verwenden:"

#: ../../tutorials/01_neural_networks.ipynb:188
msgid "Together with the quantum circuit defined above, and the observable we have created, the ``EstimatorQNN`` constructor takes in the following keyword arguments:"
msgstr "Zusammen mit der oben-definierten Quantenschaltung und der Observablen, die wir erstellt haben, übernimmt der ``EstimatorQNN`` folgende Keyword-Argumente:"

#: ../../tutorials/01_neural_networks.ipynb:190
msgid "``estimator``: optional primitive instance"
msgstr "``estimator``: optionale primitive Instanz"

#: ../../tutorials/01_neural_networks.ipynb:191
msgid "``input_params``: list of quantum circuit parameters that should be treated as “network inputs”"
msgstr "``input_params``: Liste der Quantenschaltungsparameter, die als „Netzwerkeingaben“ behandelt werden sollen"

#: ../../tutorials/01_neural_networks.ipynb:192
msgid "``weight_params``: list of quantum circuit parameters that should be treated as “network weights”"
msgstr "``weight_params``: Liste der Quantenschaltungsparameter, die als „Netzwerkgewichte“ behandelt werden sollen"

#: ../../tutorials/01_neural_networks.ipynb:194
msgid "In this example, we previously decided that the first parameter of ``params1`` should be the input, while the second should be the weight. As we are performing a local statevector simulation, we will not set the ``estimator`` parameter; the network will create an instance of the reference ``Estimator`` primitive for us. If we needed to access cloud resources or ``Aer`` simulators, we would have to define the respective ``Estimator`` instances and pass them to the ``EstimatorQNN``."
msgstr "In diesem Beispiel haben wir zuvor beschlossen, dass der erste Parameter von ``params1`` die Eingabe sein sollte, während der zweite das Gewicht rerpäsentiert. Da wir eine lokale Statevector-Simulation durchführen, werden wir nicht den ``estimator`` Parameter setzen; das Netzwerk wird eine Instanz der Referenz ``Estimator`` primitiv für uns erstellen. Falls Zugriff auf Cloud-Ressourcen oder ``Aer`` Simulatoren benötigt wird, muss man die jeweiligen ``Estimator`` Instanzen definieren und sie an den ``EstimatorQNN`` übergeben."

#: ../../tutorials/01_neural_networks.ipynb:245
msgid "We’ll see how to use the QNN in the following sections, but before that, let’s check out the ``SamplerQNN`` class."
msgstr "Wir werden sehen, wie das QNN in den folgenden Abschnitten verwendet wird, aber vorher sollten wir uns die ``SamplerQNN`` Klasse etwa genauer anschauen."

#: ../../tutorials/01_neural_networks.ipynb:257
msgid "2.2. ``SamplerQNN``"
msgstr "2.2. ``SamplerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:259
msgid "The ``SamplerQNN`` is instantiated in a similar way to the ``EstimatorQNN``, but because it directly consumes samples from measuring the quantum circuit, it does not require a custom observable."
msgstr "Der ``SamplerQNN`` wird ähnlich wie der ``EstimatorQNN`` instanziiert. Da er aber direkt Proben aus der Messung des Quantenschaltung verbraucht, benötigt er keine eigene Observable."

#: ../../tutorials/01_neural_networks.ipynb:261
msgid "These output samples are interpreted by default as the probabilities of measuring the integer index corresponding to a bitstring. However, the ``SamplerQNN`` also allows us to specify an ``interpret`` function to post-process the samples. This function should be defined so that it takes a measured integer (from a bitstring) and maps it to a new value, i.e. non-negative integer."
msgstr "Diese Ausgabeproben werden standardmäßig als die Wahrscheinlichkeiten interpretiert, den Integer-Index zu messen, der einem Bitstring entspricht. Jedoch erlaubt uns ``SamplerQNN`` auch, eine ``interpret`` Funktion zu spezifizieren, um die Samples nachzubearbeiten. Diese Funktion sollte so definiert werden, dass sie einen gemessenen Integer (aus einem Bitstring) nimmt und sie auf einen neuen Wert abbildet, d.h. nicht-negative Integer."

#: ../../tutorials/01_neural_networks.ipynb:263
msgid "**(!)** It’s important to note that if a custom ``interpret`` function is defined, the ``output_shape`` cannot be inferred by the network, and **needs to be provided explicitly**."
msgstr "**(!)** Es ist wichtig zu beachten, dass wenn eine benutzerdefinierte ``interpret`` Funktion definiert ist, die ``output_shape`` nicht vom Netzwerk inferiert werden kann und **explizit bereitgestellt werden muss**."

#: ../../tutorials/01_neural_networks.ipynb:265
msgid "**(!)** It’s also important to keep in mind that if no ``interpret`` function is used, the dimension of the probability vector will scale exponentially with the number of qubits. With a custom ``interpret`` function, this scaling can change. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, the result will be a probability vector of length 2 independently of the number of qubits."
msgstr "**(!)** Es ist ebenfalls wichtig zu beachten, dass, wenn keine ``interpret`` Funktion verwendet wird, die Dimension des Wahrscheinlichkeitsvektors exponentiell mit der Anzahl der Qubits skaliert. Im Falle einer ``interpret`` Funktion kann sich diese Skallierung jedoch ändern. Wird beispielsweise ein Index der Parität der entsprechenden Bitfolge zugeordnet, d.h. auf 0 oder 1, so ist das Ergebnis tatsächlich eine Wahrscheinlichkitsvektor von der Länge 2 und somit unabhängig von der Anzahl der Qubits."

#: ../../tutorials/01_neural_networks.ipynb:276
msgid "Let’s create a different quantum circuit for the ``SamplerQNN``. In this case, we will have two input parameters and four trainable weights that parametrize a two-local circuit."
msgstr "Lass uns nun eine andere Quantenschaltung für den ``SamplerQNN`` erstellen. In diesem Fall werden wir zwei Eingabeparameter und vier trainierbare Gewichte einstellen. Sie parametrisieren somit eine 'two-local' Schaltung."

#: ../../tutorials/01_neural_networks.ipynb:351
msgid "Similarly to the ``EstimatorQNN``, we must specify inputs and weights when instantiating the ``SamplerQNN``. In this case, the keyword arguments will be: - ``sampler``: optional primitive instance - ``input_params``: list of quantum circuit parameters that should be treated as “network inputs” - ``weight_params``: list of quantum circuit parameters that should be treated as “network weights”"
msgstr "Ähnlich wie beim ``EstimatorQNN``, müssen wir Eingaben und Gewichte angeben, wenn wir den ``SamplerQNN``` instanziieren. In diesem Fall sind die Keyword-Argumente: - ``sampler``: optionale primitive Instanz - ``input_params``: Liste der Quantenschaltungsparameter, die als „Netzwerkeingaben“ behandelt werden sollen - ``weight_params``: Liste der Quantenschaltungsparameter, die als „Netzwerkgewichte“ behandelt werden sollen."

#: ../../tutorials/01_neural_networks.ipynb:353
msgid "Please note that, once again, we are choosing not to set the ``Sampler`` instance to the QNN and relying on the default."
msgstr "Bitte beachte, dass wir erneut die ``Sampler`` Instanz nicht auf den QNN setzen und uns auf den Standard-Fall verlassen."

#: ../../tutorials/01_neural_networks.ipynb:402
msgid "In addition to the basic arguments shown above, the ``SamplerQNN`` accepts three more settings: ``input_gradients``, ``interpret``, and ``output_shape``. These will be introduced in sections 4 and 5."
msgstr "Zusätzlich zu den obigen grundlegenden Argumenten akzeptiert der ``SamplerQNN`` drei weitere Einstellungen: ``input_gradients``, ``interpret``, und ``output_shape``. Diese werden in den Abschnitten 4 und 5 eingeführt."

#: ../../tutorials/01_neural_networks.ipynb:414
msgid "3. How to Run a Forward Pass"
msgstr "3. Wie man einen Vorwärts-Pass ausführt"

#: ../../tutorials/01_neural_networks.ipynb:426
msgid "3.1. Set-Up"
msgstr "3.1. Einrichtung"

#: ../../tutorials/01_neural_networks.ipynb:428
msgid "In a real setting, the inputs would be defined by the dataset, and the weights would be defined by the training algorithm or as part of a pre-trained model. However, for the sake of this tutorial, we will specify random sets of input and weights of the right dimension:"
msgstr "In einer realen Einstellung würden die Eingaben durch den Datensatz definiert werden, und die Gewichte werden durch den Trainingsalgorithmus oder als Teil eines vorgegebenen Modells definiert. Im Hinblick auf dieses Tutorials werden wir jedoch zufällige Eingaben und Gewichte der richtigen Dimension festlegen:"

#: ../../tutorials/01_neural_networks.ipynb:440
msgid "3.1.1. ``EstimatorQNN`` Example"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:511
msgid "3.1.2. ``SamplerQNN`` Example"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:581
msgid "Once we have the inputs and the weights, let’s see the results for batched and non-batched passes."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:593
msgid "3.2. Non-batched Forward Pass"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:605
msgid "3.2.1. ``EstimatorQNN`` Example"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:616
msgid "For the ``EstimatorQNN``, the expected output shape for the forward pass is ``(1, num_qubits * num_observables)`` where ``1`` in our case is the number of samples:"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:669
msgid "3.2.2. ``SamplerQNN`` Example"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:680
msgid "For the ``SamplerQNN`` (without a custom interpret function), the expected output shape for the forward pass is ``(1, 2**num_qubits)``. With a custom interpret function, the output shape will be ``(1, output_shape)``, where ``1`` in our case is the number of samples:"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:733
msgid "3.3. Batched Forward Pass"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:745
msgid "3.3.1. ``EstimatorQNN`` Example"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:756
msgid "For the ``EstimatorQNN``, the expected output shape for the forward pass is ``(batch_size, num_qubits * num_observables)``:"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:814
msgid "3.3.2. ``SamplerQNN`` Example"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:825
msgid "For the ``SamplerQNN`` (without custom interpret function), the expected output shape for the forward pass is ``(batch_size, 2**num_qubits)``. With a custom interpret function, the output shape will be ``(batch_size, output_shape)``."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:883
msgid "4. How to Run a Backward Pass"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:885
msgid "Let’s take advantage of the inputs and weights defined above to show how the backward pass works. This pass returns a tuple ``(input_gradients, weight_gradients)``. By default, the backward pass will only calculate gradients with respect to the weight parameters."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:887
msgid "If you want to enable gradients with respect to the input parameters, you should set the following flag during the QNN instantiation:"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:893
msgid "Please remember that input gradients are **required** for the use of ``TorchConnector`` for PyTorch integration."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:905
msgid "4.1. Backward Pass without Input Gradients"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:917
msgid "4.1.1. ``EstimatorQNN`` Example"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:928
msgid "For the ``EstimatorQNN``, the expected output shape for the weight gradients is ``(batch_size, num_qubits * num_observables, num_weights)``:"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:992
msgid "4.1.2. ``SamplerQNN`` Example"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1003
msgid "For the ``SamplerQNN`` (without custom interpret function), the expected output shape for the forward pass is ``(batch_size, 2**num_qubits, num_weights)``. With a custom interpret function, the output shape will be ``(batch_size, output_shape, num_weights)``.:"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1076
msgid "4.2. Backward Pass with Input Gradients"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1078
msgid "Let’s enable the ``input_gradients`` to show what the expected output sizes are for this option."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1101
msgid "4.2.1. ``EstimatorQNN`` Example"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1112
msgid "For the ``EstimatorQNN``, the expected output shape for the input gradients is ``(batch_size, num_qubits * num_observables, num_inputs)``:"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1176
msgid "4.2.2. ``SamplerQNN`` Example"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1187
msgid "For the ``SamplerQNN`` (without custom interpret function), the expected output shape for the input gradients is ``(batch_size, 2**num_qubits, num_inputs)``. With a custom interpret function, the output shape will be ``(batch_size, output_shape, num_inputs)``."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1269
msgid "5. Advanced Functionality"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1281
msgid "5.1. ``EstimatorQNN`` with Multiple Observables"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1292
msgid "The ``EstimatorQNN`` allows to pass lists of observables for more complex QNN architectures. For example (note the change in output shape):"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1372
msgid "5.2. ``SamplerQNN`` with custom ``interpret``"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1383
msgid "One common ``interpret`` method for ``SamplerQNN`` is the ``parity`` function, which allows it to perform binary classification. As explained in the instantiation section, using interpret functions will modify the output shape of the forward and backward passes. In the case of the parity interpret function, ``output_shape`` is fixed to ``2``. Therefore, the expected forward and weight gradient shapes are ``(batch_size, 2)`` and ``(batch_size, 2, num_weights)``, respectively:"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1465
msgid "6. Conclusion"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1467
msgid "In this tutorial, we introduced the two neural networks classes provided by ``qiskit-machine-learning``, namely the ``EstimatorQNN`` and ``SamplerQNN``, which extend the base ``NeuralNetwork`` class. We provided some theoretical background, the key steps for QNN initialization, basic use in forward and backward passes, and advanced functionality."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1469
msgid "We now encourage you to play around with the problem setup and see how different circuit sizes, input, and weight parameter lengths influence the output shapes."
msgstr ""

