msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-08-24 12:38+0000\n"
"PO-Revision-Date: 2021-08-24 13:24\n"
"Last-Translator: \n"
"Language-Team: German\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: de\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/01_neural_networks.po\n"
"X-Crowdin-File-ID: 9628\n"
"Language: de_DE\n"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/01_neural_networks.ipynb`__."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "Neuronale Quantennetze"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "Dieses Notebook demonstriert die verschiedenen generischen Implementierungen von Quantennetzwerken (QNN) in Qiskit Machine Learning. Sie sind als allgemeine rechnerische Einheiten ohne bestimmten Anwendungsfall gedacht. Abhängig von der Anwendung kann eine gewisse Art von Netzwerk mehr oder weniger gut geeignet sein, oder muss möglicherweise auf eine bestimmte Art konfiguriert werden. Die verfügbaren neuronalen Netze werden nun genauer vorgestellt:"

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks."
msgstr "``NeuralNetwork``: Das Interface für neuronale Netze."

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``OpflowQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr "``OpflowQNN``: Ein Netzwerk, das auf der Auswertung von quantenmechanischen Observablen basiert."

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``TwoLayerQNN``: A special ``OpflowQNN`` implementation for convenience."
msgstr "``TwoLayerQNN``: Eine bequeme Implementierung von ``OpflowQNN``."

#: ../../tutorials/01_neural_networks.ipynb:16
msgid "``CircuitQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr "``CircuitQNN``: Ein Netzwerk, das auf den Samples basiert, die aus der Messung einer Quantenschaltung resultieren."

#: ../../tutorials/01_neural_networks.ipynb:64
msgid "1. ``NeuralNetwork``"
msgstr "1. ``NeuralNetwork``"

#: ../../tutorials/01_neural_networks.ipynb:66
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interfaces are introduced."
msgstr "Das ``NeuralNetwork`` stellt die Schnittstelle für alle neuronalen Netze dar, die in Qiskit Machine Learning zur Verfügung stehen. Sie legt einen Forward- und einen Backward-Pass vor, wobei die Daten-Samples und trainierbaren Gewichte als Inputs verwendet werden. Ein ``NeuralNetwork`` ermöglicht kein Training. Dieses wird in die eigentlichen Algorithmen/Anwendungen veragert. Ein ``NeuralNetwork`` speichert also auch nicht die Werte von trainierbaren Gewichten. Im Folgenden werden unterschiedliche Implementierungen dieser Schnittstellen eingeführt."

#: ../../tutorials/01_neural_networks.ipynb:68
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes either flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr "Angenommen, ein ` ` NeuralNetwork ` ` ` namens ` ` nn ` `. Dann nimmt der ` `nn.forward (Eingabe, Gewichte) ` ` -Pass entweder flache Eingaben für die Daten und Gewichte der Größe ` `nn.num_inputs ` ` bzw. ` `nn.num_Gewichte ` ` an. ` ` NeuralNetwork ` ` unterstützt die Stapelung von Eingaben und gibt Chargen der Ausgabe der entsprechenden Form zurück."

#: ../../tutorials/01_neural_networks.ipynb:80
msgid "2. ``OpflowQNN``"
msgstr "2. ``OpflowQNN``"

#: ../../tutorials/01_neural_networks.ipynb:82
msgid "The ``OpflowQNN`` takes a (parametrized) operator from Qiskit and leverages Qiskit’s gradient framework to provide the backward pass. Such an operator can for instance be an expected value of a quantum mechanical observable with respect to a parametrized quantum state. The Parameters can be used to load classical data as well as represent trainable weights. The ``OpflowQNN`` also allows lists of operators and more complex structures to construct more complex QNNs."
msgstr "``OpflowQNN`` nimmt einen (parametrisierten) Operator von Qiskit auf und nutzt Qiskits Gradient Framework, um den Backward-Pass bereitzustellen. Ein solcher Operator kann zum Beispiel der Erwartungswert einer quantenmechanischen Observablen sein, der in Bezug auf einen parametrisierten Quantenzustand beobachtet werden kann. Die Parameter können sowohl zum Laden klassischer Daten als auch zur Darstellung trainierbarer Gewichte verwendet werden. ``OpflowQNN`` erlaubt auch Listen von Operatoren und komplexere Strukturen um komplexere QNN zu konstruieren."

#: ../../tutorials/01_neural_networks.ipynb:321
msgid "Combining multiple observables in a ``ListOp`` also allows to create more complex QNNs"
msgstr "Die Kombination mehrerer Observables in einem ``ListOp`` erlaubt es auch die Erstellung komplexerer QNN"

#: ../../tutorials/01_neural_networks.ipynb:412
msgid "3. ``TwoLayerQNN``"
msgstr "3. ``TwoLayerQN``"

#: ../../tutorials/01_neural_networks.ipynb:414
msgid "The ``TwoLayerQNN`` is a special ``OpflowQNN`` on :math:`n` qubits that consists of first a feature map to insert data and second an ansatz that is trained. The default observable is :math:`Z^{\\otimes n}`, i.e., parity."
msgstr "``TwoLayerQN`` ist ein spezielles ``OpflowQNN`` auf :math:`n` Qubit, das erstens aus einer Feature-Map zum Einfügen von Daten und zweitens einem trainierten Ansatz. Die standardmäßige Observable ist :math:`Z^{\\otimes n}`, d.h. die Parität."

#: ../../tutorials/01_neural_networks.ipynb:612
msgid "4. ``CircuitQNN``"
msgstr "4. ``CircuitQNN``"

#: ../../tutorials/01_neural_networks.ipynb:614
msgid "The ``CircuitQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples can either be interpreted as probabilities of measuring the integer index corresponding to a bitstring or directly as a batch of binary output. In the case of probabilities, gradients can be estimated efficiently and the ``CircuitQNN`` provides a backward pass as well. In case of samples, differentiation is not possible and the backward pass returns ``(None, None)``."
msgstr "Der ``CircuitQNN`` basiert auf einem (parametrisierten) ``QuantumCircuit`` und kann sowohl Eingaben als auch Gewichtsparameter annehmen und Samples aus der Messung erzeugen. Die Samples können entweder als Wahrscheinlichkeiten für die Messung des Integer-Index, der einem Bitstring entspricht, oder als Stapel von binären Ausgaben interpretiert werden. Im Falle von Wahrscheinlichkeiten können Gradienten effizient geschätzt werden, und das ``CircuitQNN`` stellt auch einen Backward-Pass zur Verfügung. Im Fall von Samples ist eine Ableitung unmöglich und der Backward-Pass gibt ``(None, None)`` zurück."

#: ../../tutorials/01_neural_networks.ipynb:617
msgid "Further, the ``CircuitQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are aggregated accordingly."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:619
msgid "A ``CircuitQNN`` can be configured to return sparse as well as dense probability vectors. If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits and a sparse recommendation is usually recommended. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr "Ein ``CircuitQN`` kann so konfiguriert werden, dass es schwach besetzte und dichte Wahrscheinlichkeitsvektoren zurückgibt. Wenn keine ``interpret`` Funktion verwendet wird, skaliert die Dimension des Wahrscheinlichkeitsvektors exponentiell mit der Anzahl der Qubits und es wird in der Regel eine schwache Variante empfohlen. Im Falle einer ``interpret`` Funktion hängt dies vom erwarteten Ergebnis ab. Wenn zum Beispiel ein Index der Parität des entsprechenden Bitstrings zugeordnet wird, also 0 oder 1, ist ein dichter Output sinnvoll und das Ergebnis wird ein Wahrscheinlichkeitsvektor von Länge 2 sein."

#: ../../tutorials/01_neural_networks.ipynb:662
msgid "4.1 Output: sparse integer probabilities"
msgstr "4.1 Ausgabe: Schwach besetzte Integer-Wahrscheinlichkeiten"

#: ../../tutorials/01_neural_networks.ipynb:761
msgid "4.2 Output: dense parity probabilities"
msgstr "4.2 Ausgabe: Dichte Paritätswahrscheinlichkeiten"

#: ../../tutorials/01_neural_networks.ipynb:869
msgid "4.3 Output: Samples"
msgstr "4.3 Ausgabe: Samples"

#: ../../tutorials/01_neural_networks.ipynb:985
msgid "4.4 Output: Parity Samples"
msgstr "4.4 Ausgabe: Paritäts-Samples"

