msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-08 17:14-0400\n"
"PO-Revision-Date: 2021-07-19 16:56\n"
"Last-Translator: \n"
"Language-Team: Hindi\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: hi\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/05_torch_connector.po\n"
"X-Crowdin-File-ID: 9636\n"
"Language: hi_IN\n"

#: ../../tutorials/05_torch_connector.ipynb:13
msgid "Run interactively in jupyter notebook."
msgstr "Jupyter рдиреЛрдЯрдмреБрдХ рдореЗрдВ рдЕрдВрддрдГрдХреНрд░рд┐рдпрд╛рддреНрдордХ рд░реВрдк рд╕реЗ рдЪрд▓рд╛рдПрдВред"

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector and Hybrid QNNs"
msgstr "рдЯреЙрд░реНрдЪ рдХрдиреЗрдХреНрдЯрд░ рдФрд░ рд╕рдВрдХрд░ QNNs"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial introduces QiskitтАЩs ``TorchConnector`` class, and demonstrates how the ``TorchConnector`` allows for a natural integration of any ``NeuralNetwork`` from Qiskit Machine Learning into a PyTorch workflow. ``TorchConnector`` takes a Qiskit ``NeuralNetwork`` and makes it available as a PyTorch ``Module``. The resulting module can be seamlessly incorporated into PyTorch classical architectures and trained jointly without additional considerations, enabling the development and testing of novel **hybrid quantum-classical** machine learning architectures."
msgstr "рдпрд╣ рдЯреНрдпреВрдЯреЛрд░рд┐рдпрд▓ Qiskit рдХреЗ ``TorchConnector`` рд╡рд░реНрдЧ рдХрд╛ рдкрд░рд┐рдЪрдп рджреЗрддрд╛ рд╣реИ, рдФрд░ рджрд░реНрд╢рд╛рддрд╛ рд╣реИ рдХрд┐ рдХреИрд╕реЗ ``TorchConnector`` Qiskit Machine Learning рд╕реЗ PyTorch рд╡рд░реНрдХрдлрд╝реНрд▓реЛ рдореЗрдВ рдХрд┐рд╕реА рднреА ``NeuralNetwork`` рдХреЗ рдкреНрд░рд╛рдХреГрддрд┐рдХ рдПрдХреАрдХрд░рдг рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддрд╛ рд╣реИред ``TorchConnector`` рдПрдХ Qiskit ``NeuralNetwork`` рд▓реЗрддрд╛ рд╣реИ рдФрд░ рдЗрд╕реЗ рдПрдХ PyTorch ``Module`` рдХреЗ рд░реВрдк рдореЗрдВ рдЙрдкрд▓рдмреНрдз рдХрд░рд╛рддрд╛ рд╣реИред рдкрд░рд┐рдгрд╛рдореА рдореЙрдбреНрдпреВрд▓ рдХреЛ рдореВрд▓ рд░реВрдк рд╕реЗ PyTorch рд╢рд╛рд╕реНрддреНрд░реАрдп рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдореЗрдВ рд╢рд╛рдорд┐рд▓ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ рдФрд░ рдЕрддрд┐рд░рд┐рдХреНрдд рд╡рд┐рдЪрд╛рд░реЛрдВ рдХреЗ рдмрд┐рдирд╛ рд╕рдВрдпреБрдХреНрдд рд░реВрдк рд╕реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ, рдЬрд┐рд╕рд╕реЗ рдЙрдкрдиреНрдпрд╛рд╕ **hybrid quantum-classical** рдорд╢реАрди рд▓рд░реНрдирд┐рдВрдЧ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдХреЗ рд╡рд┐рдХрд╛рд╕ рдФрд░ рдкрд░реАрдХреНрд╖рдг рдХреЛ рд╕рдХреНрд╖рдо рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред"

#: ../../tutorials/05_torch_connector.ipynb:15
msgid "Content:"
msgstr "рд╡рд┐рд╖рдп-рд╕реВрдЪреА"

#: ../../tutorials/05_torch_connector.ipynb:17
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__"
msgstr "`рднрд╛рдЧ 1: рд╕рд░рд▓ рд╡рд░реНрдЧреАрдХрд░рдг рдФрд░ рдкреНрд░рддрд┐рдЧрдорди <#Part-1:-Simple-Classification-&-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:19
msgid "The first part of this tutorial shows how quantum neural networks can be trained using PyTorchтАЩs automatic differentiation engine (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) for simple classification and regression tasks."
msgstr "рдЗрд╕ рдЯреНрдпреВрдЯреЛрд░рд┐рдпрд▓ рдХрд╛ рдкрд╣рд▓рд╛ рднрд╛рдЧ рджрд┐рдЦрд╛рддрд╛ рд╣реИ рдХрд┐ рдХреИрд╕реЗ PyTorch рдХреЗ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд╡рд┐рднреЗрджрди рдЗрдВрдЬрди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдХреНрд╡рд╛рдВрдЯрдо рдиреНрдпреВрд░рд▓ рдиреЗрдЯрд╡рд░реНрдХ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) рд╕рд░рд▓ рд╡рд░реНрдЧреАрдХрд░рдг рдФрд░ рдкреНрд░рддрд┐рдЧрдорди рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдПред"

#: ../../tutorials/05_torch_connector.ipynb:21
msgid "`Classification <#1.-Classification>`__"
msgstr "`рд╡рд░реНрдЧреАрдХрд░рдг <#1.-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:23
msgid "Classification with PyTorch and ``OpflowQNN``"
msgstr "PyTorch рдФрд░ ``OpflowQNN`` рдХреЗ рд╕рд╛рде рд╡рд░реНрдЧреАрдХрд░рдг"

#: ../../tutorials/05_torch_connector.ipynb:24
msgid "Classification with PyTorch and ``CircuitQNN``"
msgstr "PyTorch рдФрд░ ``OpflowQNN`` рдХреЗ рд╕рд╛рде рд╡рд░реНрдЧреАрдХрд░рдг"

#: ../../tutorials/05_torch_connector.ipynb:26
msgid "`Regression <#2.-Regression>`__"
msgstr "`рдкреНрд░рддрд┐рдЧрдорди <#2.-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:28
msgid "Regression with PyTorch and ``OpflowQNN``"
msgstr "PyTorch рдФрд░ ``OpflowQNN`` рдХреЗ рд╕рд╛рде рдкреНрд░рддрд┐рдЧрдорди"

#: ../../tutorials/05_torch_connector.ipynb:30
msgid "`Part 2: MNIST Classification, Hybrid QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"
msgstr "`рднрд╛рдЧ 2: MNIST рд╡рд░реНрдЧреАрдХрд░рдг, рд╣рд╛рдЗрдмреНрд░рд┐рдб QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"

#: ../../tutorials/05_torch_connector.ipynb:32
msgid "The second part of this tutorial illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow (in this case, a typical CNN architecture) to classify MNIST data in a hybrid quantum-classical manner."
msgstr "рдЗрд╕ рдЯреНрдпреВрдЯреЛрд░рд┐рдпрд▓ рдХрд╛ рджреВрд╕рд░рд╛ рднрд╛рдЧ рдмрддрд╛рддрд╛ рд╣реИ рдХрд┐ рд╣рд╛рдЗрдмреНрд░рд┐рдб рдХреНрд╡рд╛рдВрдЯрдо-рд╢рд╛рд╕реНрддреНрд░реАрдп рддрд░реАрдХреЗ рд╕реЗ MNIST рдбреЗрдЯрд╛ рдХреЛ рд╡рд░реНрдЧреАрдХреГрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХ (рдХреНрд╡рд╛рдВрдЯрдо) ``рдиреНрдпреВрд░рд▓рдиреЗрдЯрд╡рд░реНрдХ`` рдХреЛ рд▓рдХреНрд╖реНрдп PyTorch рд╡рд░реНрдХрдлрд╝реНрд▓реЛ (рдЗрд╕ рдорд╛рдорд▓реЗ рдореЗрдВ, рдПрдХ рд╡рд┐рд╢рд┐рд╖реНрдЯ CNN рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░) рдореЗрдВ рдХреИрд╕реЗ рдПрдореНрдмреЗрдб рдХрд┐рдпрд╛ рдЬрд╛рдПред"

#: ../../tutorials/05_torch_connector.ipynb:74
msgid "Part 1: Simple Classification & Regression"
msgstr "рднрд╛рдЧ 1: рд╕рд░рд▓ рд╡рд░реНрдЧреАрдХрд░рдг рдПрд╡рдВ рдкреНрд░рддрд┐рдЧрдорди"

#: ../../tutorials/05_torch_connector.ipynb:86
msgid "1. Classification"
msgstr "1. рд╡рд░реНрдЧреАрдХрд░рдг"

#: ../../tutorials/05_torch_connector.ipynb:88
msgid "First, we show how ``TorchConnector`` allows to train a Quantum ``NeuralNetwork`` to solve a classification tasks using PyTorchтАЩs automatic differentiation engine. In order to illustrate this, we will perform **binary classification** on a randomly generated dataset."
msgstr "рд╕рдмрд╕реЗ рдкрд╣рд▓реЗ, рд╣рдо рджрд┐рдЦрд╛рддреЗ рд╣реИрдВ рдХрд┐ рдХреИрд╕реЗ ``TorchConnector`` рдХреНрд╡рд╛рдВрдЯрдо ``NeuralNetwork`` рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдиреЗ рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддрд╛ рд╣реИ рддрд╛рдХрд┐ PyTorch рдХреЗ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд╡рд┐рднреЗрджрди рдЗрдВрдЬрди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рд╡рд░реНрдЧреАрдХрд░рдг рдХрд╛рд░реНрдпреЛрдВ рдХреЛ рд╣рд▓ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХреЗред рдЗрд╕реЗ рд╕реНрдкрд╖реНрдЯ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рд╣рдо рдмреЗрддрд░рддреАрдм рдврдВрдЧ рд╕реЗ рдЙрддреНрдкрдиреНрди рдбреЗрдЯрд╛рд╕реЗрдЯ рдкрд░ **binary classification** рдХрд░реЗрдВрдЧреЗред"

#: ../../tutorials/05_torch_connector.ipynb:144
msgid "A. Classification with PyTorch and ``OpflowQNN``"
msgstr "A. PyTorch рдФрд░ ``OpflowQNN`` рдХреЗ рд╕рд╛рде рд╡рд░реНрдЧреАрдХрд░рдг"

#: ../../tutorials/05_torch_connector.ipynb:146
msgid "Linking an ``OpflowQNN`` to PyTorch is relatively straightforward. Here we illustrate this using the ``TwoLayerQNN``, a sub-case of ``OpflowQNN`` introduced in previous tutorials."
msgstr "рдПрдХ ``OpflowQNN`` рдХреЛ PyTorch рд╕реЗ рдЬреЛрдбрд╝рдирд╛ рдЕрдкреЗрдХреНрд╖рд╛рдХреГрдд рд╕рд░рд▓ рд╣реИред рдпрд╣рд╛рдВ рд╣рдо рдЗрд╕реЗ ``TwoLayerQNN``, ``OpflowQNN`` рдХрд╛ рдПрдХ рдЙрдк-рдорд╛рдорд▓рд╛ рдЬреЛ рдкрд┐рдЫрд▓реЗ рдЯреНрдпреВрдЯреЛрд░рд┐рдпрд▓ рдореЗрдВ рдкреЗрд╢ рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛, рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реБрдП рд╕реНрдкрд╖реНрдЯ рдХрд░рддреЗ рд╣реИрдВред"

#: ../../tutorials/05_torch_connector.ipynb:254
msgid "Optimizer"
msgstr "рдЖрдкреНрдЯрдорд╛рдЗрдЬрд╝рд░"

#: ../../tutorials/05_torch_connector.ipynb:256
msgid "The choice of optimizer for training any machine learning model can be crucial in determining the success of our trainingтАЩs outcome. When using ``TorchConnector``, we get access to all of the optimizer algorithms defined in the [``torch.optim``] package (`link <https://pytorch.org/docs/stable/optim.html>`__). Some of the most famous algorithms used in popular machine learning architectures include *Adam*, *SGD*, or *Adagrad*. However, for this tutorial we will be using the L-BFGS algorithm (``torch.optim.LBFGS``), one of the most well know second-order optimization algorithms for numerical optimization."
msgstr "рдХрд┐рд╕реА рднреА рдорд╢реАрди рд▓рд░реНрдирд┐рдВрдЧ рдореЙрдбрд▓ рдХреЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рдХ рдХрд╛ рдЪреБрдирд╛рд╡ рд╣рдорд╛рд░реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рдкрд░рд┐рдгрд╛рдо рдХреА рд╕рдлрд▓рддрд╛ рдХреЛ рдирд┐рд░реНрдзрд╛рд░рд┐рдд рдХрд░рдиреЗ рдореЗрдВ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реЛ рд╕рдХрддрд╛ рд╣реИред ``TorchConnector`` рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╕рдордп, рд╣рдореЗрдВ [``torch.optim``] рдкреИрдХреЗрдЬ (`link <https://pytorch.org/docs/stable/optim.html> `__)рдореЗрдВ рдкрд░рд┐рднрд╛рд╖рд┐рдд рд╕рднреА рдЕрдиреБрдХреВрд▓рдХ рдПрд▓реНрдЧреЛрд░рд┐рджрдо рддрдХ рдкрд╣реБрдВрдЪ рдкреНрд░рд╛рдкреНрдд рд╣реЛрддреА рд╣реИред рд▓реЛрдХрдкреНрд░рд┐рдп рдорд╢реАрди рд▓рд░реНрдирд┐рдВрдЧ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдореЗрдВ рдЙрдкрдпреЛрдЧ рдХрд┐рдП рдЬрд╛рдиреЗ рд╡рд╛рд▓реЗ рдХреБрдЫ рд╕рдмрд╕реЗ рдкреНрд░рд╕рд┐рджреНрдз рдПрд▓реНрдЧреЛрд░рд┐рджрдо рдореЗрдВ *Adam*, *SGD*, рдпрд╛ *Adagrad* рд╢рд╛рдорд┐рд▓ рд╣реИрдВред рд╣рд╛рд▓рд╛рдБрдХрд┐, рдЗрд╕ рдЯреНрдпреВрдЯреЛрд░рд┐рдпрд▓ рдХреЗ рд▓рд┐рдП рд╣рдо L-BFGS рдПрд▓реНрдЧреЛрд░рд┐рдердо (``torch.optim.LBFGS``) рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗ, рдЬреЛ рд╕рдВрдЦреНрдпрд╛рддреНрдордХ рдЕрдиреБрдХреВрд▓рди рдХреЗ рд▓рд┐рдП рд╕рдмрд╕реЗ рдЕрдЪреНрдЫреА рддрд░рд╣ рд╕реЗ рдЬреНрдЮрд╛рдд рджреВрд╕рд░реЗ рдХреНрд░рдо рдХреЗ рдЕрдиреБрдХреВрд▓рди рдПрд▓реНрдЧреЛрд░рд┐рджрдо рдореЗрдВ рд╕реЗ рдПрдХ рд╣реИред"

#: ../../tutorials/05_torch_connector.ipynb:260
msgid "Loss Function"
msgstr "рд▓реЙрд╕ рдлрдВрдХрд╢рди"

#: ../../tutorials/05_torch_connector.ipynb:262
msgid "As for the loss function, we can also take advantage of PyTorchтАЩs pre-defined modules from ``torch.nn``, such as the `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ or `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."
msgstr "рд╣рд╛рдирд┐ рдлрд╝рдВрдХреНрд╢рди рдХреЗ рд▓рд┐рдП, рд╣рдо `torch.nn` рд╕реЗ PyTorch рдХреЗ рдкреВрд░реНрд╡-рдирд┐рд░реНрдзрд╛рд░рд┐рдд рдореЙрдбреНрдпреВрд▓ рдХрд╛ рднреА рд▓рд╛рдн рдЙрдард╛ рд╕рдХрддреЗ рд╣реИрдВ, рдЬреИрд╕реЗ рдХрд┐ `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ рдпрд╛ `рдорд╛рдзреНрдп рдЪреБрдХрддрд╛ рддреНрд░реБрдЯрд┐ <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ рд╣рд╛рдирд┐рдпрд╛рдБред"

#: ../../tutorials/05_torch_connector.ipynb:264
msgid "**ЁЯТб Clarification :** In classical machine learning, the general rule of thumb is to apply a Cross-Entropy loss to classification tasks, and MSE loss to regression tasks. However, this recommendation is given under the assumption that the output of the classification network is a class probability value in the [0,1] range (usually this is achieved through a Softmax layer). Because the following example for ``TwoLayerQNN`` does not include such layer, and we donтАЩt apply any mapping to the output (the following section shows an example of application of parity mapping with ``CircuitQNNs``), the QNNтАЩs output can take any value in the range [-1,1]. In case you were wondering, this is the reason why this particular example uses MSELoss for classification despite it not being the norm (but we encourage you to experiment with different loss functions and see how they can impact training results)."
msgstr "**ЁЯТб рд╕реНрдкрд╖реНрдЯреАрдХрд░рдг:** рдХреНрд▓рд╛рд╕рд┐рдХрд▓ рдорд╢реАрди рд▓рд░реНрдирд┐рдВрдЧ рдореЗрдВ, рд╕рд╛рдорд╛рдиреНрдп рдирд┐рдпрдо рдпрд╣ рд╣реИ рдХрд┐ рд╡рд░реНрдЧреАрдХрд░рдг рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдХреНрд░реЙрд╕-рдПрдВрдЯреНрд░реЙрдкреА рд╣рд╛рдирд┐, рдФрд░ рдкреНрд░рддрд┐рдЧрдорди рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдПрдордПрд╕рдИ рд╣рд╛рдирд┐ рдХреЛ рд▓рд╛рдЧреВ рдХрд┐рдпрд╛ рдЬрд╛рдПред рд╣рд╛рд▓рд╛рдВрдХрд┐, рдпрд╣ рд╕рд┐рдлрд╛рд░рд┐рд╢ рдЗрд╕ рдзрд╛рд░рдгрд╛ рдХреЗ рддрд╣рдд рджреА рдЧрдИ рд╣реИ рдХрд┐ рд╡рд░реНрдЧреАрдХрд░рдг рдиреЗрдЯрд╡рд░реНрдХ рдХрд╛ рдЖрдЙрдЯрдкреБрдЯ [0,1] рд╢реНрд░реЗрдгреА рдореЗрдВ рдПрдХ рд╡рд░реНрдЧ рд╕рдВрднрд╛рд╡реНрдпрддрд╛ рдорд╛рди рд╣реИ (рдЖрдорддреМрд░ рдкрд░ рдпрд╣ рд╕реЙрдлреНрдЯрдореИрдХреНрд╕ рдкрд░рдд рдХреЗ рдорд╛рдзреНрдпрдо рд╕реЗ рдкреНрд░рд╛рдкреНрдд рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИ)ред рдХреНрдпреЛрдВрдХрд┐ ``TwoLayerQNN`` рдХреЗ рд▓рд┐рдП рдирд┐рдореНрди рдЙрджрд╛рд╣рд░рдг рдореЗрдВ рдРрд╕реА рдкрд░рдд рд╢рд╛рдорд┐рд▓ рдирд╣реАрдВ рд╣реИ, рдФрд░ рд╣рдо рдЖрдЙрдЯрдкреБрдЯ рдкрд░ рдХреЛрдИ рдореИрдкрд┐рдВрдЧ рд▓рд╛рдЧреВ рдирд╣реАрдВ рдХрд░рддреЗ рд╣реИрдВ (рдирд┐рдореНрди рдЕрдиреБрднрд╛рдЧ ``CircuitQNNs` рдХреЗ рд╕рд╛рде рд╕рдорддрд╛ рдорд╛рдирдЪрд┐рддреНрд░рдг рдХреЗ рдЕрдиреБрдкреНрд░рдпреЛрдЧ рдХрд╛ рдПрдХ рдЙрджрд╛рд╣рд░рдг рджрд┐рдЦрд╛рддрд╛ рд╣реИ), QNN рдХрд╛ рдЖрдЙрдЯрдкреБрдЯ [-1,1] рдХреА рд╕реАрдорд╛ рдореЗрдВ рдХреЛрдИ рднреА рдорд╛рди рд▓реЗ рд╕рдХрддреЗ рд╣реИрдВред рдпрджрд┐ рдЖрдк рд╕реЛрдЪ рд░рд╣реЗ рдереЗ, рдпрд╣реА рдХрд╛рд░рдг рд╣реИ рдХрд┐ рдпрд╣ рд╡рд┐рд╢реЗрд╖ рдЙрджрд╛рд╣рд░рдг рд╡рд░реНрдЧреАрдХрд░рдг рдХреЗ рд▓рд┐рдП MSELoss рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ, рдЬрдмрдХрд┐ рдпрд╣ рдорд╛рдирдХ рдирд╣реАрдВ рд╣реИ (рд▓реЗрдХрд┐рди рд╣рдо рдЖрдкрдХреЛ рд╡рд┐рднрд┐рдиреНрди рд╣рд╛рдирд┐ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд╕рд╛рде рдкреНрд░рдпреЛрдЧ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдкреНрд░реЛрддреНрд╕рд╛рд╣рд┐рдд рдХрд░рддреЗ рд╣реИрдВ рдФрд░ рджреЗрдЦреЗрдВ рдХрд┐ рд╡реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдкрд░рд┐рдгрд╛рдореЛрдВ рдХреЛ рдХреИрд╕реЗ рдкреНрд░рднрд╛рд╡рд┐рдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ)ред"

#: ../../tutorials/05_torch_connector.ipynb:442
#: ../../tutorials/05_torch_connector.ipynb:674
msgid "The red circles indicate wrongly classified data points."
msgstr "рд▓рд╛рд▓ рдШреЗрд░реЗ рдЧрд▓рдд рд░реВрдк рд╕реЗ рд╡рд░реНрдЧреАрдХреГрдд рдбреЗрдЯрд╛ рдмрд┐рдВрджреБрдУрдВ рдХреЛ рджрд░реНрд╢рд╛рддреЗ рд╣реИрдВред"

#: ../../tutorials/05_torch_connector.ipynb:454
msgid "B. Classification with PyTorch and ``CircuitQNN``"
msgstr "B. PyTorch рдФрд░ ``CircuitQNN`` рдХреЗ рд╕рд╛рде рд╡рд░реНрдЧреАрдХрд░рдг"

#: ../../tutorials/05_torch_connector.ipynb:456
msgid "Linking an ``CircuitQNN`` to PyTorch requires a bit more attention than ``OpflowQNN``. Without the correct setup, backpropagation is not possible."
msgstr "рдПрдХ ``CircuitQNN`` рдХреЛ PyTorch рд╕реЗ рдЬреЛрдбрд╝рдиреЗ рдХреЗ рд▓рд┐рдП ``OpflowQNN`` рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рдереЛрдбрд╝рд╛ рдЕрдзрд┐рдХ рдзреНрдпрд╛рди рджреЗрдиреЗ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реИред рд╕рд╣реА рд╕реЗрдЯрдЕрдк рдХреЗ рдмрд┐рдирд╛, рдмреИрдХрдкреНрд░реЛрдкреЗрдЧреЗрд╢рди рд╕рдВрднрд╡ рдирд╣реАрдВ рд╣реИред"

#: ../../tutorials/05_torch_connector.ipynb:458
msgid "In particular, we must make sure that we are returning a dense array of probabilities in the networkтАЩs forward pass (``sparse=False``). This parameter is set up to ``False`` by default, so we just have to make sure that it has not been changed."
msgstr "рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ, рд╣рдореЗрдВ рдпрд╣ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рдирд╛ рдЪрд╛рд╣рд┐рдП рдХрд┐ рд╣рдо рдиреЗрдЯрд╡рд░реНрдХ рдХреЗ рдлреЙрд░рд╡рд░реНрдб рдкрд╛рд╕ (``sparse=False``) рдореЗрдВ рд╕рдВрднрд╛рд╡рдирд╛рдУрдВ рдХреА рдПрдХ рд╕рдШрди рд╕рд░рдгреА рд▓реМрдЯрд╛ рд░рд╣реЗ рд╣реИрдВред рдпрд╣ рдкреИрд░рд╛рдореАрдЯрд░ рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ ``рдЧрд▓рдд`` рдкрд░ рд╕реЗрдЯ рд╣реИ, рдЗрд╕рд▓рд┐рдП рд╣рдореЗрдВ рдХреЗрд╡рд▓ рдпрд╣ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рдирд╛ рд╣реИ рдХрд┐ рдЗрд╕реЗ рдмрджрд▓рд╛ рдирд╣реАрдВ рдЧрдпрд╛ рд╣реИред"

#: ../../tutorials/05_torch_connector.ipynb:460
msgid "**тЪая╕П Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``CircuitQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."
msgstr "**тЪая╕П Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``CircuitQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."

#: ../../tutorials/05_torch_connector.ipynb:523
#: ../../tutorials/05_torch_connector.ipynb:815
msgid "For a reminder on optimizer and loss function choices, you can go back to `this section <#Optimizer>`__."
msgstr "рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝рд░ рдФрд░ рд╣рд╛рдирд┐ рдлрд╝рдВрдХреНрд╢рди рд╡рд┐рдХрд▓реНрдкреЛрдВ рдкрд░ рдЕрдиреБрд╕реНрдорд╛рд░рдХ рдХреЗ рд▓рд┐рдП, рдЖрдк `рдЗрд╕ рдЕрдиреБрднрд╛рдЧ <#Optimizer>`__ рдкрд░ рд╡рд╛рдкрд╕ рдЬрд╛ рд╕рдХрддреЗ рд╣реИрдВред"

#: ../../tutorials/05_torch_connector.ipynb:686
msgid "2. Regression"
msgstr "2. рдкреНрд░рддрд┐рдЧрдорди"

#: ../../tutorials/05_torch_connector.ipynb:688
msgid "We use a model based on the ``TwoLayerQNN`` to also illustrate how to perform a regression task. The chosen dataset in this case is randomly generated following a sine wave."
msgstr "рд╣рдо ``TwoLayerQNN`` рдкрд░ рдЖрдзрд╛рд░рд┐рдд рдПрдХ рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдпрд╣ рднреА рдмрддрд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд░рддреЗ рд╣реИрдВ рдХрд┐ рдкреНрд░рддрд┐рдЧрдорди рдХрд╛рд░реНрдп рдХреИрд╕реЗ рдХрд░реЗрдВред рдЗрд╕ рдорд╛рдорд▓реЗ рдореЗрдВ рдЪреБрдирд╛ рдЧрдпрд╛ рдбреЗрдЯрд╛рд╕реЗрдЯ рдПрдХ рд╕рд╛рдЗрди рд╡реЗрд╡ рдХреЗ рдмрд╛рдж рдмреЗрддрд░рддреАрдм рдврдВрдЧ рд╕реЗ рдЙрддреНрдкрдиреНрди рд╣реЛрддрд╛ рд╣реИред"

#: ../../tutorials/05_torch_connector.ipynb:730
msgid "A. Regression with PyTorch and ``OpflowQNN``"
msgstr "A. PyTorch рдФрд░ ``OpflowQNN`` рдХреЗ рд╕рд╛рде рдкреНрд░рддрд┐рдЧрдорди"

#: ../../tutorials/05_torch_connector.ipynb:741
msgid "The network definition and training loop will be analogous to those of the classification task using ``TwoLayerQNN``. In this case, we define our own feature map and ansatz, instead of using the default values."
msgstr "рдиреЗрдЯрд╡рд░реНрдХ рдкрд░рд┐рднрд╛рд╖рд╛ рдФрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓реВрдк ``TwoLayerQNN`` рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рд╡рд╛рд▓реЗ рд╡рд░реНрдЧреАрдХрд░рдг рдХрд╛рд░реНрдп рдХреЗ рдЕрдиреБрд░реВрдк рд╣реЛрдВрдЧреЗред рдЗрд╕ рдорд╛рдорд▓реЗ рдореЗрдВ, рд╣рдо рдбрд┐рдлрд╝реЙрд▓реНрдЯ рдорд╛рдиреЛрдВ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдХреЗ рдмрдЬрд╛рдп, рдЕрдкрдиреЗ рд╕реНрд╡рдпрдВ рдХреЗ рдлреАрдЪрд░ рдореИрдк рдФрд░ ansatz рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░рддреЗ рд╣реИрдВред"

#: ../../tutorials/05_torch_connector.ipynb:963
msgid "Part 2: MNIST Classification, Hybrid QNNs"
msgstr "рднрд╛рдЧ 2: MNIST рд╡рд░реНрдЧреАрдХрд░рдг, рд╣рд╛рдЗрдмреНрд░рд┐рдб QNNs"

#: ../../tutorials/05_torch_connector.ipynb:965
msgid "In this second part, we show how to leverage a hybrid quantum-classical neural network using ``TorchConnector``, to perform a more complex image classification task on the MNIST handwritten digits dataset."
msgstr "рдЗрд╕ рджреВрд╕рд░реЗ рднрд╛рдЧ рдореЗрдВ, рд╣рдо рджрд┐рдЦрд╛рддреЗ рд╣реИрдВ рдХрд┐ MNIST рд╣рд╕реНрддрд▓рд┐рдЦрд┐рдд рдЕрдВрдХреЛрдВ рдХреЗ рдбреЗрдЯрд╛рд╕реЗрдЯ рдкрд░ рдЕрдзрд┐рдХ рдЬрдЯрд┐рд▓ рдЫрд╡рд┐ рд╡рд░реНрдЧреАрдХрд░рдг рдХрд╛рд░реНрдп рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП ``TorchConnector` рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдПрдХ рд╣рд╛рдЗрдмреНрд░рд┐рдб рдХреНрд╡рд╛рдВрдЯрдо-рд╢рд╛рд╕реНрддреНрд░реАрдп рддрдВрддреНрд░рд┐рдХрд╛ рдиреЗрдЯрд╡рд░реНрдХ рдХрд╛ рд▓рд╛рдн рдХреИрд╕реЗ рдЙрдард╛рдпрд╛ рдЬрд╛рдПред"

#: ../../tutorials/05_torch_connector.ipynb:967
msgid "For a more detailed (pre-``TorchConnector``) explanation on hybrid quantum-classical neural networks, you can check out the corresponding section in the `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."
msgstr "рд╣рд╛рдЗрдмреНрд░рд┐рдб рдХреНрд╡рд╛рдВрдЯрдо-рд╢рд╛рд╕реНрддреНрд░реАрдп рддрдВрддреНрд░рд┐рдХрд╛ рдиреЗрдЯрд╡рд░реНрдХ рдкрд░ рдЕрдзрд┐рдХ рд╡рд┐рд╕реНрддреГрдд (рдкреВрд░реНрд╡-`` рдЯреЙрд░реНрдЪ рдХрдиреЗрдХреНрдЯрд░`) рд╕реНрдкрд╖реНрдЯреАрдХрд░рдг рдХреЗ рд▓рд┐рдП, рдЖрдк `рдХрд┐рд╕реНрдХрд┐рдЯ рдкрд╛рдареНрдпрдкреБрд╕реНрддрдХ рдореЗрдВ рд╕рдВрдмрдВрдзрд┐рдд рдЕрдиреБрднрд╛рдЧ рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВред <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."

#: ../../tutorials/05_torch_connector.ipynb:996
msgid "Step 1: Defining Data-loaders for train and test"
msgstr "рдЪрд░рдг 1: рдЯреНрд░реЗрди рдФрд░ рдкрд░реАрдХреНрд╖рдг рдХреЗ рд▓рд┐рдП рдбреЗрдЯрд╛ рд▓реЛрдбрд░ рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░рдирд╛"

#: ../../tutorials/05_torch_connector.ipynb:1007
msgid "We take advantage of the ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ to directly load a subset of the `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ and define torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) for train and test."
msgstr "рд╣рдо ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ рдХрд╛ рд▓рд╛рдн рдЙрдард╛рддреЗ рд╣реБрдП `MNIST рдбреЗрдЯрд╛рд╕реЗрдЯ <https://en.wikipedia.org/wiki/MNIST_database>`__рдХреЗ рд╕рдмрд╕реЗрдЯ рдХреЛ рд╕реАрдзреЗ рд▓реЛрдб рдХрд░рддреЗ рд╣реИрдВ рдФрд░ рдЯреНрд░реЗрди рдФрд░ рдкрд░реАрдХреНрд╖рдг рдХреЗ рд▓рд┐рдП рдорд╢рд╛рд▓ ``DataLoader``\\ s (`рд▓рд┐рдВрдХ <https://pytorch.org/docs/stable/data.html>`__) рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░реЗрдВред"

#: ../../tutorials/05_torch_connector.ipynb:1048
msgid "If we perform a quick visualization we can see that the train dataset consists of images of handwritten 0s and 1s."
msgstr "рдпрджрд┐ рд╣рдо рдПрдХ рддреНрд╡рд░рд┐рдд рд╡рд┐рдЬрд╝реБрдЕрд▓рд╛рдЗрдЬрд╝реЗрд╢рди рдХрд░рддреЗ рд╣реИрдВ рддреЛ рд╣рдо рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ рдХрд┐ рдЯреНрд░реЗрди рдбреЗрдЯрд╛рд╕реЗрдЯ рдореЗрдВ рд╣рд╕реНрддрд▓рд┐рдЦрд┐рдд 0s рдФрд░ 1s рдХреА рдЫрд╡рд┐рдпрд╛рдВ рд╣реЛрддреА рд╣реИрдВред"

#: ../../tutorials/05_torch_connector.ipynb:1120
msgid "Step 2: Defining the QNN and Hybrid Model"
msgstr "рдЪрд░рдг 2: QNN рдФрд░ рд╣рд╛рдЗрдмреНрд░рд┐рдб рдореЙрдбрд▓ рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░рдирд╛"

#: ../../tutorials/05_torch_connector.ipynb:1131
msgid "This second step shows the power of the ``TorchConnector``. After defining our quantum neural network layer (in this case, a ``TwoLayerQNN``), we can embed it into a layer in our torch ``Module`` by initializing a torch connector as ``TorchConnector(qnn)``."
msgstr "рдпрд╣ рджреВрд╕рд░рд╛ рдЪрд░рдг ``TorchConnector`` рдХреА рд╢рдХреНрддрд┐ рдХреЛ рджрд░реНрд╢рд╛рддрд╛ рд╣реИред рд╣рдорд╛рд░реЗ рдХреНрд╡рд╛рдВрдЯрдо рдиреНрдпреВрд░рд▓ рдиреЗрдЯрд╡рд░реНрдХ рд▓реЗрдпрд░ (рдЗрд╕ рдорд╛рдорд▓реЗ рдореЗрдВ, рдПрдХ ``TwoLayerQNN``) рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░рдиреЗ рдХреЗ рдмрд╛рдж, рд╣рдо рдПрдХ рдЯреЙрд░реНрдЪ рдХрдиреЗрдХреНрдЯрд░ рдХреЛ ``TorchConnector(qnn)`` рдХреЗ рд░реВрдк рдореЗрдВ рдЖрд░рдВрдн рдХрд░рдХреЗ рдЗрд╕реЗ рдЕрдкрдиреЗ рдорд╢рд╛рд▓ ``рдореЙрдбреНрдпреВрд▓`` рдореЗрдВ рдПрдХ рдкрд░рдд рдореЗрдВ рдПрдореНрдмреЗрдб рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред"

#: ../../tutorials/05_torch_connector.ipynb:1133
msgid "**тЪая╕П Attention:** In order to have an adequate gradient backpropagation in hybrid models, we MUST set the initial parameter ``input_gradients`` to TRUE during the qnn initialization."
msgstr "**тЪая╕П рдзреНрдпрд╛рди рджреЗрдВ:** рд╣рд╛рдЗрдмреНрд░рд┐рдб рдореЙрдбрд▓ рдореЗрдВ рдкрд░реНрдпрд╛рдкреНрдд рдЧреНрд░реЗрдбрд┐рдПрдВрдЯ рдмреИрдХрдкреНрд░реЛрдкреЗрдЧреЗрд╢рди рдХреЗ рд▓рд┐рдП, рд╣рдореЗрдВ qnn рдЗрдирд┐рд╢рд┐рдпрд▓рд╛рдЗрдЬрд╝реЗрд╢рди рдХреЗ рджреМрд░рд╛рди рдкреНрд░рд╛рд░рдВрднрд┐рдХ рдкреИрд░рд╛рдореАрдЯрд░ ``input_gradients` рдХреЛ TRUE рдкрд░ рд╕реЗрдЯ рдХрд░рдирд╛ рд╣реЛрдЧрд╛ред"

#: ../../tutorials/05_torch_connector.ipynb:1235
msgid "Step 3: Training"
msgstr "рдЪрд░рдг 3: рдкреНрд░рд╢рд┐рдХреНрд╖рдг"

#: ../../tutorials/05_torch_connector.ipynb:1337
msgid "Step 4: Evaluation"
msgstr "рдЪрд░рдг 4: рдореВрд▓реНрдпрд╛рдВрдХрди"

#: ../../tutorials/05_torch_connector.ipynb:1440
msgid "ЁЯОЙЁЯОЙЁЯОЙЁЯОЙ **You are now able to experiment with your own hybrid datasets and architectures using Qiskit Machine Learning.** **Good Luck!**"
msgstr "ЁЯОЙЁЯОЙЁЯОЙЁЯОЙ **рдЕрдм рдЖрдк Qiskit Machine Learning рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЕрдкрдиреЗ рд╕реНрд╡рдпрдВ рдХреЗ рд╣рд╛рдЗрдмреНрд░рд┐рдб рдбреЗрдЯрд╛рд╕реЗрдЯ рдФрд░ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдХреЗ рд╕рд╛рде рдкреНрд░рдпреЛрдЧ рдХрд░рдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рд╣реИрдВред** **рд╕реМрднрд╛рдЧреНрдп!**"

