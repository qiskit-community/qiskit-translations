msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-08 17:14-0400\n"
"PO-Revision-Date: 2021-07-18 20:59\n"
"Last-Translator: \n"
"Language-Team: Hindi\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: hi\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/04_qgans_for_loading_random_distributions.po\n"
"X-Crowdin-File-ID: 9634\n"
"Language: hi_IN\n"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:13
msgid "Run interactively in jupyter notebook."
msgstr "Jupyter नोटबुक में अंतःक्रियात्मक रूप से चलाएं।"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:9
msgid "qGANs for Loading Random Distributions"
msgstr "यादृच्छिक वितरण लोड करने के लिए क्यूगेएन"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:11
msgid "Given :math:`k`-dimensional data samples, we employ a quantum Generative Adversarial Network (qGAN) to learn the data’s underlying random distribution and to load it directly into a quantum state:"
msgstr "दिए गए :math:`k`- आयामी डेटा नमूने देखते हुए, हम डेटा के अंतर्निहित यादृच्छिक वितरण को जानने के लिए और इसे सीधे क्वांटम स्थिति में लोड करने के लिए एक क्वांटम जनरेटिव एडवरसरी नेटवर्क (गेएन ) को नियोजित करते हैं:"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:13
msgid "\\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle\n\n"
msgstr "\\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle\n\n"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:15
msgid "where :math:`p_{\\theta}^{j}` describe the occurrence probabilities of the basis states :math:`\\big| j\\rangle`."
msgstr "जहां :math:`p_{\\theta}^{j}` आधार स्थिति के घटना की संभावनाओं का वर्णन करता है :math:`\\big| j\\rangle`।"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:17
msgid "The aim of the qGAN training is to generate a state :math:`\\big| g_{\\theta}\\rangle` where :math:`p_{\\theta}^{j}`, for :math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}`, describe a probability distribution that is close to the distribution underlying the training data :math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}`."
msgstr "क्यूगेएन प्रशिक्षण का उद्देश्य एक स्थिति उत्पन्न करना है :math:`\\big| g_{\\theta}\\rangle` जहां :math:`p_{\\theta}^{j}`, के लिए :math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}`, एक संभाव्यता वितरण का वर्णन करें जो प्रशिक्षण डेटा को अंतर्निहित वितरण के करीब हो :math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}`।"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:19
msgid "For further details please refer to `Quantum Generative Adversarial Networks for Learning and Loading Random Distributions <https://arxiv.org/abs/1904.00043>`__ *Zoufal, Lucchi, Woerner* [2019]."
msgstr "अधिक जानकारी के लिए कृपया `Quantum Generative Adversarial Networks for Learning and Loading Random Distributions <https://arxiv.org/abs/1904.00043>`__ *Zoufal, Lucchi, Woerner* [2019] के उल्लेलख को देखे।"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:21
msgid "For an example of how to use a trained qGAN in an application, the pricing of financial derivatives, please see the `Option Pricing with qGANs <https://github.com/Qiskit/qiskit-finance/tree/main/docs/tutorials/10_qgan_option_pricing.ipynb>`__ tutorial."
msgstr "प्रशिक्षित क्यूगेएन का एप्लीकेशन में प्रयोग का एक उदाहरण, वित्तीय डेरिवेटिव का मूल्य निर्धारण है, देखें 'क्यूगेएन विकल्प प्राजिकीकरण' <https://github.com/Qiskit/qiskit-finance/tree/main/docs/tutorials/10_qgan_option_pricing.ipynb>`__"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:56
msgid "Load the Training Data"
msgstr "प्रशिक्षण डेटा लोड करें"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:58
msgid "First, we need to load the :math:`k`-dimensional training data samples (here k=1)."
msgstr "सबसे पहले हमे :math:`k`-आयामी प्रशिक्षण डेटा नमूनों (यहाँ k =1 )को लोड करना पड़ेगा ."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:60
msgid "Next, the data resolution is set, i.e. the min/max data values and the number of qubits used to represent each data dimension."
msgstr "इसके, बाद हम डाटा रेसोलुशन अर्थात न्यूनतम/अधिकतम डेटा मान और क्यूबिट की संख्या सेट करते है जो कि प्रत्येक डेटा के आयाम का प्रतिनिधित्व करने के लिए इस्तेमाल किया जाता है."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:95
msgid "Initialize the qGAN"
msgstr "क्यूगेएन का आरम्भीकरण"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:97
msgid "The qGAN consists of a quantum generator :math:`G_{\\theta}`, i.e., an ansatz, and a classical discriminator :math:`D_{\\phi}`, a neural network."
msgstr "क्यूगेएन में क्वांटम जनरेटर :math:`G_{\\theta}` ,अर्थात एक अंसात्ज़ और शास्त्रीय डिस्क्रिमिनटोर :math:`D_{\\phi}`, एक न्यूरलनेटवर्क होते है।"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:99
msgid "To implement the quantum generator, we choose a depth-\\ :math:`1` ansatz that implements :math:`R_Y` rotations and :math:`CZ` gates which takes a uniform distribution as an input state. Notably, for :math:`k>1` the generator’s parameters must be chosen carefully. For example, the circuit depth should be :math:`>1` because higher circuit depths enable the representation of more complex structures."
msgstr "क्वांटम जनरेटर को लागू करने के लिए, हम एक गहराई-\\ :math:`1` ansatz चुनते हैं जो :math:`R_Y` घुमावों को लागू करता है और :math:`CZ` गेट जो एक इनपुट स्थिति के रूप में एक समान वितरण लेता है। विशेष रूप से, :math:`k>1` जनरेटर के मापदंडों को सावधानी से चुना जाना चाहिए। उदाहरण के लिए, सर्किट की गहराई होनी चाहिए :math:`>1` क्योंकि उच्च सर्किट गहराई अधिक जटिल संरचनाओं के प्रतिनिधित्व को सक्षम करती है।"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:101
msgid "The classical discriminator used here is based on a neural network implementation using NumPy. There is also a discriminator based on PyTorch which is not installed by default when installing Qiskit - see `Optional Install <https://github.com/Qiskit/qiskit-machine-learning#optional-installs>`__ for more information."
msgstr "यहां इस्तेमाल किया जाने वाला शास्त्रीय विवेचक NumPy का उपयोग करते हुए एक तंत्रिका नेटवर्क कार्यान्वयन पर आधारित है। PyTorch पर आधारित एक विभेदक भी है जो Qiskit को स्थापित करते समय डिफ़ॉल्ट रूप से स्थापित नहीं होता है - अधिक जानकारी के लिए `वैकल्पिक इंस्टॉल <https://github.com/Qiskit/qiskit-machine-learning#Optional-installs>`__ देखें।"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:103
msgid "Here, both networks are updated with the ADAM optimization algorithm (ADAM is qGAN optimizer default)."
msgstr "यहां, दोनों नेटवर्क को ADAM ऑप्टिमाइज़ेशन एल्गोरिथम के साथ अपडेट किया गया है (ADAM qGAN ऑप्टिमाइज़र डिफ़ॉल्ट है)।"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:164
msgid "Run the qGAN Training"
msgstr "qGAN प्रशिक्षण चलाएं"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:166
msgid "During the training the discriminator’s and the generator’s parameters are updated alternately w.r.t the following loss functions:"
msgstr "प्रशिक्षण के दौरान विवेक और जेनेरेटर के मापदंड वैकल्पिक रूप से अद्यतन किए जाते हैं:"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:168
msgid "L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right]\n\n"
msgstr "L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right]\n\n"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:170
msgid "and"
msgstr "और"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:172
msgid "L_D\\left(\\phi, \\theta\\right) =\n"
"  \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],"
msgstr "L_D\\left(\\phi, \\theta\\right) =\n"
"  \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:177
msgid "with :math:`m` denoting the batch size and :math:`g^l` describing the data samples generated by the quantum generator."
msgstr "साथ :math:`m` बैच आकार को दर्शाता है और :math:`g^l` क्वांटम जनरेटर द्वारा उत्पन्न डेटा नमूनों का वर्णन करता है।"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:179
msgid "Please note that the training, for the purpose of this notebook, has been kept briefer by the selection of a known initial point (``init_params``). Without such prior knowledge be aware training may take some while."
msgstr "कृपया ध्यान दें कि इस नोटबुक के प्रयोजन के लिए प्रशिक्षण को एक ज्ञात प्रारंभिक बिंदु (``init_params``) के चयन द्वारा संक्षिप्त रखा गया है। इस तरह के पूर्व ज्ञान के बिना जागरूक रहें प्रशिक्षण में कुछ समय लग सकता है।"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:245
msgid "Training Progress & Outcome"
msgstr "प्रशिक्षण प्रगति और परिणाम"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:247
msgid "Now, we plot the evolution of the generator’s and the discriminator’s loss functions during the training, as well as the progress in the relative entropy between the trained and the target distribution."
msgstr "अब, हम प्रशिक्षण के दौरान जनरेटर के विकास और विवेचक के नुकसान कार्यों के साथ-साथ प्रशिक्षित और लक्ष्य वितरण के बीच सापेक्ष एन्ट्रापी में प्रगति की साजिश रचते हैं।"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:249
msgid "Finally, we also compare the cumulative distribution function (CDF) of the trained distribution to the CDF of the target distribution."
msgstr "अंत में, हम प्रशिक्षित वितरण के संचयी वितरण फ़ंक्शन (सीडीएफ) की तुलना लक्ष्य वितरण के सीडीएफ से भी करते हैं।"

