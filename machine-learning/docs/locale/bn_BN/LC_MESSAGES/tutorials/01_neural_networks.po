msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-08 23:29+0000\n"
"PO-Revision-Date: 2022-11-09 00:07\n"
"Last-Translator: \n"
"Language-Team: Bengali Language\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: bengali\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/01_neural_networks.po\n"
"X-Crowdin-File-ID: 9628\n"
"Language: bn_BN\n"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/01_neural_networks.ipynb`__."
msgstr "এই পাতাটি `docs/tutorials/01_neural_networks.ipynb`__ থেকে তৈরি হয়েছে।"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "কোয়ান্টাম নিউরাল নেটওয়ার্ক"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "এই নোটবুকটিতে Qiskit মেশিন লার্নিং এর বিভিন্ন সাধারণ কোয়ান্টাম নিউরাল নেটওয়ার্ক (কিউ এন এন) এর বাস্তবায়ন  (ইমপ্লিমেন্টেশন) দেখানো হয়েছে। এই নেটওয়ার্ক গুলো প্রয়োগ-নিরপেক্ষ কম্পিউটেশনাল ইউনিট হিসেবে বোঝানো হয় যা অনেক গুলি বিভিন্ন ক্ষেত্রে ব্যবহার করা যেতে পারে। প্রয়োগের উপর নির্ভর করে, একটি নির্দিষ্ট ধরনের নেটওয়ার্ক কম-বেশি উপযুক্ত হতে পারে এবং একটি নির্দিষ্ট উপায়ে সেট আপ বা গঠন করার প্রয়োজনীয়তা দেখা দিতে পারে। নিম্নে বিভিন্ন নিউরাল নেটওয়ার্ক গুলো আরো বিশদ ভাবে আলোচনা করা হবেঃ"

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks. This is an abstract class."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``EstimatorQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``SamplerQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:17
msgid "Each implementation, ``EstimatorQNN`` and ``SamplerQNN``, takes in an optional instance of the corresponding Qiskit primitive, namely ``BaseEstimator`` and ``BaseSampler``. The latter two define two interfaces of the primitives. Qiskit provides the reference implementation as well as a backend-based implementation of the primitives. The primitives is a frontend to either a simulator or a real quantum hardware. By default, if no instance is passed to a network, an instance of the Qiskit reference primitive is created automatically by the network. For more information about primitives please refer to `Qiskit primitives <https://qiskit.org/documentation/apidoc/primitives.html>`__."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:45
msgid "1. ``NeuralNetwork``"
msgstr "১. ``NeuralNetwork``"

#: ../../tutorials/01_neural_networks.ipynb:47
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interfaces are introduced."
msgstr "``NeuralNetwork`` Qiskit মেশিন লার্নিংয়ে পাওয়া যায় এমন সব নিউরাল নেটওয়ার্কগুলির ইন্টারফেসের প্রতিনিধিত্ব করে। এটি ইনপুট হিসাবে তথ্য (ডেটা) নমুনা এবং প্রশিক্ষণযোগ্য (ট্রেইনেবল) ওয়েট গ্রহণ করে একটি ফরোয়ার্ড (সম্মুখ) এবং একটি ব্যাকওয়ার্ড (পশ্চাৎ) পাস উন্মুক্ত করে। একটি ``NeuralNetwork`` কোনও প্রশিক্ষণ (ট্রেইনিং) ক্ষমতা রাখে না, এগুলি প্রকৃত ধারাক্রম (অ্যালগরিদম) / প্রয়োগক্ষেত্রে (অ্যাপ্লিকেশন) ব্যবহার করা যায়।সুতরাং একটি, ``NeuralNetwork`` প্রশিক্ষণযোগ্য ওয়েটের মানগুলিও সঞ্চয় করে না। নিচে, এই ইন্টারফেসগুলির বিভিন্ন প্রয়োগ দেখানো হয়েছে।"

#: ../../tutorials/01_neural_networks.ipynb:49
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes either flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr "ধরুন, একটি ``NeuralNetwork`` যার সংক্ষিপ্ত নাম ``nn``। এরপরে, ``nn.forward(input, weights)`` পাসের জন্য যথাক্রমে ``nn.num_inputs`` এবং ``nn.num_weights``এর ইনপুট তথ্য ও ওয়েট (ওজন) লাগে। ``NeuralNetwork`` ইনপুটের ব্যাচিং সমর্থন করে এবং সংশ্লিষ্ট আকৃতির ফলাফলের ব্যাচ প্রদান করে।"

#: ../../tutorials/01_neural_networks.ipynb:61
msgid "2. ``EstimatorQNN``"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:63
msgid "The ``EstimatorQNN`` takes in a parametrized quantum circuit with the combined network’s feature map (input parameters) and ansatz (weight parameters), as well as an optional quantum mechanical observable, and outputs expectation value computations for the forward pass. The quantum circuit parameters can be used to load classical data as well as represent trainable weights. The ``EstimatorQNN`` also allows lists of observables to construct more complex QNNs."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:109
msgid "We create an observable manually. If it is set, then The default observable :math:`Z^{\\otimes n}`, where :math:`n` is the number of qubits, is created automatically."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:132
msgid "Construct EstimatorQNN with the observable, input parameters, and weight parameters. We don’t set the ``estimator`` parameter, the network will create an instance of the reference ``Estimator`` primitive for us."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:323
msgid "Combining multiple observables in a list allows to create more complex QNNs."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:430
msgid "4. ``SamplerQNN``"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:432
msgid "The ``SamplerQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples are interpreted as probabilities of measuring the integer index corresponding to a bitstring. Gradients can be estimated efficiently and the ``SamplerQNN`` provides a backward pass as well."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:434
msgid "Further, the ``SamplerQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are aggregated accordingly."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:436
msgid "If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:478
msgid "As in the previous example, we don’t set the ``sampler`` parameter, the network will create an instance of the reference ``Sampler`` primitive for us."
msgstr ""

