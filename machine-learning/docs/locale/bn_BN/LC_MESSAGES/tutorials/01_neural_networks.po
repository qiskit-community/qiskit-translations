msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-22 17:47+0000\n"
"PO-Revision-Date: 2021-08-01 19:41\n"
"Last-Translator: \n"
"Language-Team: Bengali Language\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: bengali\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/01_neural_networks.po\n"
"X-Crowdin-File-ID: 9628\n"
"Language: bn_BN\n"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/01_neural_networks.ipynb`__."
msgstr "এই পেজটি `docs/tutorials/01_neural_networks.ipynb`__ থেকে তৈরি হয়েছে।"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "কোয়ান্টাম নিউরাল নেটওয়ার্ক"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "এই নোটবুকটি Qiskit (কিস্কিট) মেশিন লার্নিং এ উপলব্ধ কোয়ান্টাম নিউরাল নেটওয়ার্ক (কিউ এন এন) এর বিভিন্ন রূপায়ণ (ইমপ্লিমেন্টেশন) প্রদর্শন করে। নেটওয়ার্ক গুলো অ্যাপ্লিকেশন-এগ্নস্টিক কম্পিউটেশনাল ইউনিট হিসেবে বোঝানো হয় যা অনেক গুলি বিভিন্ন ক্ষেত্রে ব্যবহার করা যেতে পারে।এপ্লিকেশনের উপর নির্ভর করে , একটি নির্দিষ্ট ধরনের নেটওয়ার্ক কম-বেশি উপযুক্ত হতে পারে এবং একটি নির্দিষ্ট উপায়ে সেটাপ করার প্রয়োজনীয়তা দেখা দিতে পারে। নিম্নে বিভিন্ন উপলব্ধ নিউরাল নেটওয়ার্ক গুলো আরো বিশদ ভাবে আলোচনা করা হবে :"

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks."
msgstr "``NeuralNetwork``: নিউরাল নেটওয়ার্কের ইন্টারফেস"

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``OpflowQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr "``OpflowQNN``: কোয়ান্টাম বলবিদ্যার পর্যবেক্ষণের মূল্যায়নের উপর ভিত্তি করে একটি নেটওয়ার্ক।"

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``TwoLayerQNN``: A special ``OpflowQNN`` implementation for convenience."
msgstr "``TwoLayerQNN``: কাজের সুবিধার জন্য একটি বিশেষ `` OpflowQNN`` বাস্তবায়ন।"

#: ../../tutorials/01_neural_networks.ipynb:16
msgid "``CircuitQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr "``CircuitQNN``: একটি নেটওয়ার্ক যা কোয়ান্টাম সার্কিট পরিমাপের ফলে নমুনাগুলির উপর ভিত্তি করে রচিত।"

#: ../../tutorials/01_neural_networks.ipynb:64
msgid "1. ``NeuralNetwork``"
msgstr "১. ``NeuralNetwork``"

#: ../../tutorials/01_neural_networks.ipynb:66
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interfaces are introduced."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:68
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes either flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:80
msgid "2. ``OpflowQNN``"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:82
msgid "The ``OpflowQNN`` takes a (parametrized) operator from Qiskit and leverages Qiskit’s gradient framework to provide the backward pass. Such an operator can for instance be an expected value of a quantum mechanical observable with respect to a parametrized quantum state. The Parameters can be used to load classical data as well as represent trainable weights. The ``OpflowQNN`` also allows lists of operators and more complex structures to construct more complex QNNs."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:321
msgid "Combining multiple observables in a ``ListOp`` also allows to create more complex QNNs"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:412
msgid "3. ``TwoLayerQNN``"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:414
msgid "The ``TwoLayerQNN`` is a special ``OpflowQNN`` on :math:`n` qubits that consists of first a feature map to insert data and second an ansatz that is trained. The default observable is :math:`Z^{\\otimes n}`, i.e., parity."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:612
msgid "4. ``CircuitQNN``"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:614
msgid "The ``CircuitQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples can either be interpreted as probabilities of measuring the integer index corresponding to a bitstring or directly as a batch of binary output. In the case of probabilities, gradients can be estimated efficiently and the ``CircuitQNN`` provides a backward pass as well. In case of samples, differentiation is not possible and the backward pass returns ``(None, None)``."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:617
msgid "Further, the ``CircuitQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are aggregated accordingly."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:619
msgid "A ``CircuitQNN`` can be configured to return sparse as well as dense probability vectors. If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits and a sparse recommendation is usually recommended. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:662
msgid "4.1 Output: sparse integer probabilities"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:761
msgid "4.2 Output: dense parity probabilities"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:869
msgid "4.3 Output: Samples"
msgstr "৪.৩ আউটপুট : নমুনা (স্যাম্পল)"

#: ../../tutorials/01_neural_networks.ipynb:985
msgid "4.4 Output: Parity Samples"
msgstr "৪.৪ আউটপুট: প্যরিটি নমুনা (স্যাম্পল)"

