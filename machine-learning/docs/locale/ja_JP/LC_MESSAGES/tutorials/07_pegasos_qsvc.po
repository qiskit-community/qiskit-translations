msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-02-07 03:44+0000\n"
"PO-Revision-Date: 2023-02-07 05:14\n"
"Last-Translator: \n"
"Language: ja\n"
"Language-Team: Japanese\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ja\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/07_pegasos_qsvc.po\n"
"X-Crowdin-File-ID: 9721\n"

#: ../../tutorials/07_pegasos_qsvc.ipynb:9
msgid "This page was generated from `docs/tutorials/07_pegasos_qsvc.ipynb`__."
msgstr "このページは `docs/tutorials/07_pegasos_qsvc.ipynb`__ から生成されました。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:9
msgid "Pegasos Quantum Support Vector Classifier"
msgstr "ペガソス量子サポートベクター分類器サポート"

#: ../../tutorials/07_pegasos_qsvc.ipynb:11
msgid "There’s another SVM based algorithm that benefits from the quantum kernel method. Here, we introduce an implementation of a another classification algorithm, which is an alternative version to the ``QSVC`` available in Qiskit Machine Learning and shown in the `“Quantum Kernel Machine Learning” <./03_quantum_kernel.ipynb>`__ tutorial. This classification algorithm implements the Pegasos algorithm from the paper “Pegasos: Primal Estimated sub-GrAdient SOlver for SVM” by Shalev-Shwartz et al., see: https://home.ttic.edu/~nati/Publications/PegasosMPB.pdf."
msgstr "量子カーネル法の恩恵を受けたSVMベースのアルゴリズムがもう一つあります。これはQiskit Machine Learningで利用できる ``QSVC`` の代替バージョンで、 `\"量子カーネル法機械学習\" <./03_quantum_kernel.ipynb>`__ tutorial で紹介されているものとは別の分類アルゴリズムの実装を紹介します。この分類アルゴリズムは、Shalev-Shwartz et al. による論文「Pegasos: Primal Estimated sub-GrAdient SOlver for SVM」のペガソスアルゴリズムを実装しています。https://home.ttic.edu/~nati/Publications/PegasosMPB.pdf を参照してください。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:14
msgid "This algorithm is an alternative to the dual optimization from the ``scikit-learn`` package, benefits from the kernel trick, and yields a training complexity that is independent of the size of the training set. Thus, the ``PegasosQSVC`` is expected to train faster than QSVC for sufficiently large training sets."
msgstr "このアルゴリズムは、 ``scikit-learn`` パッケージの二重最適化に代わるものであり、カーネルトリックの恩恵を受け、トレーニングセットのサイズに依存しないトレーニングの複雑さをもたらします。したがって、 ``PegasosQSVC`` は、十分に大きなトレーニングセットに対して、QSVC よりも高速なトレーニングが期待されます。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:16
msgid "The algorithm can be used as direct replacement of ``QSVC`` with some hyper-parameterization."
msgstr "このアルゴリズムは、 ``QSVC`` をハイパーパラメーターに直接置き換わるものとして使用できます。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:27
msgid "Let’s generate some data:"
msgstr "次のデータを生成します。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:51
msgid "We pre-process the data to ensure compatibility with the rotation encoding and split it into the training and test datasets."
msgstr "ローテーション・エンコーディングとの互換性を確保するためにデータを前処理し、トレーニングデータセットとテストデータセットに分割します。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:81
msgid "We have two features in the dataset, so we set a number of qubits to the number of features in the dataset."
msgstr "データセットには2つの特徴があるため、データセット内の特徴の数を量子ビットの数に設定します。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:83
msgid "Then we set :math:`\\tau` to the number of steps performed during the training procedure. Please note that, there is no early stopping criterion in the algorithm. The algorithm iterates over all :math:`\\tau` steps."
msgstr "次に、 :math:`\\tau` をトレーニング手順中に実行されるステップ数に設定します。アルゴリズムにはアーリーストッピングの基準がないことに注意してください。アルゴリズムはすべての :math:`\\tau` ステップを繰り返します。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:85
msgid "And the last one is the hyperparameter :math:`C`. This is a positive regularization parameter. The strength of the regularization is inversely proportional to :math:`C`. Smaller :math:`C` induce smaller weights which generally helps preventing overfitting. However, due to the nature of this algorithm, some of the computation steps become trivial for larger :math:`C`. Thus, larger :math:`C` improve the performance of the algorithm drastically. If the data is linearly separable in feature space, :math:`C` should be chosen to be large. If the separation is not perfect, :math:`C` should be chosen smaller to prevent overfitting."
msgstr "そして最後のひとつはハイパーパラメータ :math:`C` です。これは正の正則化パラメータです。正則化の強さは :math:`C` に反比例します。 :math:`C` が小さいほど重みが小さくなり、一般的にオーバーフィッティングを防ぐのに役立ちます。ただし、このアルゴリズムの性質上、 :math:`C` が大きいほど、計算ステップの一部が軽薄なものになります。したがって、 :math:`C` が大きいほど、アルゴリズムのパフォーマンスが大幅に向上します。データが特徴空間で線形分離可能である場合は、 :math:`C` を大きく選択する必要があります。分離が完全でない場合は、過剰適合を防ぐためにCを小さく選択する必要があります。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:114
msgid "The algorithm will run using:"
msgstr "アルゴリズムは以下を使用して実行されます。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:116
msgid "The default fidelity instantiated in ``FidelityQuantumKernel``"
msgstr "``FidelityQuantumKernel`` でインスタンス化されたデフォルトのフィデリティ"

#: ../../tutorials/07_pegasos_qsvc.ipynb:117
msgid "A quantum kernel created from ``ZFeatureMap``"
msgstr "``ZFeatureMap`` から作成された量子カーネル"

#: ../../tutorials/07_pegasos_qsvc.ipynb:148
msgid "The implementation ``PegasosQSVC`` is compatible with the ``scikit-learn`` interfaces and has a pretty standard way of training a model. In the constructor we pass parameters of the algorithm, in this case there are a regularization hyper-parameter :math:`C` and a number of steps."
msgstr "``PegasosQSVC`` の実装は、 ``scikit-learn`` インターフェースと互換性があり、モデルをトレーニングするためのごく標準的な方法があります。コンストラクターでは、アルゴリズムのパラメーターを渡します。この場合、正則化ハイパーパラメーター :math:`C` といくつパラメーターかのステップがあります。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:150
msgid "Then we pass training features and labels to the ``fit`` method, which trains a models and returns a fitted classifier."
msgstr "次に、トレーニングする特徴量とラベルを ``fit`` メソッドに渡し、学習済みの分類器を返します。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:152
msgid "Afterwards, we score our model using test features and labels."
msgstr "その後、テスト機能とラベルを使用してモデルにスコアを付けます。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:206
msgid "For visualization purposes we create a mesh grid of a predefined step that spans our minimum and maximum values we applied in MinMaxScaler. We also add some margin to the grid for better representation of the training and test samples."
msgstr "可視化を目的として、MinMaxScaler で適用した最小値と最大値にまたがる定義済みのステップのメッシュグリッドを作成します。また、トレーニングとテストのサンプルをより適切に表現するため、グリッドにマージンを追加します。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:231
msgid "We convert the grid to the shape compatible with the model, the shape should be ``(n_samples, n_features)``. Then for each grid point we predict a label. In our case predicted labels will be used for coloring the grid."
msgstr "グリッドをモデルと互換性のある形状に変換します。形状は ``(n_samples, n_features)`` である必要があります。次に、グリッドポイントごとのラベルを予測します。この場合、予測ラベルはグリッドの色付けに使用されます。"

#: ../../tutorials/07_pegasos_qsvc.ipynb:253
msgid "Finally, we plot our grid according to the labels/colors we obtained from the model. We also plot training and test samples."
msgstr "最後に、モデルから取得したラベル/色に従ってグリッドをプロットします。 また、トレーニングとテストのサンプルもプロットします。"

