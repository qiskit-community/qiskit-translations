msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-03-28 08:39+0000\n"
"PO-Revision-Date: 2023-03-28 10:34\n"
"Last-Translator: \n"
"Language: ja\n"
"Language-Team: Japanese\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ja\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/09_saving_and_loading_models.po\n"
"X-Crowdin-File-ID: 9887\n"

#: ../../tutorials/09_saving_and_loading_models.ipynb:9
msgid "This page was generated from `docs/tutorials/09_saving_and_loading_models.ipynb`__."
msgstr "このページは `docs/tutorials/09_saving_and_loading_models.ipynb`__ から生成されました。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:9
msgid "Saving, Loading Qiskit Machine Learning Models and Continuous Training"
msgstr "Qiskit機械学習モデルの保存、読み込み、継続的なトレーニング"

#: ../../tutorials/09_saving_and_loading_models.ipynb:11
msgid "In this tutorial we will show how to save and load Qiskit machine learning models. Ability to save a model is very important, especially when a significant amount of time is invested in training a model on a real hardware. Also, we will show how to resume training of the previously saved model."
msgstr "このチュートリアルでは、Qiskit機械学習モデルを保存およびロードする方法を示します。モデルを保存する機能は非常に重要です。特に、実際のハードウェアでモデルをトレーニングするためにかなりの時間が費やされている場合です。また、以前に保存したモデルのトレーニングを再開する方法も示します。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:13
msgid "In this tutorial we will cover how to:"
msgstr "このチュートリアルでは、次の方法について説明します。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:15
msgid "Generate a simple dataset, split it into training/test datasets and plot them"
msgstr "単純なデータセットを生成し、それをトレーニング/テストデータセットに分割してプロットします"

#: ../../tutorials/09_saving_and_loading_models.ipynb:16
msgid "Train and save a model"
msgstr "モデルをトレーニングして保存する"

#: ../../tutorials/09_saving_and_loading_models.ipynb:17
msgid "Load a saved model and resume training"
msgstr "保存したモデルをロードしてトレーニングを再開します"

#: ../../tutorials/09_saving_and_loading_models.ipynb:18
msgid "Evaluate performance of models"
msgstr "モデルのパフォーマンスを評価する"

#: ../../tutorials/09_saving_and_loading_models.ipynb:19
msgid "PyTorch hybrid models"
msgstr "PyTorchハイブリッドモデル"

#: ../../tutorials/09_saving_and_loading_models.ipynb:30
msgid "First off, we start from the required imports. We'll heavily use SciKit-Learn on the data preparation step. In the next cell we also fix a random seed for reproducibility purposes."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:64
msgid "We will be using two quantum simulators, in particular, two instances of the ``Sampler`` primitive. We'll start training on the first one, then will resume training on the second one. The approach shown in this tutorial can be used to train a model on a real hardware available on the cloud and then re-use the model for inference on a local simulator."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:88
msgid "1. Prepare a dataset"
msgstr "1. データセットの準備"

#: ../../tutorials/09_saving_and_loading_models.ipynb:90
msgid "Next step is to prepare a dataset. Here, we generate some data in the same way as in other tutorials. The difference is that we apply some transformations to the generated data. We generates ``40`` samples, each sample has ``2`` features, so our features is an array of shape ``(40, 2)``. Labels are obtained by summing up features by columns and if the sum is more than ``1`` then this sample is labeled as ``1`` and ``0`` otherwise."
msgstr "次のステップは、データセットを準備することです。ここでは、他のチュートリアルと同じ方法でいくつかのデータを生成します。違いは、生成されたデータにいくつかの変換を適用することです。 ``40`` のサンプルを生成し、各サンプルには ``2`` の特徴があるため、私たちの特徴は形状 ``(40, 2)`` の配列です。ラベルは、列ごとに特徴を合計することによって取得され、合計が ``1`` より大きい場合、このサンプルは ``1`` および ``0`` としてラベル付けされます。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:114
msgid "Then, we scale down our features into a range of ``[0, 1]`` by applying ``MinMaxScaler`` from SciKit-Learn. Model training convergence is better when this transformation is applied."
msgstr "次に、SciKit-Learnの ``MinMaxScaler`` を適用して、特徴量を ``[0, 1]`` の範囲に削減します。この変換を適用すると、モデルトレーニングの収束が向上します。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:161
msgid "Let's take a look at the features of the first ``5`` samples of our dataset after the transformation."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:219
msgid "We choose ``VQC`` or Variational Quantum Classifier as a model we will train. This model, by default, takes one-hot encoded labels, so we have to transform the labels that are in the set of ``{0, 1}`` into one-hot representation. We employ SciKit-Learn for this transformation as well. Please note that the input array must be reshaped to ``(num_samples, 1)`` first. The ``OneHotEncoder`` encoder does not work with 1D arrays and our labels is a 1D array. In this case a user must decide either an array has only one feature(our case!) or has one sample. Also, by default the encoder returns sparse arrays, but for dataset plotting it is easier to have dense arrays, so we set ``sparse`` to ``False``."
msgstr "トレーニングするモデルとして、``VQC`` または変分量子分類器を選択します。このモデルは、デフォルトでワンホットエンコードされたラベルを使用するため、 ``{0, 1}`` のセットに含まれるラベルをワンホット表現に変換する必要があります。この変換にもSciKit-Learnを採用しています。入力配列は、最初に ``(num_samples, 1)`` に再変換する必要があることに注意してください。 ``OneHotEncoder`` エンコーダーは一次元配列では機能せず、ラベルは一次元配列です。この場合、ユーザーは、配列に特徴量がひとつしかない（この場合！）か、サンプルがひとつあるかを判断する必要があります。また、デフォルトでは、エンコーダーはスパース配列を返しますが、データセットプロットの場合、密な配列を使用する方が簡単なので、 ``sparse`` を ``False`` に設定します。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:296
msgid "Let's take a look at the labels of the first ``5`` labels of the dataset. The labels should be one-hot encoded."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:354
#, python-format
msgid "Now we split our dataset into two parts: a training dataset and a test one. As a rule of thumb, 80% of a full dataset should go into a training part and 20% into a test one. Our training dataset has ``30`` samples. The test dataset should be used only once, when a model is trained to verify how well the model behaves on unseen data. We employ ``train_test_split`` from SciKit-Learn."
msgstr "次に、データセットをトレーニングデータセットとテストデータセットの2つの部分に分割します。経験則として、完全なデータセットの80％はトレーニング部分に、20％はテスト部分に入れる必要があります。トレーニングデータセットには ``30`` のサンプルがあります。テストデータセットは、モデルが見えないデータでどの程度適切に動作するかを検証するためにモデルがトレーニングされている場合に、一度だけ使用する必要があります。SciKit-Learnの ``train_test_split`` を採用しています。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:403
msgid "Now it is time to see how our dataset looks like. Let's plot it."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:470
msgid "On the plot above we see:"
msgstr "上記のプロットでは、次のようになります。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:472
msgid "Solid blue dots are the samples from the training dataset labeled as ``0``"
msgstr "青に塗られた点は、 ``0`` というラベルの付いたトレーニングデータセットからのサンプルです。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:473
msgid "Empty blue dots are the samples from the test dataset labeled as ``0``"
msgstr "青い枠線だけの点は、 ``0`` というラベルの付いたテストデータセットからのサンプルです。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:474
msgid "Solid green dots are the samples from the training dataset labeled as ``1``"
msgstr "緑に塗られた点は、 ``1`` というラベルの付いたトレーニングデータセットからのサンプルです。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:475
msgid "Empty green dots are the samples from the test dataset labeled as ``1``"
msgstr "緑色の枠線だけの点は、 ``1`` というラベルの付いたテストデータセットからのサンプルです。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:477
msgid "We'll train our model using solid dots and verify it using empty dots."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:489
msgid "2. Train a model and save it"
msgstr "2. モデルをトレーニングして保存する"

#: ../../tutorials/09_saving_and_loading_models.ipynb:491
msgid "We'll train our model in two steps. On the first step we train our model in ``20`` iterations."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:512
msgid "Create an empty array for callback to store values of the objective function."
msgstr "目的関数の値を格納するためのコールバック用の空の配列を作成します。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:533
msgid "We re-use a callback function from the Neural Network Classifier & Regressor tutorial to plot iteration versus objective function value with some minor tweaks to plot objective values at each step."
msgstr "ニューラル・ネットワーク分類（Neural Network Classifier & Regressor）のチュートリアルのコールバック関数を再利用して、反復と目的関数の値をプロットし、いくつかの微調整を加えて、各ステップで目的値をプロットします。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:576
msgid "As mentioned above we train a ``VQC`` model and set ``COBYLA`` as an optimizer with a chosen value of the ``maxiter`` parameter. Then we evaluate performance of the model to see how well it was trained. Then we save this model for a file. On the second step we load this model and will continue to work with it."
msgstr "上記のように、 ``VQC`` モデルをトレーニングし、 ``maxiter`` パラメーターの選択された値を使用して ``COBYLA`` をオプティマイザーとして設定します。次に、モデルのパフォーマンスを評価して、モデルがどの程度適切にトレーニングされたかを確認します。次に、このモデルをファイルに保存します。2番目のステップでは、このモデルをロードし、引き続き作業します。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:578
msgid "Here, we manually construct an ansatz to fix an initial point where to start optimization from."
msgstr "ここでは、最適化を開始する最初のポイントを修正するために、手動で ansatzを作成します。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:602
msgid "We create a model and set a sampler to the first sampler we created earlier."
msgstr "モデルを作成し、sampler を先ほど作成した最初のsampler に設定します。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:625
msgid "Now it is time to train the model."
msgstr "次に、モデルをトレーニングします。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:680
msgid "Let's see how well our model performs after the first step of training."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:729
msgid "Next, we save the model. You may choose any file name you want. Please note that the ``save`` method does not append an extension if it is not specified in the file name."
msgstr "次に、モデルを保存します。任意のファイル名を選択できます。ファイル名に拡張子が指定されていない場合、 ``save`` メソッドは拡張子を追加しないことに注意してください。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:751
msgid "3. Load a model and continue training"
msgstr "3. モデルをロードし、トレーニングを続行する"

#: ../../tutorials/09_saving_and_loading_models.ipynb:753
msgid "To load a model a user have to call a class method ``load`` of the corresponding model class. In our case it is ``VQC``. We pass the same file name we used in the previous section where we saved our model."
msgstr "モデルをロードするには、ユーザーは対応するモデルクラスのクラスメソッド ``load`` を呼び出す必要があります。 私たちの場合は ``VQC`` です。モデルを保存した前のセクションで使用したのと同じファイル名を渡します。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:774
msgid "Next, we want to alter the model in a way it can be trained further and on another simulator. To do so, we set the ``warm_start`` property. When it is set to ``True`` and ``fit()`` is called again the model uses weights from previous fit to start a new fit. We also set the ``sampler`` property of the underlying network to the second instance of the ``Sampler`` primitive we created in the beginning of the tutorial. Finally, we create and set a new optimizer with ``maxiter`` is set to ``80``, so the total number of iterations is ``100``."
msgstr "次に、このモデルをさらに別のシミュレーターで学習できるように変更したいと思います。そのために、 ``warm_start`` プロパティを設定します。このプロパティを ``True`` に設定し、再び ``fit()`` を呼び出すと、モデルは前回のフィットで得られた重みを使用して、新しいフィットを開始します。また、基礎となるネットワークの ``sampler`` プロパティを、チュートリアルの最初に作成した ``Sampler`` primitive の2番目のインスタンスに設定します。最後に、新しいオプティマイザーを作成し、 ``maxiter`` を ``80`` に設定して、反復処理の合計回数を ``100`` に設定します。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:798
msgid "Now we continue training our model from the state we finished in the previous section."
msgstr "次に、前のセクションで終了した状態からモデルのトレーニングを続けます。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:891
msgid "Let's see which data points were misclassified. First, we call ``predict`` to infer predicted values from the training and test features."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:913
msgid "Plot the whole dataset and the highlight the points that were classified incorrectly."
msgstr "データセット全体をプロットし、誤って分類されたポイントを強調表示します。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:989
msgid "So, if you have a large dataset or a large model you can train it in multiple steps as shown in this tutorial."
msgstr "したがって、大きなデータセットまたは大きなモデルがある場合は、このチュートリアルに示すように、複数のステップでトレーニングできます。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:1001
msgid "4. PyTorch hybrid models"
msgstr "4. PyTorchハイブリッドモデル"

#: ../../tutorials/09_saving_and_loading_models.ipynb:1003
msgid "To save and load hybrid models, when using the TorchConnector, follow the PyTorch recommendations of saving and loading the models. For more details please refer to the PyTorch Connector tutorial `here <https://qiskit.org/documentation/machine-learning/tutorials/05_torch_connector.html>`__ where a short snippet shows how to do it."
msgstr "ハイブリッドモデルを保存およびロードするには、TorchConnector を使用する場合、モデルの保存およびロードに関する PyTorch の推奨事項に従ってください。 詳細については、 `こちら <https://qiskit.org/documentation/machine-learning/tutorials/05_torch_connector.html>`__ のPyTorch Connectorチュートリアルを参照してください。ここでは、短いスニペットでその方法を示しています。"

#: ../../tutorials/09_saving_and_loading_models.ipynb:1005
msgid "Take a look at this pseudo-like code to get the idea:"
msgstr "この疑似的なコードを見て、アイデアを見つけてください。"

