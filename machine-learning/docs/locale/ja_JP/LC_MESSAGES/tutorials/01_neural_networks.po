msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-08 23:29+0000\n"
"PO-Revision-Date: 2022-11-08 23:43\n"
"Last-Translator: \n"
"Language-Team: Japanese\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ja\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/01_neural_networks.po\n"
"X-Crowdin-File-ID: 9628\n"
"Language: ja_JP\n"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/01_neural_networks.ipynb`__."
msgstr "このページは `docs/tutorials/01_neural_networks.ipynb`__ から生成されました。"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "量子ニューラル・ネットワーク"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "このノートブックでは、 Qiskit 機械学習で提供される、さまざまな汎用的な量子ニューラル・ネットワーク (QNN) の実装を紹介します。 このネットワークは、アプリケーションに依存しない計算ユニットとして、様々なユースケースに使用することができます。アプリケーションによっては、特定のタイプのネットワークが適していたり、適していなかったり、特定の方法でセットアップする必要があったりします。ここでは、次のような種類のニューラルネットワークについて、詳しく説明します。"

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks. This is an abstract class."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``EstimatorQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``SamplerQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:17
msgid "Each implementation, ``EstimatorQNN`` and ``SamplerQNN``, takes in an optional instance of the corresponding Qiskit primitive, namely ``BaseEstimator`` and ``BaseSampler``. The latter two define two interfaces of the primitives. Qiskit provides the reference implementation as well as a backend-based implementation of the primitives. The primitives is a frontend to either a simulator or a real quantum hardware. By default, if no instance is passed to a network, an instance of the Qiskit reference primitive is created automatically by the network. For more information about primitives please refer to `Qiskit primitives <https://qiskit.org/documentation/apidoc/primitives.html>`__."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:45
msgid "1. ``NeuralNetwork``"
msgstr "1. ``NeuralNetwork``"

#: ../../tutorials/01_neural_networks.ipynb:47
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interfaces are introduced."
msgstr " ``NeuralNetwork`` は、Qiskit MachineLearningで利用可能なすべてのニューラルネットワークのインターフェースを表します。データサンプルとトレーニング可能な重みを入力として取得する順伝播パスと逆伝搬パスを公開します。  ``NeuralNetwork`` にはトレーニング機能は含まれていません。これらは、実際のアルゴリズム/アプリケーションにプッシュされます。したがって、  ``NeuralNetwork`` は、トレーニング可能な重みの値も格納しません。以下では、このインターフェースのさまざまな実装を紹介します。"

#: ../../tutorials/01_neural_networks.ipynb:49
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes either flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr "``nn`` という ``NeuralNetwork``  を想定します。次に、 ``nn.forward(input, weights)``  パスは、データのフラット入力と、サイズ　``nn.num_inputs`` および ``nn.num_weights`` の重みをそれぞれ受け取ります。 ``NeuralNetwork`` は入力のバッチ処理をサポートし、対応する形状の出力のバッチを返します。"

#: ../../tutorials/01_neural_networks.ipynb:61
msgid "2. ``EstimatorQNN``"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:63
msgid "The ``EstimatorQNN`` takes in a parametrized quantum circuit with the combined network’s feature map (input parameters) and ansatz (weight parameters), as well as an optional quantum mechanical observable, and outputs expectation value computations for the forward pass. The quantum circuit parameters can be used to load classical data as well as represent trainable weights. The ``EstimatorQNN`` also allows lists of observables to construct more complex QNNs."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:109
msgid "We create an observable manually. If it is set, then The default observable :math:`Z^{\\otimes n}`, where :math:`n` is the number of qubits, is created automatically."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:132
msgid "Construct EstimatorQNN with the observable, input parameters, and weight parameters. We don’t set the ``estimator`` parameter, the network will create an instance of the reference ``Estimator`` primitive for us."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:323
msgid "Combining multiple observables in a list allows to create more complex QNNs."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:430
msgid "4. ``SamplerQNN``"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:432
msgid "The ``SamplerQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples are interpreted as probabilities of measuring the integer index corresponding to a bitstring. Gradients can be estimated efficiently and the ``SamplerQNN`` provides a backward pass as well."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:434
msgid "Further, the ``SamplerQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are aggregated accordingly."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:436
msgid "If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:478
msgid "As in the previous example, we don’t set the ``sampler`` parameter, the network will create an instance of the reference ``Sampler`` primitive for us."
msgstr ""

