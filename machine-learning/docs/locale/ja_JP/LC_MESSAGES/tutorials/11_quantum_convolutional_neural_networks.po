msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-03-28 08:39+0000\n"
"PO-Revision-Date: 2023-04-03 12:42\n"
"Last-Translator: \n"
"Language: ja\n"
"Language-Team: Japanese\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ja\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/11_quantum_convolutional_neural_networks.po\n"
"X-Crowdin-File-ID: 9840\n"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/11_quantum_convolutional_neural_networks.ipynb`__."
msgstr "このページは `docs/tutorials/11_quantum_convolutional_neural_networks.ipynb`__ から生成されました。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:9
msgid "The Quantum Convolution Neural Network"
msgstr "量子畳み込みニューラル・ネットワーク"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:21
msgid "1. Introduction"
msgstr "1. はじめに"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:32
msgid "Throughout this tutorial, we discuss a Quantum Convolutional Neural Network (QCNN), first proposed by Cong et. al. [1]. We implement such a QCNN on Qiskit by modeling both the convolutional layers and pooling layers using a quantum circuit. After building such a network, we train it to differentiate horizontal and vertical lines from a pixelated image. The following tutorial is thus divided accordingly;"
msgstr "このチュートリアルでは、Convolutional Neural Network(QCNN)の量子畳み込みニューラルネットワークについて説明します。[1]. 量子回路を使用して畳み込み層とプール層の両方をモデリングすることによって、QiskitにこのようなQCNNを実装します。 このようなネットワークを構築した後、ピクセル化された画像から水平線と垂直線を区別するように学習します。以下のチュートリアルはそれに応じて分割されます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:34
msgid "Differences between a QCNN and CCNN"
msgstr "QCNNとCCNNの違い"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:35
msgid "Components of a QCNN"
msgstr "QCNN の構成要素"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:36
msgid "Data Generation"
msgstr "データ生成"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:37
msgid "Building a QCNN"
msgstr "QCNN のビルド"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:38
msgid "Training our QCNN"
msgstr "QCNNのトレーニング"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:39
msgid "Testing our QCNN"
msgstr "QCNNのテスト"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:40
msgid "References"
msgstr "参考文献"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:42
msgid "We first begin by importing the libraries and packages we will need for this tutorial."
msgstr "まず始めに、このチュートリアルで必要となるライブラリーおよびパッケージをインポートします。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:78
msgid "1. Differences between a QCNN and CCNN"
msgstr "1. QCNNとCCNNの違い"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:90
msgid "1.1 Classical Convolutional Neural Networks"
msgstr "1.1 古典的な畳み込みニューラル・ネットワーク"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:101
msgid "Classical Convolutional Neural Networks (CCNNs) are a subclass of artificial neural networks which have the ability to determine particular features and patterns of a given input. Because of this, they are commonly used in image recognition and audio processing."
msgstr "Classical Convolutional Neural Networks (CCNNs) は、人工のニューラルネットワークのサブクラスであり、与えられた入力の特徴やパターンを決定することができます。 このため、画像認識処理や音声処理などで一般的に使用されています。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:103
msgid "The capability of determining features is a result of the two types of layers used in a CCNN, the convolutional layer and pooling layer."
msgstr "フィーチャーを決定するのは 、CCNN で使われている畳み込み層とプーリング層の２種類の層の結果です。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:105
msgid "An example of a CCNN can be seen in Figure 1, where a CCNN is trained to determine whether an input image either contains a cat or a dog. To do so, the input image passes through a series of alternating convolutional (C) and pooling layers (P), all of which detect patterns and associate each pattern to a cat or a dog. The fully connected layer (FC) provides us with an output which allows us to determine whether the input image was a cat or dog."
msgstr "CCNN の例を図 1 に示します。CCNN は、入力画像に猫と犬のどちらが含まれているかを判断するようにトレーニングされています。 そのために、入力画像は一連の畳み込み層 (C) とプーリング層 (P) を交互に通過します。すべての層でパターンが検出され、各パターンが猫または犬に関連付けられます。 全結合層 (FC) は、入力画像が猫か犬かを判断できる出力を提供します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:107
msgid "The convolutional layer makes use of a kernel, which can determine features and patterns of a particular input. An example of this is feature detection in an image, where different layers detect particular patterns in the input image. This is demonstrated in Figure 1, where the :math:`l^{th}` layer recognizes features and patterns along the :math:`ij` plane. It can then associate such features with a given output in the training process, and can use this process to train the dataset."
msgstr "畳み込み層はカーネルを利用し、特定の入力の特徴量やパターンを決定することができます。この例は画像の特徴量検出であり、異なる層が入力画像中の特定のパターンを検出します。これは図1に示されており、 :math:`l^{th}` 層は :math:`ij` 平面に沿って特徴やパターンを認識します。そして、学習プロセスにおいて、そのような特徴量を与えられた出力と関連付けることができ、このプロセスを用いてデータセットを学習させることができます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:109
msgid "On the other hand, a pooling layer reduces the dimensionality of the input data, reducing the computational cost and amount of learning parameters in the CCNN. A schematic of a CCNN can be seen below."
msgstr "一方、プーリング層は入力データの次元を減らし、CCNNの計算コストと学習パラメーターの量を減らすことができます。CCNNの模式図を以下に示します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:111
msgid "For further information on CCNN, see [2]."
msgstr "CCNNの詳細については、 [2] を参照してください。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:122
msgid "|Screenshot%202022-08-09%20at%2017.03.09.png| Figure 1. A schematic demonstration of the use of a CCNN to classify between images of a cat and dog. Here, we see the several convolutional and pooling layers being applied, all of which are decreasing in dimensionality due to the use of the pooling layers. The output of the CCNN determines whether the input image was a cat or dog. Image obtained form [1]."
msgstr "|Screenshot%2022-08-09%20at%2017.03.09.png| 図1. 猫と犬の画像の間を分類するためにCCNNを使用する概略的なデモンストレーション。ここでは、いくつかの畳み込み層とプーリング層が適用されており、プーリング層の使用により、すべての次元が減少していることがわかります。CCNNの出力は、入力画像が猫であるか犬であるかを決定します。画像は[1]の形から得られました。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:124
msgid "Screenshot%202022-08-09%20at%2017.03.09.png"
msgstr "Screenshot%202022-08-09%20at%2017.03.09.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:136
msgid "1.2 Quantum Convolutional Neural Networks"
msgstr "1.2 量子畳み込みニューラル・ネットワーク"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:147
msgid "Quantum Convolutional Neural Networks (QCNN) behave in a similar manner to CCNNs. First, we encode our pixelated image into a quantum circuit using a given feature map, such Qiskit's ZFeatureMap or ZZFeatureMap or others available in the circuit library."
msgstr "量子畳み込みニューラルネットワーク（QCNN）は、CCNNと同様の動作をします。まず、QiskitのZFeatureMapやZZFeatureMapなど、circuit ライブラリーにある所定の特徴量マップを用いて、画素化した画像を量子回路にエンコードします。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:149
msgid "After encoding our image, we apply alternating convolutional and pooling layers, as defined in the next section. By applying these alternating layers, we reduce the dimensionality of our circuit until we are left with one qubit. We can then classify our input image by measuring the output of this one remaining qubit."
msgstr "画像を符号化した後、次のセクションで定義するように、畳み込み層とプーリング層を交互に適用します。これらの層を交互に適用することで、回路の次元を減らし、1つの量子ビットを残すことができます。そして、この残った1つの量子ビットの出力を測定することで、入力画像を分類することができます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:151
msgid "The Quantum Convolutional Layer will consist of a series of two qubit unitary operators, which recognize and determine relationships between the qubits in our circuit. This unitary gates are defined below in the next section."
msgstr "量子畳み込み層は一連の2量子ビットユニタリー演算子で構成され、回路内の量子ビットの関係を認識し決定します。このユニタリーゲートは次のセクションで定義されます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:153
msgid "For the Quantum Pooling Layer, we cannot do the same as is done classically to reduce the dimension, i.e. the number of qubits in our circuit. Instead, we reduce the number of qubits by performing operations upon each until a specific point and then disregard certain qubits in a specific layer. It is these layers where we stop performing operations on certain qubits that we call our 'pooling layer'. Details of the pooling layer is discussed further in the next section."
msgstr "量子プーリング層では、古典的に行われているような、回路の次元、すなわち量子ビットの数を減らすようなことはできません。その代わりに、ある時点まで各量子ビットの演算を行い、特定の層で特定の量子ビットを無視することによって、量子ビット数を減らします。特定の量子ビットの演算を停止するこれらの層を、私たちは「プーリング層」と呼んでいます。プーリング層の詳細については、次のセクションでさらに説明します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:155
msgid "In the QCNN, each layer contains parametrized circuits, meaning we alter our output result by adjusting the parameters of each layer. When training our QCNN, it is these parameters that are adjusted to reduce the loss function of our QCNN."
msgstr "QCNNでは各層にパラメーター化された回路があり、各層のパラメーターを調整することで出力結果を変化させられます。QCNNを学習する際には、これらのパラメーターを調整し、QCNNの損失関数を減少させます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:166
msgid "A simple example of four qubit QCNN can be seen below."
msgstr "4量子ビットのQCNNの簡単な例を以下に示します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:177
msgid "|figure2.png|"
msgstr "|figure2.png|"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:179
msgid "figure2.png"
msgstr "figure2.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:190
msgid "Figure 2: Example QCNN containing four qubits. The first Convolutional Layer acts on all the qubits. This is followed by the first pooling layer, which reduces the dimensionality of the QCNN from four qubits to two qubits by disregarding the first two. The second Convolutional layer then detects features between the two qubits still in use in the QCNN, followed by another pooling layer, which reduces the dimensionality from two qubits to one, which will be our output qubit."
msgstr "図2: 4つの量子ビットを含むQCNNの例。最初の畳み込み層は全ての量子ビットに作用します。これは最初の2つの量子ビットを無視することによって、QCNNの次元を4つの量子ビットから2つの量子ビットに減少させるものです。次に2番目の畳み込み層が、QCNNでまだ使用されている2つの量子ビットの間の特徴を検出し、さらにプーリング層が続いて、2つの量子ビットから1つに次元を減少させ、これが我々の出力量子ビットとなります。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:202
msgid "2. Components of a QCNN"
msgstr "2. QCNN の構成要素"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:213
msgid "As discussed in Section 1 of this tutorial, a CCNN will contain both convolutional and pooling layers. Here, we define these layers for the QCNN in terms of gates applied to a Quantum Circuit and demonstrate an example for each layer for 4 qubits."
msgstr "このチュートリアルのセクション 1 で議論したように、CCNN は畳み込み層とプーリング層の両方を含むことになります。ここでは、量子回路に適用されるゲートという観点から QCNN のためにこれらの層を定義し、4量子ビットのための各層の例を示します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:215
msgid "Each of these layers will contain parameters which are tuned throughout the training process to minimize the loss function and train the QCNN to classify between horizontal and vertical lines."
msgstr "これらの各層は、損失関数を最小化し、QCNNが水平線と垂直線を分類するように学習プロセスを通じて調整されるパラメーターを含んでいます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:217
msgid "In theory, one could apply any parametrized circuit for both the convolutional and pooling layers of our network. For example in [2], the Gellmann Matrices (which are the three dimensional generalization of the Pauli Matrices) are used as generators for each unitary gate acting on a pair of qubits."
msgstr "理論的には、我々のネットワークの畳み込み層とプーリング層の両方に、任意のパラメーター化された回路を適用することができます。例えば、[2] では、Gellmann行列(Pauli行列の3次元一般化) が、1組の量子ビットに作用する各ユニタリーゲートの生成子として使用されています。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:219
msgid "Here, we take a different approach and form our parametrized circuit based on the two qubit unitary as proposed in [3]. This states that every unitary matrix in :math:`U(4)` can be decomposed such that"
msgstr "ここでは、異なるアプローチとして、[3]で提案された2量子ビットのユニタリーに基づいてパラメーター化された回路を構成します。これは、 :math:`U(4)` のすべてのユニタリー行列が、以下のように分解できることを述べています。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:221
msgid "U = (A_1 \\otimes A_2) \\cdot N(\\alpha, \\beta, \\gamma) \\cdot (A_3 \\otimes A_4)\n\n"
msgstr "U = (A_1 \\otime A_2) \\cdot N(\\alpha, \\beta, \\gamma) \\cdot (A_3 \\otime A_4)\n\n"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:223
msgid "where :math:`A_j \\in \\text{SU}(2)`, :math:`\\otimes` is the tensor product, and :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])`, where :math:`\\alpha, \\beta, \\gamma` are the parameters that we can adjust."
msgstr "ここで、 :math:`A_j \\in \\text{SU}(2)` 、 :math:`\\otimes` はテンソル積、 :math:`N(\\alpha, \\beta, \\gamma) = exp(i [\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])` 、ここで :math:`\\alpha, \\beta, \\gamma` は調整できるパラメーターです。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:225
msgid "From this, it is evident that each unitary depends on 15 parameters and implies that in order for the QCNN to be able to span the whole Hilbert space, each unitary in our QCNN must contain 15 parameters each."
msgstr "このことから、各ユニタリーは15個のパラメーターに依存しており、QCNNがHilbert空間全体をカバーするためには、我々のQCNNの各ユニタリーはそれぞれ15個のパラメーターを含んでいなければならないことがわかります。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:227
msgid "Tuning this large amount of parameters would be difficult and would lead to long training times. To overcome this problem, we restrict our ansatz to a particular subspace of the Hilbert space and define the two qubit unitary gate as :math:`N(\\alpha, \\beta, \\gamma)`. These two qubit unitaries, as seen in [3] can be seen below and are applied to all neighboring qubits each of the layers in the QCNN."
msgstr "この大量のパラメーターを調整するのは難しく、学習時間が長くなってしまいます。この問題を克服するために、私たちはansatzをヒルベルト空間の特定の部分空間に制限し、2量子ビットユニタリーゲートを :math:`N(\\alpha, \\beta, \\gamma)` として定義します。これらの2量子ビットのユニタリーは[3]に見られるように、QCNNの各層で隣接するすべての量子ビットに適用されるもので、以下のようになります。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:229
msgid "Note that by only using :math:`N(\\alpha, \\beta, \\gamma)` as our two qubit unitary for the parametrized layers, we are restricting our QCNN to a particular subspace, one in which the optimal solution may not be contained in and reducing the accuracy of the QCNN. For the purpose of this tutorial, we will use this parametrized circuit to decrease the training time of our QCNN."
msgstr "QCNN を特定の部分空間に限定することで、最適解が含まれない可能性があり、QCNN の精度が低下することに注意してください。このチュートリアルの目的では、このパラメーター化された回路を使ってQCNNの学習時間を短縮することにします。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:240
msgid "|circuit2.png|"
msgstr "|circuit2.png|"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:242
msgid "circuit2.png"
msgstr "circuit2.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:253
msgid "Figure 3: Parametrized two qubit unitary circuit for :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])` as seen in [3], where :math:`\\alpha = \\frac{\\pi}{2} - 2\\theta`, :math:`\\beta = 2\\phi - \\frac{\\pi}{2}` and :math:`\\gamma = \\frac{\\pi}{2} - 2\\lambda` as seen in the circuit. This two qubit unitary will be applied to all neighboring qubits in our feature map."
msgstr "図 3: :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ] のパラメーター化された 2 量子ビット ユニタリー回路 )` [3] に見られるように、ここで :math:`\\alpha = \\frac{\\pi}{2} - 2\\theta`, :math:`\\beta = 2\\phi - \\frac{\\pi}{2}` と :math:`\\gamma = \\frac{\\pi}{2} - 2\\lambda` が回路に見られます。 この 2 量子ビットユニタリーは、特徴量マップ内の隣接するすべての量子ビットに適用されます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:265
msgid "2.1 Convolutional Layer"
msgstr "2.1 畳み込み層"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:276
msgid "The next step in this tutorial is to define the Convolutional Layers of our QCNN. These layers are then applied to the qubits after the data has been encoded through use of the feature map."
msgstr "このチュートリアルの次のステップは、QCNNの畳み込み層を定義することです。これらの層は、データが特徴量マップの使用によりエンコードされた後、量子ビットに適用されます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:278
msgid "To do so we first need to determine a parametrized unitary gate, which will be used to create our convolutional and pooling layers."
msgstr "そのためには、まず、畳み込み層とプーリング層の作成に使用するパラメーター化されたユニタリーゲートを決定する必要があります。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:325
msgid "Now that we have defined these unitaries, it is time to create a function for the convolutional layer in our QCNN. To do so, we apply the two qubit unitary to neighboring qubits as seen in the ``conv_layer`` function below."
msgstr "さて、これらのユニタリーを定義したところで、QCNNの畳み込み層の関数を作成することにします。これを行うには、以下の ``conv_layer`` 関数で見られるように、隣接する量子ビットに2量子ビットのユニタリーを適用します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:327
msgid "Note that we first apply the two qubit unitary to all even pairs of qubits followed by applying to odd pairs of qubits in a circular coupling manner, i.e. the as well as neighboring qubits being coupled, the first and final qubit are also coupled through a unitary gate."
msgstr "つまり、隣接する量子ビットが結合されるのと同様に、最初と最後の量子ビットもユニタリーゲートを通して結合されるのです。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:329
msgid "Note that we add barriers into our quantum circuits for convenience when plotting, however they are not required for the actual QCNN and can be extracted from the following circuits."
msgstr "なお、プロットする際の便宜上、量子回路にバリアーを追加していますが、実際のQCNNでは不要であり、以下の回路から削除することが可能です。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:382
msgid "2.2 Pooling Layer"
msgstr "2.2 プーリング層"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:393
msgid "The purpose of a pooling layer is to reduce the dimensions of our Quantum Circuit, i.e. reduce the number of qubits in our circuit, while retaining as much information as possible from previously learned data. Reducing the amount of qubits also reduces the computational cost of the overall circuit, as the number of parameters that the QCNN needs to learn decreases."
msgstr "プーリング層の目的は、以前に学習したデータからできるだけ多くの情報を保持しながら、量子回路の次元を小さくすること、すなわち回路の量子ビットの数を減らすことです。量子ビットの数を減らすことは、QCNNが学習する必要のあるパラメーターの数が減るため、回路全体の計算コストも減らすことができます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:395
msgid "However, one cannot simply decrease the amount of qubits in our quantum circuit. Because of this, we must define the pooling layer in a different manner compared with the classical approach."
msgstr "しかし、量子回路に含まれる量子ビットの数を単純に減らすことはできません。このため、古典的なアプローチとは異なる方法でプーリング層を定義する必要があります。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:397
msgid "To 'artificially' reduce the number of qubits in our circuit, we first begin by creating pairs of the :math:`N` qubits in our system."
msgstr "回路内の量子ビットの数を「人為的に」減らすために、まずシステム内の :math:`N` 個の量子ビットのペアを作ることから始めます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:399
msgid "After initially pairing all the qubits, we apply our generalized 2 qubit unitary to each pair, as described previously. After applying this two qubit unitary, we then ignore one qubit from each pair of qubits for the remainder of the neural network."
msgstr "最初にすべての量子ビットをペアリングした後、前述のように一般化された2量子ビットユニタリーを各ペアに適用します。この2量子ビットのユニタリーを適用した後、ニューラルネットワークの残りの部分では、各ペアの量子ビットから1つの量子ビットを無視します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:401
msgid "This layer therefore has the overall effect of 'combining' the information of the two qubits into one qubit by first applying the unitary circuit, encoding information from one qubit into another, before disregarding one of qubits for the remainder of the circuit and not performing any operations or measurements on it."
msgstr "この層は、まずユニタリー回路を適用して、1つの量子ビットの情報を別の量子ビットに符号化し、残りの回路では一方の量子ビットを無視し、それに対していかなる演算や測定も行わないことで、2つの量子ビットの情報を1つに「結合」する全体効果を持ちます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:403
msgid "We note that one could also apply a dynamic circuit to reduce the dimensionality in the pooling layers. This would involve performing measurements on certain qubits in the circuit and having an intermediate classical feedback loop in our pooling layers. By applying these measurements, one would also be reducing the dimensionality of the circuit."
msgstr "プーリング層の次元を減らすために動的回路を適用することも可能であることに留意してください。これは、回路内の特定の量子ビットの測定を行い、我々のプーリング層に中間的な古典的なフィードバック・ループを持たせることになります。これらの測定を適用することによって、回路の次元を減らすこともできるでしょう。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:405
msgid "In this tutorial, we apply the former approach, and disregard qubits in each pooling layer. Using this approach, we thus create a QCNN Pooling Layer which transforms the dimensions of our :math:`N` qubit Quantum Circuit to :math:`N/2`."
msgstr "このチュートリアルでは、前者のアプローチを適用し、各プーリング層の量子ビットを無視します。このアプローチを用いて、私たちは :math:`N` 量子回路の次元を :math:`N/2` に変換するQCNNプーリング層を作成します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:407
msgid "To do so, we first define a two qubit unitary, which transforms the two qubit system to one."
msgstr "そのために、まず、2量子ビット系を1量子ビットに変換する2量子ビットユニタリーを定義します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:451
msgid "After applying this two qubit unitary circuit, we neglect the first qubit (q0) in future layers and only use the second qubit (q1) in our QCNN"
msgstr "この2量子ビットのユニタリー回路を適用した後、その後の層では第1量子ビット (q0) を無視し、第2量子ビット (q1) のみをQCNNで使用します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:453
msgid "We apply this two qubit pooling layer to different pairs of qubits to create our pooling layer for N qubits. As an example we then plot it for four qubits."
msgstr "この2量子ビットのプーリング層を異なる量子ビットのペアに適用し、N量子ビットのプーリング層を作成します。例として、4つの量子ビットについてプロットしてみます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:503
msgid "In this particular example, we reduce the dimensionality of our four qubit circuit to the last two qubits, i.e. the last two qubits in this particular example. These qubits are then used in the next layer, while the first two are neglected for the remainder of the QCNN."
msgstr "この特定の例では、4つの量子ビット回路の次元を最後の2つの量子ビットにまで縮小します。これらの量子ビットは次の層で使用され、最初の2つはQCNNの残りの部分では無視されます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:515
msgid "3. Data Generation"
msgstr "3. データ生成"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:526
msgid "One common use of a CCNN is an image classifier, where a CCNN detects particular features and patterns (such as straight lines or curves) of the pixelated images through the use of the feature maps in the convolutional layer. By learning the relationship between these features, it can then classify and label handwritten digits with ease."
msgstr "CCNNは、畳み込み層の特徴量マップを利用して、ピクセル化された画像の特定の特徴やパターン (直線や曲線など) を検出することができます。これらの特徴量間の関係を学習することで、手書きの数字を簡単に分類し、ラベル付けすることができます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:528
msgid "Because of a classical CNN's ability to recognize features and patterns easily, we will train our QCNN to also determine patterns and features of a given set of pixelated images, and classify between two different patterns."
msgstr "古典的なCNNは特徴やパターンを簡単に認識できるため、QCNNも与えられた画素画像のパターンや特徴を判断し、2つの異なるパターンの間で分類できるように訓練します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:530
msgid "To simplify the dataset, we only consider 2 x 4 pixelated images. The patterns we will train the QCNN to distinguish will be a horizontal or vertical line, which can be placed anywhere in the image, alongside a noisy background."
msgstr "データセットを単純化するために、我々は2×4ピクセルの画像のみを考慮します。QCNNが識別するために訓練するパターンは、水平または垂直の線であり、画像内のどこにでも配置でき、ノイズの多い背景と一緒に配置できます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:532
msgid "We first begin by generating this dataset. To create a 'horizontal' or 'vertical' line, we assign pixels value to be :math:`\\frac{\\pi}{2}` which will represent the line in our pixelated image. We create a noisy background by assigning every other pixel a random value between :math:`0` and :math:`\\frac{\\pi}{4}` which will create a noisy background."
msgstr "まず、このデータセットを生成することから始めます。 「水平」または「垂直」な線を作成するために、ピクセル値を :math:`frac{\\pi}{2}` に割り当てます。これは、ピクセル化された画像中の線を表現します。他のピクセルには :math:`0` から :math:`frac{\\pi}{4}` の間のランダムな値を割り当てて、ノイズの多い背景を作成します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:534
msgid "Note that when we create our dataset, we need to split it into the training set and testing set of images, the datasets we train and test our neural network respectively."
msgstr "なお、データセットを作成する際には、画像のトレーニングセットとテストセットに分割する必要があり、それぞれニューラルネットワークのトレーニングとテストを行うデータセットとなります。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:536
msgid "We also need to label our datasets such that the QCNN can learn to differentiate between the two patterns. In this example we label images with a horizontal line with -1 and images with a vertical line +1."
msgstr "また、QCNNが2つのパターンを区別することを学習できるように、データセットにラベル付けする必要があります。この例では、横線のある画像に-1、縦線のある画像に+1のラベルを付けます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:591
msgid "Let's now create our dataset below and split it into our test and training datasets."
msgstr "それでは、以下のようにデータセットを作成し、テスト用とトレーニング用のデータセットに分割してみましょう。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:616
msgid "Let's see some examples in our dataset"
msgstr "データセットでいくつかの例を見てみましょう。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:651
msgid "As we can see each image contains either a vertical or horizontal line, that the QCNN will learn how to differentiate. Now that we have built our dataset, it is time to discuss the components of the QCNN and build our model."
msgstr "見ての通り、各画像には縦線と横線があり、QCNNはそれを区別する方法を学習します。さて、データセットが構築できたので、次はQCNNの構成要素について議論し、モデルを構築する番です。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:663
msgid "4. Modeling our QCNN"
msgstr "4. QCNNのモデリング"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:674
msgid "Now that we have defined both the convolutional layers it is now time to build our QCNN, which will consist of alternating pooling and convolutional layers."
msgstr "さて、両方の畳み込み層を定義したので、次は QCNN を構築する番であり、プーリング層と畳み込み層を交互に構成します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:676
msgid "As the images in our dataset contains 8 pixels, we will use 8 qubits in our QCNN."
msgstr "データセットの画像は8ピクセルであるため、QCNNでは8個の量子ビットを使用することにします。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:678
msgid "We encode our dataset into our QCNN by applying a feature map. One can create a feature map using one of Qiskit's built in feature maps, such as ZFeatureMap or ZZFeatureMap."
msgstr "我々は、特徴量マップを適用することによってデータセットをQCNNにエンコードします。特徴量マップは、ZFeatureMapやZZFeatureMapなど、Qiskitに組み込まれている特徴量マップのいずれかを使用して作成することができます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:680
msgid "After analyzing several different Feature maps for this dataset, it was found that QCNN obtains the greatest accuracy when the Z feature map is used. Therefore, throughout the remainder of the tutorial we will use the Z feature Map, of which can be seen below."
msgstr "このデータセットに対していくつかの異なる特徴量マップを分析した結果、QCNN は Z feature mapを使用した場合に最も高い精度が得られることがわかりました。したがって、このチュートリアルの残りの部分では、以下に示すZ feature map を使用することにします。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:711
msgid "We create a function for our QCNN, which will contain three sets of alternating convolutional and pooling layers, which can be seen in the schematic below. Through the use of the pooling layers, we thus reduce the dimensionality of our QCNN from eight qubits to one."
msgstr "QCNNの関数を作成します。この関数は、以下の概略図に見られるように、畳み込み層とプーリング層を3つ交互に含みます。プーリング層の使用により、我々はQCNNの次元を8量子ビットから1量子ビットに減少させることができます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:722
msgid "|Screenshot%202022-08-10%20at%2021.42.39.png|"
msgstr "|Screenshot%202022-08-10%20at%2021.42.39.png|"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:724
msgid "Screenshot%202022-08-10%20at%2021.42.39.png"
msgstr "Screenshot%202022-08-10%20at%2021.42.39.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:735
msgid "To classify our image dataset of horizontal and vertical lines, we measure the expectation value of the Pauli Z operator of the final qubit. Based on the obtained value being +1 or -1, we can conclude that the input image contained either a horizontal or vertical line."
msgstr "水平線と垂直線の画像データセットを分類するために、最後の量子ビットのパウリZ演算子の期待値を測定します。得られた値が+1または-1であることに基づいて、入力画像に水平または垂直な線が含まれていると結論付けることができます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:747
msgid "5. Training our QCNN"
msgstr "5. QCNNのトレーニング"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:758
msgid "The next step is to build our model using our training data."
msgstr "次のステップは、学習データを使ってモデルを構築することです。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:760
msgid "To classify our system, we perform a measurement from the output circuit. The value we obtain will thus classify whether our input data contains either a vertical line or horizontal line."
msgstr "このシステムを分類するために、出力回路から計測を行います。この測定値により、入力データが縦線か横線かを分類します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:762
msgid "The measurement we have chosen in this tutorial is :math:`<Z>`, i.e. the expectation value of the Pauli Z qubit for the final qubit. Measuring this expectation value, we obtain +1 or -1, which correspond to a vertical or horizontal line respectively."
msgstr "このチュートリアルで選んだ測定値は :math:`<Z>` 、すなわち、最終的な量子ビットに対するPauli Z量子ビットの期待値です。この期待値を測定すると、+1または-1が得られ、それぞれ垂直線または水平線に対応します。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:837
msgid "We will also define a callback function to use when training our model. This allows us to view and plot the loss function per each iteration in our training process."
msgstr "また、モデルの学習時に使用するコールバック関数も定義します。これにより、学習過程における各反復ごとの損失関数を表示し、プロットすることができます。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:865
msgid "In this example, we will use the COBYLA optimizer to train our classifier, which is a numerical optimization method commonly used for classification machine learning algorithms."
msgstr "この例では、分類器の学習にCOBYLAオプティマイザーを使用します。これは、分類機械学習アルゴリズムによく使用される数値最適化手法です。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:867
msgid "We then place the the callback function, optimizer and operator of our QCNN created above into Qiskit's built in Neural Network Classifier, which we can then use to train our model."
msgstr "そして、上記で作成したQCNNのコールバック関数、オプティマイザー、演算子をQiskitに内蔵されたニューラルネットワーク分類器に配置し、それを使ってモデルの学習を行います。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:869
msgid "Since model training may take a long time we have already pre-trained the model for some iterations and saved the pre-trained weights. We'll continue training from that point by setting ``initial_point`` to a vector of pre-trained weights."
msgstr "モデルの学習には長い時間がかかる可能性があるため、すでにいくつかの反復で事前学習したモデルがあり、事前学習済みの重みを保存してあります。 ``initial_point`` に学習済みの重みのベクトルを設定することで、その時点から学習を継続することにします。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:898
msgid "After creating this classifier, we can train our QCNN using our training dataset and each image's corresponding label. Because we previously defined the callback function, we plot the overall loss of our system per iteration."
msgstr "この分類器を作成した後、学習データセットと各画像に対応するラベルを用いてQCNNを学習することができます。コールバック関数を定義したので、反復ごとのシステムの全体的な損失をプロットします。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:900
msgid "It may take some time to train the QCNN so be patient!"
msgstr "QCNNの学習には時間がかかるので、気長に待ちましょう。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:962
msgid "As we can see from above, the QCNN converges slowly, hence our ``initial_point`` was already close to an optimal solution. The next step is to determine whether our QCNN can classify data seen in our test image data set."
msgstr "上図からわかるように、QCNN はゆっくりと収束するので、``initial_point`` は既に最適解に近いものでした。次のステップは、このQCNNがテスト画像データセットに見られるデータを分類できるかどうかを判断することです。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:974
msgid "6. Testing our QCNN"
msgstr "6. QCNNのテスト"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:985
msgid "After building and training our dataset we now test whether our QCNN can predict images that are not from our test data set."
msgstr "データセットの構築と学習が完了したら、今度はQCNNがテストデータセット以外の画像を予測できるかどうかをテストしてみましょう。"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1052
msgid "From above, we can indeed see that our QCNN can classify horizontal and vertical lines! Congratulations! Through the use of quantum circuits and quantum convolutional and pooling layers, you have built a Quantum Convolutional Neural Network!"
msgstr "上図から、私たちのQCNNは水平線と垂直線を分類できることがわかります。おめでとうございます。量子回路と量子畳み込み層と量子プーリング層を使って、あなたは量子畳み込みニューラルネットワークを構築しました!"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1064
msgid "7. References"
msgstr "7. 参考文献"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1075
msgid "[1] Cong, I., Choi, S. & Lukin, M.D. Quantum convolutional neural networks. Nat. Phys. 15, 1273–1278 (2019). https://doi.org/10.1038/s41567-019-0648-8"
msgstr "[1] Cong, I., Choi, S. & Lukin, M.D. Quantum convolutional neural networks. Nat. Phys. 15, 1273–1278 (2019). https://doi.org/10.1038/s41567-019-0648-8"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1077
msgid "[2] IBM Convolutional Neural Networks https://www.ibm.com/cloud/learn/convolutional-neural-networks"
msgstr "[2] IBM Convolutional Neural Networks https://www.ibm.com/cloud/learn/convolutional-neural-networks"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1079
msgid "[3] Vatan, Farrokh, and Colin Williams. \"Optimal quantum circuits for general two-qubit gates.\" Physical Review A 69.3 (2004): 032315."
msgstr "[3] Vatan, Farrokh, and Colin Williams. “Optimal quantum circuits for general two-qubit gates.” Physical Review A 69.3 (2004): 032315."

