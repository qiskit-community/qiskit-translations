msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-08-24 12:38+0000\n"
"PO-Revision-Date: 2021-10-08 03:54\n"
"Last-Translator: \n"
"Language-Team: Japanese\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ja\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/05_torch_connector.po\n"
"X-Crowdin-File-ID: 9636\n"
"Language: ja_JP\n"

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "This page was generated from `docs/tutorials/05_torch_connector.ipynb`__."
msgstr "このページは `docs/tutorials/05_torch_connector.ipynb`__ から生成されました。"

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector and Hybrid QNNs"
msgstr "Torch コネクターおよびハイブリッド QNN"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial introduces Qiskit’s ``TorchConnector`` class, and demonstrates how the ``TorchConnector`` allows for a natural integration of any ``NeuralNetwork`` from Qiskit Machine Learning into a PyTorch workflow. ``TorchConnector`` takes a Qiskit ``NeuralNetwork`` and makes it available as a PyTorch ``Module``. The resulting module can be seamlessly incorporated into PyTorch classical architectures and trained jointly without additional considerations, enabling the development and testing of novel **hybrid quantum-classical** machine learning architectures."
msgstr "このチュートリアルでは、Qiskitの ``TorchConnector`` クラスを紹介します。そして、 ``TorchConnector`` が Qiskit 機械学習から PyTorch ワークフローに ``NeuralNetwork`` を自然に統合する方法を示します。 ``TorchConnector`` は Qiskitの ``NeuralNetwork`` を受け取り、PyTorchの ``Module`` として利用できるようにします。 得られたモジュールは、PyTorchの古典アーキテクチャーにシームレスに組み込むことができ、追加の考慮事項なしに一緒に学習することができます。 また、新しい **ハイブリッド量子古典** 機械学習アーキテクチャーの開発とテストを可能にします。"

#: ../../tutorials/05_torch_connector.ipynb:15
msgid "Content:"
msgstr "目次:"

#: ../../tutorials/05_torch_connector.ipynb:17
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__"
msgstr "`パート 1: 簡単な分類と回帰 <#Part-1:-Simple-Classification-&-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:19
msgid "The first part of this tutorial shows how quantum neural networks can be trained using PyTorch’s automatic differentiation engine (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) for simple classification and regression tasks."
msgstr "このチュートリアルの最初の部分は、PyTorchの自動微分エンジン( ``torch.autograd``、 `リンク <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) を使用して簡単な分類と回帰タスクのための量子ニューラルネットワークを学習させる方法を示しています。"

#: ../../tutorials/05_torch_connector.ipynb:21
msgid "`Classification <#1.-Classification>`__"
msgstr "`分類 <#1.-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:23
msgid "Classification with PyTorch and ``OpflowQNN``"
msgstr "PyTorch と ``OpflowQNN`` を用いた分類"

#: ../../tutorials/05_torch_connector.ipynb:24
msgid "Classification with PyTorch and ``CircuitQNN``"
msgstr "PyTorch と ``CircuitQNN`` を用いた分類"

#: ../../tutorials/05_torch_connector.ipynb:26
msgid "`Regression <#2.-Regression>`__"
msgstr "`回帰 <#2.-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:28
msgid "Regression with PyTorch and ``OpflowQNN``"
msgstr "PyTorchと ``OpflowQNN`` による回帰"

#: ../../tutorials/05_torch_connector.ipynb:30
msgid "`Part 2: MNIST Classification, Hybrid QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"
msgstr "`パート 2: MNIST 分類、ハイブリッドQNN <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"

#: ../../tutorials/05_torch_connector.ipynb:32
msgid "The second part of this tutorial illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow (in this case, a typical CNN architecture) to classify MNIST data in a hybrid quantum-classical manner."
msgstr "このチュートリアルの 2 番目の部分では、ハイブリッドの量子古典的な方法で MNIST データを分類するため、 (量子) ``NeuralNetwork`` をターゲットの PyTorch ワークフロー ( この場合は、典型的な CNN アーキテクチャー) に組み込む方法を説明しています。"

#: ../../tutorials/05_torch_connector.ipynb:74
msgid "Part 1: Simple Classification & Regression"
msgstr "パート 1: 簡単な分類と回帰"

#: ../../tutorials/05_torch_connector.ipynb:86
msgid "1. Classification"
msgstr "1. 分類"

#: ../../tutorials/05_torch_connector.ipynb:88
msgid "First, we show how ``TorchConnector`` allows to train a Quantum ``NeuralNetwork`` to solve a classification tasks using PyTorch’s automatic differentiation engine. In order to illustrate this, we will perform **binary classification** on a randomly generated dataset."
msgstr "最初に、``TorchConnector`` が PyTorch の自動微分エンジンを使用して、分類タスクを解決するために 量子 ``NeuralNetwork`` を学習させる方法を示します。 これを示すために、ランダムに生成されたデータセットに対し **バイナリ分類** を実行します。"

#: ../../tutorials/05_torch_connector.ipynb:144
msgid "A. Classification with PyTorch and ``OpflowQNN``"
msgstr "A. PyTorch と ``OpflowQNN`` を用いた分類"

#: ../../tutorials/05_torch_connector.ipynb:146
msgid "Linking an ``OpflowQNN`` to PyTorch is relatively straightforward. Here we illustrate this using the ``TwoLayerQNN``, a sub-case of ``OpflowQNN`` introduced in previous tutorials."
msgstr "``OpflowQNN`` を PyTorch にリンクするのは比較的簡単です。ここでは、前のチュートリアルで紹介した ``OpflowQNN`` のサブケースである ``TwoLayerQNN`` を使用して説明します。"

#: ../../tutorials/05_torch_connector.ipynb:254
msgid "Optimizer"
msgstr "オプティマイザー"

#: ../../tutorials/05_torch_connector.ipynb:256
msgid "The choice of optimizer for training any machine learning model can be crucial in determining the success of our training’s outcome. When using ``TorchConnector``, we get access to all of the optimizer algorithms defined in the [``torch.optim``] package (`link <https://pytorch.org/docs/stable/optim.html>`__). Some of the most famous algorithms used in popular machine learning architectures include *Adam*, *SGD*, or *Adagrad*. However, for this tutorial we will be using the L-BFGS algorithm (``torch.optim.LBFGS``), one of the most well know second-order optimization algorithms for numerical optimization."
msgstr "あらゆる機械学習モデルを学習させる上でオプティマイザーの選択は、学習の成果を決定する上で非常に重要です。 ``TorchConnector`` を使用する場合、[``torch.optim``] パッケージ (`リンク <https://pytorch.org/docs/stable/optim.html>`__) で定義されているすべてのオプティマイザー・アルゴリズムを使用できます。 一般的な機械学習アーキテクチャーで使用される最も有名なアルゴリズムには、*Adam*、*SGD*、または *Adagrad* があります。 しかし、このチュートリアルではL-BFGSアルゴリズム(``torch.optim.LBFGS``)を使用します。 数値最適化のための最もよく知られている2次最適化アルゴリズムの1つです。"

#: ../../tutorials/05_torch_connector.ipynb:260
msgid "Loss Function"
msgstr "損失関数"

#: ../../tutorials/05_torch_connector.ipynb:262
msgid "As for the loss function, we can also take advantage of PyTorch’s pre-defined modules from ``torch.nn``, such as the `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ or `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."
msgstr "損失関数については、`交差エントロピー <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ や `平均二乗誤差 <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ 損失といった、 ``torch.nn`` パッケージからPyTorchの事前定義モジュールを利用することができます。"

#: ../../tutorials/05_torch_connector.ipynb:264
msgid "**💡 Clarification :** In classical machine learning, the general rule of thumb is to apply a Cross-Entropy loss to classification tasks, and MSE loss to regression tasks. However, this recommendation is given under the assumption that the output of the classification network is a class probability value in the [0,1] range (usually this is achieved through a Softmax layer). Because the following example for ``TwoLayerQNN`` does not include such layer, and we don’t apply any mapping to the output (the following section shows an example of application of parity mapping with ``CircuitQNNs``), the QNN’s output can take any value in the range [-1,1]. In case you were wondering, this is the reason why this particular example uses MSELoss for classification despite it not being the norm (but we encourage you to experiment with different loss functions and see how they can impact training results)."
msgstr "**💡 解説 :** 古典機械学習において一般的な経験則は、分類タスクに交差エントロピー損失を適用し、回帰タスクにMSE損失を適用することです。 しかし、この推奨は、分類ネットワークの出力が [0 , 1] 範囲 (通常は Softmax レイヤーを介して達成) の分類確率値であることを前提としています。 ``TwoLayerQNN`` の以下の例にはそのようなレイヤーが含まれないため、また、出力にマッピングを適用することもない (次のセクションでは ``CircuitQNNs`` を使用したパリティ・マッピングの例を示します) ため、QNNの出力は、[-1,1] の範囲で任意の値を取ることができます。 因みに、これが、この特定の例でMSELossを一般的でないのにも関わらず分類に使用している理由です(ただし、さまざまな損失関数を試して、学習結果にどのような影響を与えるかを確認することをお勧めします)。"

#: ../../tutorials/05_torch_connector.ipynb:442
#: ../../tutorials/05_torch_connector.ipynb:674
msgid "The red circles indicate wrongly classified data points."
msgstr "赤い丸は、誤って分類されたデータポイントを示します。"

#: ../../tutorials/05_torch_connector.ipynb:454
msgid "B. Classification with PyTorch and ``CircuitQNN``"
msgstr "B. PyTorch と ``CircuitQNN`` を用いた分類"

#: ../../tutorials/05_torch_connector.ipynb:456
msgid "Linking an ``CircuitQNN`` to PyTorch requires a bit more attention than ``OpflowQNN``. Without the correct setup, backpropagation is not possible."
msgstr "``CircuitQNN`` を PyTorch にリンクするには、``OpflowQNN`` よりも少し注意が必要です。正しい設定がなければ、バックプロパゲーションはできません。"

#: ../../tutorials/05_torch_connector.ipynb:458
msgid "In particular, we must make sure that we are returning a dense array of probabilities in the network’s forward pass (``sparse=False``). This parameter is set up to ``False`` by default, so we just have to make sure that it has not been changed."
msgstr "特に、ネットワークのフォワードパス(``sparse=False``) に確率の密な配列を返していることを確認する必要があります。 このパラメーターはデフォルトでは ``False`` に設定されているため、変更されていないことを確認する必要があります。"

#: ../../tutorials/05_torch_connector.ipynb:460
msgid "**⚠️ Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``CircuitQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."
msgstr "**⚠️ 注意:** カスタムのinterpret関数を定義した場合 (例: ``parity``) 、期待する出力の形状 (例: ``2``) を明示的に指定する必要があります。``CircuitQNN`` の初期設定に関する詳細は、`公式のQiskitドキュメンテーション <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__ を参照してください。"

#: ../../tutorials/05_torch_connector.ipynb:523
#: ../../tutorials/05_torch_connector.ipynb:815
msgid "For a reminder on optimizer and loss function choices, you can go back to `this section <#Optimizer>`__."
msgstr "オプティマイザーと損失関数の選択について思い出すには、`このセクション <#Optimizer>`__ に戻ってください。"

#: ../../tutorials/05_torch_connector.ipynb:686
msgid "2. Regression"
msgstr "2. 回帰"

#: ../../tutorials/05_torch_connector.ipynb:688
msgid "We use a model based on the ``TwoLayerQNN`` to also illustrate how to perform a regression task. The chosen dataset in this case is randomly generated following a sine wave."
msgstr "``TwoLayerQNN`` に基づいたモデルを使用して、回帰タスクの実行方法を説明します。 今回選択されたデータセットは、正弦波に沿ってランダムに生成されたものです。"

#: ../../tutorials/05_torch_connector.ipynb:730
msgid "A. Regression with PyTorch and ``OpflowQNN``"
msgstr "A. PyTorchと ``OpflowQNN`` による回帰"

#: ../../tutorials/05_torch_connector.ipynb:741
msgid "The network definition and training loop will be analogous to those of the classification task using ``TwoLayerQNN``. In this case, we define our own feature map and ansatz, instead of using the default values."
msgstr "ネットワーク定義と学習ループは、``TwoLayerQNN`` を使用した分類タスクのものと類似しています。 この場合、デフォルト値を使用するのではなく、独自の特徴マップとansatzを定義します。"

#: ../../tutorials/05_torch_connector.ipynb:963
msgid "Part 2: MNIST Classification, Hybrid QNNs"
msgstr "パート 2: MNIST 分類、ハイブリッドQNN"

#: ../../tutorials/05_torch_connector.ipynb:965
msgid "In this second part, we show how to leverage a hybrid quantum-classical neural network using ``TorchConnector``, to perform a more complex image classification task on the MNIST handwritten digits dataset."
msgstr "2番目の部分では、``TorchConnector`` を使用したハイブリッドの量子古典的なニューラルネットワークの活用方法を示します。 より複雑な画像分類タスクをMNISTの手書きの数字データセットで実行します。"

#: ../../tutorials/05_torch_connector.ipynb:967
msgid "For a more detailed (pre-``TorchConnector``) explanation on hybrid quantum-classical neural networks, you can check out the corresponding section in the `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."
msgstr "ハイブリッドの量子古典ニューラルネットワークの詳細(``TorchConnector`` の前)については、`Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__ の対応するセクションを参照してください。"

#: ../../tutorials/05_torch_connector.ipynb:996
msgid "Step 1: Defining Data-loaders for train and test"
msgstr "ステップ 1: 学習とテスト用のデータ・ローダーの定義"

#: ../../tutorials/05_torch_connector.ipynb:1007
msgid "We take advantage of the ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ to directly load a subset of the `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ and define torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) for train and test."
msgstr "``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ を利用して、 `MNIST データセット <https://en.wikipedia.org/wiki/MNIST_database>`__ のサブセットを直接ロードし、学習とテストのための ``DataLoader`` (`リンク <https://pytorch.org/docs/stable/data.html>`__) を定義します。"

#: ../../tutorials/05_torch_connector.ipynb:1048
msgid "If we perform a quick visualization we can see that the train dataset consists of images of handwritten 0s and 1s."
msgstr "簡単な可視化を実行すると、学習のデータセットは手書きの0と1の画像で構成されていることがわかります。"

#: ../../tutorials/05_torch_connector.ipynb:1120
msgid "Step 2: Defining the QNN and Hybrid Model"
msgstr "ステップ 2: QNNとハイブリッド・モデルの定義"

#: ../../tutorials/05_torch_connector.ipynb:1131
msgid "This second step shows the power of the ``TorchConnector``. After defining our quantum neural network layer (in this case, a ``TwoLayerQNN``), we can embed it into a layer in our torch ``Module`` by initializing a torch connector as ``TorchConnector(qnn)``."
msgstr "この2番目のステップは、 ``TorchConnector`` の実力を示します。 量子ニューラルネットワーク層を定義した後 (この場合は ``TwoLayerQNN``) 、torchコネクターを ``TorchConnector(qnn)`` として初期化することで、torch ``Module`` のレイヤーに埋め込むことができます。"

#: ../../tutorials/05_torch_connector.ipynb:1133
msgid "**⚠️ Attention:** In order to have an adequate gradient backpropagation in hybrid models, we MUST set the initial parameter ``input_gradients`` to TRUE during the qnn initialization."
msgstr "**⚠️ 注意:** ハイブリッド・モデルで、適切な勾配バックプロパゲーションを行うためには、QNNの初期化中に、初期パラメーター ``input_gradients`` を TRUE に設定する必要があります。"

#: ../../tutorials/05_torch_connector.ipynb:1235
msgid "Step 3: Training"
msgstr "ステップ 3: 学習"

#: ../../tutorials/05_torch_connector.ipynb:1337
msgid "Step 4: Evaluation"
msgstr "ステップ 4: 評価"

#: ../../tutorials/05_torch_connector.ipynb:1440
msgid "🎉🎉🎉🎉 **You are now able to experiment with your own hybrid datasets and architectures using Qiskit Machine Learning.** **Good Luck!**"
msgstr "🎉🎉🎉🎉🎉 **これで、Qiskit 機械学習を使用して、独自のハイブリッド・データセットとアーキテクチャを試すことができます。** **頑張ってください!**"

