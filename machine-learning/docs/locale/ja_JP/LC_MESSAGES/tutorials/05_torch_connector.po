msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-12-15 16:59+0000\n"
"PO-Revision-Date: 2021-12-15 17:18\n"
"Last-Translator: \n"
"Language-Team: Japanese\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ja\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/05_torch_connector.po\n"
"X-Crowdin-File-ID: 9636\n"
"Language: ja_JP\n"

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "This page was generated from `docs/tutorials/05_torch_connector.ipynb`__."
msgstr "ã“ã®ãƒšãƒ¼ã‚¸ã¯ `docs/tutorials/05_torch_connector.ipynb`__ ã‹ã‚‰ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚"

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector and Hybrid QNNs"
msgstr "Torch ã‚³ãƒã‚¯ã‚¿ãƒ¼ãŠã‚ˆã³ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ QNN"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial introduces Qiskitâ€™s ``TorchConnector`` class, and demonstrates how the ``TorchConnector`` allows for a natural integration of any ``NeuralNetwork`` from Qiskit Machine Learning into a PyTorch workflow. ``TorchConnector`` takes a Qiskit ``NeuralNetwork`` and makes it available as a PyTorch ``Module``. The resulting module can be seamlessly incorporated into PyTorch classical architectures and trained jointly without additional considerations, enabling the development and testing of novel **hybrid quantum-classical** machine learning architectures."
msgstr "ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€Qiskitã® ``TorchConnector`` ã‚¯ãƒ©ã‚¹ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚ãã—ã¦ã€ ``TorchConnector`` ãŒ Qiskit æ©Ÿæ¢°å­¦ç¿’ã‹ã‚‰ PyTorch ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã« ``NeuralNetwork`` ã‚’è‡ªç„¶ã«çµ±åˆã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚ ``TorchConnector`` ã¯ Qiskitã® ``NeuralNetwork`` ã‚’å—ã‘å–ã‚Šã€PyTorchã® ``Module`` ã¨ã—ã¦åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚ å¾—ã‚‰ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€PyTorchã®å¤å…¸ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¼ã«ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã€è¿½åŠ ã®è€ƒæ…®äº‹é …ãªã—ã«ä¸€ç·’ã«å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ ã¾ãŸã€æ–°ã—ã„ **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰é‡å­å¤å…¸** æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¼ã®é–‹ç™ºã¨ãƒ†ã‚¹ãƒˆã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:15
msgid "Content:"
msgstr "ç›®æ¬¡:"

#: ../../tutorials/05_torch_connector.ipynb:17
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__"
msgstr "`ãƒ‘ãƒ¼ãƒˆ 1: ç°¡å˜ãªåˆ†é¡ã¨å›å¸° <#Part-1:-Simple-Classification-&-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:19
msgid "The first part of this tutorial shows how quantum neural networks can be trained using PyTorchâ€™s automatic differentiation engine (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) for simple classification and regression tasks."
msgstr "ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã®æœ€åˆã®éƒ¨åˆ†ã¯ã€PyTorchã®è‡ªå‹•å¾®åˆ†ã‚¨ãƒ³ã‚¸ãƒ³( ``torch.autograd``ã€ `ãƒªãƒ³ã‚¯ <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) ã‚’ä½¿ç”¨ã—ã¦ç°¡å˜ãªåˆ†é¡ã¨å›å¸°ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã®é‡å­ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å­¦ç¿’ã•ã›ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:21
msgid "`Classification <#1.-Classification>`__"
msgstr "`åˆ†é¡ <#1.-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:23
msgid "Classification with PyTorch and ``OpflowQNN``"
msgstr "PyTorch ã¨ ``OpflowQNN`` ã‚’ç”¨ã„ãŸåˆ†é¡"

#: ../../tutorials/05_torch_connector.ipynb:24
msgid "Classification with PyTorch and ``CircuitQNN``"
msgstr "PyTorch ã¨ ``CircuitQNN`` ã‚’ç”¨ã„ãŸåˆ†é¡"

#: ../../tutorials/05_torch_connector.ipynb:26
msgid "`Regression <#2.-Regression>`__"
msgstr "`å›å¸° <#2.-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:28
msgid "Regression with PyTorch and ``OpflowQNN``"
msgstr "PyTorchã¨ ``OpflowQNN`` ã«ã‚ˆã‚‹å›å¸°"

#: ../../tutorials/05_torch_connector.ipynb:30
msgid "`Part 2: MNIST Classification, Hybrid QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"
msgstr "`ãƒ‘ãƒ¼ãƒˆ 2: MNIST åˆ†é¡ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰QNN <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"

#: ../../tutorials/05_torch_connector.ipynb:32
msgid "The second part of this tutorial illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow (in this case, a typical CNN architecture) to classify MNIST data in a hybrid quantum-classical manner."
msgstr "ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã® 2 ç•ªç›®ã®éƒ¨åˆ†ã§ã¯ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã®é‡å­å¤å…¸çš„ãªæ–¹æ³•ã§ MNIST ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é¡ã™ã‚‹ãŸã‚ã€ (é‡å­) ``NeuralNetwork`` ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã® PyTorch ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ ( ã“ã®å ´åˆã¯ã€å…¸å‹çš„ãª CNN ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¼) ã«çµ„ã¿è¾¼ã‚€æ–¹æ³•ã‚’èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:85
msgid "Part 1: Simple Classification & Regression"
msgstr "ãƒ‘ãƒ¼ãƒˆ 1: ç°¡å˜ãªåˆ†é¡ã¨å›å¸°"

#: ../../tutorials/05_torch_connector.ipynb:97
msgid "1. Classification"
msgstr "1. åˆ†é¡"

#: ../../tutorials/05_torch_connector.ipynb:99
msgid "First, we show how ``TorchConnector`` allows to train a Quantum ``NeuralNetwork`` to solve a classification tasks using PyTorchâ€™s automatic differentiation engine. In order to illustrate this, we will perform **binary classification** on a randomly generated dataset."
msgstr "æœ€åˆã«ã€``TorchConnector`` ãŒ PyTorch ã®è‡ªå‹•å¾®åˆ†ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€åˆ†é¡ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã« é‡å­ ``NeuralNetwork`` ã‚’å­¦ç¿’ã•ã›ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚ ã“ã‚Œã‚’ç¤ºã™ãŸã‚ã«ã€ãƒ©ãƒ³ãƒ€ãƒ ã«ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã— **ãƒã‚¤ãƒŠãƒªåˆ†é¡** ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:152
msgid "A. Classification with PyTorch and ``OpflowQNN``"
msgstr "A. PyTorch ã¨ ``OpflowQNN`` ã‚’ç”¨ã„ãŸåˆ†é¡"

#: ../../tutorials/05_torch_connector.ipynb:154
msgid "Linking an ``OpflowQNN`` to PyTorch is relatively straightforward. Here we illustrate this using the ``TwoLayerQNN``, a sub-case of ``OpflowQNN`` introduced in previous tutorials."
msgstr "``OpflowQNN`` ã‚’ PyTorch ã«ãƒªãƒ³ã‚¯ã™ã‚‹ã®ã¯æ¯”è¼ƒçš„ç°¡å˜ã§ã™ã€‚ã“ã“ã§ã¯ã€å‰ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ç´¹ä»‹ã—ãŸ ``OpflowQNN`` ã®ã‚µãƒ–ã‚±ãƒ¼ã‚¹ã§ã‚ã‚‹ ``TwoLayerQNN`` ã‚’ä½¿ç”¨ã—ã¦èª¬æ˜ã—ã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:271
msgid "Optimizer"
msgstr "ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼"

#: ../../tutorials/05_torch_connector.ipynb:273
msgid "The choice of optimizer for training any machine learning model can be crucial in determining the success of our trainingâ€™s outcome. When using ``TorchConnector``, we get access to all of the optimizer algorithms defined in the [``torch.optim``] package (`link <https://pytorch.org/docs/stable/optim.html>`__). Some of the most famous algorithms used in popular machine learning architectures include *Adam*, *SGD*, or *Adagrad*. However, for this tutorial we will be using the L-BFGS algorithm (``torch.optim.LBFGS``), one of the most well know second-order optimization algorithms for numerical optimization."
msgstr "ã‚ã‚‰ã‚†ã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã•ã›ã‚‹ä¸Šã§ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã®é¸æŠã¯ã€å­¦ç¿’ã®æˆæœã‚’æ±ºå®šã™ã‚‹ä¸Šã§éå¸¸ã«é‡è¦ã§ã™ã€‚ ``TorchConnector`` ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€[``torch.optim``] ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ (`ãƒªãƒ³ã‚¯ <https://pytorch.org/docs/stable/optim.html>`__) ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã™ã¹ã¦ã®ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ãƒ»ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚ ä¸€èˆ¬çš„ãªæ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¼ã§ä½¿ç”¨ã•ã‚Œã‚‹æœ€ã‚‚æœ‰åãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã¯ã€*Adam*ã€*SGD*ã€ã¾ãŸã¯ *Adagrad* ãŒã‚ã‚Šã¾ã™ã€‚ ã—ã‹ã—ã€ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯L-BFGSã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ (``torch.optim.LBFGS``)ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ æ•°å€¤æœ€é©åŒ–ã®ãŸã‚ã®æœ€ã‚‚ã‚ˆãçŸ¥ã‚‰ã‚Œã¦ã„ã‚‹2æ¬¡æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®1ã¤ã§ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:277
msgid "Loss Function"
msgstr "æå¤±é–¢æ•°"

#: ../../tutorials/05_torch_connector.ipynb:279
msgid "As for the loss function, we can also take advantage of PyTorchâ€™s pre-defined modules from ``torch.nn``, such as the `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ or `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."
msgstr "æå¤±é–¢æ•°ã«ã¤ã„ã¦ã¯ã€`äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ ã‚„ `å¹³å‡äºŒä¹—èª¤å·® <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ æå¤±ã¨ã„ã£ãŸã€ ``torch.nn`` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‹ã‚‰PyTorchã®äº‹å‰å®šç¾©ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:281
msgid "**ğŸ’¡ Clarification :** In classical machine learning, the general rule of thumb is to apply a Cross-Entropy loss to classification tasks, and MSE loss to regression tasks. However, this recommendation is given under the assumption that the output of the classification network is a class probability value in the [0,1] range (usually this is achieved through a Softmax layer). Because the following example for ``TwoLayerQNN`` does not include such layer, and we donâ€™t apply any mapping to the output (the following section shows an example of application of parity mapping with ``CircuitQNNs``), the QNNâ€™s output can take any value in the range [-1,1]. In case you were wondering, this is the reason why this particular example uses MSELoss for classification despite it not being the norm (but we encourage you to experiment with different loss functions and see how they can impact training results)."
msgstr "**ğŸ’¡ è§£èª¬ :** å¤å…¸æ©Ÿæ¢°å­¦ç¿’ã«ãŠã„ã¦ä¸€èˆ¬çš„ãªçµŒé¨“å‰‡ã¯ã€åˆ†é¡ã‚¿ã‚¹ã‚¯ã«äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±ã‚’é©ç”¨ã—ã€å›å¸°ã‚¿ã‚¹ã‚¯ã«MSEæå¤±ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã™ã€‚ ã—ã‹ã—ã€ã“ã®æ¨å¥¨ã¯ã€åˆ†é¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å‡ºåŠ›ãŒ [0 , 1] ç¯„å›² (é€šå¸¸ã¯ Softmax ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä»‹ã—ã¦é”æˆ) ã®åˆ†é¡ç¢ºç‡å€¤ã§ã‚ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¦ã„ã¾ã™ã€‚ ``TwoLayerQNN`` ã®ä»¥ä¸‹ã®ä¾‹ã«ã¯ãã®ã‚ˆã†ãªãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒå«ã¾ã‚Œãªã„ãŸã‚ã€ã¾ãŸã€å‡ºåŠ›ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã‚‚ãªã„ (æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ ``CircuitQNNs`` ã‚’ä½¿ç”¨ã—ãŸãƒ‘ãƒªãƒ†ã‚£ãƒ»ãƒãƒƒãƒ”ãƒ³ã‚°ã®ä¾‹ã‚’ç¤ºã—ã¾ã™) ãŸã‚ã€QNNã®å‡ºåŠ›ã¯ã€[-1,1] ã®ç¯„å›²ã§ä»»æ„ã®å€¤ã‚’å–ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ å› ã¿ã«ã€ã“ã‚ŒãŒã€ã“ã®ç‰¹å®šã®ä¾‹ã§MSELossã‚’ä¸€èˆ¬çš„ã§ãªã„ã®ã«ã‚‚é–¢ã‚ã‚‰ãšåˆ†é¡ã«ä½¿ç”¨ã—ã¦ã„ã‚‹ç†ç”±ã§ã™(ãŸã ã—ã€ã•ã¾ã–ã¾ãªæå¤±é–¢æ•°ã‚’è©¦ã—ã¦ã€å­¦ç¿’çµæœã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™)ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:458
#: ../../tutorials/05_torch_connector.ipynb:696
msgid "The red circles indicate wrongly classified data points."
msgstr "èµ¤ã„ä¸¸ã¯ã€èª¤ã£ã¦åˆ†é¡ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’ç¤ºã—ã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:470
msgid "B. Classification with PyTorch and ``CircuitQNN``"
msgstr "B. PyTorch ã¨ ``CircuitQNN`` ã‚’ç”¨ã„ãŸåˆ†é¡"

#: ../../tutorials/05_torch_connector.ipynb:472
msgid "Linking an ``CircuitQNN`` to PyTorch requires a bit more attention than ``OpflowQNN``. Without the correct setup, backpropagation is not possible."
msgstr "``CircuitQNN`` ã‚’ PyTorch ã«ãƒªãƒ³ã‚¯ã™ã‚‹ã«ã¯ã€``OpflowQNN`` ã‚ˆã‚Šã‚‚å°‘ã—æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚æ­£ã—ã„è¨­å®šãŒãªã‘ã‚Œã°ã€ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã§ãã¾ã›ã‚“ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:474
msgid "In particular, we must make sure that we are returning a dense array of probabilities in the networkâ€™s forward pass (``sparse=False``). This parameter is set up to ``False`` by default, so we just have to make sure that it has not been changed."
msgstr "ç‰¹ã«ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹(``sparse=False``) ã«ç¢ºç‡ã®å¯†ãªé…åˆ—ã‚’è¿”ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ ã“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ ``False`` ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€å¤‰æ›´ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:476
msgid "**âš ï¸ Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``CircuitQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."
msgstr "**âš ï¸ æ³¨æ„:** ã‚«ã‚¹ã‚¿ãƒ ã®interpreté–¢æ•°ã‚’å®šç¾©ã—ãŸå ´åˆ (ä¾‹: ``parity``) ã€æœŸå¾…ã™ã‚‹å‡ºåŠ›ã®å½¢çŠ¶ (ä¾‹: ``2``) ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚``CircuitQNN`` ã®åˆæœŸè¨­å®šã«é–¢ã™ã‚‹è©³ç´°ã¯ã€`å…¬å¼ã®Qiskitãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__ ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:544
#: ../../tutorials/05_torch_connector.ipynb:834
msgid "For a reminder on optimizer and loss function choices, you can go back to `this section <#Optimizer>`__."
msgstr "ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã¨æå¤±é–¢æ•°ã®é¸æŠã«ã¤ã„ã¦æ€ã„å‡ºã™ã«ã¯ã€`ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ <#Optimizer>`__ ã«æˆ»ã£ã¦ãã ã•ã„ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:708
msgid "2. Regression"
msgstr "2. å›å¸°"

#: ../../tutorials/05_torch_connector.ipynb:710
msgid "We use a model based on the ``TwoLayerQNN`` to also illustrate how to perform a regression task. The chosen dataset in this case is randomly generated following a sine wave."
msgstr "``TwoLayerQNN`` ã«åŸºã¥ã„ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€å›å¸°ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œæ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚ ä»Šå›é¸æŠã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€æ­£å¼¦æ³¢ã«æ²¿ã£ã¦ãƒ©ãƒ³ãƒ€ãƒ ã«ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:751
msgid "A. Regression with PyTorch and ``OpflowQNN``"
msgstr "A. PyTorchã¨ ``OpflowQNN`` ã«ã‚ˆã‚‹å›å¸°"

#: ../../tutorials/05_torch_connector.ipynb:762
msgid "The network definition and training loop will be analogous to those of the classification task using ``TwoLayerQNN``. In this case, we define our own feature map and ansatz, instead of using the default values."
msgstr "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å®šç¾©ã¨å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã¯ã€``TwoLayerQNN`` ã‚’ä½¿ç”¨ã—ãŸåˆ†é¡ã‚¿ã‚¹ã‚¯ã®ã‚‚ã®ã¨é¡ä¼¼ã—ã¦ã„ã¾ã™ã€‚ ã“ã®å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã™ã‚‹ã®ã§ã¯ãªãã€ç‹¬è‡ªã®ç‰¹å¾´ãƒãƒƒãƒ—ã¨ansatzã‚’å®šç¾©ã—ã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:957
msgid "Part 2: MNIST Classification, Hybrid QNNs"
msgstr "ãƒ‘ãƒ¼ãƒˆ 2: MNIST åˆ†é¡ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰QNN"

#: ../../tutorials/05_torch_connector.ipynb:959
msgid "In this second part, we show how to leverage a hybrid quantum-classical neural network using ``TorchConnector``, to perform a more complex image classification task on the MNIST handwritten digits dataset."
msgstr "2ç•ªç›®ã®éƒ¨åˆ†ã§ã¯ã€``TorchConnector`` ã‚’ä½¿ç”¨ã—ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã®é‡å­å¤å…¸çš„ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ´»ç”¨æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚ ã‚ˆã‚Šè¤‡é›‘ãªç”»åƒåˆ†é¡ã‚¿ã‚¹ã‚¯ã‚’MNISTã®æ‰‹æ›¸ãã®æ•°å­—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å®Ÿè¡Œã—ã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:961
msgid "For a more detailed (pre-``TorchConnector``) explanation on hybrid quantum-classical neural networks, you can check out the corresponding section in the `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."
msgstr "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã®é‡å­å¤å…¸ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è©³ç´°(``TorchConnector`` ã®å‰)ã«ã¤ã„ã¦ã¯ã€`Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__ ã®å¯¾å¿œã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:999
msgid "Step 1: Defining Data-loaders for train and test"
msgstr "ã‚¹ãƒ†ãƒƒãƒ— 1: å­¦ç¿’ã¨ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ­ãƒ¼ãƒ€ãƒ¼ã®å®šç¾©"

#: ../../tutorials/05_torch_connector.ipynb:1010
msgid "We take advantage of the ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ to directly load a subset of the `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ and define torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) for train and test."
msgstr "``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ ã‚’åˆ©ç”¨ã—ã¦ã€ `MNIST ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ <https://en.wikipedia.org/wiki/MNIST_database>`__ ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ç›´æ¥ãƒ­ãƒ¼ãƒ‰ã—ã€å­¦ç¿’ã¨ãƒ†ã‚¹ãƒˆã®ãŸã‚ã® ``DataLoader`` (`ãƒªãƒ³ã‚¯ <https://pytorch.org/docs/stable/data.html>`__) ã‚’å®šç¾©ã—ã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:1053
msgid "If we perform a quick visualization we can see that the train dataset consists of images of handwritten 0s and 1s."
msgstr "ç°¡å˜ãªå¯è¦–åŒ–ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€å­¦ç¿’ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯æ‰‹æ›¸ãã®0ã¨1ã®ç”»åƒã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:1127
msgid "Step 2: Defining the QNN and Hybrid Model"
msgstr "ã‚¹ãƒ†ãƒƒãƒ— 2: QNNã¨ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ»ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©"

#: ../../tutorials/05_torch_connector.ipynb:1138
msgid "This second step shows the power of the ``TorchConnector``. After defining our quantum neural network layer (in this case, a ``TwoLayerQNN``), we can embed it into a layer in our torch ``Module`` by initializing a torch connector as ``TorchConnector(qnn)``."
msgstr "ã“ã®2ç•ªç›®ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€ ``TorchConnector`` ã®å®ŸåŠ›ã‚’ç¤ºã—ã¾ã™ã€‚ é‡å­ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å±¤ã‚’å®šç¾©ã—ãŸå¾Œ (ã“ã®å ´åˆã¯ ``TwoLayerQNN``) ã€torchã‚³ãƒã‚¯ã‚¿ãƒ¼ã‚’ ``TorchConnector(qnn)`` ã¨ã—ã¦åˆæœŸåŒ–ã™ã‚‹ã“ã¨ã§ã€torch ``Module`` ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«åŸ‹ã‚è¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:1140
msgid "**âš ï¸ Attention:** In order to have an adequate gradient backpropagation in hybrid models, we MUST set the initial parameter ``input_gradients`` to TRUE during the qnn initialization."
msgstr "**âš ï¸ æ³¨æ„:** ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ»ãƒ¢ãƒ‡ãƒ«ã§ã€é©åˆ‡ãªå‹¾é…ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ãŸã‚ã«ã¯ã€QNNã®åˆæœŸåŒ–ä¸­ã«ã€åˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ ``input_gradients`` ã‚’ TRUE ã«è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"

#: ../../tutorials/05_torch_connector.ipynb:1245
msgid "Step 3: Training"
msgstr "ã‚¹ãƒ†ãƒƒãƒ— 3: å­¦ç¿’"

#: ../../tutorials/05_torch_connector.ipynb:1346
msgid "Step 4: Evaluation"
msgstr "ã‚¹ãƒ†ãƒƒãƒ— 4: è©•ä¾¡"

#: ../../tutorials/05_torch_connector.ipynb:1450
msgid "ğŸ‰ğŸ‰ğŸ‰ğŸ‰ **You are now able to experiment with your own hybrid datasets and architectures using Qiskit Machine Learning.** **Good Luck!**"
msgstr "ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ **ã“ã‚Œã§ã€Qiskit æ©Ÿæ¢°å­¦ç¿’ã‚’ä½¿ç”¨ã—ã¦ã€ç‹¬è‡ªã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è©¦ã™ã“ã¨ãŒã§ãã¾ã™ã€‚** **é ‘å¼µã£ã¦ãã ã•ã„!**"

