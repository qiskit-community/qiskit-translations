msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-03-28 08:39+0000\n"
"PO-Revision-Date: 2023-04-03 12:42\n"
"Last-Translator: \n"
"Language: ja\n"
"Language-Team: Japanese\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ja\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/03_quantum_kernel.po\n"
"X-Crowdin-File-ID: 9632\n"

#: ../../tutorials/03_quantum_kernel.ipynb:9
msgid "This page was generated from `docs/tutorials/03_quantum_kernel.ipynb`__."
msgstr "このページは `docs/tutorials/03_quantum_kernel.ipynb`__ から生成されました。"

#: ../../tutorials/03_quantum_kernel.ipynb:9
msgid "Quantum Kernel Machine Learning"
msgstr "量子カーネル法機械学習"

#: ../../tutorials/03_quantum_kernel.ipynb:12
msgid "Overview"
msgstr "概要"

#: ../../tutorials/03_quantum_kernel.ipynb:14
msgid "The general task of machine learning is to find and study patterns in data. For many datasets, the datapoints are better understood in a higher dimensional feature space. This is the fundamental principle behind a series of machine learning algorithms known as *kernel methods*."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:16
msgid "In this notebook, you will learn how to define quantum kernels using ``qiskit-machine-learning`` and how these can be plugged into different algorithms to solve classification and clustering problems."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:18
msgid "All examples used in this tutorial are based on this reference paper: `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:20
msgid "The content is structured as follows:"
msgstr "このコンテンツの構造は以下のとおりです。"

#: ../../tutorials/03_quantum_kernel.ipynb:22
msgid "`Introduction <#1.-Introduction>`__"
msgstr "`はじめに <#1.-Introduction>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:23
msgid "`Classification <#2.-Classification>`__"
msgstr "`分類 <#2.-Classification>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:24
msgid "`Clustering <#3.-Clustering>`__"
msgstr "`クラスタリング <#3.-Clustering>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:25
msgid "`Kernel Principal Components Analysis <#4.-Kernel-Principal-Component-Analysis>`__"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:26
msgid "`Conclusion <#5.-Conclusion>`__"
msgstr "`結論 <#5.-Conclusion>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:38
msgid "1. Introduction"
msgstr "1. はじめに"

#: ../../tutorials/03_quantum_kernel.ipynb:41
msgid "1.1. Kernel Methods for Machine Learning"
msgstr "1.1. 機械学習のカーネル・メソッド"

#: ../../tutorials/03_quantum_kernel.ipynb:43
msgid "Kernel methods are a collection of pattern analysis algorithms that use kernel functions to operate in a high-dimensional feature space. The best-known application of kernel methods is in **Support Vector Machines (SVMs)**, supervised learning algorithms commonly used for classification tasks. The main goal of SVMs is to find decision boundaries to separate a given set of data points into classes. When these data spaces are not linearly separable, SVMs can benefit from the use of kernels to find these boundaries."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:46
msgid "Formally, decision boundaries are hyperplanes in a high dimensional space. The kernel function implicitly maps input data into this higher dimensional space, where it can be easier to solve the initial problem. In other words, kernels may allow data distributions that were originally non-linearly separable to become a linearly separable problem. This is an effect known as the \"kernel trick\"."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:48
msgid "There are use-cases for kernel-based unsupervised algorithms too, for example, in the context of clustering. **Spectral Clustering** is a technique where data points are treated as nodes of a graph, and the clustering task is viewed as a graph partitioning problem where nodes are mapped to a space where they can be easily segregated to form clusters."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:51
msgid "1.2. Kernel Functions"
msgstr "1.2 . カーネル関数"

#: ../../tutorials/03_quantum_kernel.ipynb:53
msgid "Mathematically, kernel functions follow:"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:55
msgid ":math:`k(\\vec{x}_i, \\vec{x}_j) = \\langle f(\\vec{x}_i), f(\\vec{x}_j) \\rangle`"
msgstr ":math:`k(\\vec{x}_i, \\vec{x}_j) = \\langle f(\\vec{x}_i), f(\\vec{x}_j) \\rangle`"

#: ../../tutorials/03_quantum_kernel.ipynb:57
msgid "where \\* :math:`k` is the kernel function \\* :math:`\\vec{x}_i, \\vec{x}_j` are :math:`n` dimensional inputs \\* :math:`f` is a map from :math:`n`-dimension to :math:`m`-dimension space and \\* :math:`\\langle a,b \\rangle` denotes the inner product"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:59
msgid "When considering finite data, a kernel function can be represented as a matrix:"
msgstr "有限データを考慮する場合、カーネル関数は次のような行列として表現することができます。"

#: ../../tutorials/03_quantum_kernel.ipynb:61
msgid ":math:`K_{ij} = k(\\vec{x}_i,\\vec{x}_j)`."
msgstr ":math:`K_{ij} = k(\\vec{x}_i,\\vec{x}_j)`."

#: ../../tutorials/03_quantum_kernel.ipynb:64
msgid "1.3. Quantum Kernels"
msgstr "1.3 量子カーネル"

#: ../../tutorials/03_quantum_kernel.ipynb:66
msgid "The main idea behind quantum kernel machine learning is to leverage quantum feature maps to perform the kernel trick. In this case, the quantum kernel is created by mapping a classical feature vector :math:`\\vec{x}` to a Hilbert space using a quantum feature map :math:`\\phi(\\vec{x})`. Mathematically:"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:68
msgid ":math:`K_{ij} = \\left| \\langle \\phi(\\vec{x}_i)| \\phi(\\vec{x}_j) \\rangle \\right|^{2}`"
msgstr ":math:`K_{ij} = \\left| \\langle \\phi(\\vec{x}_i)| \\phi(\\vec{x}_j) \\rangle \\right|^{2}`"

#: ../../tutorials/03_quantum_kernel.ipynb:70
msgid "where \\* :math:`K_{ij}` is the kernel matrix \\* :math:`\\vec{x}_i, \\vec{x}_j` are :math:`n` dimensional inputs \\* :math:`\\phi(\\vec{x})` is the quantum feature map \\* :math:`\\left| \\langle a|b \\rangle \\right|^{2}` denotes the overlap of two quantum states :math:`a` and :math:`b`"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:72
msgid "Quantum kernels can be plugged into common classical kernel learning algorithms such as SVMs or clustering algorithms, as you will see in the examples below. They can also be leveraged in new quantum kernel methods like ``QSVC`` `class <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.algorithms.QSVC.html>`__ provided by ``qiskit-machine-learning`` which is explored in this tutorial, and other methods as shown in later tutorials on `Pegasos QSVC <https://github.com/Qiskit/qiskit-machine-learning/blob/main/docs/tutorials/07_pegasos_qsvc.ipynb>`__ and `QKA <https://github.com/Qiskit/qiskit-machine-learning/blob/main/docs/tutorials/08_quantum_kernel_trainer.ipynb>`__."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:77
msgid "Before introducing any example, we set up the global seed to ensure reproducibility:"
msgstr "例を紹介する前に、再現性を確保するためにグローバル・シードをセットアップします。"

#: ../../tutorials/03_quantum_kernel.ipynb:101
msgid "2. Classification"
msgstr "2.分類"

#: ../../tutorials/03_quantum_kernel.ipynb:103
msgid "This section illustrates a quantum kernel classification workflow using ``qiskit-machine-learning``."
msgstr "このセクションでは、 ``qiskit-machine-learning`` を使用した量子カーネル分類ワークフローについて説明します。"

#: ../../tutorials/03_quantum_kernel.ipynb:115
msgid "2.1. Defining the dataset"
msgstr "2.1. データセットの定義"

#: ../../tutorials/03_quantum_kernel.ipynb:126
msgid "For this example, we will use the *ad hoc dataset* as described in the reference `paper <https://arxiv.org/pdf/1804.11326.pdf>`__."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:128
msgid "We can define the dataset dimension and get our train and test subsets:"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:160
msgid "This dataset is two-dimensional, the two features are represented by the :math:`x` and :math:`y` coordinates, and it has two class labels: A and B. We can plot it and see what the distribution looks like. We define utility functions to plot the dataset."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:227
msgid "Now we actually plot the dataset for classification:"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:257
msgid "2.2. Defining the quantum kernel"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:259
msgid "The next step is to create a quantum kernel instance that will help classify this data."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:261
msgid "We use the ``FidelityQuantumKernel`` `class <https://github.com/Qiskit/qiskit-machine-learning/blob/main/qiskit_machine_learning/kernels/fidelity_quantum_kernel.py>`__, and pass two input arguments to its constructor:"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:263
msgid "``feature_map``: in this case, a two-qubit ``ZZFeatureMap`` `instance <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:265
msgid "``fidelity``: in this case, the ``ComputeUncompute`` `fidelity <https://qiskit.org/documentation/stubs/qiskit.algorithms.state_fidelities.ComputeUncompute.html>`__ subroutine that leverages the ``Sampler`` `primitive <https://qiskit.org/documentation/stubs/qiskit.primitives.Sampler.html>`__."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:267
msgid "**NOTE:** If you don't pass a ``Sampler`` or ``Fidelity`` instance, then the instances of the reference ``Sampler`` and ``ComputeUncompute`` classes (found in ``qiskit.primitives``) will be created by default."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:300
msgid "2.3. Classification with SVC"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:302
msgid "The quantum kernel can now be plugged into classical kernel methods, such as the ``SVC`` `algorithm <https://scikit-learn.org/stable/modules/svm.html>`__ from ``scikit-learn``. This algorithm allows us to define a `custom kernel <https://scikit-learn.org/stable/modules/svm.html#custom-kernels>`__ in two ways: 1. by providing the kernel as a **callable function** 2. by precomputing the **kernel matrix**"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:314
msgid "Kernel as a callable function"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:316
msgid "We define a SVC model and directly pass the ``evaluate`` function of the quantum kernel as a callable. Once the model is created, we train it by calling the ``fit`` method on the training dataset and evaluate the model for accuracy with ``score``."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:370
msgid "Precomputed kernel matrix"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:372
msgid "Instead of passing a function of the quantum kernel as a callable, we can also precompute training and testing kernel matrices before passing them to the ``scikit-learn`` ``SVC`` algorithm."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:374
msgid "To extract the train and test matrices, we can call ``evaluate`` on the previously defined kernel and visualize them graphically as follows:"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:416
msgid "To use these matrices, we set the ``kernel`` parameter of a new ``SVC`` instance to ``\"precomputed\"``. We train the classifier by calling ``fit`` with the training matrix and training dataset. Once the model is trained, we evaluate it using the test matrix on the test dataset."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:468
msgid "2.4. Classification with QSVC"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:470
msgid "``QSVC`` is an alternative training algorithm provided by ``qiskit-machine-learning`` for convenience. It is an extension of ``SVC`` that takes in a quantum kernel instead of the ``kernel.evaluate`` method shown before."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:524
msgid "2.5. Evaluation of models used for classification"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:585
msgid "As the classification dataset is small, we find that the three models achieve 100% accuracy."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:597
msgid "3. Clustering"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:599
msgid "The second workflow in this tutorial focuses on a clustering task using ``qiskit-machine-learning`` and the spectral clustering algorithm from ``scikit-learn``."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:611
msgid "3.1. Defining the dataset"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:613
msgid "We will once again use the *ad hoc dataset*, but now generated with a higher gap of ``0.6`` (previous example: ``0.3``) between the two classes."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:615
msgid "Note that clustering falls under the category of unsupervised machine learning, so a test dataset is not required."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:645
msgid "We plot the clustering dataset below:"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:695
msgid "3.2. Defining the Quantum Kernel"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:697
msgid "We use an identical setup as in the classification example. We create another instance of the ``FidelityQuantumKernel`` class with a ``ZZFeatureMap``, but you might notice that in this case we do not provide a ``fidelity`` instance. This is because the ``ComputeUncompute`` method provided in the previous case is instantiated by default when the fidelity instance is not provided explicitly."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:721
msgid "3.3. Clustering with the Spectral Clustering Model"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:723
msgid "The ``scikit-learn`` spectral clustering algorithm allows us to define a custom kernel in two ways (just like ``SVC``): 1. by providing the kernel as a **callable function** 2. by precomputing the **kernel matrix**."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:725
msgid "With the current ``FidelityQuantumKernel`` class in ``qiskit-machine-learning``, we can only use the latter option, so we precompute the kernel matrix by calling ``evaluate`` and visualize it as follows:"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:759
msgid "Next, we define a spectral clustering model and fit it using the precomputed kernel. Further, we score the labels using normalized mutual information, since we know the class labels a priori (before hand)."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:814
msgid "4. Kernel Principal Component Analysis"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:816
msgid "This section focuses on a Principal Component Analysis task using a kernel PCA algorithm. We calculate a kernel matrix using a ``ZZFeatureMap`` and show that this approach translates the original features into a new space, where axes are chosen along principal components. In this space the classification task can be performed with a simpler model rather than an SVM."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:828
msgid "4.1. Defining the dataset"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:830
msgid "We again use the *ad hoc dataset* with a gap of ``0.6`` between the two classes. This dataset resembles the dataset we had in the clustering section, the difference is that in this case ``test_size`` is not zero."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:860
msgid "We plot the training and test datasets below. Our ultimate goal in this section is to construct new coordinates where the two classes can be linearly separated."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:890
msgid "4.2. Defining the Quantum Kernel"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:892
msgid "We proceed with the same kernel setup as it was in the classification task, namely a ``ZZFeatureMap`` circuit as a feature map and an instance of ``FidelityQuantumKernel``."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:914
msgid "Then, we evaluate kernel matrices for the training and test features."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:937
msgid "4.3. Comparison of Kernel PCA on gaussian and quantum kernel"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:939
msgid "In this section we use the ``KernelPCA`` implementation from ``scikit-learn``, with the ``kernel`` parameter set to \"rbf\" for a gaussian kernel and \"precomputed\" for a quantum kernel. The former is very popular in classical machine learning models, whereas the latter allows using a quantum kernel defined as ``qpca_kernel``."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:941
msgid "One can observe that the gaussian kernel based Kernel PCA model fails to make the dataset linearly separable, while the quantum kernel succeeds."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:943
msgid "While usually PCA is used to reduce the number of features in a dataset, or in other words to reduce dimensionality of a dataset, we don't do that here. Rather we keep the number of dimensions and employ the kernel PCA, mostly for visualization purposes, to show that classification on the transformed dataset becomes easily tractable by linear methods, like logistic regression. We use this method to separate two classes in the principal component space with a ``LogisticRegression`` model from ``scikit-learn``. As usual we train it by calling the ``fit`` method on the training dataset and evaluate the model for accuracy with ``score``."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:974
msgid "Here we train and score a model."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:1025
msgid "Let's plot the results. First, we plot the transformed dataset we get with the quantum kernel. On the same plot we also add model results. Then, we plot the transformed dataset we get with the gaussian kernel."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:1089
msgid "As we can see, the data points on the right figure are not separable, but they are on the left figure, hence in case of quantum kernel we can apply linear models on the transformed dataset and this is why SVM classifier works perfectly well on the *ad hoc* dataset as we saw in the `classification section <#2.-Classification>`__."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:1101
msgid "5. Conclusion"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:1103
msgid "In this tutorial:"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:1105
msgid "We reviewed the fundamentals of quantum kernel learning"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:1106
msgid "We understood how to define quantum kernels as instances of ``FidelityQuantumKernel``"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:1107
msgid "We learned how to use the ``scikit-learn`` ``SVC`` algorithm with a custom quantum kernel as a callable function vs precomputed quantum kernel matrix for classification"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:1108
msgid "We learned how to train classifiers with the ``QSVC`` algorithm from ``qiskit-machine-learning``"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:1109
msgid "We learned how to use the ``scikit-learn`` ``SpectralClustering`` algorithms with a precomputed quantum kernel matrix for clustering"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:1110
msgid "We investigated how to plug in a quantum kernel into ``scikit-learn``'s ``KernelPCA`` algorithm and transform the ad-hoc dataset into a new one that can be tackled by a linear model."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:1121
msgid "For further reference, ``scikit-learn`` has other algorithms that can use a precomputed kernel matrix, such as:"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:1123
msgid "`Agglomerative clustering <https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html>`__"
msgstr "`Agglomerative clustering <https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:1124
msgid "`Support vector regression <https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html>`__"
msgstr "`Support vector regression <https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:1125
msgid "`Ridge regression <https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html>`__"
msgstr "`Ridge regression <https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:1126
msgid "`Gaussian process regression <https://scikit-learn.org/stable/modules/gaussian_process.html>`__"
msgstr "`Gaussian process regression <https://scikit-learn.org/stable/modules/gaussian_process.html>`__"

