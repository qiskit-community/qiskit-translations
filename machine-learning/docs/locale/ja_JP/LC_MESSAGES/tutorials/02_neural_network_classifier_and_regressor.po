msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-03-28 08:39+0000\n"
"PO-Revision-Date: 2023-03-28 13:45\n"
"Last-Translator: \n"
"Language: ja\n"
"Language-Team: Japanese\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ja\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/02_neural_network_classifier_and_regressor.po\n"
"X-Crowdin-File-ID: 9630\n"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:9
msgid "This page was generated from `docs/tutorials/02_neural_network_classifier_and_regressor.ipynb`__."
msgstr "このページは `docs/tutorials/02_neural_network_classifier_and_regressor.ipynb`__ から生成されました。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:9
msgid "Neural Network Classifier & Regressor"
msgstr "ニューラル・ネットワーク分類器と回帰器"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:11
msgid "In this tutorial we show how the ``NeuralNetworkClassifier`` and ``NeuralNetworkRegressor`` are used. Both take as an input a (Quantum) ``NeuralNetwork`` and leverage it in a specific context. In both cases we also provide a pre-configured variant for convenience, the Variational Quantum Classifier (``VQC``) and Variational Quantum Regressor (``VQR``). The tutorial is structured as follows:"
msgstr "このチュートリアルでは、``NeuralNetworkClassifier`` と ``NeuralNetworkRegressor`` がどのように使用されるかを示します。どちらも入力として (量子) ``NeuralNetwork`` を受け取り、特定のコンテキストでそれを活用します。どちらの場合も、利便性のためにあらかじめ設定されたバリエーション、変分量子分類器 (Variational Quantum Classifier, ``VQC``) と変分量子回帰器 (Variational Quantum Regressor, ``VQR``) を提供しています。チュートリアルの構成は以下の通りです。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:13
msgid "`Classification <#Classification>`__"
msgstr "`分類 <#Classification>`__"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:15
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:104
msgid "Classification with an ``EstimatorQNN``"
msgstr "``EstimatorQNN`` による分類"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:16
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:380
msgid "Classification with a ``SamplerQNN``"
msgstr "``SamplerQNN`` による分類"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:17
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:600
msgid "Variational Quantum Classifier (``VQC``)"
msgstr "変分量子分類器 (``VQC``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:19
msgid "`Regression <#Regression>`__"
msgstr "`回帰 <#Regression>`__"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:21
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1048
msgid "Regression with an ``EstimatorQNN``"
msgstr "`EstimatorQNN`` による回帰"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:22
msgid "Variational Quantum Regressor (``VQR``)"
msgstr "変分量子回帰器 (``VQR``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:57
msgid "Classification"
msgstr "分類"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:59
msgid "We prepare a simple classification dataset to illustrate the following algorithms."
msgstr "以下のアルゴリズムを説明するために、簡単な分類データセットを用意します。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:106
msgid "First we show how an ``EstimatorQNN`` can be used for classification within a ``NeuralNetworkClassifier``. In this context, the ``EstimatorQNN`` is expected to return one-dimensional output in :math:`[-1, +1]`. This only works for binary classification and we assign the two classes to :math:`\\{-1, +1\\}`."
msgstr "まず、 ``EstimatorQNN`` が ``NeuralNetworkClassifier`` の中でどのように分類に使われるかを示します。ここでは、 ``OpflowQNN`` は、 :math:`[-1, +1]` の1次元の出力を返すことが期待されています。 これは、二値分類にしか使えないので、2つのクラスを :math:`\\{-1, +1\\}` に割り当てます。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:142
msgid "Create a quantum neural network"
msgstr "量子ニューラル・ネットワークの作成"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:201
msgid "We will add a callback function called ``callback_graph``. This will be called for each iteration of the optimizer and will be passed two parameters: the current weights and the value of the objective function at those weights. For our function, we append the value of the objective function to an array so we can plot iteration versus objective function value and update the graph with each iteration. However, you can do whatever you want with a callback function as long as it gets the two parameters mentioned passed."
msgstr "``callback_graph`` というコールバック関数を追加します。 これはオプティマイザの反復ごとに呼び出され、現在の重みとその重みでの目的関数の値という、2つのパラメータが渡されます。 ここでは関数に、目的関数の値を配列に追加します。これによって反復と目的関数の値をプロットし、反復ごとにグラフを更新することができます。とはいえ、2つのパラメータが渡される限り、コールバック関数であなたは何でも好きなことをすることができます。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:330
msgid "Now, when the model is trained, we can explore the weights of the neural network. Please note, the number of weights is defined by ansatz."
msgstr "さて、モデルの学習が完了したら、ニューラルネットワークの重みを探索することができます。重みの数はansatzで定義されていることに注意してください。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:382
msgid "Next we show how a ``SamplerQNN`` can be used for classification within a ``NeuralNetworkClassifier``. In this context, the ``SamplerQNN`` is expected to return :math:`d`-dimensional probability vector as output, where :math:`d` denotes the number of classes. The underlying ``Sampler`` primitive returns quasi-distributions of bit strings and we just need to define a mapping from the measured bitstrings to the different classes. For binary classification we use the parity mapping."
msgstr "次に、 ``SamplerQNN`` が ``NeuralNetworkClassifier`` の中でどのように分類に使われるかを示します。ここでは、 ``SamplerQNN`` は、 :math:`d` -次元の確率ベクトルを出力として返すことが期待されます。ここで :math:`d` はクラス数です。基礎となる ``Sampler`` primitiveはビット列の準分布を返すので、測定されたビット列から異なるクラスへのマッピングを定義するだけでよいのです。2値分類には、パリティーマッピングを用います。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:553
msgid "Again, once the model is trained we can take a look at the weights. As we set ``reps=1`` explicitly in our ansatz, we can see less parameters than in the previous model."
msgstr "繰り返しになりますが、モデルの学習が完了したら、重みを見ることができます。Ansatzで明示的に ``reps=1`` を設定しているので、前のモデルよりもパラメーターが少なくなっていることがわかります。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:602
msgid "The ``VQC`` is a special variant of the ``NeuralNetworkClassifier`` with a ``SamplerQNN``. It applies a parity mapping (or extensions to multiple classes) to map from the bitstring to the classification, which results in a probability vector, which is interpreted as a one-hot encoded result. By default, it applies this the ``CrossEntropyLoss`` function that expects labels given in one-hot encoded format and will return predictions in that format too."
msgstr "``VQC`` は、``SamplerQNN`` を用いた ``NeuralNetworkClassifier`` の特別なバリエーションです。``VQC`` は、パリティー・マッピング（または複数のクラスへの拡張）を適用して、ビット列から分類にマッピングし、その結果、確率ベクトルが得られ、ワンショットでエンコードされた結果として解釈されます。デフォルトでは、 ``CrossEntropyLoss`` 関数を適用します。この関数は、ワンショットでエンコードされたフォーマットで与えられたラベルを想定しており、そのフォーマットでも予測値を返します。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:721
msgid "Multiple classes with VQC"
msgstr "VQC を使用した複数のクラス"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:723
msgid "In this section we generate an artificial dataset that contains samples of three classes and show how to train a model to classify this dataset. This example shows how to tackle more interesting problems in machine learning. Of course, for a sake of short training time we prepare a tiny dataset. We employ ``make_classification`` from SciKit-Learn to generate a dataset. There 10 samples in the dataset, 2 features, that means we can still have a nice plot of the dataset, as well as no redundant features, these are features are generated as a combinations of the other features. Also, we have 3 different classes in the dataset, each classes one kind of centroid and we set class separation to ``2.0``, a slight increase from the default value of ``1.0`` to ease the classification problem."
msgstr "この節では，3つのクラスのサンプルを含む人工データセットを生成し，このデータセットを分類するモデルをどのように学習するかを示します。この例は，機械学習におけるより興味深い問題への取り組み方を示しています。もちろん、学習時間を短くするために、小さなデータセットを用意します。SciKit-Learnの ``make_classification`` を用いてデータセットを生成します。データセットには10個のサンプル、2個の特徴量がありますが、これはデータセットをきれいにプロットできることと、冗長な特徴はなく、これらは他の特徴量の組み合わせとして生成されることを意味しています。また、データセットには3つの異なるクラスがあり、それぞれのクラスには1種類のセントロイドがあります。クラス分離は、分類問題を緩和するために、デフォルト値の ``1.0`` から少し増やして ``2.0`` に設定しました。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:726
msgid "Once the dataset is generated we scale the features into the range ``[0, 1]``."
msgstr "データセットが生成されると、その機能を ``[0, 1]`` の範囲に拡大します。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:759
msgid "Let's see how our dataset looks like."
msgstr "データセットがどのように見えるか見てみましょう。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:814
msgid "We also transform labels and make them categorical."
msgstr "また、ラベルを変換してカテゴリー化することもできます。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:863
msgid "We create an instance of ``VQC`` similar to the previous example, but in this case we pass a minimal set of parameters. Instead of feature map and ansatz we pass just the number of qubits that is equal to the number of features in the dataset, an optimizer with a low number of iteration to reduce training time, a quantum instance, and a callback to observe progress."
msgstr "前の例と同様に ``VQC`` のインスタンスを作成しますが、今回は最小限のパラメーターを渡します。特徴量マップとansatzの代わりに、データセットの特徴量数に等しい量子ビットの数、学習時間を短縮するための低い反復回数のオプティマイザー、量子インスタンス、そして進捗を確認するためのコールバックを渡します。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:888
msgid "Start the training process in the same way as in previous examples."
msgstr "前の例と同じ方法でトレーニング・プロセスを開始します。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:954
msgid "Despite we had the low number of iterations, we achieved quite a good score. Let see the output of the ``predict`` method and compare the output with the ground truth."
msgstr "反復回数が少なかったにもかかわらず、私たちはかなり良いスコアを達成しました。 ``predict`` メソッドの出力を確認し、出力と基本となる真の値と比較してみましょう。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1005
msgid "Regression"
msgstr "回帰"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1007
msgid "We prepare a simple regression dataset to illustrate the following algorithms."
msgstr "以下のアルゴリズムを説明するために、簡単な回帰データセットを用意します。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1050
msgid "Here we restrict to regression with an ``EstimatorQNN`` that returns values in :math:`[-1, +1]`. More complex and also multi-dimensional models could be constructed, also based on ``SamplerQNN`` but that exceeds the scope of this tutorial."
msgstr "ここでは、 :math:`[-1, +1]` の値を返す ``EstimatorQNN`` を使った回帰に限定します。もっと複雑で多次元のモデルを ``SamplerQNN`` をベースにして構築することもできますが、このチュートリアルの範囲を超えています。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1187
msgid "Similarly to the classification models, we can obtain an array of trained weights by querying a corresponding property of the model. In this model we have only one parameter defined as ``param_y`` above."
msgstr "分類モデルと同様に、モデルの対応するプロパティーを問い合わせることで、学習済み重みの配列を取得することができます。このモデルでは，上記の ``param_y`` として定義されたパラメーターを1つだけ持ちます。"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1234
msgid "Regression with the Variational Quantum Regressor (``VQR``)"
msgstr "変分量子回帰器 (``VQR``) による回帰"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1236
msgid "Similar to the ``VQC`` for classification, the ``VQR`` is a special variant of the ``NeuralNetworkRegressor`` with a ``EstimatorQNN``. By default it considers the ``L2Loss`` function to minimize the mean squared error between predictions and targets."
msgstr "``VQR`` は、分類用の ``VQC`` と同様に、``EstimatorQNN`` を用いた ``NeuralNetworkRegressor`` の特別な改良版です。デフォルトでは、予測値と目標値の間の平均二乗誤差を最小化するために、 ``L2Loss`` 関数を考慮します。"

