msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-12 22:21+0000\n"
"PO-Revision-Date: 2021-07-12 23:08\n"
"Last-Translator: \n"
"Language-Team: Vietnamese\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: vi\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials.po\n"
"X-Crowdin-File-ID: 9528\n"
"Language: vi_VN\n"

#: ../../tutorials/01_neural_networks.ipynb:13
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:13
#: ../../tutorials/03_quantum_kernel.ipynb:13
#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:13
#: ../../tutorials/05_torch_connector.ipynb:13
msgid "Run interactively in jupyter notebook."
msgstr "Chạy tương tác trong jupyter notebook."

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "Mạng Neuron Lượng tử"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "Notebook này triển khai các mạng neuron lượng tử cơ bản (QNN) khác nhau được cung cấp trong Trình Học máy Qiskit. Các mạng này được tạo ra để là các đơn vị tính toán không phụ thuộc vào bất kỳ ứng dụng cụ thể nào mà có thể được sử dụng cho nhiều trường hợp ứng dụng khác nhau. Tuỳ thuộc vào ứng dụng, sẽ có mạng phù hợp hơn, hoặc không phù hợp bằng, và có thể yêu cầu sắp đặt theo một cách nhất định. Các mạng neuron có sẵn sau đây sẽ được thảo luận chi tiết hơn:"

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks."
msgstr "``NeuralNetwork``: Giao diện cho các mạng neuron."

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``OpflowQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr "``OpflowQNN``: Mạng dựa trên việc đánh giá các đại lượng cơ học lượng tử quan sát được."

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``TwoLayerQNN``: A special ``OpflowQNN`` implementation for convenience."
msgstr "``TwoLayerQNN``: Cách cài đặt ``OpflowQNN`` đặc biệt nhằm mục đích thuận tiện."

#: ../../tutorials/01_neural_networks.ipynb:16
msgid "``CircuitQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr "``CircuitQNN``: Mạng dựa trên các mẫu có được từ các phép đo trên một mạch lượng tử."

#: ../../tutorials/01_neural_networks.ipynb:64
msgid "1. ``NeuralNetwork``"
msgstr "1. ``NeuralNetwork``"

#: ../../tutorials/01_neural_networks.ipynb:66
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interfaces are introduced."
msgstr "``NeuralNetwork`` đại diện cho giao điện của tất cả mạng neuron sẵn có trong Trình Học Máy Qiskit. Nó chỉ ra một đường chuyền tới và lui, lấy các mẫu dữ liệu và các biến có thể huấn luyện được làm đầu vào. Một ``NeuralNetwork`` không có bất kỳ khả năng huấn luyện nào, những trọng trách này được chuyển giao cho chính các thuật toán/ứng dụng. Do đó, một ``NeuralNetwork`` cũng không lưu trữ các giá trị cho các biến có thể huấn luyện được. Mục sau đây sẽ giới thiệu các cách triển khai khác nhau của giao diện này."

#: ../../tutorials/01_neural_networks.ipynb:68
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes either flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr "Giả sử một ``NeuralNetwork`` gọi là ``nn``. Sau đó, đường chuyền ``nn.forward(input, weights)`` lấy một trong hai đầu vào, một là cho dữ liệu và và hai là cho trọng lượng của kích thước ``nn.num_inputs`` và ``nn.num_weights``, tương ứng. ``NeuralNetwork`` hỗ trợ đầu dưới dạng các đợt và trả lại các đợt đầu ra với hình dạng tương ứng."

#: ../../tutorials/01_neural_networks.ipynb:80
msgid "2. ``OpflowQNN``"
msgstr "2. ``OpflowQNN``"

#: ../../tutorials/01_neural_networks.ipynb:82
msgid "The ``OpflowQNN`` takes a (parametrized) operator from Qiskit and leverages Qiskit’s gradient framework to provide the backward pass. Such an operator can for instance be an expected value of a quantum mechanical observable with respect to a parametrized quantum state. The Parameters can be used to load classical data as well as represent trainable weights. The ``OpflowQNN`` also allows lists of operators and more complex structures to construct more complex QNNs."
msgstr "``OpflowQNN`` lấy một toán tử (được tham số hoá) từ Qiskit và tận dụng khung gradient của Qiskit để cung cấp đường chuyền ngược lại. Một toán tử như vậy có thể là một giá trị trông đợi của một đại lượng quan sát cơ học lượng tử với một trạng thái lượng tử tham số. Các tham số có thể được sử dụng để tải dữ liệu cổ điển cũng như đại diện cho trọng lượng đào tạo được.``OpflowQNN`` cũng cho phép danh sách các toán tử và các cấu trúc phức tạp hơn để xây dựng những QNN phức tạp hơn."

#: ../../tutorials/01_neural_networks.ipynb:321
msgid "Combining multiple observables in a ``ListOp`` also allows to create more complex QNNs"
msgstr "Kết hợp nhiều đại lượng quan sát trong một ```ListOp`` cũng cho phép tạo những QNN phức tạp hơn"

#: ../../tutorials/01_neural_networks.ipynb:412
msgid "3. ``TwoLayerQNN``"
msgstr "3. ``TwoLayerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:414
msgid "The ``TwoLayerQNN`` is a special ``OpflowQNN`` on :math:`n` qubits that consists of first a feature map to insert data and second an ansatz that is trained. The default observable is :math:`Z^{\\otimes n}`, i.e., parity."
msgstr "``TwoLayerQNN`` là một ``OpflowQNN`` đặc biệt trên :math:`n` qubit bao gồm: thứ nhất là một đồ tính năng để chèn dữ liệu và thứ hai là một ansatz được đào tạo. Các đại lượng quan sát mặc định là :math:`Z^{\\otimes n}`,ví dụ: tính chẵn lẻ."

#: ../../tutorials/01_neural_networks.ipynb:612
msgid "4. ``CircuitQNN``"
msgstr "4. ``CircuitQNN``"

#: ../../tutorials/01_neural_networks.ipynb:614
msgid "The ``CircuitQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples can either be interpreted as probabilities of measuring the integer index corresponding to a bitstring or directly as a batch of binary output. In the case of probabilities, gradients can be estimated efficiently and the ``CircuitQNN`` provides a backward pass as well. In case of samples, differentiation is not possible and the backward pass returns ``(None, None)``."
msgstr "``CircuitQNN`` dựa trên một ``QuantumCircuit`` (tham số hóa). Hàm này có thể lấy đầu vào cũng như các thông số trọng lượng và tạo ra các mẫu từ phép đo. Các mẫu có thể được hiểu là xác suất để đo chỉ số của số nguyên tương ứng với một chuỗi bit hoặc trực tiếp như một đợt đầu ra nhị phân. Trong trường hợp xác suất, các gradient có thể được ước tính một cách hiệu quả và `` CircuitQNN`` cung cấp đường truyền ngược. Trong trường hợp các mẫu, sự vi phân là không thể và đường truyền trả lại ``(None, None)``."

#: ../../tutorials/01_neural_networks.ipynb:617
msgid "Further, the ``CircuitQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are aggregated accordingly."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:619
msgid "A ``CircuitQNN`` can be configured to return sparse as well as dense probability vectors. If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits and a sparse recommendation is usually recommended. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr "Một ``CircuitQNN`` có thể được thiết lập để trả lại các vectơ xác suất rời rạc cũng như đặc. Nếu không có hàm ``interpret`` nào được sử dụng, kích cỡ của chiều của vectơ xác suất sẽ được nhân lên theo hàm mũ với số lượng qubit và sự rời rạc thường được khuyến khích sử dụng. Trong trường hợp của một hàm ``interpret`` nó phụ thuộc vào kết quả mong đợi. Nếu, ví dụ, một chỉ số được ánh xạ đến tính chẵn lẻ của chuỗi bit tương ứng, tức là đối với 0 hoặc 1, một đầu ra dày đặc có nghĩa và kết quả sẽ là một vectơ xác suất của độ dài 2."

#: ../../tutorials/01_neural_networks.ipynb:662
msgid "4.1 Output: sparse integer probabilities"
msgstr "4.1 Thông tin đầu ra: xác suất số nguyên thưa thớt"

#: ../../tutorials/01_neural_networks.ipynb:761
msgid "4.2 Output: dense parity probabilities"
msgstr "4.2: Thông tin đầu ra: xác suất chẵn lẻ dày đặc"

#: ../../tutorials/01_neural_networks.ipynb:869
msgid "4.3 Output: Samples"
msgstr "4.3 Thông tin đầu ra: Các mẫu"

#: ../../tutorials/01_neural_networks.ipynb:985
msgid "4.4 Output: Parity Samples"
msgstr "4.4: Thông tin đầu ra: Các mẫu chẵn lẻ"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:9
msgid "Neural Network Classifier & Regressor"
msgstr "Bộ phân loại & hồi quy mạng thần kinh"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:11
msgid "In this tutorial we show how the ``NeuralNetworkClassifier`` and ``NeuralNetworkRegressor`` are used. Both take as an input a (Quantum) ``NeuralNetwork`` and leverage it in a specific context. In both cases we also provide a pre-configured variant for convenience, the Variational Quantum Classifier (``VQC``) and Variational Quantum Regressor (``VQR``). The tutorial is structured as follows:"
msgstr "Trong hướng dẫn này, chúng tôi hiện cách sử dụng ``NeuralNetworkClassifier`` và ``NeuralNetworkRegressor``. Cả hai sử dụng như một đầu vào là một ``NeuralNetwork`` (lượng tử) và tận dụng nó trong một bối cảnh cụ thể. Trong cả hai trường hợp, chúng tôi cũng cung cấp một biến thể được thiết lập trước để thuận tiện, Biến thể phân loại lượng tử (``VQC``) và Biến thể Hồi quy Lượng tử (`` VQR``). Hướng dẫn được cấu trúc như sau:"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:13
msgid "`Classification <#Classification>`__"
msgstr "`Phân Loại <#Classification>`__"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:15
msgid "Classification with an ``OpflowQNN``"
msgstr "Phân loại với ``OpflowQNN``"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:16
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:249
msgid "Classification with a ``CircuitQNN``"
msgstr "Phân loại với ``CircuitQNN``"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:17
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:398
msgid "Variational Quantum Classifier (``VQC``)"
msgstr "Biến thể Phân loại Lượng tử (``VQC``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:19
msgid "`Regression <#Regression>`__"
msgstr "`Hồi Quy <#Regression>`__"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:21
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:539
msgid "Regression with an ``OpflowQNN``"
msgstr "Hồi quy với một ``OpflowQNN``"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:22
msgid "Variational Quantum Regressor (``VQR``)"
msgstr "Biến thể Hồi quy Lượng tử (``VQR``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:70
#: ../../tutorials/03_quantum_kernel.ipynb:53
msgid "Classification"
msgstr "Phân loại"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:72
msgid "We prepare a simple classification dataset to illustrate the following algorithms."
msgstr "Chúng tôi chuẩn bị một tập dữ liệu phân loại đơn giản để minh họa các thuật toán sau đây."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:117
msgid "Classification with the an ``OpflowQNN``"
msgstr "Phân loại với ``OpflowQNN``"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:119
msgid "First we show how an ``OpflowQNN`` can be used for classification within a ``NeuralNetworkClassifier``. In this context, the ``OpflowQNN`` is expected to return one-dimensional output in :math:`[-1, +1]`. This only works for binary classification and we assign the two classes to :math:`\\{-1, +1\\}`. For convenience, we use the ``TwoLayerQNN``, which is a special type of ``OpflowQNN`` defined via a feature map and an ansatz."
msgstr "Đầu tiên chúng ta cho thấy cách mà ``OpflowQNN`` có thể được sử dụng cho việc phân loại trong một ``NeuralNetworkClassifier``. Trong trường hợp này, ``OpflowQNN`` được trông đợi sẽ trả lại một đầu ra một chiều trong :math:`[-1, +1]`. Điều này chỉ đúng với sự phân loại nhị phân và chúng ta chỉ định hai lớp vào :math:`\\{-1, +1\\}`. Để tiện hơn, chúng ta sử dụng ``TwoLayerQNN``, là một loại đặc biệt của ``OpflowQNN`` được định nghĩa qua một ánh xạ tính năng và một ansatz."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:251
msgid "Next we show how a ``CircuitQNN`` can be used for classification within a ``NeuralNetworkClassifier``. In this context, the ``CircuitQNN`` is expected to return :math:`d`-dimensional probability vector as output, where :math:`d` denotes the number of classes. Sampling from a ``QuantumCircuit`` automatically results in a probability distribution and we just need to define a mapping from the measured bitstrings to the different classes. For binary classification we use the parity mapping."
msgstr "Sau đó chúng ta chỉ ra cách mà một ``CircuitQNN`` được sử dụng cho việc phân loại trong ``NeuralNetworkClassifier``. Trong trường hợp này ``CircuitQNN`` được trông đợi sẽ trả lại một đầu ra véc-tơ :math:`d` chiều, trong đó :math:`d` đại diện cho số lớp. Lấy mẫu từ ``QuantumCircuit`` tự động tạo ra thành sự phân phối xác suất và chúng ta chỉ cần định nghĩa một ánh xạ từ chuỗi bit đo được tới các lớp khác nhau. Chúng ta dùng ánh xạ chẵn lẻ cho sự phân loại nhị phân."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:400
msgid "The ``VQC`` is a special variant of the ``NeuralNetworkClassifier`` with a ``CircuitQNN``. It applies a parity mapping (or extensions to multiple classes) to map from the bitstring to the classification, which results in a probability vector, which is interpreted as a one-hot encoded result. By default, it applies this the ``CrossEntropyLoss`` function that expects labels given in one-hot encoded format and will return predictions in that format too."
msgstr "``VQC`` là một biến thể đặc biệt của ``NeuralNetworkClassifier`` với một ``CircuitQNN``. Nó áp dụng một ánh xạ chẵn lẻ (hoặc mở rộng cho nhiều lớp) để ánh xạ từ chuỗi bit đến phân loại, dẫn đến một véc-tơ xác suất, được hiểu là một kết quả được mã hóa một nóng. Theo mặc định, nó áp dụng cho hàm ``CrossEntropyLoss`` trông đợi các nhãn được cung cấp trong một định dạng mã hóa một nóng và sẽ trả về những dự đoán trong định dạng đó."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:496
msgid "Regression"
msgstr "Hồi quy"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:498
msgid "We prepare a simple regression dataset to illustrate the following algorithms."
msgstr "Chúng tôi chuẩn bị một tập dữ liệu hồi quy đơn giản để minh họa cho các thuật toán sau đây."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:541
msgid "Here we restrict to regression with an ``OpflowQNN`` that returns values in :math:`[-1, +1]`. More complex and also multi-dimensional models could be constructed, also based on ``CircuitQNN`` but that exceeds the scope of this tutorial."
msgstr "Ở đây chúng ta hạn chế hồi quy với mộ ``OpflowQNN`` trả về các giá trị trong :math:` [-1, + 1] `. Nhiều mô hình phức tạp và đa chiều cũng có thể được xây dựng, cũng dựa trên ``CircuitQNN`` nhưng điều đó vượt quá phạm vi của hướng dẫn này."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:648
msgid "Regression with the Variational Quantum Regressor (``VQR``)"
msgstr "Hồi quy với Biến Hồi quy Lượng tử (``VQR``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:650
msgid "Similar to the ``VQC`` for classification, the ``VQR`` is a special variant of the ``NeuralNetworkRegressor`` with a ``OpflowQNN``. By default it considers the ``L2Loss`` function to minimize the mean squared error between predictions and targets."
msgstr "Tương tự như ``VQC`` cho phân loại, ``VQR`` là một biến thể đặc biệt của ``NeuralNetworkRegressor`` với một ``OpflowQNN``. Theo mặc định, nó xét hàm ``L2Loss`` để giảm thiểu lỗi bình phương trung bình giữa các dự đoán và mục tiêu."

#: ../../tutorials/03_quantum_kernel.ipynb:9
msgid "Quantum Kernel Machine Learning"
msgstr "Nhân của trình học máy lượng tử"

#: ../../tutorials/03_quantum_kernel.ipynb:11
msgid "The general task of machine learning is to find and study patterns in data. For many datasets, the datapoints are better understood in a higher dimensional feature space, through the use of a kernel function: :math:`k(\\vec{x}_i, \\vec{x}_j) = \\langle f(\\vec{x}_i), f(\\vec{x}_j) \\rangle` where :math:`k` is the kernel function, :math:`\\vec{x}_i, \\vec{x}_j` are :math:`n` dimensional inputs, :math:`f` is a map from :math:`n`-dimension to :math:`m`-dimension space and :math:`\\langle a,b \\rangle` denotes the dot product. When considering finite data, a kernel function can be represented as a matrix: :math:`K_{ij} = k(\\vec{x}_i,\\vec{x}_j)`."
msgstr "Nhiệm vụ chung của học máy là để tìm và nghiên cứu những mô hình trong dữ liệu. Với rất nhiều tập dữ liệu, các điểm dữ liệu có thể được hiểu tốt hơn trong những không gian tính năng với số chiều lớn hơn, do đó chúng sử dụng hàm hạt nhân: :math:`k(\\vec{x}_i, \\vec{x}_j) = \\langle f(\\vec{x}_i), f(\\vec{x}_j) \\rangle` trong đó :math:`k` là hàm hạt nhân, :math:`\\vec{x}_i, \\vec{x}_j` là những đầu vào :math:`n` chiều, :math:`f`là một ánh xạ từ không gian :math:`n` chiều tới không gian :math:`m` chiều và :math:`\\langle a,b \\rangle` chỉ tích vô hướng. Khi xem xét một dữ liệu có hạn, một hàm hạt nhân có thể được viết dưới dạng mọt ma trận: :math:`K_{ij} = k(\\vec{x}_i,\\vec{x}_j)`."

#: ../../tutorials/03_quantum_kernel.ipynb:14
msgid "In quantum kernel machine learning, a quantum feature map :math:`\\phi(\\vec{x})` is used to map a classical feature vector :math:`\\vec{x}` to a quantum Hilbert space, :math:`| \\phi(\\vec{x})\\rangle \\langle \\phi(\\vec{x})|`, such that :math:`K_{ij} = \\left| \\langle \\phi^\\dagger(\\vec{x}_j)| \\phi(\\vec{x}_i) \\rangle \\right|^{2}`. See `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__ for more details."
msgstr "Trong học máy nhân lượng tử, một ánh xạ tính năng lượng tử :math:`\\phi(\\vec{x})` được sử dụng để ánh xạ một véc-tơ tính năng cổ điển :math:`\\vec{x}` cho một không gian Hilbert lượng tử, :math:`| \\phi(\\vec{x})\\rangle \\langle \\phi(\\vec{x})|`, sao cho :math:`K_{ij} = \\left| \\langle \\phi^\\dagger(\\vec{x}_j)| \\phi(\\vec{x}_i) \\rangle \\right|^{2}`. Xem `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__ để biết thêm chi tiết."

#: ../../tutorials/03_quantum_kernel.ipynb:16
msgid "In this notebook, we use ``qiskit`` to calculate a kernel matrix using a quantum feature map, then use this kernel matrix in ``scikit-learn`` classification and clustering algorithms."
msgstr "Trong notebook này, chúng tôi sử dụng ``qiskit`` để tính toán một ma trận nhân sử dụng một ánh xạ tính năng lượng tử, sau đó sử dụng ma trận nhân này trong các thuật toán phân loại và phân cụm ``scikit-learn``."

#: ../../tutorials/03_quantum_kernel.ipynb:55
msgid "For our classification example, we will use the *ad hoc dataset* as described in `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__, and the ``scikit-learn`` `support vector machine <https://scikit-learn.org/stable/modules/svm.html>`__ classification (``svc``) algorithm."
msgstr "Dành cho ví dụ về phân loại, chúng ta sẽ lại sử dụng tập dữ liệu *ad hoc dataset* như đã mô tả trong `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__, and thuật toán phân loại (``svc``) ``scikit-learn`` `support vector machine <https://scikit-learn.org/stable/modules/svm.html>`__."

#: ../../tutorials/03_quantum_kernel.ipynb:111
msgid "With our training and testing datasets ready, we set up the ``QuantumKernel`` class to calculate a kernel matrix using the `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__, and the ``BasicAer`` ``qasm_simulator`` using 1024 shots."
msgstr "Với việc đào tạo và thử dữ liệu kiểm tra sẵn sàng, chúng tôi thiết lập lớp ``QuantumKernel`` để tính một ma trận hạt nhân bằng cách sử dụng `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__, và ``BasicAer`` ``qasm_simulator`` với 1024 lần chạy."

#: ../../tutorials/03_quantum_kernel.ipynb:138
msgid "The ``scikit-learn`` ``svc`` algorithm allows us to define a `custom kernel <https://scikit-learn.org/stable/modules/svm.html#custom-kernels>`__ in two ways: by providing the kernel as a callable function or by precomputing the kernel matrix. We can do either of these using the ``QuantumKernel`` class in ``qiskit``."
msgstr "Thuật toán ``scikit-learn`` ``svc`` cho phép chúng ta xác định `nhân tùy chỉnh <https://scikit-learn.org/stable/modules/svm.html#custom-kernels>`__ theo hai cách: bằng cách cung cấp nhân như một hàm có thể gọi được hoặc bằng cách tính toán trước ma trận hạt nhân. Chúng ta có thể dùng một trong hai cách này bằng cách sử dụng lớp ``QuantumKernel`` trong ``qiskit``."

#: ../../tutorials/03_quantum_kernel.ipynb:140
msgid "The following code gives the kernel as a callable function:"
msgstr "Mã sau cung cấp nhân như một hàm có thể gọi được:"

#: ../../tutorials/03_quantum_kernel.ipynb:184
msgid "The following code precomputes and plots the training and testing kernel matrices before providing them to the ``scikit-learn`` ``svc`` algorithm:"
msgstr "Mã sau đây tính toán trước và vẽ đồ thị sự đào tạo và thử nghiệm ma trận hạt nhân trước khi cung cấp chúng vào thuật toán ``scikit-learn`` ``svc``:"

#: ../../tutorials/03_quantum_kernel.ipynb:250
msgid "``qiskit`` also contains the ``qsvc`` class that extends the ``sklearn svc`` class, that can be used as follows:"
msgstr "``qiskit`` cũng chứa lớp ``qsvc`` để mở rộng lớp ``sklearn svc``, có thể được sử dụng như sau:"

#: ../../tutorials/03_quantum_kernel.ipynb:295
msgid "Clustering"
msgstr "Cụm dữ liệu"

#: ../../tutorials/03_quantum_kernel.ipynb:297
msgid "For our clustering example, we will again use the *ad hoc dataset* as described in `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__, and the ``scikit-learn`` ``spectral`` clustering algorithm."
msgstr "Với ví dụ về cụm dữ liệu, chúng ta sẽ lại sử dụng tập dữ liệu *ad hoc dataset* như đã mô tả trong `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__, và thuật toán phân cụm dữ liệu ``scikit-learn`` ``spectral``."

#: ../../tutorials/03_quantum_kernel.ipynb:299
msgid "We will regenerate the dataset with a larger gap between the two classes, and as clustering is an unsupervised machine learning task, we don’t need a test sample."
msgstr "Chúng ta sẽ tái tạo tập dữ liệu với khoảng cách lớn hơn giữa hai lớp, và vì cụm dữ liệu là một nhiệm vụ học máy không giám sát, chúng ta không cần mẫu thử nghiệm."

#: ../../tutorials/03_quantum_kernel.ipynb:350
msgid "We again set up the ``QuantumKernel`` class to calculate a kernel matrix using the `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__, and the BasicAer ``qasm_simulator`` using 1024 shots."
msgstr "Chúng tôi một lần nữa thiết lập lớp ``QuantumKernel`` để tính một ma trận hạt nhân bằng cách sử dụng `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__, và BasicAer ``qasm_simulator`` sử dụng 1024 lần chạy."

#: ../../tutorials/03_quantum_kernel.ipynb:377
msgid "The scikit-learn spectral clustering algorithm allows us to define a [custom kernel] in two ways: by providing the kernel as a callable function or by precomputing the kernel matrix. Using the QuantumKernel class in qiskit, we can only use the latter."
msgstr "Thuật toán phân cụm phổ scikit-learn cho phép chúng ta xác định một [hạt nhân tùy chỉnh] theo hai cách: bằng cách cung cấp hạt nhân như một hàm có thể gọi được hoặc bằng cách tính toán trước ma trận hạt nhân. Sử dụng lớp QuantumKernel trong qiskit, chúng ta chỉ có thể sử dụng cách thứ hai."

#: ../../tutorials/03_quantum_kernel.ipynb:379
msgid "The following code precomputes and plots the kernel matrices before providing it to the scikit-learn spectral clustering algorithm, and scoring the labels using normalized mutual information, since we a priori know the class labels."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:439
msgid "``scikit-learn`` has other algorithms that can use a precomputed kernel matrix, here are a few:"
msgstr "``scikit-learn`` có các thuật toán khác có thể sử dụng ma trận hạt nhân (kernel matrix) được tính toán trước, đây là một số ít:"

#: ../../tutorials/03_quantum_kernel.ipynb:441
msgid "`Agglomerative clustering <https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html>`__"
msgstr "`Phân cụm sát nhập (Agglomerative Clustering) <https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:442
msgid "`Support vector regression <https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html>`__"
msgstr "`Véc-tơ hỗ trợ hồi quy <https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:443
msgid "`Ridge regression <https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html>`__"
msgstr "`Hồi quy Ridge <https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:444
msgid "`Gaussian process regression <https://scikit-learn.org/stable/modules/gaussian_process.html>`__"
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:445
msgid "`Principal component analysis <https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html>`__"
msgstr "`Phân tích thành phần chính <https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html>`__"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:9
msgid "qGANs for Loading Random Distributions"
msgstr "các qGAN để tải sự phân phối ngẫu nhiên"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:11
msgid "Given :math:`k`-dimensional data samples, we employ a quantum Generative Adversarial Network (qGAN) to learn the data’s underlying random distribution and to load it directly into a quantum state:"
msgstr "Với mẫu dữ liệu :math:`k` chiều, chúng tôi sử dụng một Mạng Lượng Tử Đối Địch (qGAN) để tìm hiểu phân phối ngẫu nhiên cơ bản của dữ liệu và tải trực tiếp nó vào trạng thái lượng tử:"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:13
msgid "\\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle\n\n"
msgstr "\\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle\n\n"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:15
msgid "where :math:`p_{\\theta}^{j}` describe the occurrence probabilities of the basis states :math:`\\big| j\\rangle`."
msgstr "với :math:`p_{\\theta}^{j}` miêu tả xác suất xảy ra của hệ cơ sở trạng thái :math:`\\big| j\\rangle`."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:17
msgid "The aim of the qGAN training is to generate a state :math:`\\big| g_{\\theta}\\rangle` where :math:`p_{\\theta}^{j}`, for :math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}`, describe a probability distribution that is close to the distribution underlying the training data :math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}`."
msgstr "Mục đích của việc đào tạo qGAN là để tạo một trạng thái :math:`\\big| g_{\\theta}\\rangle` trong đó :math:`p_{\\theta}^{j}`, với :math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}`, miêu tả một hàm phân phối xác suất sát với sự phân phối của dữ liệu đào tạo nằm trong đó :math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}`."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:19
msgid "For further details please refer to `Quantum Generative Adversarial Networks for Learning and Loading Random Distributions <https://arxiv.org/abs/1904.00043>`__ *Zoufal, Lucchi, Woerner* [2019]."
msgstr "Để có thêm chi tiết hãy tham khảo `Quantum Generative Adversarial Networks for Learning and Loading Random Distributions <https://arxiv.org/abs/1904.00043>`__ *Zoufal, Lucchi, Woerner* [2019]."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:21
msgid "For an example of how to use a trained qGAN in an application, the pricing of financial derivatives, please see the `Option Pricing with qGANs <https://github.com/Qiskit/qiskit-finance/tree/main/docs/tutorials/10_qgan_option_pricing.ipynb>`__ tutorial."
msgstr "Ví dụ về cách sử dụng một qGAN được đào tạo trong một ứng dụng, giá của các phát sinh tài chính, vui lòng xem hướng dẫn ` Quyền chọn (cổ phiếu): Định giá quyền chọn với các qGAN <https://github.com/Qiskit/qiskit-finance/tree/main/docs/tutorials/10_qgan_option_pricing.ipynb>`__."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:56
msgid "Load the Training Data"
msgstr "Tải dữ liệu đào tạo"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:58
msgid "First, we need to load the :math:`k`-dimensional training data samples (here k=1)."
msgstr "Đầu tiên, chúng ta cần tải các mẫu dữ liệu đào tạo :math:`k`- chiều (ở đây k=1)."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:60
msgid "Next, the data resolution is set, i.e. the min/max data values and the number of qubits used to represent each data dimension."
msgstr "Tiếp theo, độ phân giải dữ liệu được đặt, tức các giá trị dữ liệu nhỏ nhất/lớn nhất và số lượng qubit được sử dụng để đại diện cho mỗi chiều dữ liệu."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:95
msgid "Initialize the qGAN"
msgstr "Khởi tạo qGAN"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:97
msgid "The qGAN consists of a quantum generator :math:`G_{\\theta}`, i.e., an ansatz, and a classical discriminator :math:`D_{\\phi}`, a neural network."
msgstr "Qgan bao gồm một bộ tạo lượng tử :math:`G_{\\theta}`, i.e., một ansatz, và một bộ phân loại tách biệt :math:`D_{\\phi}`, một mạng lưới neuron."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:99
msgid "To implement the quantum generator, we choose a depth-\\ :math:`1` ansatz that implements :math:`R_Y` rotations and :math:`CZ` gates which takes a uniform distribution as an input state. Notably, for :math:`k>1` the generator’s parameters must be chosen carefully. For example, the circuit depth should be :math:`>1` because higher circuit depths enable the representation of more complex structures."
msgstr "Để thi hành một bộ tạo lượng tử, chúng ta chọn ansatz có độ sâu \\ :math:`1` thực thi các phép quay :math:`R_Y` và các cổng :math:`CZ` gates với một trạng thái đầu vào đều liên tục. Cụ thể, cho :math:`k>1` tham số của bộ tạo cần được chọn một cách cẩn thận. Ví dụ như, độ sâu của mạch nên :math:`>1` vì mạch càng sâu thì cho phép biểu diễn những cấu trúc càng phức tạp."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:101
msgid "The classical discriminator used here is based on a neural network implementation using NumPy. There is also a discriminator based on PyTorch which is not installed by default when installing Qiskit - see `Optional Install <https://github.com/Qiskit/qiskit-machine-learning#optional-installs>`__ for more information."
msgstr "Bộ tách biệt cổ điển được sử dụng ở đây dựa trên việc thực hiện mạng neuron bằng cách sử dụng NumPy. Ngoài ra còn có một bộ tách biệt dựa trên PyTorch không được cài đặt mặc định khi cài đặt Qiskit - xem `Optional Install <https://github.com/Qiskit/qiskit-machine-learning#optional-installs>`__ để có thêm thông tin."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:103
msgid "Here, both networks are updated with the ADAM optimization algorithm (ADAM is qGAN optimizer default)."
msgstr "Ở đây, cả hai mạng được cập nhật với thuật toán tối ưu hóa ADAM (ADAM là qGAN tối ưu hóa mặc định)."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:164
msgid "Run the qGAN Training"
msgstr "Chạy đào tạo qGAN"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:166
msgid "During the training the discriminator’s and the generator’s parameters are updated alternately w.r.t the following loss functions:"
msgstr "Trong quá trình đào tạo các tham số của bộ tách biệt của bộ tạo được cập nhật một cách luân phiên dựa trên các hàm mất mát sau:"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:168
msgid "L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right]\n\n"
msgstr "L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right]\n\n"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:170
msgid "and"
msgstr "và"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:172
msgid "L_D\\left(\\phi, \\theta\\right) =\n"
"  \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],"
msgstr "L_D\\left(\\phi, \\theta\\right) =\n"
"  \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:177
msgid "with :math:`m` denoting the batch size and :math:`g^l` describing the data samples generated by the quantum generator."
msgstr "với :math:`m` là kích cỡ của mẻ và :math:`g^l` miêu tả những mẫu dữ liệu được tạo bởi bộ tạo lượng tử."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:179
msgid "Please note that the training, for the purpose of this notebook, has been kept briefer by the selection of a known initial point (``init_params``). Without such prior knowledge be aware training may take some while."
msgstr "Xin lưu ý rằng việc đào tạo, trong mục đích của notebook này, đã được giữ ngắn gọn hơn bằng cách lựa chọn điểm khởi đầu đã biết (``init_params``). Nếu không có thông tin như vậy trước thì sự đào tạo có thể mất một thời gian."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:245
msgid "Training Progress & Outcome"
msgstr "Tiến trình đào tạo & kết quả"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:247
msgid "Now, we plot the evolution of the generator’s and the discriminator’s loss functions during the training, as well as the progress in the relative entropy between the trained and the target distribution."
msgstr "Bây giờ, chúng ta vẽ đồ thị sự tiến hóa của sự mất mát của bộ tạo và bộ tách biệt trong suốt quá trình đào tạo, cũng như sự tiến bộ trong entropy tương đối giữa các sự phân phối của nhóm được đào tạo và mục tiêu cuối cùng."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:249
msgid "Finally, we also compare the cumulative distribution function (CDF) of the trained distribution to the CDF of the target distribution."
msgstr "Cuối cùng, chúng ta cũng so sánh hàm phân phối tích lũy (CDF) của phân phối được đào tạo với CDF của phân phối mục tiêu."

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector and Hybrid QNNs"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial introduces Qiskit’s ``TorchConnector`` class, and demonstrates how the ``TorchConnector`` allows for a natural integration of any ``NeuralNetwork`` from Qiskit Machine Learning into a PyTorch workflow. ``TorchConnector`` takes a Qiskit ``NeuralNetwork`` and makes it available as a PyTorch ``Module``. The resulting module can be seamlessly incorporated into PyTorch classical architectures and trained jointly without additional considerations, enabling the development and testing of novel **hybrid quantum-classical** machine learning architectures."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:15
msgid "Content:"
msgstr "Nội dung:"

#: ../../tutorials/05_torch_connector.ipynb:17
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:19
msgid "The first part of this tutorial shows how quantum neural networks can be trained using PyTorch’s automatic differentiation engine (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) for simple classification and regression tasks."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:21
msgid "`Classification <#1.-Classification>`__"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:23
msgid "Classification with PyTorch and ``OpflowQNN``"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:24
msgid "Classification with PyTorch and ``CircuitQNN``"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:26
msgid "`Regression <#2.-Regression>`__"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:28
msgid "Regression with PyTorch and ``OpflowQNN``"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:30
msgid "`Part 2: MNIST Classification, Hybrid QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:32
msgid "The second part of this tutorial illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow (in this case, a typical CNN architecture) to classify MNIST data in a hybrid quantum-classical manner."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:74
msgid "Part 1: Simple Classification & Regression"
msgstr "Phần 1: Phân loại đơn giản và Hồi quy"

#: ../../tutorials/05_torch_connector.ipynb:86
msgid "1. Classification"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:88
msgid "First, we show how ``TorchConnector`` allows to train a Quantum ``NeuralNetwork`` to solve a classification tasks using PyTorch’s automatic differentiation engine. In order to illustrate this, we will perform **binary classification** on a randomly generated dataset."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:144
msgid "A. Classification with PyTorch and ``OpflowQNN``"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:146
msgid "Linking an ``OpflowQNN`` to PyTorch is relatively straightforward. Here we illustrate this using the ``TwoLayerQNN``, a sub-case of ``OpflowQNN`` introduced in previous tutorials."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:254
msgid "Optimizer"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:256
msgid "The choice of optimizer for training any machine learning model can be crucial in determining the success of our training’s outcome. When using ``TorchConnector``, we get access to all of the optimizer algorithms defined in the [``torch.optim``] package (`link <https://pytorch.org/docs/stable/optim.html>`__). Some of the most famous algorithms used in popular machine learning architectures include *Adam*, *SGD*, or *Adagrad*. However, for this tutorial we will be using the L-BFGS algorithm (``torch.optim.LBFGS``), one of the most well know second-order optimization algorithms for numerical optimization."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:260
msgid "Loss Function"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:262
msgid "As for the loss function, we can also take advantage of PyTorch’s pre-defined modules from ``torch.nn``, such as the `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ or `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:264
msgid "**💡 Clarification :** In classical machine learning, the general rule of thumb is to apply a Cross-Entropy loss to classification tasks, and MSE loss to regression tasks. However, this recommendation is given under the assumption that the output of the classification network is a class probability value in the [0,1] range (usually this is achieved through a Softmax layer). Because the following example for ``TwoLayerQNN`` does not include such layer, and we don’t apply any mapping to the output (the following section shows an example of application of parity mapping with ``CircuitQNNs``), the QNN’s output can take any value in the range [-1,1]. In case you were wondering, this is the reason why this particular example uses MSELoss for classification despite it not being the norm (but we encourage you to experiment with different loss functions and see how they can impact training results)."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:442
#: ../../tutorials/05_torch_connector.ipynb:674
msgid "The red circles indicate wrongly classified data points."
msgstr "Vòng tròn màu đỏ biểu thị các điểm dữ liệu bị phân loại sai."

#: ../../tutorials/05_torch_connector.ipynb:454
msgid "B. Classification with PyTorch and ``CircuitQNN``"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:456
msgid "Linking an ``CircuitQNN`` to PyTorch requires a bit more attention than ``OpflowQNN``. Without the correct setup, backpropagation is not possible."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:458
msgid "In particular, we must make sure that we are returning a dense array of probabilities in the network’s forward pass (``sparse=False``). This parameter is set up to ``False`` by default, so we just have to make sure that it has not been changed."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:460
msgid "**⚠️ Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``CircuitQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:523
#: ../../tutorials/05_torch_connector.ipynb:815
msgid "For a reminder on optimizer and loss function choices, you can go back to `this section <#Optimizer>`__."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:686
msgid "2. Regression"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:688
msgid "We use a model based on the ``TwoLayerQNN`` to also illustrate how to perform a regression task. The chosen dataset in this case is randomly generated following a sine wave."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:730
msgid "A. Regression with PyTorch and ``OpflowQNN``"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:741
msgid "The network definition and training loop will be analogous to those of the classification task using ``TwoLayerQNN``. In this case, we define our own feature map and ansatz, instead of using the default values."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:963
msgid "Part 2: MNIST Classification, Hybrid QNNs"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:965
msgid "In this second part, we show how to leverage a hybrid quantum-classical neural network using ``TorchConnector``, to perform a more complex image classification task on the MNIST handwritten digits dataset."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:967
msgid "For a more detailed (pre-``TorchConnector``) explanation on hybrid quantum-classical neural networks, you can check out the corresponding section in the `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:996
msgid "Step 1: Defining Data-loaders for train and test"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:1007
msgid "We take advantage of the ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ to directly load a subset of the `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ and define torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) for train and test."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:1048
msgid "If we perform a quick visualization we can see that the train dataset consists of images of handwritten 0s and 1s."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:1120
msgid "Step 2: Defining the QNN and Hybrid Model"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:1131
msgid "This second step shows the power of the ``TorchConnector``. After defining our quantum neural network layer (in this case, a ``TwoLayerQNN``), we can embed it into a layer in our torch ``Module`` by initializing a torch connector as ``TorchConnector(qnn)``."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:1133
msgid "**⚠️ Attention:** In order to have an adequate gradient backpropagation in hybrid models, we MUST set the initial parameter ``input_gradients`` to TRUE during the qnn initialization."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:1235
msgid "Step 3: Training"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:1337
msgid "Step 4: Evaluation"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:1440
msgid "🎉🎉🎉🎉 **You are now able to experiment with your own hybrid datasets and architectures using Qiskit Machine Learning.** **Good Luck!**"
msgstr ""

#: ../../tutorials/index.rst:3
msgid "Machine Learning Tutorials"
msgstr "Hướng dẫn Machine Learning"

