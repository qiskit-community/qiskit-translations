msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-02-07 03:44+0000\n"
"PO-Revision-Date: 2023-02-07 05:15\n"
"Last-Translator: \n"
"Language: pl\n"
"Language-Team: Polish\n"
"Plural-Forms: nplurals=4; plural=(n==1 ? 0 : (n%10>=2 && n%10<=4) && (n%100<12 || n%100>14) ? 1 : n!=1 && (n%10>=0 && n%10<=1) || (n%10>=5 && n%10<=9) || (n%100>=12 && n%100<=14) ? 2 : 3);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: pl\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/07_pegasos_qsvc.po\n"
"X-Crowdin-File-ID: 9721\n"

#: ../../tutorials/07_pegasos_qsvc.ipynb:9
msgid "This page was generated from `docs/tutorials/07_pegasos_qsvc.ipynb`__."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:9
msgid "Pegasos Quantum Support Vector Classifier"
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:11
msgid "There’s another SVM based algorithm that benefits from the quantum kernel method. Here, we introduce an implementation of a another classification algorithm, which is an alternative version to the ``QSVC`` available in Qiskit Machine Learning and shown in the `“Quantum Kernel Machine Learning” <./03_quantum_kernel.ipynb>`__ tutorial. This classification algorithm implements the Pegasos algorithm from the paper “Pegasos: Primal Estimated sub-GrAdient SOlver for SVM” by Shalev-Shwartz et al., see: https://home.ttic.edu/~nati/Publications/PegasosMPB.pdf."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:14
msgid "This algorithm is an alternative to the dual optimization from the ``scikit-learn`` package, benefits from the kernel trick, and yields a training complexity that is independent of the size of the training set. Thus, the ``PegasosQSVC`` is expected to train faster than QSVC for sufficiently large training sets."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:16
msgid "The algorithm can be used as direct replacement of ``QSVC`` with some hyper-parameterization."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:27
msgid "Let’s generate some data:"
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:51
msgid "We pre-process the data to ensure compatibility with the rotation encoding and split it into the training and test datasets."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:81
msgid "We have two features in the dataset, so we set a number of qubits to the number of features in the dataset."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:83
msgid "Then we set :math:`\\tau` to the number of steps performed during the training procedure. Please note that, there is no early stopping criterion in the algorithm. The algorithm iterates over all :math:`\\tau` steps."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:85
msgid "And the last one is the hyperparameter :math:`C`. This is a positive regularization parameter. The strength of the regularization is inversely proportional to :math:`C`. Smaller :math:`C` induce smaller weights which generally helps preventing overfitting. However, due to the nature of this algorithm, some of the computation steps become trivial for larger :math:`C`. Thus, larger :math:`C` improve the performance of the algorithm drastically. If the data is linearly separable in feature space, :math:`C` should be chosen to be large. If the separation is not perfect, :math:`C` should be chosen smaller to prevent overfitting."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:114
msgid "The algorithm will run using:"
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:116
msgid "The default fidelity instantiated in ``FidelityQuantumKernel``"
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:117
msgid "A quantum kernel created from ``ZFeatureMap``"
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:148
msgid "The implementation ``PegasosQSVC`` is compatible with the ``scikit-learn`` interfaces and has a pretty standard way of training a model. In the constructor we pass parameters of the algorithm, in this case there are a regularization hyper-parameter :math:`C` and a number of steps."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:150
msgid "Then we pass training features and labels to the ``fit`` method, which trains a models and returns a fitted classifier."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:152
msgid "Afterwards, we score our model using test features and labels."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:206
msgid "For visualization purposes we create a mesh grid of a predefined step that spans our minimum and maximum values we applied in MinMaxScaler. We also add some margin to the grid for better representation of the training and test samples."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:231
msgid "We convert the grid to the shape compatible with the model, the shape should be ``(n_samples, n_features)``. Then for each grid point we predict a label. In our case predicted labels will be used for coloring the grid."
msgstr ""

#: ../../tutorials/07_pegasos_qsvc.ipynb:253
msgid "Finally, we plot our grid according to the labels/colors we obtained from the model. We also plot training and test samples."
msgstr ""

