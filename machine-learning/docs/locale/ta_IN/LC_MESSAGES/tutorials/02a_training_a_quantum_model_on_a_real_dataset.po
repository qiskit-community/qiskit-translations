msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-11-10 17:18+0000\n"
"PO-Revision-Date: 2023-11-10 18:25\n"
"Last-Translator: \n"
"Language: ta\n"
"Language-Team: Tamil\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.13.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ta\n"
"X-Crowdin-File: /main/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/02a_training_a_quantum_model_on_a_real_dataset.po\n"
"X-Crowdin-File-ID: 9883\n"

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:9
msgid "This page was generated from `docs/tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb`__."
msgstr "இந்தப் பக்கம் `docs/tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb`__ இலிருந்து உருவாக்கப்பட்டது."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:9
msgid "Training a Quantum Model on a Real Dataset"
msgstr "உண்மையான தரவுத்தொகுப்பில் குவாண்டம் மாதிரியைப் பயிற்றுவித்தல்"

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:11
msgid "This tutorial will demonstrate how to train a quantum machine learning model to tackle a classification problem. Previous tutorials have featured small, artificial datasets. Here we will increase the problem complexity by considering a real-life classical dataset. We decided to pick a very well-known – albeit still relatively small – problem: the Iris flower dataset. This dataset even has its own Wikipedia `page <https://en.wikipedia.org/wiki/Iris_flower_data_set>`__. Although the Iris dataset is well known to data scientists, we will briefly introduce it to refresh our memories. For comparison, we'll first train a classical counterpart to the quantum model."
msgstr "வகைப்பாடு சிக்கலைச் சமாளிக்க குவாண்டம் இயந்திர கற்றல் மாதிரியை எவ்வாறு பயிற்றுவிப்பது என்பதை இந்தப் பயிற்சி விளக்குகிறது. முந்தைய பயிற்சிகள் சிறிய, செயற்கை தரவுத்தொகுப்புகளைக் கொண்டிருந்தன. இங்கே நிஜ வாழ்க்கை கிளாசிக்கல் தரவுத்தொகுப்பைக் கருத்தில் கொண்டு சிக்கலின் சிக்கலை அதிகரிப்போம். மிகவும் நன்கு அறியப்பட்ட - இன்னும் சிறியதாக இருந்தாலும் - பிரச்சனை: ஐரிஸ் மலர் தரவுத்தொகுப்பைத் தேர்வுசெய்ய முடிவு செய்தோம். இந்தத் தரவுத்தொகுப்பில் அதன் சொந்த விக்கிபீடியா `பக்கம் <https://en.wikipedia.org/wiki/Iris_flower_data_set>`__ உள்ளது. ஐரிஸ் தரவுத்தொகுப்பு தரவு விஞ்ஞானிகளுக்கு நன்கு தெரிந்திருந்தாலும், நமது நினைவுகளைப் புதுப்பிக்க சுருக்கமாக அதை அறிமுகப்படுத்துவோம். ஒப்பிடுகையில், முதலில் குவாண்டம் மாதிரிக்கு ஒரு கிளாசிக்கல் ஒப்பீட்டைப் பயிற்றுவிப்போம்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:14
msgid "So, let's get started:"
msgstr "எனவே, தொடங்குவோம்:"

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:16
msgid "First, we'll load the dataset and explore what it looks like."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:17
msgid "Next, we'll train a classical model using `SVC <https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html>`__ from `scikit-learn <https://scikit-learn.org/>`__ to see how well the classification problem can be solved using classical methods."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:18
msgid "After that, we'll introduce the Variational Quantum Classifier (VQC)."
msgstr "அதன் பிறகு, நாம் விரிவான Quantum Classifier (VQC) அறிமுகம் செய்யும்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:19
msgid "To conclude, we'll compare the results obtained from both models."
msgstr "முடிவுக்கு, நாங்கள் இரண்டு மாதிரிகளில் இருந்து பெறப்பட்ட முடிவுகளையும் ஒப்பிடுவேன்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:22
msgid "1. Exploratory Data Analysis"
msgstr "1. ஆய்வுத் தரவுப் பகுப்பாய்வு"

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:24
msgid "First, let us explore the Iris dataset this tutorial will use and see what it contains. For our convenience, this `dataset <https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset>`__ is available in scikit-learn and can be loaded easily."
msgstr "முதலில், இந்த டுடோரியல் பயன்படுத்தும் ஐரிஸ் தரவுத்தொகுப்பை ஆராய்ந்து அதில் என்ன இருக்கிறது என்பதைப் பார்ப்போம். எங்கள் வசதிக்காக, இந்த `டேட்டாசெட் <https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset>`__ scikit-learnல் கிடைக்கிறது மற்றும் எளிதாக ஏற்ற முடியும்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:47
msgid "If no parameters are specified in the ``load_iris`` function, then a dictionary-like object is returned by scikit-learn. Let's print the description of the dataset and see what is inside."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:290
msgid "There are a few interesting observations we can find from this dataset description:"
msgstr "இந்தத் தரவுத்தொகுப்பு விளக்கத்திலிருந்து நாம் காணக்கூடிய சில சுவாரஸ்யமான அவதானிப்புகள் உள்ளன:"

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:292
msgid "There are 150 samples (instances) in the dataset."
msgstr "தரவுத்தொகுப்பில் 150 மாதிரிகள் (நிகழ்வுகள்) உள்ளன."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:293
msgid "There are four features (attributes) in each sample."
msgstr "ஒவ்வொரு மாதிரியிலும் நான்கு அம்சங்கள் (பண்புகள்) உள்ளன."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:294
msgid "There are three labels (classes) in the dataset."
msgstr "தரவுத்தொகுப்பில் மூன்று லேபிள்கள் (வகுப்புகள்) உள்ளன."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:295
msgid "The dataset is perfectly balanced, as there are the same number of samples (50) in each class."
msgstr "ஒவ்வொரு வகுப்பிலும் ஒரே மாதிரியான மாதிரிகள் (50) இருப்பதால், தரவுத்தொகுப்பு முற்றிலும் சமநிலையில் உள்ளது."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:296
msgid "We can see features are not normalized, and their value ranges are different, e.g., :math:`[4.3, 7.9]` and :math:`[0.1, 2.5]` for sepal length and petal width, respectively. So, transforming the features to the same scale may be helpful."
msgstr "அம்சங்கள் இயல்பாக்கப்படாமல் இருப்பதையும், அவற்றின் மதிப்பு வரம்புகள் வேறுபட்டிருப்பதையும் பார்க்கலாம், எ.கா., :math:`[4.3, 7.9]` மற்றும் :math:`[0.1, 2.5]` முறையே செப்பல் நீளம் மற்றும் இதழ் அகலம். எனவே, அம்சங்களை ஒரே அளவில் மாற்றுவது உதவியாக இருக்கும்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:297
msgid "As stated in the table above, feature-to-class correlation in some cases is very high; this may lead us to think that our model should cope well with the dataset."
msgstr "மேலே உள்ள அட்டவணையில் கூறப்பட்டுள்ளபடி, சில சந்தர்ப்பங்களில் அம்சம்-வகுப்பு தொடர்பு மிகவும் அதிகமாக உள்ளது; இது எங்கள் மாதிரி தரவுத்தொகுப்பைச் சரியாகச் சமாளிக்க வேண்டும் என்று நினைக்க வழிவகுக்கும்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:299
msgid "We only examined the dataset description, but additional properties are available in the ``iris_data`` object. Now we are going to work with features and labels from the dataset."
msgstr "தரவுத்தொகுப்பு விளக்கத்தை மட்டுமே நாங்கள் ஆய்வு செய்தோம், ஆனால் கூடுதல் பண்புகள் ``iris_data`` பொருளில் உள்ளன. இப்போது நாம் தரவுத்தொகுப்பிலிருந்து அம்சங்கள் மற்றும் லேபிள்களுடன் வேலை செய்யப் போகிறோம்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:321
msgid "Firstly, we'll normalize the features. Namely, we will apply a simple transformation to represent all features on the same scale. In our case, we squeeze all features onto the interval :math:`[0, 1]`. Normalization is a common technique in machine learning and often leads to better numerical stability and convergence of an algorithm."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:323
msgid "We can use ``MinMaxScaler`` from scikit-learn to perform this. Without specifying parameters, this does exactly what is required: maps data onto :math:`[0, 1]`."
msgstr "இதைச் செய்ய, scikit-learn இலிருந்து ``MinMaxScaler`` ஐப் பயன்படுத்தலாம். அளவுருக்களைக் குறிப்பிடாமல், இது சரியாகத் தேவையானதைச் செய்கிறது: :math:`[0, 1]` இல் தரவை வரைபடமாக்குகிறது."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:346
msgid "Let's see how our data looks. We plot the features pair-wise to see if there's an observable correlation between them."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:407
msgid "From the plots, we see that class ``0`` is easily separable from the other two classes, while classes ``1`` and ``2`` are sometimes intertwined, especially regarding the \"sepal width\" feature."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:409
msgid "Next, let's see how classical machine learning handles this dataset."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:412
msgid "2. Training a Classical Machine Learning Model"
msgstr "2. கிளாசிக்கல் மெஷின் கற்றல் மாதிரியைப் பயிற்றுவித்தல்"

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:414
msgid "Before we train a model, we should split the dataset into two parts: a training dataset and a test dataset. We'll use the former to train the model and the latter to verify how well our models perform on unseen data."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:416
msgid "As usual, we'll ask scikit-learn to do the boring job for us. We'll also fix the seed to ensure the results are reproducible."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:443
msgid "We train a classical Support Vector Classifier from scikit-learn. For the sake of simplicity, we don't tweak any parameters and rely on the default values."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:467
msgid "Now we check out how well our classical model performs. We will analyze the scores in the conclusion section."
msgstr "எங்கள் கிளாசிக்கல் மாடல் எவ்வளவு சிறப்பாகச் செயல்படுகிறது என்பதை இப்போது பார்க்கிறோம். முடிவுப் பிரிவில் மதிப்பெண்களைப் பகுப்பாய்வு செய்வோம்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:519
msgid "As can be seen from the scores, the classical SVC algorithm performs very well. Next up, it's time to look at quantum machine learning models."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:522
msgid "3. Training a Quantum Machine Learning Model"
msgstr "3. குவாண்டம் மெஷின் கற்றல் மாதிரியைப் பயிற்றுவித்தல்"

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:524
msgid "As an example of a quantum model, we'll train a variational quantum classifier (VQC). The VQC is the simplest classifier available in Qiskit Machine Learning and is a good starting point for newcomers to quantum machine learning who have a background in classical machine learning."
msgstr "ஒரு குவாண்டம் மாதிரியின் உதாரணமாக, ஒரு மாறுபாடு குவாண்டம் வகைப்படுத்தியை (VQC) பயிற்றுவிப்போம். VQC என்பது கிஸ்கிட் மெஷின் லேர்னிங்கில் கிடைக்கும் எளிமையான வகைப்படுத்தியாகும், மேலும் இது கிளாசிக்கல் மெஷின் லேர்னிங்கில் பின்னணியைக் கொண்ட குவாண்டம் மெஷின் லேர்னிங்கில் புதிதாக வருபவர்களுக்கு ஒரு நல்ல தொடக்கப் புள்ளியாகும்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:526
msgid "But before we train a model, let's examine what comprises the ``VQC`` class. Two of its central elements are the feature map and ansatz. What these are will now be explained."
msgstr "ஆனால் ஒரு மாதிரியைப் பயிற்றுவிப்பதற்கு முன், ``VQC`` வகுப்பை உள்ளடக்கியதாக ஆராய்வோம். அதன் இரண்டு மையக் கூறுகள் அம்ச வரைபடம் மற்றும் அன்சாட்ஸ் ஆகும். இவை என்ன என்பது இப்போது விளக்கப்படும்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:528
msgid "Our data is classical, meaning it consists of a set of bits, not qubits. We need a way to encode the data as qubits. This process is crucial if we want to obtain an effective quantum model. We usually refer to this mapping as data encoding, data embedding, or data loading and this is the role of the feature map. While feature mapping is a common ML mechanism, this process of loading data into quantum states does not appear in classical machine learning as that only operates in the classical world."
msgstr "எங்கள் தரவு கிளாசிக்கல், அதாவது இது பிட்களின் தொகுப்பைக் கொண்டுள்ளது, குவிட்கள் அல்ல. தரவை குவிட்களாக குறியாக்கம் செய்ய நமக்கு ஒரு வழி தேவை. பயனுள்ள குவாண்டம் மாதிரியைப் பெற விரும்பினால் இந்த செயல்முறை முக்கியமானது. நாங்கள் வழக்கமாக இந்த மேப்பிங்கை தரவு குறியாக்கம், தரவு உட்பொதித்தல் அல்லது தரவு ஏற்றுதல் என குறிப்பிடுகிறோம், இதுவே அம்ச வரைபடத்தின் பங்கு. அம்ச மேப்பிங் ஒரு பொதுவான ML பொறிமுறையாக இருந்தாலும், குவாண்டம் நிலைகளில் தரவை ஏற்றும் இந்த செயல்முறை கிளாசிக்கல் இயந்திர கற்றலில் தோன்றாது, ஏனெனில் இது கிளாசிக்கல் உலகில் மட்டுமே செயல்படுகிறது."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:531
msgid "Once the data is loaded, we must immediately apply a parameterized quantum circuit. This circuit is a direct analog to the layers in classical neural networks. It has a set of tunable parameters or weights. The weights are optimized such that they minimize an objective function. This objective function characterizes the distance between the predictions and known labeled data. A parameterized quantum circuit is also called a parameterized trial state, variational form, or ansatz. Perhaps, the latter is the most widely used term."
msgstr "தரவு ஏற்றப்பட்டதும், நாம் உடனடியாக ஒரு அளவுரு குவாண்டம் சர்க்யூட்டைப் பயன்படுத்த வேண்டும். இந்த சுற்று கிளாசிக்கல் நரம்பியல் நெட்வொர்க்குகளில் உள்ள அடுக்குகளுக்கு நேரடி அனலாக் ஆகும். இது சரிசெய்யக்கூடிய அளவுருக்கள் அல்லது எடைகளின் தொகுப்பைக் கொண்டுள்ளது. எடைகள் ஒரு புறநிலை செயல்பாட்டைக் குறைக்கும் வகையில் உகந்ததாக இருக்கும். இந்த புறநிலை செயல்பாடு கணிப்புகள் மற்றும் அறியப்பட்ட லேபிளிடப்பட்ட தரவுகளுக்கு இடையிலான தூரத்தை வகைப்படுத்துகிறது. ஒரு அளவுருவாக்கப்பட்ட குவாண்டம் சர்க்யூட் ஒரு அளவுருப்படுத்தப்பட்ட சோதனை நிலை, மாறுபாடு வடிவம் அல்லது அன்சாட்ஸ் என்றும் அழைக்கப்படுகிறது. ஒருவேளை, பிந்தையது மிகவும் பரவலாகப் பயன்படுத்தப்படும் சொல்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:534
msgid "For more information, we direct the reader to the `Quantum Machine Learning Course <https://learn.qiskit.org/course/machine-learning>`__."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:536
msgid "Our choice of feature map will be the ``ZZFeatureMap``. The ``ZZFeatureMap`` is one of the standard feature maps in the Qiskit circuit library. We pass ``num_features`` as ``feature_dimension``, meaning the feature map will have ``num_features`` or ``4`` qubits."
msgstr "அம்ச வரைபடத்தின் எங்கள் தேர்வு ``ZZFeatureMap`` ஆகும். ``ZZFeatureMap` என்பது Qiskit சர்க்யூட் லைப்ரரியில் உள்ள நிலையான அம்ச வரைபடங்களில் ஒன்றாகும். ``num_features`` என்பதை ``feature_dimension`` எனக் கடந்து செல்கிறோம், அதாவது அம்ச வரைபடத்தில் ``num_features`` அல்லது ``4`` குவிட்கள் இருக்கும்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:538
msgid "We decompose the feature map into its constituent gates to give the reader a flavor of how feature maps may look."
msgstr "அம்ச வரைபடங்கள் எவ்வாறு தோற்றமளிக்கலாம் என்பதை வாசகருக்கு வழங்க, அம்ச வரைபடத்தை அதன் தொகுதி வாயில்களாகச் சிதைக்கிறோம்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:602
msgid "If you look closely at the feature map diagram, you will notice parameters ``x[0], ..., x[3]``. These are placeholders for our features."
msgstr "அம்ச வரைபட வரைபடத்தை நீங்கள் உற்று நோக்கினால், ``x[0], ..., x[3]`` அளவுருக்களைக் காண்பீர்கள். இவை எங்கள் அம்சங்களுக்கான ஒதுக்கிடங்கள்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:604
msgid "Now we create and plot our ansatz. Pay attention to the repetitive structure of the ansatz circuit. We define the number of these repetitions using the ``reps`` parameter."
msgstr "இப்போது நாங்கள் எங்கள் அன்சாட்ஸை உருவாக்கி, திட்டமிடுகிறோம். அன்சாட்ஸ் சுற்றுகளின் மீண்டும் மீண்டும் கட்டமைப்பிற்கு கவனம் செலுத்துங்கள். ``reps`` அளவுருவைப் பயன்படுத்தி இந்த மறுநிகழ்வுகளின் எண்ணிக்கையை நாங்கள் வரையறுக்கிறோம்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:666
msgid "This circuit has 16 parameters named ``θ[0], ..., θ[15]``. These are the trainable weights of the classifier."
msgstr "இந்தச் சுற்றுக்கு ``θ[0], ..., θ[15]`` என்ற 16 அளவுருக்கள் உள்ளன. இவை வகைப்படுத்தியின் பயிற்சிக்குரிய எடைகள்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:668
msgid "We then choose an optimization algorithm to use in the training process. This step is similar to what you may find in classical deep learning frameworks. To make the training process faster, we choose a gradient-free optimizer. You may explore other optimizers available in Qiskit."
msgstr "பயிற்சி செயல்பாட்டில் பயன்படுத்த ஒரு தேர்வுமுறை அல்காரிதத்தை நாங்கள் தேர்வு செய்கிறோம். கிளாசிக்கல் டீப் லேர்னிங் ஃப்ரேம்வொர்க்குகளில் நீங்கள் காணக்கூடியதைப் போலவே இந்தப் படியும் இருக்கும். பயிற்சி செயல்முறையை விரைவுபடுத்த, சாய்வு இல்லாத ஆப்டிமைசரை நாங்கள் தேர்வு செய்கிறோம். Qiskit இல் கிடைக்கும் பிற உகப்பாக்கிகளை நீங்கள் ஆராயலாம்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:691
msgid "In the next step, we define where to train our classifier. We can train on a simulator or a real quantum computer. Here, we will use a simulator. We create an instance of the ``Sampler`` primitive. This is the reference implementation that is statevector based. Using qiskit runtime services you can create a sampler that is backed by a quantum computer."
msgstr "அடுத்த கட்டத்தில், எங்கள் வகைப்படுத்திக்கு எங்கு பயிற்சி அளிக்க வேண்டும் என்பதை நாங்கள் வரையறுக்கிறோம். நாம் ஒரு சிமுலேட்டர் அல்லது உண்மையான குவாண்டம் கணினியில் பயிற்சி பெறலாம். இங்கே, நாம் ஒரு சிமுலேட்டரைப் பயன்படுத்துவோம். ``Sampler`` பழமையான நிகழ்வை உருவாக்குகிறோம். இது ஸ்டேட்வெக்டர் அடிப்படையிலான குறிப்பு செயலாக்கமாகும். qiskit இயக்க நேர சேவைகளைப் பயன்படுத்தி, நீங்கள் ஒரு குவாண்டம் கணினியால் ஆதரிக்கப்படும் மாதிரியை உருவாக்கலாம்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:714
msgid "We will add a callback function called ``callback_graph``. ``VQC`` will call this function for each evaluation of the objective function with two parameters: the current weights and the value of the objective function at those weights. Our callback will append the value of the objective function to an array so we can plot the iteration versus the objective function value. The callback will update the plot at each iteration. Note that you can do whatever you want inside a callback function, so long as it has the two-parameter signature we mentioned above."
msgstr "``callback_graph`` என்றழைக்கப்படும் கால்பேக் செயல்பாட்டைச் சேர்ப்போம். புறநிலை செயல்பாட்டின் ஒவ்வொரு மதிப்பீட்டிற்கும் ``VQC`` இந்தச் செயல்பாட்டை இரண்டு அளவுருக்களுடன் அழைக்கும்: தற்போதைய எடைகள் மற்றும் அந்த எடைகளில் உள்ள புறநிலை செயல்பாட்டின் மதிப்பு. எங்கள் கால்பேக் புறநிலை செயல்பாட்டின் மதிப்பை ஒரு அணியில் சேர்க்கும், எனவே புறநிலை செயல்பாடு மதிப்புக்கு எதிராக மறு செய்கையை நாம் திட்டமிடலாம். அழைப்பு ஒவ்வொரு மறு செய்கையிலும் ப்ளாட்டை புதுப்பிக்கும். நாம் மேலே குறிப்பிட்டுள்ள இரண்டு அளவுரு கையொப்பம் இருக்கும் வரை, ஒரு கால்பேக் செயல்பாட்டிற்குள் நீங்கள் என்ன வேண்டுமானாலும் செய்யலாம் என்பதை நினைவில் கொள்ளவும்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:750
msgid "Now we are ready to construct the classifier and fit it."
msgstr "இப்போது நாங்கள் வகைப்படுத்தியை உருவாக்கி அதைப் பொருத்த தயாராக இருக்கிறோம்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:752
msgid "``VQC`` stands for \"variational quantum classifier.\" It takes a feature map and an ansatz and constructs a quantum neural network automatically. In the simplest case it is enough to pass the number of qubits and a quantum instance to construct a valid classifier. You may omit the ``sampler`` parameter, in this case a ``Sampler`` instance will be created for you in the way we created it earlier. We created it manually for illustrative purposes only."
msgstr "``VQC` என்பது \"மாறுபட்ட குவாண்டம் வகைப்படுத்தி\" என்பதைக் குறிக்கிறது. இது ஒரு அம்ச வரைபடம் மற்றும் ஒரு அன்சாட்ஸை எடுத்து தானாகவே ஒரு குவாண்டம் நியூரல் நெட்வொர்க்கை உருவாக்குகிறது. எளிமையான வழக்கில், சரியான வகைப்படுத்தியை உருவாக்க, குவிட்களின் எண்ணிக்கையையும் குவாண்டம் நிகழ்வையும் அனுப்பினால் போதும். நீங்கள் ``மாதிரி`` அளவுருவைத் தவிர்க்கலாம், இந்தச் சந்தர்ப்பத்தில் நாங்கள் முன்பு உருவாக்கிய வழியில் உங்களுக்காக ``மாதிரி`` நிகழ்வு உருவாக்கப்படும். விளக்க நோக்கங்களுக்காக மட்டுமே நாங்கள் அதை கைமுறையாக உருவாக்கியுள்ளோம்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:754
msgid "Training may take some time. Please, be patient."
msgstr "பயிற்சி சிறிது நேரம் ஆகலாம். தயவுசெய்து பொறுமையாக இருங்கள்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:826
msgid "Let's see how the quantum model performs on the real-life dataset."
msgstr "நிஜ வாழ்க்கை தரவுத்தொகுப்பில் குவாண்டம் மாதிரி எவ்வாறு செயல்படுகிறது என்பதைப் பார்ப்போம்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:878
msgid "As we can see, the scores are high, and the model can be used to predict labels on unseen data."
msgstr "நாம் பார்க்கிறபடி, மதிப்பெண்கள் அதிகமாக உள்ளன, மேலும் பார்க்காத தரவுகளில் லேபிள்களைக் கணிக்க மாதிரியைப் பயன்படுத்தலாம்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:880
msgid "Now let's see what we can tune to get even better models."
msgstr "இன்னும் சிறந்த மாடல்களைப் பெற என்ன டியூன் செய்யலாம் என்பதை இப்போது பார்க்கலாம்."

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:882
msgid "The key components are the feature map and the ansatz. You can tweak parameters. In our case, you may change the ``reps`` parameter that specifies how repetitions of a gate pattern we add to the circuit. Larger values lead to more entanglement operations and more parameters. Thus, the model can be more flexible, but the higher number of parameters also adds complexity, and training such a model usually takes more time. Furthermore, we may end up overfitting the model. You can try the other feature maps and ansatzes available in the `Qiskit circuit library <https://qiskit.org/documentation/apidoc/circuit_library.html#n-local-circuits>`__, or you can come up with custom circuits."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:884
msgid "You may try other optimizers. Qiskit contains a bunch of them. Some of them are gradient-free, others not. If you choose a gradient-based optimizer, e.g., ``L_BFGS_B``, expect the training time to increase. Additionally to the objective function, these optimizers must evaluate the gradient with respect to the training parameters, which leads to an increased number of circuit executions per iteration."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:885
msgid "Another option is to randomly (or deterministically) sample ``initial_point`` and fit the model several times."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:887
msgid "But what if a dataset contains more features than a modern quantum computer can handle? Recall, in this example, we had the same number of qubits as the number of features in the dataset, but this may not always be the case."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:890
msgid "4. Reducing the Number of Features"
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:892
msgid "In this section, we reduce the number of features in our dataset and train our models again. We'll move through faster this time as the steps are the same except for the first, where we apply a PCA transformation."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:894
msgid "We transform our four features into two features only. This dimensionality reduction is for educational purposes only. As you saw in the previous section, we can train a quantum model using all four features from the dataset."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:896
msgid "Now, we can easily plot these two features on a single figure."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:956
msgid "As usual, we split the dataset first, then fit a classical model."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:1014
msgid "The results are still good but slightly worse compared to the initial version. Let's see how a quantum model deals with them. As we now have two qubits, we must recreate the feature map and ansatz."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:1038
msgid "We also reduce the maximum number of iterations we run the optimization process for, as we expect it to converge faster because we now have fewer qubits."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:1059
msgid "Now we construct a quantum classifier from the new parameters and train it."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:1173
msgid "Well, the scores are higher than a fair coin toss but could be better. The objective function is almost flat towards the end, meaning increasing the number of iterations won't help, and model performance will stay the same. Let's see what we can do with another ansatz."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:1288
msgid "The scores are better than in the previous setup. Perhaps if we had used more iterations, we could do even better."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:1300
msgid "5. Conclusion"
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:1302
msgid "In this tutorial, we have built two classical and three quantum machine learning models. Let's print an overall table with our results."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:1371
msgid "Unsurprisingly, the classical models perform better than their quantum counterparts, but classical ML has come a long way, and quantum ML has yet to reach that level of maturity. As we can see, we achieved the best results using a classical support vector machine. But the quantum model trained on four features was also quite good. When we reduced the number of features, the performance of all models went down as expected. So, if resources permit training a model on a full-featured dataset without any reduction, you should train such a model. If not, you may expect to compromise between dataset size, training time, and score."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:1374
msgid "Another observation is that even a simple ansatz change can lead to better results. The two-feature model with the ``EfficientSU2`` ansatz performs better than the one with ``RealAmplitudes``. That means the choice of hyperparameters plays the same critical role in quantum ML as in classical ML, and searching for optimal hyperparameters may take a long time. You may apply the same techniques we use in classical ML, such as random/grid or more sophisticated approaches."
msgstr ""

#: ../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.ipynb:1376
msgid "We hope this brief tutorial helps you to take the leap from classical to quantum ML."
msgstr ""

