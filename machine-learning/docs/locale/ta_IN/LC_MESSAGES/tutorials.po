msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-06-29 14:17+0000\n"
"PO-Revision-Date: 2021-07-03 11:23\n"
"Last-Translator: \n"
"Language-Team: Tamil\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ta\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials.po\n"
"X-Crowdin-File-ID: 9528\n"
"Language: ta_IN\n"

#: ../../tutorials/01_neural_networks.ipynb:13
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:13
#: ../../tutorials/03_quantum_kernel.ipynb:13
#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:13
#: ../../tutorials/05_torch_connector.ipynb:13
msgid "Run interactively in jupyter notebook."
msgstr "ஜூபிட்டர் நோட்புக்கில் ஊடாடும் வகையில் இயக்கவும்."

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "குவாண்டம் நியூரல் நெட்வொர்க்குகள்"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "இந்த நோட்புக் qiskit இயந்திர கற்றலில் வழங்கப்பட்ட வெவ்வேறு பொதுவான குவாண்டம் நியூரல் நெட்வொர்க் (QNN) செயலாக்கங்களை நிரூபிக்கிறது. நெட்வொர்க்குகள் பயன்பாட்டு-அஞ்ஞான கணக்கீட்டு அலகுகளாகக் கருதப்படுகின்றன, அவை பலவிதமான பயன்பாட்டு நிகழ்வுகளுக்குப் பயன்படுத்தப்படலாம். பயன்பாட்டைப் பொறுத்து, ஒரு குறிப்பிட்ட வகை நெட்வொர்க் அதிகமாகவோ அல்லது குறைவாகவோ பொருத்தமானதாக இருக்கலாம் மற்றும் ஒரு குறிப்பிட்ட வழியில் அமைக்க வேண்டியிருக்கும். பின்வரும் வெவ்வேறு நரம்பியல் நெட்வொர்க்குகள் இப்போது விரிவாக விவாதிக்கப்படும்:"

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks."
msgstr "``NeuralNetwork``: நரம்பியல் நெட்வொர்க்குகளுக்கான இடைமுகம்."

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``OpflowQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr "``OpflowQNN``: குவாண்டம் மெக்கானிக்கல் அவதானிப்புகளின் மதிப்பீட்டை அடிப்படையாகக் கொண்ட பிணையம்."

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``TwoLayerQNN``: A special ``OpflowQNN`` implementation for convenience."
msgstr "``TwoLayerQNN``: வசதிக்காக ஒரு சிறப்பு ``OpflowQNN`` செயல்படுத்தல்."

#: ../../tutorials/01_neural_networks.ipynb:16
msgid "``CircuitQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr "``CircuitQNN``: குவாண்டம் சுற்றுவட்டத்தை அளவிடுவதன் விளைவாக மாதிரிகளை அடிப்படையாகக் கொண்ட பிணையம்."

#: ../../tutorials/01_neural_networks.ipynb:64
msgid "1. ``NeuralNetwork``"
msgstr "1. ``NeuralNetwork``"

#: ../../tutorials/01_neural_networks.ipynb:66
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interfaces are introduced."
msgstr "``NeuralNetwork`` என்பது qiskit இயந்திர கற்றலில் கிடைக்கும் அனைத்து நரம்பியல் நெட்வொர்க்குகளுக்கான இடைமுகத்தைக் குறிக்கிறது. இது தரவு மாதிரிகள் மற்றும் பயிற்சியளிக்கக்கூடிய எடைகளை உள்ளீடாக எடுத்து முன்னோக்கி மற்றும் பின்தங்கிய பாஸை அம்பலப்படுத்துகிறது. ``NeuralNetwork`` எந்த பயிற்சி திறன்களையும் கொண்டிருக்கவில்லை, இவை உண்மையான வழிமுறைகள் / பயன்பாடுகளுக்குத் தள்ளப்படுகின்றன. எனவே, ஒரு ``NeuralNetwork`` பயிற்சியளிக்கக்கூடிய எடைகளுக்கான மதிப்புகளையும் சேமிக்காது. பின்வருவனவற்றில், இந்த இடைமுகங்களின் வெவ்வேறு செயலாக்கங்கள் அறிமுகப்படுத்தப்படுகின்றன."

#: ../../tutorials/01_neural_networks.ipynb:68
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes either flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr "``nn`` எனப்படும் ``NeuralNetwork`` என்று வைத்துக்கொள்வோம். பின்னர், ``nn.forward(input, weights)`` பாஸ் முறையே தரவு மற்றும் எடைகள் ``nn.num_inputs`` மற்றும் ``nn.num_weights`` ஆகியவற்றிற்கான தட்டையான உள்ளீடுகளை எடுக்கும். ``NeuralNetwork`` உள்ளீடுகளின் தொகுப்பை ஆதரிக்கிறது மற்றும் தொடர்புடைய வடிவத்தின் வெளியீட்டின் தொகுப்புகளை வழங்குகிறது."

#: ../../tutorials/01_neural_networks.ipynb:80
msgid "2. ``OpflowQNN``"
msgstr "2. ``OpflowQNN``"

#: ../../tutorials/01_neural_networks.ipynb:82
msgid "The ``OpflowQNN`` takes a (parametrized) operator from Qiskit and leverages Qiskit’s gradient framework to provide the backward pass. Such an operator can for instance be an expected value of a quantum mechanical observable with respect to a parametrized quantum state. The Parameters can be used to load classical data as well as represent trainable weights. The ``OpflowQNN`` also allows lists of operators and more complex structures to construct more complex QNNs."
msgstr "``OpflowQNN`` qiskit-டிலிருந்து ஒரு (அளவுரு) ஆபரேட்டரை எடுத்து பின்தங்கிய பாஸை வழங்க qiskit-டின் சாய்வு கட்டமைப்பை ஆதரிக்கிறது. அத்தகைய ஆபரேட்டர் உதாரணமாக, ஒரு அளவுரு குவாண்டம் நிலையைப் பொறுத்தவரை கவனிக்கக்கூடிய ஒரு குவாண்டம் இயந்திரத்தின் எதிர்பார்க்கப்படும் மதிப்பாக இருக்கலாம். கிளாசிக்கல் தரவை ஏற்றுவதற்கும், பயிற்சியளிக்கக்கூடிய எடைகளைக் குறிப்பதற்கும் அளவுருக்கள் பயன்படுத்தப்படலாம். ``OpflowQNN`` ஆபரேட்டர்கள் மற்றும் மிகவும் சிக்கலான கட்டமைப்புகளின் பட்டியல்களை மிகவும் சிக்கலான QNN களை உருவாக்க அனுமதிக்கிறது."

#: ../../tutorials/01_neural_networks.ipynb:321
msgid "Combining multiple observables in a ``ListOp`` also allows to create more complex QNNs"
msgstr "``ListOp`` இல் பல அவதானிப்புகளை இணைப்பது மிகவும் சிக்கலான QNN களை உருவாக்க அனுமதிக்கிறது"

#: ../../tutorials/01_neural_networks.ipynb:412
msgid "3. ``TwoLayerQNN``"
msgstr "3. ``TwoLayerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:414
msgid "The ``TwoLayerQNN`` is a special ``OpflowQNN`` on :math:`n` qubits that consists of first a feature map to insert data and second an ansatz that is trained. The default observable is :math:`Z^{\\otimes n}`, i.e., parity."
msgstr "``TwoLayerQNN`` என்பது ஒரு சிறப்பு ``OpflowQNN`` இல் :math:`n` குவிட்ஸ், இது முதலில் தரவைச் செருகுவதற்கான அம்ச வரைபடத்தையும், இரண்டாவதாக பயிற்சியளிக்கப்பட்ட ஒரு அன்சாட்ஸையும் கொண்டுள்ளது. இயல்புநிலையாகக் காணக்கூடியது :math:`Z^{\\otimes n}`, அதாவது, சமநிலை."

#: ../../tutorials/01_neural_networks.ipynb:612
msgid "4. ``CircuitQNN``"
msgstr "4. ``CircuitQNN``"

#: ../../tutorials/01_neural_networks.ipynb:614
msgid "The ``CircuitQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples can either be interpreted as probabilities of measuring the integer index corresponding to a bitstring or directly as a batch of binary output. In the case of probabilities, gradients can be estimated efficiently and the ``CircuitQNN`` provides a backward pass as well. In case of samples, differentiation is not possible and the backward pass returns ``(None, None)``."
msgstr "``CircuitQNN`` என்பது ஒரு (அளவுருவாக்கப்பட்ட) ``QuantumCircuit`` ஐ அடிப்படையாகக் கொண்டது. இது உள்ளீடு மற்றும் எடை அளவுருக்களை எடுத்து அளவீட்டிலிருந்து மாதிரிகளை உருவாக்குகிறது. மாதிரிகள் ஒரு பிட்ஸ்ட்ரிங்கிற்கு ஒத்த முழு எண் குறியீட்டை அளவிடுவதற்கான நிகழ்தகவுகள் அல்லது நேரடியாக பைனரி வெளியீட்டின் தொகுப்பாக விளக்கப்படலாம். நிகழ்தகவுகளின் விஷயத்தில், சாய்வுகளை திறமையாக மதிப்பிடலாம் மற்றும் ``CircuitQNN`` பின்தங்கிய பாஸையும் வழங்குகிறது. மாதிரிகள் விஷயத்தில், வேறுபாடு சாத்தியமில்லை மற்றும் பின்தங்கிய பாஸ் ``(None, None)``."

#: ../../tutorials/01_neural_networks.ipynb:617
msgid "Further, the ``CircuitQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are agregated accordingly."
msgstr "மேலும், ``CircuitQNN`` மாதிரிகளை பிந்தைய செயலாக்க ``interpret`` செயல்பாட்டைக் குறிப்பிட அனுமதிக்கிறது. இது ஒரு அளவிடப்பட்ட முழு எண்ணை (ஒரு பிட்ஸ்ட்ரிங்கிலிருந்து) எடுத்து புதிய குறியீட்டிற்கு வரைபடமாக்கும் என்று எதிர்பார்க்கப்படுகிறது, அதாவது எதிர்மறை அல்லாத முழு எண். இந்த வழக்கில், வெளியீட்டு வடிவத்தை வழங்க வேண்டும் மற்றும் அதற்கேற்ப நிகழ்தகவுகள் ஒருங்கிணைக்கப்படுகின்றன."

#: ../../tutorials/01_neural_networks.ipynb:619
msgid "A ``CircuitQNN`` can be configured to return sparse as well as dense probability vectors. If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits and a sparse recommendation is usually recommended. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr "``CircuitQNN`` ஐ சிதறல் மற்றும் அடர்த்தியான நிகழ்தகவு திசையன்களைத் தரும்படி கட்டமைக்க முடியும். ``interpret`` செயல்பாடு எதுவும் பயன்படுத்தப்படாவிட்டால், நிகழ்தகவு திசையன் அளவீடுகளின் அளவு பரிமாணங்களின் எண்ணிக்கையுடன் அதிவேகமாக அளவிடப்படுகிறது மற்றும் ஒரு சிதறிய பரிந்துரை பொதுவாக பரிந்துரைக்கப்படுகிறது. ``interpret`` செயல்பாட்டின் போது அது எதிர்பார்த்த முடிவைப் பொறுத்தது. உதாரணமாக, ஒரு குறியீட்டு தொடர்புடைய பிட்ஸ்ட்ரிங்கின் சமநிலையுடன் பொருத்தப்பட்டால், அதாவது, 0 அல்லது 1 க்கு, அடர்த்தியான வெளியீடு அர்த்தமுள்ளதாக இருக்கும், இதன் விளைவாக நீளம் 2 இன் நிகழ்தகவு திசையன் இருக்கும்."

#: ../../tutorials/01_neural_networks.ipynb:662
msgid "4.1 Output: sparse integer probabilities"
msgstr "4.1 வெளியீடு: சிதறல் முழு எண் நிகழ்தகவுகள்"

#: ../../tutorials/01_neural_networks.ipynb:761
msgid "4.2 Output: dense parity probabilities"
msgstr "4.2 வெளியீடு: அடர்த்தியான சமநிலை நிகழ்தகவுகள்"

#: ../../tutorials/01_neural_networks.ipynb:869
msgid "4.3 Output: Samples"
msgstr "4.3 வெளியீடு: மாதிரிகள்"

#: ../../tutorials/01_neural_networks.ipynb:985
msgid "4.4 Output: Parity Samples"
msgstr "4.4 வெளியீடு: பரிதி மாதிரிகள்"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:9
msgid "Neural Network Classifier & Regressor"
msgstr "நரம்பியல் நெட்வொர்க் வகைப்படுத்தி & பின்னடைவு"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:11
msgid "In this tutorial we show how the ``NeuralNetworkClassifier`` and ``NeuralNetworkRegressor`` are used. Both take as an input a (Quantum) ``NeuralNetwork`` and leverage it in a specific context. In both cases we also provide a pre-configured variant for convenience, the Variational Quantum Classifier (``VQC``) and Variational Quantum Regressor (``VQR``). The tutorial is structured as follows:"
msgstr "இந்த டுடோரியலில் ``NeuralNetworkClassifier`` மற்றும் ``NeuralNetworkRegressor`` எவ்வாறு பயன்படுத்தப்படுகின்றன என்பதைக் காட்டுகிறோம். இருவரும் ஒரு உள்ளீடாக ஒரு (குவாண்டம்) ``NeuralNetwork`` ஐ எடுத்து ஒரு குறிப்பிட்ட சூழலில் பயன்படுத்துகிறார்கள். இரண்டு நிகழ்வுகளிலும் வசதிக்காக முன்பே உள்ளமைக்கப்பட்ட மாறுபாட்டை நாங்கள் வழங்குகிறோம், மாறுபட்ட குவாண்டம் வகைப்படுத்தி (``VQC``) மற்றும் மாறுபட்ட குவாண்டம் பின்னடைவு (``VQR``). பயிற்சி பின்வருமாறு கட்டமைக்கப்பட்டுள்ளது:"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:13
msgid "`Classification <#Classification>`__"
msgstr "`Classification <#Classification>`__"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:15
msgid "Classification with an ``OpflowQNN``"
msgstr "``OpflowQNN`` உடன் வகைப்பாடு"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:16
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:249
msgid "Classification with a ``CircuitQNN``"
msgstr "``CircuitQNN`` உடன் வகைப்பாடு"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:17
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:398
msgid "Variational Quantum Classifier (``VQC``)"
msgstr "மாறுபட்ட குவாண்டம் வகைப்படுத்தி (``VQC``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:19
msgid "`Regression <#Regression>`__"
msgstr "`Regression <#Regression>`__"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:21
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:539
msgid "Regression with an ``OpflowQNN``"
msgstr "``OpflowQNN`` உடன் பின்னடைவு"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:22
msgid "Variational Quantum Regressor (``VQR``)"
msgstr "மாறுபட்ட குவாண்டம் பின்னடைவு (`` VQR``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:70
#: ../../tutorials/03_quantum_kernel.ipynb:53
#: ../../tutorials/05_torch_connector.ipynb:69
msgid "Classification"
msgstr "வகைப்படுத்துதல்"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:72
msgid "We prepare a simple classification dataset to illustrate the following algorithms."
msgstr "பின்வரும் வழிமுறைகளை விளக்குவதற்கு எளிய வகைப்பாடு தரவுத்தொகுப்பை நாங்கள் தயார் செய்கிறோம்."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:117
msgid "Classification with the an ``OpflowQNN``"
msgstr "``OpflowQNN`` உடன் வகைப்பாடு"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:119
msgid "First we show how an ``OpflowQNN`` can be used for classification within a ``NeuralNetworkClassifier``. In this context, the ``OpflowQNN`` is expected to return one-dimensional output in :math:`[-1, +1]`. This only works for binary classification and we assign the two classes to :math:`\\{-1, +1\\}`. For convenience, we use the ``TwoLayerQNN``, which is a special type of ``OpflowQNN`` defined via a feature map and an ansatz."
msgstr "முதலில் ``NeuralNetworkClassifier`` க்குள் வகைப்படுத்தலுக்கு ``OpflowQNN`` எவ்வாறு பயன்படுத்தப்படலாம் என்பதைக் காண்பிப்போம். இந்த சூழலில், `` OpflowQNN`` இதில் ஒரு பரிமாண வெளியீட்டை வழங்கும் :math:`[-1, +1]`. இது பைனரி வகைப்பாட்டிற்கு மட்டுமே செயல்படும், மேலும் இரண்டு வகுப்புகளையும் இதற்கு ஒதுக்குகிறோம் :math:`\\{-1, +1\\}`. வசதிக்காக, ``TwoLayerQNN`` ஐப் பயன்படுத்துகிறோம், இது ஒரு சிறப்பு வகை ``OpflowQNN`` ஒரு அம்ச வரைபடம் மற்றும் ஒரு அன்சாட்ஸ் வழியாக வரையறுக்கப்பட்டுள்ளது."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:251
msgid "Next we show how a ``CircuitQNN`` can be used for classification within a ``NeuralNetworkClassifier``. In this context, the ``CircuitQNN`` is expected to return :math:`d`-dimensional probability vector as output, where :math:`d` denotes the number of classes. Sampling from a ``QuantumCircuit`` automatically results in a probability distribution and we just need to define a mapping from the measured bitstrings to the different classes. For binary classification we use the parity mapping."
msgstr "அடுத்து ``NeuralNetworkClassifier`` க்குள் வகைப்படுத்தலுக்கு ``CircuitQNN`` எவ்வாறு பயன்படுத்தப்படலாம் என்பதைக் காண்பிப்போம். இந்த சூழலில், ``CircuitQNN`` திரும்பும் என்று எதிர்பார்க்கப்படுகிறது :math:`d`-பரிமாண நிகழ்தகவு திசையன் வெளியீடாக, எங்கே :math:`d` என்பது வகுப்புகளின் எண்ணிக்கையைக் குறிக்கிறது. ``QuantumCircuit`` இலிருந்து மாதிரியானது தானாக நிகழ்தகவு விநியோகத்தில் விளைகிறது, மேலும் அளவிடப்பட்ட பிட்ஸ்ட்ரிங்கிலிருந்து வெவ்வேறு வகுப்புகளுக்கு ஒரு மேப்பிங்கை வரையறுக்க வேண்டும். பைனரி வகைப்பாட்டிற்கு நாங்கள் பரிதி மேப்பிங்கைப் பயன்படுத்துகிறோம்."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:400
msgid "The ``VQC`` is a special variant of the ``NeuralNetworkClassifier`` with a ``CircuitQNN``. It applies a parity mapping (or extensions to multiple classes) to map from the bitstring to the classification, which results in a probability vector, which is interpreted as a one-hot encoded result. By default, it applies this the ``CrossEntropyLoss`` function that expects labels given in one-hot encoded format and will return predictions in that format too."
msgstr "``VQC`` என்பது ``CircuitQNN`` உடன் ``NeuralNetworkClassifier`` சிறப்பு மாறுபாடாகும். இது பிட்ஸ்ட்ரிங்கிலிருந்து வகைப்பாட்டிற்கு வரைபட ஒரு சமநிலை மேப்பிங்கை (அல்லது பல வகுப்புகளுக்கு நீட்டிப்புகள்) பயன்படுத்துகிறது, இதன் விளைவாக நிகழ்தகவு திசையன் உருவாகிறது, இது ஒரு சூடான குறியாக்கப்பட்ட விளைவாக விளக்கப்படுகிறது. இயல்பாக, இது ஒரு ஹாட் என்கோடட் வடிவத்தில் கொடுக்கப்பட்ட லேபிள்களை எதிர்பார்க்கும் ``CrossEntropyLoss`` செயல்பாட்டைப் பயன்படுத்துகிறது, மேலும் அந்த வடிவமைப்பிலும் கணிப்புகளைத் தரும்."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:496
#: ../../tutorials/05_torch_connector.ipynb:524
msgid "Regression"
msgstr "பின்னடைவு"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:498
msgid "We prepare a simple regression dataset to illustrate the following algorithms."
msgstr "பின்வரும் வழிமுறைகளை விளக்குவதற்கு எளிய பின்னடைவு தரவுத்தொகுப்பை நாங்கள் தயார் செய்கிறோம்."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:541
msgid "Here we restrict to regression with an ``OpflowQNN`` that returns values in :math:`[-1, +1]`. More complex and also multi-dimensional models could be constructed, also based on ``CircuitQNN`` but that exceeds the scope of this tutorial."
msgstr ":math:`[-1, +1]` இல் மதிப்புகளை வழங்கும் ``OpflowQNN`` உடன் பின்னடைவை இங்கு கட்டுப்படுத்துகிறோம். ``CircuitQNN`` ஐ அடிப்படையாகக் கொண்டு மிகவும் சிக்கலான மற்றும் பல பரிமாண மாதிரிகள் உருவாக்கப்படலாம், ஆனால் இது இந்த டுடோரியலின் நோக்கத்தை மீறுகிறது."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:648
msgid "Regression with the Variational Quantum Regressor (``VQR``)"
msgstr "மாறுபட்ட குவாண்டம் பின்னடைவுடன் பின்னடைவு (``VQR``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:650
msgid "Similar to the ``VQC`` for classification, the ``VQR`` is a special variant of the ``NeuralNetworkRegressor`` with a ``OpflowQNN``. By default it considers the ``L2Loss`` function to minimize the mean squared error between predictions and targets."
msgstr "வகைப்பாட்டிற்கான ``VQC`` ஐப் போலவே, ``VQR`` என்பது ``OpflowQNN`` உடன் ``NeuralNetworkRegressor`` இன் சிறப்பு மாறுபாடாகும். முன்னிருப்பாக இது கணிப்புகள் மற்றும் இலக்குகளுக்கு இடையிலான சராசரி ஸ்கொயர் பிழையைக் குறைக்க ``L2Loss`` செயல்பாட்டைக் கருதுகிறது."

#: ../../tutorials/03_quantum_kernel.ipynb:9
msgid "Quantum Kernel Machine Learning"
msgstr "குவாண்டம் கர்னல் இயந்திர வழி கற்றல்"

#: ../../tutorials/03_quantum_kernel.ipynb:11
msgid "The general task of machine learning is to find and study patterns in data. For many datasets, the datapoints are better understood in a higher dimensional feature space, through the use of a kernel function: :math:`k(\\vec{x}_i, \\vec{x}_j) = \\langle f(\\vec{x}_i), f(\\vec{x}_j) \\rangle` where :math:`k` is the kernel function, :math:`\\vec{x}_i, \\vec{x}_j` are :math:`n` dimensional inputs, :math:`f` is a map from :math:`n`-dimension to :math:`m`-dimension space and :math:`\\langle a,b \\rangle` denotes the dot product. When considering finite data, a kernel function can be represented as a matrix: :math:`K_{ij} = k(\\vec{x}_i,\\vec{x}_j)`."
msgstr "இயந்திர கற்றலின் பொதுவான பணி தரவுகளில் வடிவங்களைக் கண்டறிந்து படிப்பதாகும். பல தரவுத்தொகுப்புகளுக்கு, ஒரு கர்னல் செயல்பாட்டின் மூலம் தரவு புள்ளிகள் உயர் பரிமாண அம்ச இடத்தில் நன்கு புரிந்து கொள்ளப்படுகின்றன: :math:`k(\\vec{x}_i, \\vec{x}_j) = \\langle f(\\vec{x}_i), f(\\vec{x}_j) \\rangle` where :math:`k` என்பது கர்னல் செயல்பாடு ,:math:`\\vec{x}_i, \\vec{x}_j` are :math:`n` பரிமாண உள்ளீடுகள் ,:math:`f` என்பது ஒரு வரைபடம் :math:`n`- பரிமாணத்திலிருந்து :math:`m` பரிமாண இடைவெளி மற்றும் :math:`\\langle a,b \\rangle` புள்ளி தயாரிப்பு குறிக்கிறது. வரையறுக்கப்பட்ட தரவைக் கருத்தில் கொள்ளும்போது, ​​ஒரு கர்னல் செயல்பாட்டை மேட்ரிக்ஸாகக் குறிப்பிடலாம் : :math:`K_{ij} = k(\\vec{x}_i,\\vec{x}_j)`."

#: ../../tutorials/03_quantum_kernel.ipynb:14
msgid "In quantum kernel machine learning, a quantum feature map :math:`\\phi(\\vec{x})` is used to map a classical feature vector :math:`\\vec{x}` to a quantum Hilbert space, :math:`| \\phi(\\vec{x})\\rangle \\langle \\phi(\\vec{x})|`, such that :math:`K_{ij} = \\left| \\langle \\phi^\\dagger(\\vec{x}_j)| \\phi(\\vec{x}_i) \\rangle \\right|^{2}`. See `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__ for more details."
msgstr "குவாண்டம் கர்னல் இயந்திர கற்றலில், ஒரு குவாண்டம் அம்ச வரைபடம் :math:`\\phi(\\vec{x})` ஒரு கிளாசிக்கல் அம்ச திசையன் வரைபடத்தை பயன்படுத்தப்படுகிறது :math:`\\vec{x}` ஒரு குவாண்டம் ஹில்பர்ட் இடத்திற்கு ,:math:`| \\phi(\\vec{x})\\rangle \\langle \\phi(\\vec{x})|`, அதாவது :math:`K_{ij} = \\left| \\langle \\phi^\\dagger(\\vec{x}_j)| \\phi(\\vec{x}_i) \\rangle \\right|^{2}`. மேலும் விவரங்களுக்கு `குவாண்டம் மேம்படுத்தப்பட்ட அம்ச இடைவெளிகளுடன் மேற்பார்வையிடப்பட்ட கற்றல் <https://arxiv.org/pdf/1804.11326.pdf>`__ ஐப் பார்க்கவும்."

#: ../../tutorials/03_quantum_kernel.ipynb:16
msgid "In this notebook, we use ``qiskit`` to calculate a kernel matrix using a quantum feature map, then use this kernel matrix in ``scikit-learn`` classification and clustering algorithms."
msgstr "இந்த நோட்புக்கில், ஒரு குவாண்டம் அம்ச வரைபடத்தைப் பயன்படுத்தி கர்னல் மேட்ரிக்ஸைக் கணக்கிட ``qiskit`` ஐப் பயன்படுத்துகிறோம், பின்னர் இந்த கர்னல் மேட்ரிக்ஸை ``scikit-learn`` வகைப்பாடு மற்றும் கிளஸ்டரிங் வழிமுறைகளில் பயன்படுத்துகிறோம்."

#: ../../tutorials/03_quantum_kernel.ipynb:55
msgid "For our classification example, we will use the *ad hoc dataset* as described in `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__, and the ``scikit-learn`` `support vector machine <https://scikit-learn.org/stable/modules/svm.html>`__ classification (``svc``) algorithm."
msgstr "எங்கள் வகைப்பாடு எடுத்துக்காட்டுக்கு, `குவாண்டம் மேம்படுத்தப்பட்ட அம்ச இடைவெளிகளுடன் கற்றல் மேற்பார்வை <https://arxiv.org/pdf/1804.11326.pdf>`__, மற்றும் ``scikit-learn`` `ஆதரவு திசையன் இயந்திரம் <https://scikit-learn.org/stable/modules/svm.html>`__ வகைப்பாடு (``svc``) வழிமுறை ஆகியவற்றைக் கொண்டு விவரிக்கப்பட்டுள்ளபடி *ad hoc dataset* ஐ பயன்படுத்துவோம்."

#: ../../tutorials/03_quantum_kernel.ipynb:111
msgid "With our training and testing datasets ready, we set up the ``QuantumKernel`` class to calculate a kernel matrix using the `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__, and the ``BasicAer`` ``qasm_simulator`` using 1024 shots."
msgstr "எங்கள் பயிற்சி மற்றும் சோதனை தரவுத்தொகுப்புகள் தயாராக இருப்பதால், `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`_ ஐப் பயன்படுத்தி கர்னல் மேட்ரிக்ஸைக் கணக்கிட ``QuantumKernel`` வகுப்பை அமைத்துள்ளோம், மற்றும் 1024 காட்சிகளைப் பயன்படுத்தி ``BasicAer`` ``qasm_simulator``."

#: ../../tutorials/03_quantum_kernel.ipynb:138
msgid "The ``scikit-learn`` ``svc`` algorithm allows us to define a `custom kernel <https://scikit-learn.org/stable/modules/svm.html#custom-kernels>`__ in two ways: by providing the kernel as a callable function or by precomputing the kernel matrix. We can do either of these using the ``QuantumKernel`` class in ``qiskit``."
msgstr "``scikit-learn`` ``svc`` வழிமுறை ஒரு `custom kernel <https://scikit-learn.org/stable/modules/svm.html#custom-kernels>`__ ஐ இரண்டு வழிகளில் வரையறுக்க அனுமதிக்கிறது: கர்னலை அழைக்கக்கூடிய செயல்பாடாக வழங்குவதன் மூலம் அல்லது கர்னல் மேட்ரிக்ஸை முன்கூட்டியே கணக்கிடுவதன் மூலம். ``Qiskit`` இல் ``QuantumKernel`` வகுப்பைப் பயன்படுத்தி இவற்றில் ஒன்றை நாம் செய்யலாம்."

#: ../../tutorials/03_quantum_kernel.ipynb:140
msgid "The following code gives the kernel as a callable function:"
msgstr "பின்வரும் குறியீடு கர்னலை அழைக்கக்கூடிய செயல்பாடாக வழங்குகிறது:"

#: ../../tutorials/03_quantum_kernel.ipynb:184
msgid "The following code precomputes and plots the training and testing kernel matrices before providing them to the ``scikit-learn`` ``svc`` algorithm:"
msgstr "பின்வரும் குறியீடு பயிற்சி மற்றும் சோதனை கர்னல் மெட்ரிக்குகளை ``scikit-learn`` ``svc`` அல்காரிதத்திற்கு வழங்குவதற்கு முன் முன்வைத்து திட்டமிடுகிறது:"

#: ../../tutorials/03_quantum_kernel.ipynb:250
msgid "``qiskit`` also contains the ``qsvc`` class that extends the ``sklearn svc`` class, that can be used as follows:"
msgstr "``Qiskit`` இல் ``sklearn svc`` வகுப்பை நீட்டிக்கும் ``qsvc`` வகுப்பும் உள்ளது, அவை பின்வருமாறு பயன்படுத்தப்படலாம்:"

#: ../../tutorials/03_quantum_kernel.ipynb:295
msgid "Clustering"
msgstr "கிளஸ்டரிங்"

#: ../../tutorials/03_quantum_kernel.ipynb:297
msgid "For our clustering example, we will again use the *ad hoc dataset* as described in `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__, and the ``scikit-learn`` ``spectral`` clustering algorithm."
msgstr "எங்கள் கிளஸ்டரிங் எடுத்துக்காட்டுக்கு, குவாண்டம் மேம்படுத்தப்பட்ட அம்ச இடைவெளிகளுடன் <https://arxiv.org/pdf/1804.11326.pdf>`__, மற்றும் ``scikit-learn-`` ``spectral`` க்ளஸ்டரிங் அல்காரிதம் கற்றுக்கொள்ளுங்கள்."

#: ../../tutorials/03_quantum_kernel.ipynb:299
msgid "We will regenerate the dataset with a larger gap between the two classes, and as clustering is an unsupervised machine learning task, we don’t need a test sample."
msgstr "தரவுத்தொகுப்பை இரண்டு வகுப்புகளுக்கு இடையில் ஒரு பெரிய இடைவெளியுடன் மீண்டும் உருவாக்குவோம், மேலும் க்ளஸ்டரிங் ஒரு மேற்பார்வை செய்யப்படாத இயந்திர கற்றல் பணியாக இருப்பதால், எங்களுக்கு ஒரு சோதனை மாதிரி தேவையில்லை."

#: ../../tutorials/03_quantum_kernel.ipynb:350
msgid "We again set up the ``QuantumKernel`` class to calculate a kernel matrix using the `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__, and the BasicAer ``qasm_simulator`` using 1024 shots."
msgstr "`ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__, மற்றும் BasicAer ஐப் பயன்படுத்தி கர்னல் மேட்ரிக்ஸைக் கணக்கிட ``QuantumKernel`` வகுப்பை மீண்டும் அமைத்தோம். 1024 காட்சிகளைப் பயன்படுத்தி ``qasm_simulator``."

#: ../../tutorials/03_quantum_kernel.ipynb:377
msgid "The scikit-learn spectral clustering algorithm allows us to define a [custom kernel] in two ways: by providing the kernel as a callable function or by precomputing the kernel matrix. Using the QuantumKernel class in qiskit, we can only use the latter."
msgstr "ஸ்கிக்கிட்-லர் ஸ்பெக்ட்ரல் க்ளஸ்டரிங் அல்காரிதம் ஒரு [தனிப்பயன் கர்னலை] இரண்டு வழிகளில் வரையறுக்க அனுமதிக்கிறது: கர்னலை அழைக்கக்கூடிய செயல்பாடாக வழங்குவதன் மூலம் அல்லது கர்னல் மேட்ரிக்ஸை முன்கூட்டியே கணக்கிடுவதன் மூலம். Qiskit-டில் குவாண்டம் கர்னல் வகுப்பைப் பயன்படுத்தி, பிந்தையதை மட்டுமே பயன்படுத்த முடியும்."

#: ../../tutorials/03_quantum_kernel.ipynb:379
msgid "The following code precomputes and plots the kernel matrices before providing it to the scikit-learn spectral clustering algorithm, and scoring the labels using normalized mutual information, since we apriori know the class labels."
msgstr "ஸ்கிரிட்-லர்ன் ஸ்பெக்ட்ரல் க்ளஸ்டரிங் அல்காரிதத்திற்கு கர்னல் மெட்ரிக்ஸை வழங்குவதற்கு முன் பின்வரும் குறியீடு முன்னறிவிக்கிறது மற்றும் திட்டமிடுகிறது, மேலும் வகுப்பு லேபிள்களை நாங்கள் அறிந்திருப்பதால், இயல்பாக்கப்பட்ட பரஸ்பர தகவல்களைப் பயன்படுத்தி லேபிள்களை அடித்தோம்."

#: ../../tutorials/03_quantum_kernel.ipynb:439
msgid "``scikit-learn`` has other algorithms that can use a precomputed kernel matrix, here are a few:"
msgstr "``scikit-learn`` க்கு முன்பே வடிவமைக்கப்பட்ட கர்னல் மேட்ரிக்ஸைப் பயன்படுத்தக்கூடிய பிற வழிமுறைகள் உள்ளன, இங்கே சில:"

#: ../../tutorials/03_quantum_kernel.ipynb:441
msgid "`Agglomerative clustering <https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html>`__"
msgstr "`Agglomerative clustering <https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:442
msgid "`Support vector regression <https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html>`__"
msgstr "`Support vector regression <https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:443
msgid "`Ridge regression <https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html>`__"
msgstr "`Ridge regression <https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:444
msgid "`Guassian process regression <https://scikit-learn.org/stable/modules/gaussian_process.html>`__"
msgstr "`Guassian process regression <https://scikit-learn.org/stable/modules/gaussian_process.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:445
msgid "`Principal component analysis <https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html>`__"
msgstr "`Principal component analysis <https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html>`__"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:9
msgid "qGANs for Loading Random Distributions"
msgstr "சீரற்ற விநியோகங்களை ஏற்றுவதற்கான qGAN கள்"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:11
msgid "Given :math:`k`-dimensional data samples, we employ a quantum Generative Adversarial Network (qGAN) to learn the data’s underlying random distribution and to load it directly into a quantum state:"
msgstr "கொடுக்கப்பட்டவை :math:`k` பரிமாண தரவு மாதிரிகள், தரவின் அடிப்படை சீரற்ற விநியோகத்தைக் கற்றுக்கொள்வதற்கும் அதை நேரடியாக ஒரு குவாண்டம் நிலைக்கு ஏற்றுவதற்கும் ஒரு குவாண்டம் ஜெனரேடிவ் அட்வர்சரியல் நெட்வொர்க்கை (qGAN) பயன்படுத்துகிறோம்:"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:13
msgid "\\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle\n\n"
msgstr "\\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle\n\n"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:15
msgid "where :math:`p_{\\theta}^{j}` describe the occurrence probabilities of the basis states :math:`\\big| j\\rangle`."
msgstr "where :math:`p_{\\theta}^{j}` describe the occurrence probabilities of the basis states :math:`\\big| j\\rangle`."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:17
msgid "The aim of the qGAN training is to generate a state :math:`\\big| g_{\\theta}\\rangle` where :math:`p_{\\theta}^{j}`, for :math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}`, describe a probability distribution that is close to the distribution underlying the training data :math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}`."
msgstr "Qgan பயிற்சியின் நோக்கம் ஒரு நிலையை உருவாக்குவது :math:`\\big| g_{\\theta}\\rangle` எங்கே:math:`p_{\\theta}^{j}`, இதற்கு :math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}`, பயிற்சித் தரவின் அடிப்படையிலான விநியோகத்திற்கு நெருக்கமான நிகழ்தகவு விநியோகத்தை விவரிக்கவும்: :math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}`."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:19
msgid "For further details please refer to `Quantum Generative Adversarial Networks for Learning and Loading Random Distributions <https://arxiv.org/abs/1904.00043>`__ *Zoufal, Lucchi, Woerner* [2019]."
msgstr "மேலும் விவரங்களுக்கு, `Quantum Generative Adversarial Networks for Learning and Loading Random Distributions <https://arxiv.org/abs/1904.00043>`__ *Zoufal, Lucchi, Woerner* [2019] ஐப் பார்க்கவும்."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:21
msgid "For an example of how to use a trained qGAN in an application, the pricing of financial derivatives, please see the `Option Pricing with qGANs <https://github.com/Qiskit/qiskit-finance/tree/main/docs/tutorials/10_qgan_option_pricing.ipynb>`__ tutorial."
msgstr "ஒரு பயன்பாட்டில் பயிற்சி பெற்ற qGAN ஐ எவ்வாறு பயன்படுத்துவது என்பதற்கான எடுத்துக்காட்டுக்கு, நிதி வழித்தோன்றல்களின் விலை, தயவுசெய்து `Option Pricing with qGANs <https://github.com/Qiskit/qiskit-finance/tree/main/docs/tutorials/10_qgan_option_pricing.ipynb>`__பயிற்சி."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:56
msgid "Load the Training Data"
msgstr "பயிற்சி தரவை ஏற்றவும்"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:58
msgid "First, we need to load the :math:`k`-dimensional training data samples (here k=1)."
msgstr "முதலில், நாம்: கணிதத்தை ஏற்ற வேண்டும் :math:`k` பரிமாண பயிற்சி தரவு மாதிரிகள் (இங்கே k = 1)."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:60
msgid "Next, the data resolution is set, i.e. the min/max data values and the number of qubits used to represent each data dimension."
msgstr "அடுத்து, தரவுத் தீர்மானம் அமைக்கப்பட்டுள்ளது, அதாவது நிமிடம் / அதிகபட்ச தரவு மதிப்புகள் மற்றும் ஒவ்வொரு தரவு பரிமாணத்தையும் குறிக்கப் பயன்படுத்தப்படும் குவிட்களின் எண்ணிக்கை."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:95
msgid "Initialize the qGAN"
msgstr "qGAN ஐத் தொடங்கவும்"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:97
msgid "The qGAN consists of a quantum generator :math:`G_{\\theta}`, i.e., an ansatz, and a classical discriminator :math:`D_{\\phi}`, a neural network."
msgstr "qGAN ஒரு குவாண்டம் ஜெனரேட்டரைக் கொண்டுள்ளது :math:`G_{\\theta}`, அதாவது, ஒரு அன்சாட்ஸ் மற்றும் ஒரு கிளாசிக்கல் பாகுபாடு காண்பிப்பவர் :math:`D_{\\phi}`, ஒரு நரம்பியல் வலைப்பின்னல்."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:99
msgid "To implement the quantum generator, we choose a depth-\\ :math:`1` ansatz that implements :math:`R_Y` rotations and :math:`CZ` gates which takes a uniform distribution as an input state. Notably, for :math:`k>1` the generator’s parameters must be chosen carefully. For example, the circuit depth should be :math:`>1` because higher circuit depths enable the representation of more complex structures."
msgstr "குவாண்டம் ஜெனரேட்டரை செயல்படுத்த, ஒரு ஆழம்- math :math:`1` அன்சாட்ஸ் செயல்படுத்துகிறது :math:`R_Y` சுழற்சிகள் மற்றும் :math:`CZ` வாயில்கள் ஒரு சீரான விநியோகத்தை உள்ளீட்டு நிலையாக எடுத்துக்கொள்கின்றன. குறிப்பாக, இதற்கு :math:`k>1` ஜெனரேட்டரின் அளவுருக்கள் கவனமாக தேர்ந்தெடுக்கப்பட வேண்டும். எடுத்துக்காட்டாக, சுற்று ஆழம் இருக்க வேண்டும் :math:`>1` ஏனெனில் அதிக சுற்று ஆழங்கள் மிகவும் சிக்கலான கட்டமைப்புகளின் பிரதிநிதித்துவத்தை செயல்படுத்துகின்றன."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:101
msgid "The classical discriminator used here is based on a neural network implementation using NumPy. There is also a discriminator based on PyTorch which is not installed by default when installing Qiskit - see `Optional Install <https://github.com/Qiskit/qiskit-machine-learning#optional-installs>`__ for more information."
msgstr "இங்கே பயன்படுத்தப்படும் கிளாசிக்கல் பாகுபாடு NumPy ஐப் பயன்படுத்தி ஒரு நரம்பியல் பிணைய செயலாக்கத்தை அடிப்படையாகக் கொண்டது. Qiskit-டை நிறுவும் போது இயல்பாக நிறுவப்படாத பைடார்ச்சின் அடிப்படையில் ஒரு பாகுபாடு காண்பிப்பவர் இருக்கிறார் - மேலும் தகவலுக்கு `Optional Install <https://github.com/Qiskit/qiskit-machine-learning#optional-installs>`__ ஐப் பார்க்கவும்."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:103
msgid "Here, both networks are updated with the ADAM optimization algorithm (ADAM is qGAN optimizer default)."
msgstr "இங்கே, இரண்டு நெட்வொர்க்குகளும் ADAM தேர்வுமுறை வழிமுறையுடன் புதுப்பிக்கப்படுகின்றன (ADAM என்பது qGAN உகப்பாக்கி இயல்புநிலை)."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:164
msgid "Run the qGAN Training"
msgstr "qGAN பயிற்சியை இயக்கவும்"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:166
msgid "During the training the discriminator’s and the generator’s parameters are updated alternately w.r.t the following loss functions:"
msgstr "பயிற்சியின் போது பாகுபாடு காண்பிப்பவர் மற்றும் ஜெனரேட்டரின் அளவுருக்கள் மாறி மாறி புதுப்பிக்கப்படும் w.r.t பின்வரும் இழப்பு செயல்பாடுகள்:"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:168
msgid "L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right]\n\n"
msgstr "L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right]\n\n"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:170
msgid "and"
msgstr "மற்றும்"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:172
msgid "L_D\\left(\\phi, \\theta\\right) =\n"
"  \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],"
msgstr "L_D\\left(\\phi, \\theta\\right) =\n"
"  \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:177
msgid "with :math:`m` denoting the batch size and :math:`g^l` describing the data samples generated by the quantum generator."
msgstr "உடன் :math:`m` தொகுதி அளவைக் குறிக்கிறது மற்றும் :math:`g^l` குவாண்டம் ஜெனரேட்டரால் உருவாக்கப்பட்ட தரவு மாதிரிகளை விவரிக்கிறது."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:179
msgid "Please note that the training, for the purpose of this notebook, has been kept briefer by the selection of a known initial point (``init_params``). Without such prior knowledge be aware training may take some while."
msgstr "இந்த நோட்புக்கின் நோக்கத்திற்காக, அறியப்பட்ட ஆரம்ப புள்ளியை (``init_params``) தேர்ந்தெடுப்பதன் மூலம் பயிற்சி சுருக்கமாக வைக்கப்பட்டுள்ளது என்பதை நினைவில் கொள்க. அத்தகைய முன் அறிவு இல்லாமல் விழிப்புணர்வு பயிற்சி சிறிது நேரம் ஆகலாம்."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:245
msgid "Training Progress & Outcome"
msgstr "பயிற்சி முன்னேற்றம் மற்றும் விளைவு"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:247
msgid "Now, we plot the evolution of the generator’s and the discriminator’s loss functions during the training, as well as the progress in the relative entropy between the trained and the target distribution."
msgstr "இப்போது, ​​ஜெனரேட்டரின் பரிணாம வளர்ச்சியையும், பயிற்சியின் போது பாகுபாடு காண்பவரின் இழப்பு செயல்பாடுகளையும், பயிற்சி பெற்ற மற்றும் இலக்கு விநியோகத்திற்கும் இடையிலான ஒப்பீட்டு என்ட்ரோபியின் முன்னேற்றத்தையும் நாங்கள் திட்டமிடுகிறோம்."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:249
msgid "Finally, we also compare the cumulative distribution function (CDF) of the trained distribution to the CDF of the target distribution."
msgstr "இறுதியாக, பயிற்சி பெற்ற விநியோகத்தின் ஒட்டுமொத்த விநியோக செயல்பாட்டை (சி. டி. எஃப்) இலக்கு விநியோகத்தின் சி. டி. எஃப் உடன் ஒப்பிடுகிறோம்."

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector"
msgstr "டார்ச் இணைப்பான்"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial shows how the ``TorchConnector`` allows to use any ``NeuralNetwork`` from Qiskit Machine Learning and integrate it in a PyTorch workflow. The ``TorchConnector`` takes any ``NeuralNetwork`` and makes it available as a PyTorch ``Module``."
msgstr "Qiskit மெஷின் கற்றலில் இருந்து ``NeuralNetwork`` ஐப் பயன்படுத்தவும், பைடார்ச் பணிப்பாய்வுகளில் அதை ஒருங்கிணைக்கவும் ``TorchConnector`` எவ்வாறு அனுமதிக்கிறது என்பதை இந்த பயிற்சி காட்டுகிறது. ``TorchConnector`` எந்த ``நியூரல்நெட்வொர்க்கையும்`` எடுத்து பைட்டோர்ச் ``Module`` ஆகக் கிடைக்கச் செய்கிறது."

#: ../../tutorials/05_torch_connector.ipynb:14
msgid "Content:"
msgstr "உள்ளடக்கம்:"

#: ../../tutorials/05_torch_connector.ipynb:16
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__ - Classification - Classification with PyTorch and the ``OpflowQNN`` - Classification with PyTorch and the ``CircuitQNN`` - Regression - Regression with PyTorch and the ``OpflowQNN``"
msgstr "`பகுதி 1: எளிய வகைப்பாடு மற்றும் பின்னடைவு <# பகுதி -1: -சிலி-வகைப்பாடு - & - பின்னடைவு>`__ - வகைப்பாடு - பைடார்ச்சுடன் வகைப்பாடு மற்றும் ``OpflowQNN`` - பைடார்ச் மற்றும் ``CircuitQNN`` - பின்னடைவு - பைடார்ச் மற்றும் ``OpflowQNN`` உடன் பின்னடைவு"

#: ../../tutorials/05_torch_connector.ipynb:18
msgid "`Part 2: MNIST Classification <#Part-2:-MNIST-Classification>`__"
msgstr "`பகுதி 2: MNIST வகைப்பாடு <# பகுதி -2: -MNIST- வகைப்பாடு>`__"

#: ../../tutorials/05_torch_connector.ipynb:20
msgid "Illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow to classify MNIST data."
msgstr "MNIST தரவை வகைப்படுத்த ஒரு (குவாண்டம்) ``NeuralNetwork`` ஐ இலக்கு பைட்டோர்ச் பணிப்பாய்வுகளில் எவ்வாறு உட்பொதிப்பது என்பதை விளக்குகிறது."

#: ../../tutorials/05_torch_connector.ipynb:57
msgid "Part 1: Simple Classification & Regression"
msgstr "பகுதி 1: எளிய வகைப்பாடு மற்றும் பின்னடைவு"

#: ../../tutorials/05_torch_connector.ipynb:71
msgid "First, we show how the ``TorchConnector`` can be used to use a Quantum ``NeuralNetwork`` to solve a classification tasks. Therefore, we generate a simple random data set."
msgstr "முதலில், ஒரு வகைப்பாடு பணிகளைத் தீர்க்க குவாண்டம் ``NeuralNetwork`` ஐப் பயன்படுத்த ``TorchConnector`` எவ்வாறு பயன்படுத்தப்படலாம் என்பதைக் காண்பிப்போம். எனவே, நாங்கள் ஒரு எளிய சீரற்ற தரவு தொகுப்பை உருவாக்குகிறோம்."

#: ../../tutorials/05_torch_connector.ipynb:117
msgid "Classification with PyTorch and the ``OpflowQNN``"
msgstr "பைடார்ச் மற்றும் ``OpflowQNN`` உடன் வகைப்பாடு"

#: ../../tutorials/05_torch_connector.ipynb:119
msgid "Linking an ``OpflowQNN`` to PyTorch is relatively straight-forward. Here we illustrate this using the ``TwoLayerQNN``."
msgstr "``OpflowQNN`` ஐ PyTorch உடன் இணைப்பது ஒப்பீட்டளவில் நேராக முன்னோக்கி உள்ளது. `` TwoLayerQNN`` ஐப் பயன்படுத்தி இதை இங்கே விளக்குகிறோம்."

#: ../../tutorials/05_torch_connector.ipynb:330
msgid "The red circles indicate wrongly classified data points."
msgstr "சிவப்பு வட்டங்கள் தவறாக வகைப்படுத்தப்பட்ட தரவு புள்ளிகளைக் குறிக்கின்றன."

#: ../../tutorials/05_torch_connector.ipynb:342
msgid "Classification with PyTorch and the ``CircuitQNN``"
msgstr "பைடார்ச் மற்றும் ``CircuitQNN`` உடன் வகைப்பாடு"

#: ../../tutorials/05_torch_connector.ipynb:344
msgid "Linking an ``CircuitQNN`` to PyTorch requires the correct setup, otherwise backpropagation is not possible."
msgstr "``CircuitQNN`` ஐ பைடார்ச்சுடன் இணைக்க சரியான அமைப்பு தேவைப்படுகிறது, இல்லையெனில் பின்செலுத்தல் சாத்தியமில்லை."

#: ../../tutorials/05_torch_connector.ipynb:526
msgid "We use a model based on the ``TwoLayerQNN`` to also illustrate an regression task."
msgstr "பின்னடைவு பணியை விளக்குவதற்கு ``TwoLayerQNN`` ஐ அடிப்படையாகக் கொண்ட மாதிரியைப் பயன்படுத்துகிறோம்."

#: ../../tutorials/05_torch_connector.ipynb:758
msgid "Part 2: MNIST Classification"
msgstr "பகுதி 2: MNIST வகைப்பாடு"

#: ../../tutorials/05_torch_connector.ipynb:760
msgid "Also see Qiskit Textbook: https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html"
msgstr "Qiskit பாடப்புத்தகத்தையும் காண்க: https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html"

#: ../../tutorials/index.rst:3
msgid "Machine Learning Tutorials"
msgstr "இயந்திர வழி கற்றல் பயிற்சிகள்"

