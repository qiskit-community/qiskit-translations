msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-06-29 14:17+0000\n"
"PO-Revision-Date: 2021-07-07 21:24\n"
"Last-Translator: \n"
"Language-Team: Turkish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: tr\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials.po\n"
"X-Crowdin-File-ID: 9528\n"
"Language: tr_TR\n"

#: ../../tutorials/01_neural_networks.ipynb:13
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:13
#: ../../tutorials/03_quantum_kernel.ipynb:13
#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:13
#: ../../tutorials/05_torch_connector.ipynb:13
msgid "Run interactively in jupyter notebook."
msgstr "Jupyter not defterinde etkileşimli olarak çalıştırın."

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "Kuantum Sinir Ağları"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "Bu not defteri, Qiskit Makine Öğrenmesi içinde sağlanan farklı kuantum sinirsel ağ (QNN) uygulamalarını gösterir. Ağlar, birçok farklı senaryo için kullanılabilen uygulama-agnostik hesaplama birimleri olarak ifade edilir. Uygulamaya bağlı olarak, belirli bir ağ tipi belirli bir şekilde kurulmak için daha çok ya da daha az uygun olabilir ve belirli bir şekilde ayarlanması gerekebilir. Aşağıdaki farklı kullanılabilir sinirsel ağlar artık daha ayrıntılı olarak ele alınacak:"

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks."
msgstr "``NeuralNetwork``: Sinirsel ağlar için arayüz."

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``OpflowQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr "``OpflowQNN``: Kuantum mekaniksel gözlemlenebilirlerin değerlendirilmesine dayalı bir ağ."

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``TwoLayerQNN``: A special ``OpflowQNN`` implementation for convenience."
msgstr "` \"TwoLayerQNN ` `: Uygunluk için özel bir `\" OpflowQNN ` ` uygulaması."

#: ../../tutorials/01_neural_networks.ipynb:16
msgid "``CircuitQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr "``CircuitQNN``: Bir kuantum devresinin ölçülmesinden kaynaklanan örneklere dayalı bir ağ."

#: ../../tutorials/01_neural_networks.ipynb:64
msgid "1. ``NeuralNetwork``"
msgstr "1. ``NeuralNetwork``"

#: ../../tutorials/01_neural_networks.ipynb:66
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interfaces are introduced."
msgstr "``NeuralNetwork`` Qiskit makine öğrenimindeki bütün sinir ağları için olan arayüzü temsil eder. Veri örneklerini ve öğretilebilir yükleri alarak ileri ve geri geçişe maruz bırakır. Bir ``NeuralNetwork`` herhangi bir eğitim yeteneği içermez, bunlar gerçek algoritmalara / uygulamalara bırakılmıştır. Böylelikle bir ``NeuralNetwork`` eğitilebilir yükler için değerleri de depo etmez. Aşağıda, bu arayüzün farklı yerine getirmeleri gösterilmiştir."

#: ../../tutorials/01_neural_networks.ipynb:68
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes either flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr "Bir ``NeuralNetwork`` ün ``nn`` diye adlandırıldığını varsayalım. Sonra, ``nn.forward(input, weights)`` geçişi hem veri hem de ``nn.num_inputs`` ve ``nn.num_weights`` ın ağırlıklarının boyutu için sırasıyla düz girişler alır. ``NeuralNetwork`` girdi toplulaştırmayı destekler ve karşılık gelen şeklin çıktı grubunu verir."

#: ../../tutorials/01_neural_networks.ipynb:80
msgid "2. ``OpflowQNN``"
msgstr "2. ``OpflowQNN``"

#: ../../tutorials/01_neural_networks.ipynb:82
msgid "The ``OpflowQNN`` takes a (parametrized) operator from Qiskit and leverages Qiskit’s gradient framework to provide the backward pass. Such an operator can for instance be an expected value of a quantum mechanical observable with respect to a parametrized quantum state. The Parameters can be used to load classical data as well as represent trainable weights. The ``OpflowQNN`` also allows lists of operators and more complex structures to construct more complex QNNs."
msgstr "``OpflowQNN`` Qiskit'ten (parametreli) bir operatör alır ve geriye doğru geçişi sağlamak için Qiskit'in gradyan çerçevesinden yararlanır. Böyle bir operatör örneğin parametreli bir kuantum durumuna göre gözlemlenebilir bir kuantum mekaniğinin beklenen değeri olabilir. Parametreler, klasik verileri yüklemek ve eğitilebilir ağırlıkları temsil etmek için kullanılabilir.``OpflowQNN``ayrıca daha karmaşık QNN'ler oluşturmak için operatör listelerine ve daha karmaşık yapılara izin verir."

#: ../../tutorials/01_neural_networks.ipynb:321
msgid "Combining multiple observables in a ``ListOp`` also allows to create more complex QNNs"
msgstr "Çoklu gözlemlenebiliri bir ``ListOp`` içinde birleştirmek, daha karmaşık QNN'ler oluşturmaya da olanak tanır"

#: ../../tutorials/01_neural_networks.ipynb:412
msgid "3. ``TwoLayerQNN``"
msgstr "3. ` ` TwoLayerQNN ` `"

#: ../../tutorials/01_neural_networks.ipynb:414
msgid "The ``TwoLayerQNN`` is a special ``OpflowQNN`` on :math:`n` qubits that consists of first a feature map to insert data and second an ansatz that is trained. The default observable is :math:`Z^{\\otimes n}`, i.e., parity."
msgstr "``TwoLayerQNN`` önce veri eklemek için bir öznitelik haritasından ve ikinci olarak eğitilmiş bir ansatzdan oluşan :math:`n` kübitler üzerinde özel bir ``OpflowQNN``dir. Varsayılan gözlemlenebilir :math:`Z^{\\otimes n}`, yani., paritedir."

#: ../../tutorials/01_neural_networks.ipynb:612
msgid "4. ``CircuitQNN``"
msgstr "4. ``CircuitQNN``"

#: ../../tutorials/01_neural_networks.ipynb:614
msgid "The ``CircuitQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples can either be interpreted as probabilities of measuring the integer index corresponding to a bitstring or directly as a batch of binary output. In the case of probabilities, gradients can be estimated efficiently and the ``CircuitQNN`` provides a backward pass as well. In case of samples, differentiation is not possible and the backward pass returns ``(None, None)``."
msgstr "``CircuitQNN`` (parametreli olan) bir ``QuantumCircuit``i temel alır. Bu, ağırlık parametrelerinin yanı sıra girdi alabilir ve ölçümden örnekler üretebilmektedir. Örnekler, bir bit dizisine karşılık gelen tamsayı indeksini ölçme olasılıkları olarak veya doğrudan bir ikili çıktı partisi olarak yorumlanabilir. Olasılıklar durumunda, gradyanlar verimli bir şekilde tahmin edilebilir ve ``CircuitQNN`` geriye doğru bir geçiş de sağlar. Örnekler söz konusu olduğunda, farklılaşma mümkün değildir ve geriye doğru geçiş ``(None, None)`` değerini döndürür."

#: ../../tutorials/01_neural_networks.ipynb:617
msgid "Further, the ``CircuitQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are agregated accordingly."
msgstr "Ek olarak, ``CircuitQNN``, örnekleri sonradan işlemek için bir ``interpret`` (yorumlama) fonksiyonu belirtmeye izin verir. Bunun ölçülen bir tamsayı (bir bit dizisinden) alması ve onu yeni bir dizine, yani negatif olmayan tam sayıya eşlemesi beklenir. Bu durumda, çıktı şeklinin sağlanması gerekmektedir ve olasılıklar buna göre toplanır."

#: ../../tutorials/01_neural_networks.ipynb:619
msgid "A ``CircuitQNN`` can be configured to return sparse as well as dense probability vectors. If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits and a sparse recommendation is usually recommended. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr "Bir ``CircuitQNN`` yoğun olasılık vektörlerinin yanı sıra seyrek şekilde de döndürecek şekilde yapılandırılabilir. Herhangi bir ``interpret`` fonksiyonu kullanılmazsa, olasılık vektörünün boyutu, kübit sayısıyla üstel olarak ölçeklenir ve genellikle seyrek bir öneri önerilir. Bir ``interpret`` fonksiyonu olması durumunda, beklenen sonuca bağlıdır. Örneğin, bir indeks karşılık gelen bit dizgisinin paritesine, yani 0 veya 1'e eşlenirse, yoğun bir çıktı anlamlıdır ve sonuç, uzunluk 2 olan bir olasılık vektörü olacaktır."

#: ../../tutorials/01_neural_networks.ipynb:662
msgid "4.1 Output: sparse integer probabilities"
msgstr "4.1 Çıktı: seyrek tamsayı olasılıkları"

#: ../../tutorials/01_neural_networks.ipynb:761
msgid "4.2 Output: dense parity probabilities"
msgstr "4.2 Çıktı: yoğun eşlik olasılıkları"

#: ../../tutorials/01_neural_networks.ipynb:869
msgid "4.3 Output: Samples"
msgstr "4.3 Çıktı: Örnekler"

#: ../../tutorials/01_neural_networks.ipynb:985
msgid "4.4 Output: Parity Samples"
msgstr "4.4 Çıktı: Eşlik Örnekleri"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:9
msgid "Neural Network Classifier & Regressor"
msgstr "Sinirsel Ağ Sınıflandırıcısı ve Regresörü"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:11
msgid "In this tutorial we show how the ``NeuralNetworkClassifier`` and ``NeuralNetworkRegressor`` are used. Both take as an input a (Quantum) ``NeuralNetwork`` and leverage it in a specific context. In both cases we also provide a pre-configured variant for convenience, the Variational Quantum Classifier (``VQC``) and Variational Quantum Regressor (``VQR``). The tutorial is structured as follows:"
msgstr "Bu eğitimde ` NeuralNetworkClassifier ` ve ` ` NeuralNetworkRegressor ` `ın nasıl kullanıldığını gösteriyoruz. Her ikisini de (Quantum) ` ` NeuralNetwork ` ` a giriş olarak alın ve belirli bir bağlamda kullanın. Her iki durumda da, kolaylık amacıyla önceden yapılandırılmış bir çeşitleme sağlıyoruz: Varitional Quantum Classifier (` ` VQC ` `) ve Varitional Quantum Regressor (` ` VQR ` `). Öğretici program aşağıdaki gibi yapılandırılır:"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:13
msgid "`Classification <#Classification>`__"
msgstr "`Classification <#Classification>`__"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:15
msgid "Classification with an ``OpflowQNN``"
msgstr "` ` OpflowQNN ` ` ile Sınıflandırma"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:16
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:249
msgid "Classification with a ``CircuitQNN``"
msgstr "` ` CircuitQNN ` ` ile Sınıflandırma"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:17
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:398
msgid "Variational Quantum Classifier (``VQC``)"
msgstr "Değişimsel Kuantum Sınıflandırıcısı (` ` VQC ` `)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:19
msgid "`Regression <#Regression>`__"
msgstr "`Regression <#Regression>`__"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:21
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:539
msgid "Regression with an ``OpflowQNN``"
msgstr "` ` OpflowQNN ` ` ile Regresyon"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:22
msgid "Variational Quantum Regressor (``VQR``)"
msgstr "Değişimsel Kuantum Regresörü (` ` VQC ` `)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:70
#: ../../tutorials/03_quantum_kernel.ipynb:53
#: ../../tutorials/05_torch_connector.ipynb:69
msgid "Classification"
msgstr "Sınıflandırma"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:72
msgid "We prepare a simple classification dataset to illustrate the following algorithms."
msgstr "Takip eden algoritmaları göstermek için basit bir sınıflandırma veri seti hazırlıyoruz."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:117
msgid "Classification with the an ``OpflowQNN``"
msgstr "` ` OpflowQNN ` ` ile Sınıflandırma"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:119
msgid "First we show how an ``OpflowQNN`` can be used for classification within a ``NeuralNetworkClassifier``. In this context, the ``OpflowQNN`` is expected to return one-dimensional output in :math:`[-1, +1]`. This only works for binary classification and we assign the two classes to :math:`\\{-1, +1\\}`. For convenience, we use the ``TwoLayerQNN``, which is a special type of ``OpflowQNN`` defined via a feature map and an ansatz."
msgstr "İlk olarak ``OpflowQNN``nin nasıl kullanılabileceğini bir ``NeuralNetworkClassifier`` içinde sınıflandırma ile gösteriyoruz. Bu anlamda, ``OpflowQNN``nin :math:`[-1, +1]` biçiminde tek boyutlu çıktı döndürmesi beklenir. Bu yalnızca ikili sınıflandırma için çalışır ve iki sınıfı :math:`\\{-1, +1\\}` olarak atarız. Bize kolaylık sağlaması için, bir özellik haritası ve bir ansatz ile tanımlanan özel bir ``OpflowQNN`` türü olan ``TwoLayerQNN`` kullanıyoruz."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:251
msgid "Next we show how a ``CircuitQNN`` can be used for classification within a ``NeuralNetworkClassifier``. In this context, the ``CircuitQNN`` is expected to return :math:`d`-dimensional probability vector as output, where :math:`d` denotes the number of classes. Sampling from a ``QuantumCircuit`` automatically results in a probability distribution and we just need to define a mapping from the measured bitstrings to the different classes. For binary classification we use the parity mapping."
msgstr "Daha sonra bir \"NeuralNetworkClassifier\" içinde sınıflandırma için bir \"CircuitQNN\"nin nasıl kullanılabileceğini göstereceğiz. Bu bağlamda, ``CircuitQNN`` çıktı olarak :math:`d` boyutlu olasılık vektörü döndürmesi beklenir, burada :math:`d` sınıf sayısını gösterir. Bir \"QuantumCircuit\"ten örnekleme, otomatik olarak bir olasılık dağılımıyla sonuçlanır ve bizim sadece ölçülen bit dizilerinden farklı sınıflara bir eşleme tanımlamamız gerekir. İkili sınıflandırma için eşitlik eşlemesini kullanıyoruz."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:400
msgid "The ``VQC`` is a special variant of the ``NeuralNetworkClassifier`` with a ``CircuitQNN``. It applies a parity mapping (or extensions to multiple classes) to map from the bitstring to the classification, which results in a probability vector, which is interpreted as a one-hot encoded result. By default, it applies this the ``CrossEntropyLoss`` function that expects labels given in one-hot encoded format and will return predictions in that format too."
msgstr "\"VQC\" \"CircuitQNN\" ile \"NeuralNetworkClassifier\"ın özel bir çeşididir. Bit dizgisinden sınıflandırmaya eşlemek için bir eşlik eşlemesi (veya birden çok sınıfa uzantılar) uygular, bu da tek-sıcak kodlanmış bir sonuç olarak yorumlanan bir olasılık vektörü ile sonuçlanır. Varsayılan olarak tek-sıcak kodlanmış biçimde verilen etiketleri bekleyen ve bu biçimde de tahminler döndüren ``CrossEntropyLoss`` işlevini uygular."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:496
#: ../../tutorials/05_torch_connector.ipynb:524
msgid "Regression"
msgstr "Gerileme (Regresyon)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:498
msgid "We prepare a simple regression dataset to illustrate the following algorithms."
msgstr "Aşağıdaki algoritmaları göstermek için basit bir regresyon veri kümesi hazırlıyoruz."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:541
msgid "Here we restrict to regression with an ``OpflowQNN`` that returns values in :math:`[-1, +1]`. More complex and also multi-dimensional models could be constructed, also based on ``CircuitQNN`` but that exceeds the scope of this tutorial."
msgstr "Burada, :math:`[-1, +1]` içindeki değerleri döndüren bir ``OpflowQNN`` ile gerilemeyi kısıtlıyoruz. ``CircuitQNN``ye dayalı olarak daha karmaşık ve ayrıca çok boyutlu modeller oluşturulabilir, ancak bu bu eğitimin kapsamını aşmaktadır."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:648
msgid "Regression with the Variational Quantum Regressor (``VQR``)"
msgstr "Varyasyonel Kuantum Regresörü (``VQR``) ile Regresyon"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:650
msgid "Similar to the ``VQC`` for classification, the ``VQR`` is a special variant of the ``NeuralNetworkRegressor`` with a ``OpflowQNN``. By default it considers the ``L2Loss`` function to minimize the mean squared error between predictions and targets."
msgstr "Sınıflandırma için ``VQC``ye benzer şekilde, ``VQR``, ``OpflowQNN`` ile ``NeuralNetworkRegressor``un özel bir çeşididir. Varsayılan olarak tahminler ve hedefler arasındaki ortalama karesel hatayı en aza indirmek için ``L2Loss`` işlevini dikkate alır."

#: ../../tutorials/03_quantum_kernel.ipynb:9
msgid "Quantum Kernel Machine Learning"
msgstr "Kuantum Çekirdek Makine Öğrenimi"

#: ../../tutorials/03_quantum_kernel.ipynb:11
msgid "The general task of machine learning is to find and study patterns in data. For many datasets, the datapoints are better understood in a higher dimensional feature space, through the use of a kernel function: :math:`k(\\vec{x}_i, \\vec{x}_j) = \\langle f(\\vec{x}_i), f(\\vec{x}_j) \\rangle` where :math:`k` is the kernel function, :math:`\\vec{x}_i, \\vec{x}_j` are :math:`n` dimensional inputs, :math:`f` is a map from :math:`n`-dimension to :math:`m`-dimension space and :math:`\\langle a,b \\rangle` denotes the dot product. When considering finite data, a kernel function can be represented as a matrix: :math:`K_{ij} = k(\\vec{x}_i,\\vec{x}_j)`."
msgstr "Makine öğrenmesinin genel görevi, verilerdeki kalıpları bulmak ve incelemektir. Birçok veri kümesi için, veri noktaları daha yüksek boyutlu bir öznitelik uzayında, bir çekirdek fonksiyonu kullanılarak daha iyi anlaşılır: :math:`k(\\vec{x}_i, \\vec{x}_j) = \\langle f(\\ vec{x}_i), f(\\vec{x}_j) \\rangle` burada :math:`k` çekirdek fonksiyonudur, :math:`\\vec{x}_i, \\vec{x}_j` :math:`n` boyutlu girdiler, :math:`f` :math:`n`-boyutundan :math:`m`-boyut uzayına ve :math:`\\langle a,b \\rangle` arasındaki bir haritadır ve nokta çarpımını gösterir. Sonlu verileri dikkate alırken; bir çekirdek fonksiyonu, bir matris olarak temsil edilebilir: :math:`K_{ij} = k(\\vec{x}_i,\\vec{x}_j)`."

#: ../../tutorials/03_quantum_kernel.ipynb:14
msgid "In quantum kernel machine learning, a quantum feature map :math:`\\phi(\\vec{x})` is used to map a classical feature vector :math:`\\vec{x}` to a quantum Hilbert space, :math:`| \\phi(\\vec{x})\\rangle \\langle \\phi(\\vec{x})|`, such that :math:`K_{ij} = \\left| \\langle \\phi^\\dagger(\\vec{x}_j)| \\phi(\\vec{x}_i) \\rangle \\right|^{2}`. See `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__ for more details."
msgstr "Kuantum çekirdek makine öğreniminde, bir kuantum öznitelik haritası :math:`\\phi(\\vec{x})` klasik bir özellik vektörünü :math:`\\vec{x}` bir kuantum Hilbert uzayına eşlemek için kullanılır, :math:`| \\phi(\\vec{x})\\rangle \\langle \\phi(\\vec{x})|`, öyle ki :math:`K_{ij} = \\left| \\langle \\phi^\\dagger(\\vec{x}_j)| \\phi(\\vec{x}_i) \\rangle \\right|^{2}`.Daha fazla ayrıntı için `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__ bölümüne bakın."

#: ../../tutorials/03_quantum_kernel.ipynb:16
msgid "In this notebook, we use ``qiskit`` to calculate a kernel matrix using a quantum feature map, then use this kernel matrix in ``scikit-learn`` classification and clustering algorithms."
msgstr "Bu defterde, bir kuantum özellik haritası kullanarak bir çekirdek matrisini hesaplamak için \"qiskit\" kullanıyoruz, ardından bu çekirdek matrisini \"scikit-learn\"'de sınıflandırma ve kümeleme algoritmalarında kullanıyoruz."

#: ../../tutorials/03_quantum_kernel.ipynb:55
msgid "For our classification example, we will use the *ad hoc dataset* as described in `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__, and the ``scikit-learn`` `support vector machine <https://scikit-learn.org/stable/modules/svm.html>`__ classification (``svc``) algorithm."
msgstr "Sınıflandırma örneğimiz için, `Kuantum geliştirilmiş özellik alanlarıyla denetimli öğrenme <https://arxiv.org/pdf/1804.11326.pdf>`__ ve ```scikit-learn ile denetimli öğrenme'de açıklandığı gibi *ad hoc veri kümesini* kullanacağız. `` `destek vektör makinesi <https://scikit-learn.org/stable/modules/svm.html>`__ sınıflandırma (```svc``) algoritması."

#: ../../tutorials/03_quantum_kernel.ipynb:111
msgid "With our training and testing datasets ready, we set up the ``QuantumKernel`` class to calculate a kernel matrix using the `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__, and the ``BasicAer`` ``qasm_simulator`` using 1024 shots."
msgstr "`ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__ kullanarak bir çekirdek matrisi hesaplamak için ``QuantumKernel`` sınıfını ve 1024 deneme kullanarak BasicAer ``qasm_simulator``ı yeniden çalıştırdık."

#: ../../tutorials/03_quantum_kernel.ipynb:138
msgid "The ``scikit-learn`` ``svc`` algorithm allows us to define a `custom kernel <https://scikit-learn.org/stable/modules/svm.html#custom-kernels>`__ in two ways: by providing the kernel as a callable function or by precomputing the kernel matrix. We can do either of these using the ``QuantumKernel`` class in ``qiskit``."
msgstr "````scikit-learn``` ```svc`` algoritması iki şekilde bir `özel çekirdek<https://scikit-learn.org/stable/modules/svm.html#custom-kernels>`__ tanımlamamıza olanak tanır: çekirdeği çağrılabilir bir fonksiyon olarak koşullayarak veya çekirdek matrisini önceden hesaplayarak.Bunlardan herhangi birini \"qiskit\" içindeki \"QuantumKernel\" sınıfını kullanarak yapabiliriz."

#: ../../tutorials/03_quantum_kernel.ipynb:140
msgid "The following code gives the kernel as a callable function:"
msgstr "Takip eden kod, çekirdeği çağrılabilir bir fonksiyon olarak verir:"

#: ../../tutorials/03_quantum_kernel.ipynb:184
msgid "The following code precomputes and plots the training and testing kernel matrices before providing them to the ``scikit-learn`` ``svc`` algorithm:"
msgstr "Aşağıdaki kod, eğitim ve test çekirdek matrislerini ``scikit-learn`` ``svc`` algoritmasına sağlamadan evvel önceden hesaplar ve çizer:"

#: ../../tutorials/03_quantum_kernel.ipynb:250
msgid "``qiskit`` also contains the ``qsvc`` class that extends the ``sklearn svc`` class, that can be used as follows:"
msgstr "``qiskit`` ayrıca ``sklearn svc`` sınıfını genişleten ``qsvc`` sınıfını da içerir ve aşağıdaki gibi kullanılabilir:"

#: ../../tutorials/03_quantum_kernel.ipynb:295
msgid "Clustering"
msgstr "Kümelemek"

#: ../../tutorials/03_quantum_kernel.ipynb:297
msgid "For our clustering example, we will again use the *ad hoc dataset* as described in `Supervised learning with quantum enhanced feature spaces <https://arxiv.org/pdf/1804.11326.pdf>`__, and the ``scikit-learn`` ``spectral`` clustering algorithm."
msgstr ""

#: ../../tutorials/03_quantum_kernel.ipynb:299
msgid "We will regenerate the dataset with a larger gap between the two classes, and as clustering is an unsupervised machine learning task, we don’t need a test sample."
msgstr "Veri kümesini iki sınıf arasında daha büyük bir boşlukla yeniden oluşturacağız ve kümeleme denetimsiz bir makine öğrenimi görevi olduğundan, bir test örneğine ihtiyacımız yok."

#: ../../tutorials/03_quantum_kernel.ipynb:350
msgid "We again set up the ``QuantumKernel`` class to calculate a kernel matrix using the `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__, and the BasicAer ``qasm_simulator`` using 1024 shots."
msgstr "`ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__ kullanarak bir çekirdek matrisi hesaplamak için ``QuantumKernel`` sınıfını ve 1024 deneme kullanarak BasicAer ``qasm_simulator``ı yeniden çalıştırdık."

#: ../../tutorials/03_quantum_kernel.ipynb:377
msgid "The scikit-learn spectral clustering algorithm allows us to define a [custom kernel] in two ways: by providing the kernel as a callable function or by precomputing the kernel matrix. Using the QuantumKernel class in qiskit, we can only use the latter."
msgstr "Scikit-learn spektral kümeleme algoritması, bir [özel çekirdek] tanımlamamızı iki şekilde sağlamaktadır: Çekirdeği çağrılabilir bir fonksiyon olarak temin ederek veya çekirdek matrisini önceden hesaplayarak sağlayabilir. Qiskit'te QuantumKernel sınıfını kullanarak, yalnızca ikincisini kullanabilmekteyiz."

#: ../../tutorials/03_quantum_kernel.ipynb:379
msgid "The following code precomputes and plots the kernel matrices before providing it to the scikit-learn spectral clustering algorithm, and scoring the labels using normalized mutual information, since we apriori know the class labels."
msgstr "Takip eden kod, sınıf etiketlerini önceden bildiğimiz için, scikit-learn spektral kümeleme algoritmasına sağlamadan ve etiketleri normalleştirilmiş karşılıklı bilgileri kullanarak puanlamadan önce çekirdek matrislerini önceden hesaplar ve çizer."

#: ../../tutorials/03_quantum_kernel.ipynb:439
msgid "``scikit-learn`` has other algorithms that can use a precomputed kernel matrix, here are a few:"
msgstr "``scikit-learn`` önceden hesaplanmış bir çekirdek matrisi kullanabilen başka algoritmalara sahiptir, işte birkaçı:"

#: ../../tutorials/03_quantum_kernel.ipynb:441
msgid "`Agglomerative clustering <https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html>`__"
msgstr "`Agglomerative clustering <https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:442
msgid "`Support vector regression <https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html>`__"
msgstr "`Support vector regression <https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:443
msgid "`Ridge regression <https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html>`__"
msgstr "`Ridge regression <https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:444
msgid "`Guassian process regression <https://scikit-learn.org/stable/modules/gaussian_process.html>`__"
msgstr "`Gaussian regresyon süreci <https://scikit-learn.org/stable/modules/gaussian_process.html>`__"

#: ../../tutorials/03_quantum_kernel.ipynb:445
msgid "`Principal component analysis <https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html>`__"
msgstr "`Principal component analysis <https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html>`__"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:9
msgid "qGANs for Loading Random Distributions"
msgstr "Rastgele Dağıtımları Yüklemek için qGAN'lar"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:11
msgid "Given :math:`k`-dimensional data samples, we employ a quantum Generative Adversarial Network (qGAN) to learn the data’s underlying random distribution and to load it directly into a quantum state:"
msgstr "Verilen :math:`k`-boyutlu veri örneklerini, verinin temeldeki rastgele dağılımını öğrenmek ve doğrudan bir kuantum durumuna yüklemek için bir kuantum Üretken Karşıt Ağ (quantum Generative Adversarial Network - qGAN) kullanıyoruz:"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:13
msgid "\\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle\n\n"
msgstr "\\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle\n\n"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:15
msgid "where :math:`p_{\\theta}^{j}` describe the occurrence probabilities of the basis states :math:`\\big| j\\rangle`."
msgstr "burada :math:`p_{\\theta}^{j}` temel durumların oluşma olasılıklarını tanımlar :math:`\\big| j\\rangle`."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:17
msgid "The aim of the qGAN training is to generate a state :math:`\\big| g_{\\theta}\\rangle` where :math:`p_{\\theta}^{j}`, for :math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}`, describe a probability distribution that is close to the distribution underlying the training data :math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}`."
msgstr "qGAN eğitimin hedefi, :math:`p_{\\theta}^{j}` olduğu yerde :math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}` için bir :math:`\\big| g_{\\theta}\\rangle` durumu oluşturmaktır, eğitimin verisinin :math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}` temelinde yatan dağılıma yakın bir olasılık dağılımı tanımlayın."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:19
msgid "For further details please refer to `Quantum Generative Adversarial Networks for Learning and Loading Random Distributions <https://arxiv.org/abs/1904.00043>`__ *Zoufal, Lucchi, Woerner* [2019]."
msgstr "Daha fazla ayrıntı için lütfen `Quantum Generative Adversarial Networks for Learning and Loading Random Distributions <https://arxiv.org/abs/1904.00043>`__ *Zoufal, Lucchi, Woerner* [2019].'a bakınız."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:21
msgid "For an example of how to use a trained qGAN in an application, the pricing of financial derivatives, please see the `Option Pricing with qGANs <https://github.com/Qiskit/qiskit-finance/tree/main/docs/tutorials/10_qgan_option_pricing.ipynb>`__ tutorial."
msgstr "Herhangi bir uygulamada eğitimli qGAN'ın nasıl kullanılacağına, finansal olan türevlerinin fiyatlandırılmasına ilişkin bir örnek için lütfen <https://github.com/Qiskit/qiskit-finance/tree/main/docs/tutorials/10_qgan_option_pricing.ipynb>`__ eğitimine bakın."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:56
msgid "Load the Training Data"
msgstr "Çalıştırma Verilerinin Yüklenmesi"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:58
msgid "First, we need to load the :math:`k`-dimensional training data samples (here k=1)."
msgstr "İlk olarak, :math:`k` boyutlu eğitim verisi örneklerini yüklememiz gerekiyor (burada k=1)."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:60
msgid "Next, the data resolution is set, i.e. the min/max data values and the number of qubits used to represent each data dimension."
msgstr "Ardından, veri çözünürlüğü, yani her bir veri boyutunu temsil etmek için kullanılan min/maks veri değerleri ve kübit sayısı ayarlanır."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:95
msgid "Initialize the qGAN"
msgstr "qGAN'ı başlatma"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:97
msgid "The qGAN consists of a quantum generator :math:`G_{\\theta}`, i.e., an ansatz, and a classical discriminator :math:`D_{\\phi}`, a neural network."
msgstr "qGAN, bir kuantum üretecidir. :math:`G_{\\theta}`, yani bir ansatz , bir klasik ayırıcı :math:`D_{\\phi}`, ve bir sinir ağından oluşur."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:99
msgid "To implement the quantum generator, we choose a depth-\\ :math:`1` ansatz that implements :math:`R_Y` rotations and :math:`CZ` gates which takes a uniform distribution as an input state. Notably, for :math:`k>1` the generator’s parameters must be chosen carefully. For example, the circuit depth should be :math:`>1` because higher circuit depths enable the representation of more complex structures."
msgstr "Kuantum üretecini uygulamak için, girdi durumu olarak düzenli bir dağılım alan :math:`R_Y` dönüşlerini uygulayan bir derinlik için -\\ :math:`1` , ansatz ve :math:`CZ` kapılarını seçiyoruz. Özellikle, :math:`k>1` için üretecin parametreleri dikkatli seçilmelidir."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:101
msgid "The classical discriminator used here is based on a neural network implementation using NumPy. There is also a discriminator based on PyTorch which is not installed by default when installing Qiskit - see `Optional Install <https://github.com/Qiskit/qiskit-machine-learning#optional-installs>`__ for more information."
msgstr "Burada kullanılan klasik ayırıcı, sinir ağı uygulamasına dayanan NumPy'ı kullanmatadır. Qiskit'i kurarken varsayılan olarak kurulmayan PyTorch'a dayalı olan bir ayrıcı da vardır. Daha fazla bilgi için `Optional Install <https://github.com/Qiskit/qiskit-machine-learning#optional-installs>`__'e bakınız."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:103
msgid "Here, both networks are updated with the ADAM optimization algorithm (ADAM is qGAN optimizer default)."
msgstr "Burada her iki ağ da ADAM optimizasyon algoritmasıyla güncellenir (ADAM, qGAN optimize edici varsayılanıdır)."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:164
msgid "Run the qGAN Training"
msgstr "qGAN Eğitimini çalıştırın"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:166
msgid "During the training the discriminator’s and the generator’s parameters are updated alternately w.r.t the following loss functions:"
msgstr "Eğitim sırasında diskriminatör ve üreten parametreleri aşağıdaki kayıp fonksiyonlar ile dönüşümlü olarak güncellenir:"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:168
msgid "L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right]\n\n"
msgstr "L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right]\n\n"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:170
msgid "and"
msgstr "ve"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:172
msgid "L_D\\left(\\phi, \\theta\\right) =\n"
"  \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],"
msgstr "L_D\\left(\\phi, \\theta\\right) =\n"
"  \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:177
msgid "with :math:`m` denoting the batch size and :math:`g^l` describing the data samples generated by the quantum generator."
msgstr "toplu iş boyutunu gösteren :math:`m` ve :math:`g^l` kuantum üreteci tarafından üretilen veri örneklerini tanımlar."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:179
msgid "Please note that the training, for the purpose of this notebook, has been kept briefer by the selection of a known initial point (``init_params``). Without such prior knowledge be aware training may take some while."
msgstr "Bu not defterinin amacı eğitimin, bilinen bir başlangıç noktasının (``init_params``) seçilmesiyle daha kısa tutulduğunu lütfen unutmayın. Böyle bir ön bilgi olmadan, eğitimin biraz zaman alabileceğinin farkında olun."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:245
msgid "Training Progress & Outcome"
msgstr "Eğitim İlerleyişi ve Sonucu"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:247
msgid "Now, we plot the evolution of the generator’s and the discriminator’s loss functions during the training, as well as the progress in the relative entropy between the trained and the target distribution."
msgstr "Şimdi, eğitim sırasında üreticinin ve ayrımcının kayıp fonksiyonlarının evrimini ve ayrıca eğitilmiş ve hedef dağılım arasındaki göreli entropideki ilerlemesini çiziyoruz."

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:249
msgid "Finally, we also compare the cumulative distribution function (CDF) of the trained distribution to the CDF of the target distribution."
msgstr "Son olarak, eğitilmiş dağıtımın kümülatif dağılım fonksiyonunu (CDF) hedef dağılımın CDF'si ile de karşılaştırırız."

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector"
msgstr "Torch Bağlantısı"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial shows how the ``TorchConnector`` allows to use any ``NeuralNetwork`` from Qiskit Machine Learning and integrate it in a PyTorch workflow. The ``TorchConnector`` takes any ``NeuralNetwork`` and makes it available as a PyTorch ``Module``."
msgstr "Bu eğitim ``TorchConnector``un Qiskit Machine Learning'den herhangi bir ``NeuralNetwork`` kullanımına nasıl izin verdiğini ve bunu bir PyTorch iş akışına nasıl entegre ettiğini göstermektedir. Burada ``TorchConnector``, herhangi bir ``NeuralNetwork``ü alır ve onu bir PyTorch ``Module`` olarak kullanılabilir hale getirir."

#: ../../tutorials/05_torch_connector.ipynb:14
msgid "Content:"
msgstr "İçerik:"

#: ../../tutorials/05_torch_connector.ipynb:16
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__ - Classification - Classification with PyTorch and the ``OpflowQNN`` - Classification with PyTorch and the ``CircuitQNN`` - Regression - Regression with PyTorch and the ``OpflowQNN``"
msgstr "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__ - Classification - Classification with PyTorch and the ``OpflowQNN`` - Classification with PyTorch and the ``CircuitQNN`` - Regression - Regression with PyTorch and the ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:18
msgid "`Part 2: MNIST Classification <#Part-2:-MNIST-Classification>`__"
msgstr "`Part 2: MNIST Classification <#Part-2:-MNIST-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:20
msgid "Illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow to classify MNIST data."
msgstr "MNIST verilerini sınıflandırmak için bir (Kuantum) ``NeuralNetwork`` bir hedef PyTorch iş akışına nasıl yerleştirileceğini gösterir."

#: ../../tutorials/05_torch_connector.ipynb:57
msgid "Part 1: Simple Classification & Regression"
msgstr "Bölüm 1: Basit Sınıflandırma ve Regresyon"

#: ../../tutorials/05_torch_connector.ipynb:71
msgid "First, we show how the ``TorchConnector`` can be used to use a Quantum ``NeuralNetwork`` to solve a classification tasks. Therefore, we generate a simple random data set."
msgstr "İlk olarak, bir sınıflandırma görevlerini çözmek için bir Quantum ``NeuralNetwork`` kullanmak için ``TorchConnector``un nasıl kullanılabileceğini gösteriyoruz. Bu nedenle, basit bir rastgele veri seti oluşturuyoruz."

#: ../../tutorials/05_torch_connector.ipynb:117
msgid "Classification with PyTorch and the ``OpflowQNN``"
msgstr "PyTorch ve ``OpflowQNN`` ile Sınıflandırma"

#: ../../tutorials/05_torch_connector.ipynb:119
msgid "Linking an ``OpflowQNN`` to PyTorch is relatively straight-forward. Here we illustrate this using the ``TwoLayerQNN``."
msgstr "Bir ``OpflowQNN``i PyTorch'a bağlamak nispeten basittir. Burada bunu ``TwoLayerQNN`` kullanarak gösteriyoruz."

#: ../../tutorials/05_torch_connector.ipynb:330
msgid "The red circles indicate wrongly classified data points."
msgstr "Kırmızı daireler yanlış sınıflandırılmış veri noktalarını gösterir."

#: ../../tutorials/05_torch_connector.ipynb:342
msgid "Classification with PyTorch and the ``CircuitQNN``"
msgstr "PyTorch ve ``CircuitQNN`` ile Sınıflandırma"

#: ../../tutorials/05_torch_connector.ipynb:344
msgid "Linking an ``CircuitQNN`` to PyTorch requires the correct setup, otherwise backpropagation is not possible."
msgstr "Bir ``CircuitQNN``i PyTorch'a bağlanmak için doğru kurulum gerekir, aksi hâlde geri yayılım mümkün değildir."

#: ../../tutorials/05_torch_connector.ipynb:526
msgid "We use a model based on the ``TwoLayerQNN`` to also illustrate an regression task."
msgstr "Bir regresyon görevini de göstermek için ``TwoLayerQNN``e dayalı bir model kullanıyoruz."

#: ../../tutorials/05_torch_connector.ipynb:758
msgid "Part 2: MNIST Classification"
msgstr "2. Bölüm: MNIST Sınıflandırması"

#: ../../tutorials/05_torch_connector.ipynb:760
msgid "Also see Qiskit Textbook: https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html"
msgstr "Qiskit Ders Kitabına da bakın: https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html"

#: ../../tutorials/index.rst:3
msgid "Machine Learning Tutorials"
msgstr "Makine Öğrenimi Eğitselleri"

