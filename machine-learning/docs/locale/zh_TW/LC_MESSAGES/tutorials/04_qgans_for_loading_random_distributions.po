msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-04-29 17:32+0000\n"
"PO-Revision-Date: 2022-04-29 18:00\n"
"Last-Translator: \n"
"Language-Team: Chinese Traditional\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.10.1\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: zh-TW\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/04_qgans_for_loading_random_distributions.po\n"
"X-Crowdin-File-ID: 9634\n"
"Language: zh_TW\n"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:9
msgid "This page was generated from `docs/tutorials/04_qgans_for_loading_random_distributions.ipynb`__."
msgstr "此頁面是從 `docs/tutorials/04_qgans_for_loading_random_distributions.ipynb `__ 產生的。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:9
msgid "qGANs for Loading Random Distributions"
msgstr "使用 qGAN 編寫隨機分佈"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:11
msgid "Given :math:`k`-dimensional data samples, we employ a quantum Generative Adversarial Network (qGAN) to learn the data’s underlying random distribution and to load it directly into a quantum state:"
msgstr "給定 :math:`k`維度的數據樣本，我們使用quantum Generative Adversarial Network (qGAN) 來學習數據背後的隨機分佈並將其直接加載到量子狀態中。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:13
msgid "\\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle\n\n"
msgstr "\\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle\n\n"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:15
msgid "where :math:`p_{\\theta}^{j}` describe the occurrence probabilities of the basis states :math:`\\big| j\\rangle`."
msgstr "其中 :math:`p_{\\theta}^{j}`表示基態出現的概率:math:`\\big| j\\rangle`。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:17
msgid "The aim of the qGAN training is to generate a state :math:`\\big| g_{\\theta}\\rangle` where :math:`p_{\\theta}^{j}`, for :math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}`, describe a probability distribution that is close to the distribution underlying the training data :math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}`."
msgstr "Qgan 學習的目的是生成量子態 :math:`\\big| g_{\\theta}\\rangle`。其中:math:`p_{\\theta}^{j}`是:math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}`描述一個接近訓練數據基礎分佈:math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}`的概率分佈"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:19
msgid "For further details please refer to `Quantum Generative Adversarial Networks for Learning and Loading Random Distributions <https://arxiv.org/abs/1904.00043>`__ *Zoufal, Lucchi, Woerner* [2019]."
msgstr "有關更多信息，請參閱`Quantum Generative Adversarial Networks for Learning and Loading Random Distributions <https://arxiv.org/abs/1904.00043>`__ *Zoufal, Lucchi, Woerner* [2019]。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:21
msgid "For an example of how to use a trained qGAN in an application, the pricing of financial derivatives, please see the `Option Pricing with qGANs <https://github.com/Qiskit/qiskit-finance/tree/main/docs/tutorials/10_qgan_option_pricing.ipynb>`__ tutorial."
msgstr "作為如何在應用程式中使用受過訓練的 qGAN 的例子，金融導數的價格，請參閱`Option Pricing with qGANs <https://github.com/Qiskit/qiskit-finance/tree/main/docs/tutorials/10_qgan_option_pricing.ipynb>`__教程。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:58
msgid "Load the Training Data"
msgstr "載入訓練數據"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:60
msgid "First, we need to load the :math:`k`-dimensional training data samples (here k=1)."
msgstr "首先，我們需要載入 :math:`k' 維訓練數據樣本（這裡 k=1）。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:62
msgid "Next, the data resolution is set, i.e. the min/max data values and the number of qubits used to represent each data dimension."
msgstr "接下來，設置數據解析，即最小和最大數據值，以及用於表示每個數據維度的量子位元。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:97
msgid "Initialize the qGAN"
msgstr "Qgan 初始化"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:99
msgid "The qGAN consists of a quantum generator :math:`G_{\\theta}`, i.e., an ansatz, and a classical discriminator :math:`D_{\\phi}`, a neural network."
msgstr "Qgan 由一個量子生成器 :math:`G_{\\theta}`，即所謂的擬設，和一個神經網絡古典分類器:math:`D_{\\phi}`。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:101
msgid "To implement the quantum generator, we choose a depth-\\ :math:`1` ansatz that implements :math:`R_Y` rotations and :math:`CZ` gates which takes a uniform distribution as an input state. Notably, for :math:`k>1` the generator’s parameters must be chosen carefully. For example, the circuit depth should be :math:`>1` because higher circuit depths enable the representation of more complex structures."
msgstr "為了實作量子生成器，我們使用深度-\\ :math:`1`的擬設，包含一個 :math:`R_Y` 旋轉和一個:math:`CZ`閘，以均勻分佈作為輸入。值得注意的是，必須仔細選擇生成器參數，例如:電路深度為 :math:`>1`，因為電路越深，能夠表示的結構越複雜。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:103
msgid "The classical discriminator used here is based on a neural network implementation using NumPy. There is also a discriminator based on PyTorch which is not installed by default when installing Qiskit - see `Optional Install <https://github.com/Qiskit/qiskit-machine-learning#optional-installs>`__ for more information."
msgstr "這裡使用的經典分類器基於 NumPy 的神經網絡實作。還有一些基於 PyTorch 的分類器，當你未依預設安裝Qiskit。有關更多信息，請參閱 `Optional Install <https://github.com/Qiskit/qiskit-machine-learning#optional-installs>`。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:105
msgid "Here, both networks are updated with the ADAM optimization algorithm (ADAM is qGAN optimizer default)."
msgstr "在這裡，兩個網絡都由 ADAM 最佳化演算法更新（ADAM 是 qGAN 的預設優化器）。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:169
msgid "Run the qGAN Training"
msgstr "執行 qGAN 訓練"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:171
msgid "During the training the discriminator’s and the generator’s parameters are updated alternately w.r.t the following loss functions:"
msgstr "在訓練中，分類器和生成器參數根據以下損失函數交替更新："

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:173
msgid "L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right]\n\n"
msgstr "L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right]\n\n"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:175
msgid "and"
msgstr "和"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:177
msgid "L_D\\left(\\phi, \\theta\\right) =\n"
"  \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],"
msgstr "L_D\\left(\\phi, \\theta\\right) =\n"
"  \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:182
msgid "with :math:`m` denoting the batch size and :math:`g^l` describing the data samples generated by the quantum generator."
msgstr "其中 :math:`m`表示批量大小，而 :math:`g^l` 表示由量子生成器生成的數據樣本。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:184
msgid "Please note that the training, for the purpose of this notebook, has been kept briefer by the selection of a known initial point (``init_params``). Without such prior knowledge be aware training may take some while."
msgstr "請注意，為了筆記本的目的，藉由指定已知初始點（``init_params``）保持簡短。如果沒有這些先備知識，訓練可能需要一些時間。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:260
msgid "Training Progress & Outcome"
msgstr "訓練進度與成果"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:262
msgid "Now, we plot the evolution of the generator’s and the discriminator’s loss functions during the training, as well as the progress in the relative entropy between the trained and the target distribution."
msgstr "接下來，我們繪製訓練中生成器和判別器的損失函數的轉移，以及訓練分佈和目標分佈之間的相對熵的轉移。"

#: ../../tutorials/04_qgans_for_loading_random_distributions.ipynb:264
msgid "Finally, we also compare the cumulative distribution function (CDF) of the trained distribution to the CDF of the target distribution."
msgstr "最後，我們還將訓練分佈的累積分佈函數 (CDF) 與目標分佈的 CDF 進行比較。"

