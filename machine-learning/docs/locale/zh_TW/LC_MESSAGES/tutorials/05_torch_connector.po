msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-02-17 23:23+0000\n"
"PO-Revision-Date: 2022-03-31 19:53\n"
"Last-Translator: \n"
"Language-Team: Chinese Traditional\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: zh-TW\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/05_torch_connector.po\n"
"X-Crowdin-File-ID: 9636\n"
"Language: zh_TW\n"

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "This page was generated from `docs/tutorials/05_torch_connector.ipynb`__."
msgstr "此頁面是從 `docs/tutorials/05_torch_connector.ipynb`__ 產生的。"

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector and Hybrid QNNs"
msgstr "Torch 連接器及混合式 QNNs"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial introduces Qiskit’s ``TorchConnector`` class, and demonstrates how the ``TorchConnector`` allows for a natural integration of any ``NeuralNetwork`` from Qiskit Machine Learning into a PyTorch workflow. ``TorchConnector`` takes a Qiskit ``NeuralNetwork`` and makes it available as a PyTorch ``Module``. The resulting module can be seamlessly incorporated into PyTorch classical architectures and trained jointly without additional considerations, enabling the development and testing of novel **hybrid quantum-classical** machine learning architectures."
msgstr "本教程介紹 Qiskit 的 ``TorchConnector`` 類別。然後展示了``TorchConnector`` 如何自然地將來自 Qiskit 機器學習的 ``NeuralNetwork`` 整合到 PyTorch 工作流程中。 `` TorchConnector`` 採用 Qiskit 的 ``NeuralNetwork`` 並將其作為 PyTorch 的 ``Module`` 使用。生成的模塊可以無縫融合到 PyTorch 的古典架構中並一起訓練，無需任何額外考慮。它還支持新**hybrid quantum-classical** 機器學習架構的開發和測試。"

#: ../../tutorials/05_torch_connector.ipynb:15
msgid "Content:"
msgstr "內容："

#: ../../tutorials/05_torch_connector.ipynb:17
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__"
msgstr "`第 1 部分：簡單分類和回歸 <# 第 1 部分：-Simple-Classification-&-Regression>` __"

#: ../../tutorials/05_torch_connector.ipynb:19
msgid "The first part of this tutorial shows how quantum neural networks can be trained using PyTorch’s automatic differentiation engine (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) for simple classification and regression tasks."
msgstr "本教程的第一部分使用 PyTorch 的自動區分引擎(``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__)。它展示如何訓練用於簡單分類和回歸任務的量子神經網絡。"

#: ../../tutorials/05_torch_connector.ipynb:21
msgid "`Classification <#1.-Classification>`__"
msgstr "`分類 <#1.-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:23
msgid "Classification with PyTorch and ``OpflowQNN``"
msgstr "使用 PyTorch 及 ``OpflowQNN`` 進行分類"

#: ../../tutorials/05_torch_connector.ipynb:24
msgid "Classification with PyTorch and ``CircuitQNN``"
msgstr "使用 PyTorch 及 ``CircuitQNN`` 進行分類"

#: ../../tutorials/05_torch_connector.ipynb:26
msgid "`Regression <#2.-Regression>`__"
msgstr "`迴歸 <#2.-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:28
msgid "Regression with PyTorch and ``OpflowQNN``"
msgstr "使用PyTorch 與 ``OpflowQNN`` 進行迴歸"

#: ../../tutorials/05_torch_connector.ipynb:30
msgid "`Part 2: MNIST Classification, Hybrid QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"
msgstr "`第 2 部分：MNIST 分類，混合 QNN<#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"

#: ../../tutorials/05_torch_connector.ipynb:32
msgid "The second part of this tutorial illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow (in this case, a typical CNN architecture) to classify MNIST data in a hybrid quantum-classical manner."
msgstr "在教程的第二部分說明如何將（Quantum） ``NeuralNetwork`` 嵌入目標 PyTorch 工作流程（在此案例中，是典型的 CNN 架構），以混合式量子古典方式分類 MNIST 數據。"

#: ../../tutorials/05_torch_connector.ipynb:85
msgid "Part 1: Simple Classification & Regression"
msgstr "第一部分：簡單分類與迴歸"

#: ../../tutorials/05_torch_connector.ipynb:97
msgid "1. Classification"
msgstr "1. 分類"

#: ../../tutorials/05_torch_connector.ipynb:99
msgid "First, we show how ``TorchConnector`` allows to train a Quantum ``NeuralNetwork`` to solve a classification tasks using PyTorch’s automatic differentiation engine. In order to illustrate this, we will perform **binary classification** on a randomly generated dataset."
msgstr "首先，我們展示了``TorchConnector``如何使用 PyTorch 的自動區分引擎來訓練量子``NeuralNetwork``來解決分類任務。為了說明這一點，我們會準備一個隨機生成資料集的**binary classification**"

#: ../../tutorials/05_torch_connector.ipynb:152
msgid "A. Classification with PyTorch and ``OpflowQNN``"
msgstr "A. 使用 PyTorch 及 ``OpflowQNN`` 進行分類"

#: ../../tutorials/05_torch_connector.ipynb:154
msgid "Linking an ``OpflowQNN`` to PyTorch is relatively straightforward. Here we illustrate this using the ``TwoLayerQNN``, a sub-case of ``OpflowQNN`` introduced in previous tutorials."
msgstr "將 ``OpflowQNN``鏈接到 PyTorch 相對容易。本節使用“TwoLayerQNN”，它是之前教程中介紹的“OpflowQNN”的一個子案例。"

#: ../../tutorials/05_torch_connector.ipynb:295
msgid "Optimizer"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:297
msgid "The choice of optimizer for training any machine learning model can be crucial in determining the success of our training’s outcome. When using ``TorchConnector``, we get access to all of the optimizer algorithms defined in the [``torch.optim``] package (`link <https://pytorch.org/docs/stable/optim.html>`__). Some of the most famous algorithms used in popular machine learning architectures include *Adam*, *SGD*, or *Adagrad*. However, for this tutorial we will be using the L-BFGS algorithm (``torch.optim.LBFGS``), one of the most well know second-order optimization algorithms for numerical optimization."
msgstr "選擇用於訓練任何機器學習模型的優化器對於確定學習結果非常重要。使用``TorchConnector``時，在[``torch.optim``]套件中（`link <https://pytorch.org/docs/stable/optim.html>` __）我們可以使用所有優化器演算法。常見機器學習架構中最著名的演算法有 * Adam *、* SGD * 或 * Adagrad *。但是，本教程使用 L-BFGS 演算法（``torch.optim.LBFGS``）。它是最著名的用於數值優化的二階優化演算法之一。"

#: ../../tutorials/05_torch_connector.ipynb:301
msgid "Loss Function"
msgstr "損失函數"

#: ../../tutorials/05_torch_connector.ipynb:303
msgid "As for the loss function, we can also take advantage of PyTorch’s pre-defined modules from ``torch.nn``, such as the `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ or `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."
msgstr "至於損失函數，我們也可以從 ` `torch. nn``中利用 PyTorch的預先定義模組，例如 `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ 或`Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."

#: ../../tutorials/05_torch_connector.ipynb:305
msgid "**💡 Clarification :** In classical machine learning, the general rule of thumb is to apply a Cross-Entropy loss to classification tasks, and MSE loss to regression tasks. However, this recommendation is given under the assumption that the output of the classification network is a class probability value in the [0,1] range (usually this is achieved through a Softmax layer). Because the following example for ``TwoLayerQNN`` does not include such layer, and we don’t apply any mapping to the output (the following section shows an example of application of parity mapping with ``CircuitQNNs``), the QNN’s output can take any value in the range [-1,1]. In case you were wondering, this is the reason why this particular example uses MSELoss for classification despite it not being the norm (but we encourage you to experiment with different loss functions and see how they can impact training results)."
msgstr "** 💡 說明：** 在古典機器學習中的一個常見經驗法則是將交叉熵損失應用於分類任務，將 MSE 損失應用於迴歸任務。但是，這個推薦是在假設分類網絡的輸出是[0, 1] 範圍內的類別概率值（通常通過Softmax層實現）。下面的``TwoLayerQNN`` 範例不包含這樣的層，也沒有任何對輸出應用映射（以下顯示了使用“CircuitQNNs”應用奇偶校驗映射的範例)。因此，QNN 的輸出可以取[-1,1] 範圍內的任何值。順便說一句，這就是我們在這個特定範例中使用 MSELoss 進行分類的原因，即使它並不是範數（但我們建議你去嘗試不同的損失函數以查看它們如何影響訓練結果）。"

#: ../../tutorials/05_torch_connector.ipynb:512
#: ../../tutorials/05_torch_connector.ipynb:781
msgid "The red circles indicate wrongly classified data points."
msgstr "紅色圓圈表示錯誤的分類數據點。"

#: ../../tutorials/05_torch_connector.ipynb:524
msgid "B. Classification with PyTorch and ``CircuitQNN``"
msgstr "B. 使用 PyTorch 和 ` CircuitQNN`` 進行分類"

#: ../../tutorials/05_torch_connector.ipynb:526
msgid "Linking an ``CircuitQNN`` to PyTorch requires a bit more attention than ``OpflowQNN``. Without the correct setup, backpropagation is not possible."
msgstr "將“CircuitQNN”鏈接到PyTorch需要比“OpflowQNN”更加小心。沒有正確的設置，反向傳播是不可能的。"

#: ../../tutorials/05_torch_connector.ipynb:528
msgid "In particular, we must make sure that we are returning a dense array of probabilities in the network’s forward pass (``sparse=False``). This parameter is set up to ``False`` by default, so we just have to make sure that it has not been changed."
msgstr "特別是，我們必須確保我們在網絡的前向傳遞中返回一個密集的概率數組(``sparse=False``)。 依預設，此參數設定為 ``False`` ，因此我們必須確定它尚未變更。"

#: ../../tutorials/05_torch_connector.ipynb:530
msgid "**⚠️ Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``CircuitQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."
msgstr "**⚠️ 注意：** 如果我們定義自訂解譯功能（在範例中：``parity``），我們必須記住明確提供所需的輸出形狀（範例： ``2``）。 如需 ` ` CircuitQNN`` 起始參數設定的相關資訊，請參閱 `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__。"

#: ../../tutorials/05_torch_connector.ipynb:602
#: ../../tutorials/05_torch_connector.ipynb:930
msgid "For a reminder on optimizer and loss function choices, you can go back to `this section <#Optimizer>`__."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:793
msgid "2. Regression"
msgstr "2. 迴歸"

#: ../../tutorials/05_torch_connector.ipynb:795
msgid "We use a model based on the ``TwoLayerQNN`` to also illustrate how to perform a regression task. The chosen dataset in this case is randomly generated following a sine wave."
msgstr "我們使用以 ``TwoLayerQNN`` 為基礎的模型，也說明如何執行迴歸作業。在這種情況下，選擇的資料集是在正弦波之後隨機生成的。"

#: ../../tutorials/05_torch_connector.ipynb:836
msgid "A. Regression with PyTorch and ``OpflowQNN``"
msgstr "A. 使用PyTorch 及 ``OpflowQNN`` 進行迴歸"

#: ../../tutorials/05_torch_connector.ipynb:847
msgid "The network definition and training loop will be analogous to those of the classification task using ``TwoLayerQNN``. In this case, we define our own feature map and ansatz, instead of using the default values."
msgstr "網路定義和訓練迴圈會與使用 ``TwoLayerQNN`` 的分類任務類似。在此情況下，我們定義了自己的特徵圖和擬設，而不是使用預設值。"

#: ../../tutorials/05_torch_connector.ipynb:1067
msgid "Part 2: MNIST Classification, Hybrid QNNs"
msgstr "第 2 部分：MNIST分類、混合式 QNNs"

#: ../../tutorials/05_torch_connector.ipynb:1069
msgid "In this second part, we show how to leverage a hybrid quantum-classical neural network using ``TorchConnector``, to perform a more complex image classification task on the MNIST handwritten digits dataset."
msgstr "第二部分展示如何通過 ``TorchConnector``利用混合量子古典神經網絡。在 MNIST 手寫數字資料集上執行更複雜的圖像分類任務。"

#: ../../tutorials/05_torch_connector.ipynb:1071
msgid "For a more detailed (pre-``TorchConnector``) explanation on hybrid quantum-classical neural networks, you can check out the corresponding section in the `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."
msgstr "有關混合量子古典神經網絡的更多信息（在``TorchConnector``之前），請參閱`Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__ 相對應的部分。"

#: ../../tutorials/05_torch_connector.ipynb:1109
msgid "Step 1: Defining Data-loaders for train and test"
msgstr "步驟 1：定義用於訓練和測試的數據加載器"

#: ../../tutorials/05_torch_connector.ipynb:1120
msgid "We take advantage of the ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ to directly load a subset of the `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ and define torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) for train and test."
msgstr "利用``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>` __去加載一個子集 `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database> ，並直接定義一個 ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) 用於訓練和測試。"

#: ../../tutorials/05_torch_connector.ipynb:1163
msgid "If we perform a quick visualization we can see that the train dataset consists of images of handwritten 0s and 1s."
msgstr "執行簡單的可視化後，您可以看到訓練資料集由手寫的 0 和 1 圖像組成。"

#: ../../tutorials/05_torch_connector.ipynb:1237
msgid "Step 2: Defining the QNN and Hybrid Model"
msgstr "步驟 2：定義 QNN 和混合式模型"

#: ../../tutorials/05_torch_connector.ipynb:1248
msgid "This second step shows the power of the ``TorchConnector``. After defining our quantum neural network layer (in this case, a ``TwoLayerQNN``), we can embed it into a layer in our torch ``Module`` by initializing a torch connector as ``TorchConnector(qnn)``."
msgstr "第二步展示了``TorchConnector`` 的強大功能。在定義了量子神經網絡層（在本例中為``TwoLayerQNN``）之後，我們可以通過將torch connector 初始化為`` TorchConnector (qnn) `` 並將其嵌入到 ``Module``中。"

#: ../../tutorials/05_torch_connector.ipynb:1250
msgid "**⚠️ Attention:** In order to have an adequate gradient backpropagation in hybrid models, we MUST set the initial parameter ``input_gradients`` to TRUE during the qnn initialization."
msgstr "** ⚠️ 注意：** 為了在混合模型中得到正確的梯度反向傳播，我們必須在 QNN 初始化期間設置初始參數 `` input_gradients`` 為 TRUE 。"

#: ../../tutorials/05_torch_connector.ipynb:1368
msgid "Step 3: Training"
msgstr "步驟 3：訓練"

#: ../../tutorials/05_torch_connector.ipynb:1482
msgid "Step 4: Evaluation"
msgstr "步驟 4 ：評估"

#: ../../tutorials/05_torch_connector.ipynb:1592
msgid "🎉🎉🎉🎉 **You are now able to experiment with your own hybrid datasets and architectures using Qiskit Machine Learning.** **Good Luck!**"
msgstr ""

