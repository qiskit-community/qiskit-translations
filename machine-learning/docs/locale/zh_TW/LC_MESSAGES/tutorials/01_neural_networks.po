msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-04-29 17:32+0000\n"
"PO-Revision-Date: 2022-04-29 18:00\n"
"Last-Translator: \n"
"Language-Team: Chinese Traditional\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.10.1\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: zh-TW\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/01_neural_networks.po\n"
"X-Crowdin-File-ID: 9628\n"
"Language: zh_TW\n"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/01_neural_networks.ipynb`__."
msgstr "此頁面是從 `docs/tutorials/01_neural_networks.ipynb`__ 產生的。"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "量子神經網絡"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "本筆記本介紹了由 Qiskit 機器學習提供的各種通用量子神經網絡 (QNN) 實作。該網絡可作為獨立於應用程序的計算單元用於各種使用範例。根據您的應用程序，某些類型的網絡可能或多或少適合，或者您可能需要以特定方式設置它們。本節詳細介紹以下類型的神經網絡："

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks."
msgstr "``NeuralNetwork``：神經網絡介面。"

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``OpflowQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr "``OpflowQNN``：基於量子物理觀察量評估的網絡。"

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``TwoLayerQNN``: A special ``OpflowQNN`` implementation for convenience."
msgstr "`` TwoLayerQNN``：為方便起見的`` OpflowQNN`` 的特殊實作。"

#: ../../tutorials/01_neural_networks.ipynb:16
msgid "``CircuitQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr "``CircuitQNN``：基於通過測量量子電路獲得的樣本的網絡。"

#: ../../tutorials/01_neural_networks.ipynb:66
msgid "1. ``NeuralNetwork``"
msgstr "1. ``NeuralNetwork``"

#: ../../tutorials/01_neural_networks.ipynb:68
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interfaces are introduced."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:70
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes either flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:82
msgid "2. ``OpflowQNN``"
msgstr "2. ``OpflowQNN``"

#: ../../tutorials/01_neural_networks.ipynb:84
msgid "The ``OpflowQNN`` takes a (parametrized) operator from Qiskit and leverages Qiskit’s gradient framework to provide the backward pass. Such an operator can for instance be an expected value of a quantum mechanical observable with respect to a parametrized quantum state. The Parameters can be used to load classical data as well as represent trainable weights. The ``OpflowQNN`` also allows lists of operators and more complex structures to construct more complex QNNs."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:351
msgid "Combining multiple observables in a ``ListOp`` also allows to create more complex QNNs"
msgstr "您還可以通過將多個在``ListOp``觀察量結合來創建更複雜的 QNNs。"

#: ../../tutorials/01_neural_networks.ipynb:450
msgid "3. ``TwoLayerQNN``"
msgstr "3. ``TwoLayerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:452
msgid "The ``TwoLayerQNN`` is a special ``OpflowQNN`` on :math:`n` qubits that consists of first a feature map to insert data and second an ansatz that is trained. The default observable is :math:`Z^{\\otimes n}`, i.e., parity."
msgstr "``TwoLayerQNN`` 是一個特殊的``OpflowQNN`` 在:math:`n`量子位元上，由首先插入數據的特徵圖和第二個學習的擬設組成。預設觀察值是 :math:`Z^{\\otimes n}`，即奇偶校驗。"

#: ../../tutorials/01_neural_networks.ipynb:663
msgid "4. ``CircuitQNN``"
msgstr "4. ``CircuitQNN``"

#: ../../tutorials/01_neural_networks.ipynb:665
msgid "The ``CircuitQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples can either be interpreted as probabilities of measuring the integer index corresponding to a bitstring or directly as a batch of binary output. In the case of probabilities, gradients can be estimated efficiently and the ``CircuitQNN`` provides a backward pass as well. In case of samples, differentiation is not possible and the backward pass returns ``(None, None)``."
msgstr "`` CircuitQNN`` 基於（參數化的）`` QuantumCircuit``。這可以獲取輸入以及重量參數並從測量中生成樣本。樣本可以解釋為測量位元串對應的整數索引的概率，或可以直接解釋為一批二進制的輸出。在概率的情況下，可以有效地估計梯度，並且 ``CircuitQNN`` 還提供了反向傳遞。對於樣本，區分是不可能的，反向傳遞返回`` (None, None) ``。"

#: ../../tutorials/01_neural_networks.ipynb:668
msgid "Further, the ``CircuitQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are aggregated accordingly."
msgstr "此外，``CircuitQNN`` 允許您指定一個 `` interpret`` 函數來對樣本進行後處理。期望獲取一個測量的整數（來自一個位元串）並將其映射到一個新的索引，即一個非負整數。在這種情況下，您需要提供輸出的形式，而概率將相應調整。"

#: ../../tutorials/01_neural_networks.ipynb:670
msgid "A ``CircuitQNN`` can be configured to return sparse as well as dense probability vectors. If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits and a sparse recommendation is usually recommended. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr "`` CircuitQNN`` 可以設置為返回稀疏概率向量和密集概率向量。如果不使用 `interpret` 函數，隨機向量的維數會隨著量子位元的數量呈指數增長，因此通常建議使用稀疏的。當使用 `` interpret`` 函數時，它取決於預期的結果。例如，如果將索引映射到相應位元串的奇偶校驗，即映射到 0 或 1，那麼密集輸出就有意義，結果是長度為 2 的隨機向量。"

#: ../../tutorials/01_neural_networks.ipynb:713
msgid "4.1 Output: sparse integer probabilities"
msgstr "4.1 輸出：稀疏整數的概率"

#: ../../tutorials/01_neural_networks.ipynb:818
msgid "4.2 Output: dense parity probabilities"
msgstr "4.2 輸出：密集奇偶概率"

#: ../../tutorials/01_neural_networks.ipynb:939
msgid "4.3 Output: Samples"
msgstr "4.3 輸出：樣本"

#: ../../tutorials/01_neural_networks.ipynb:1071
msgid "4.4 Output: Parity Samples"
msgstr "4.4 輸出：奇偶校驗樣本"

