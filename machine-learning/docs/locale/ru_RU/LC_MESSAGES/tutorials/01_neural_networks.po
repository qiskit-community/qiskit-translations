msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-08-11 21:47+0000\n"
"PO-Revision-Date: 2022-08-11 22:30\n"
"Last-Translator: \n"
"Language-Team: Russian\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.10.3\n"
"Plural-Forms: nplurals=4; plural=((n%10==1 && n%100!=11) ? 0 : ((n%10 >= 2 && n%10 <=4 && (n%100 < 12 || n%100 > 14)) ? 1 : ((n%10 == 0 || (n%10 >= 5 && n%10 <=9)) || (n%100 >= 11 && n%100 <= 14)) ? 2 : 3));\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ru\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/01_neural_networks.po\n"
"X-Crowdin-File-ID: 9628\n"
"Language: ru_RU\n"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/01_neural_networks.ipynb`__."
msgstr "Страница создана на основе `docs/tutorials/01_neural_networks.ipynb`__."

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "Квантовые нейронные сети"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "Этот блокнот демонстрирует различные общие реализации квантовых нейронных сетей (QNN), предоставляемые в Qiskit Machine Learning. Сети предназначены для использования в качестве вычислительных единиц, не зависящих от области применения, которые могут быть использованы для множества различных случаев. В зависимости от задачи, конкретный тип сети может быть более или менее подходящим и может потребовать определенной настройки. Ниже будут более подробно рассмотрены различные доступные нейронные сети:"

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks."
msgstr "` ` NeuralNetwork ` `: Интерфейс для нейронных сетей."

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``OpflowQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr "``OpflowQN``: Сеть, основанная на оценке квантово-механических наблюдений."

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``TwoLayerQNN``: A special ``OpflowQNN`` implementation for convenience."
msgstr "``TwoLayerQNN``: Специальная реализация ``OpflowQNN`` для удобства."

#: ../../tutorials/01_neural_networks.ipynb:16
msgid "``CircuitQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr "\" CircuitQNN ` `: сеть, основанная на образцах, полученных в результате измерения квантовой цепи."

#: ../../tutorials/01_neural_networks.ipynb:66
msgid "1. ``NeuralNetwork``"
msgstr "1. ` ` NeuralNetwork ` `"

#: ../../tutorials/01_neural_networks.ipynb:68
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interfaces are introduced."
msgstr "``NeuralNetwork`` это интерфейс для всех нейронных сетей, доступных в Qiskit Machine Learning. Он предоставляет собой прямой и обратный проход, принимающий на вход образцы данных и обучаемые веса. ``NeuralNetwork`` не содержит никаких возможностей для обучения, они предоставляются конкретными алгоритмами / приложениями. Таким образом, ``NeuralNetwork`` также не хранит значения обучаемых весов. Далее будут представлены различные реализации этих интерфейсов."

#: ../../tutorials/01_neural_networks.ipynb:70
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes either flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr "Предположим, что ``NeuralNetwork`` называется ``nn``. Затем проход ``nn.forward(input, weights)`` принимает либо одинаковые входные значения для данных и весов размера ``nn. um_inputs`` и ``nn.num_weights``, соответственно. ``NeuralNetwork`` поддерживает группировку входных данных и возвращает набор выходных данных соответствующей формы."

#: ../../tutorials/01_neural_networks.ipynb:82
msgid "2. ``OpflowQNN``"
msgstr "2. ` ` OpflowQNN ` `"

#: ../../tutorials/01_neural_networks.ipynb:84
msgid "The ``OpflowQNN`` takes a (parametrized) operator from Qiskit and leverages Qiskit’s gradient framework to provide the backward pass. Such an operator can for instance be an expected value of a quantum mechanical observable with respect to a parametrized quantum state. The Parameters can be used to load classical data as well as represent trainable weights. The ``OpflowQNN`` also allows lists of operators and more complex structures to construct more complex QNNs."
msgstr "Функция ``OpflowQNN`` принимает (параметризованный) оператор из Qiskit и использует градиентную схему Qiskit для обеспечения обратного прохода. Таким оператором может быть, например, математическое ожидание квантово-механической наблюдаемой величины относительно параметризованного квантового состояния. Параметры могут быть использованы для загрузки классических данных, а также для представления обучаемых весов. В ``OpflowQNN`` также допускаются списки операторов и более сложные структуры для построения более сложных QNN."

#: ../../tutorials/01_neural_networks.ipynb:356
msgid "Combining multiple observables in a ``ListOp`` also allows to create more complex QNNs"
msgstr "Объединение нескольких наблюдаемых в ``ListOp`` также позволяет создавать более сложные QNN"

#: ../../tutorials/01_neural_networks.ipynb:457
msgid "3. ``TwoLayerQNN``"
msgstr "3. ` ` TwoLayerQNN ` `"

#: ../../tutorials/01_neural_networks.ipynb:459
msgid "The ``TwoLayerQNN`` is a special ``OpflowQNN`` on :math:`n` qubits that consists of first a feature map to insert data and second an ansatz that is trained. The default observable is :math:`Z^{\\otimes n}`, i.e., parity."
msgstr "``TwoLayerQNN` - это специальная ``OpflowQNN`` на :math:`n` кубитах, которая состоит из: (1) карты признаков для вставки данных и (2) анзаца, который обучается. Наблюдаемой по умолчанию является :math:`Z^{\\otimes n}`, т.е. четность."

#: ../../tutorials/01_neural_networks.ipynb:673
msgid "4. ``CircuitQNN``"
msgstr "4. ` ` CircuitQNN ` `"

#: ../../tutorials/01_neural_networks.ipynb:675
msgid "The ``CircuitQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples can either be interpreted as probabilities of measuring the integer index corresponding to a bitstring or directly as a batch of binary output. In the case of probabilities, gradients can be estimated efficiently and the ``CircuitQNN`` provides a backward pass as well. In case of samples, differentiation is not possible and the backward pass returns ``(None, None)``."
msgstr "В основе ``CircuitQNN`` лежит (параметризованная) ``QuantumCircuit``. Она может принимать как входные, так и весовые параметры и производит выборки из измерений. Выборки могут быть интерпретированы как вероятности измерения целочисленного индекса, соответствующего битовой строке, или непосредственно как пакет двоичного вывода. В случае вероятностей градиенты могут быть оценены эффективно, а ``CircuitQNN`` обеспечивает также обратный проход. В случае выборок дифференцирование невозможно, и обратный проход возвращает ``(None, None)``."

#: ../../tutorials/01_neural_networks.ipynb:678
msgid "Further, the ``CircuitQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are aggregated accordingly."
msgstr "Более того, ``CircuitQNN`` позволяет указать ``interpret`` (интерпретирующую) функцию для последующей обработки выборки. Предполагается, что она будет принимать измеренное целое число (из битовой строки) и преобразовывать его в новый индекс, т.е. неотрицательное целое число. В этом случае необходимо указать форму выходных данных, и вероятности будут распределены соответствующим образом."

#: ../../tutorials/01_neural_networks.ipynb:680
msgid "A ``CircuitQNN`` can be configured to return sparse as well as dense probability vectors. If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits and a sparse recommendation is usually recommended. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr "``CircuitQNN`` может быть настроен на возврат как разреженных, так и плотных векторов вероятности. Если не используется функция ``interpret'', размерность вектора вероятности экспоненциально растет с числом кубитов, поэтому обычно рекомендуется использовать разреженную рекомендацию. В случае ``interpret'' (интерпретирующей) функции это зависит от ожидаемого результата. Если, например, индекс сопоставляется с четностью соответствующей битовой строки, т.е. с 0 или 1, то имеет смысл плотный вывод, и результатом будет вектор вероятностей длины 2."

#: ../../tutorials/01_neural_networks.ipynb:723
msgid "4.1 Output: sparse integer probabilities"
msgstr "4.1 Выходные данные: разреженные целочисленные вероятности"

#: ../../tutorials/01_neural_networks.ipynb:830
msgid "4.2 Output: dense parity probabilities"
msgstr "4.1 Выходные данные: плотные четные вероятности"

#: ../../tutorials/01_neural_networks.ipynb:953
msgid "4.3 Output: Samples"
msgstr "4.3 Выходные данные: выборки"

#: ../../tutorials/01_neural_networks.ipynb:1087
msgid "4.4 Output: Parity Samples"
msgstr "4.4 Выходные данные: четные выборки"

