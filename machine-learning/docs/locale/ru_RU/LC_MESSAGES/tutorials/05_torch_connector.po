msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-22 17:47+0000\n"
"PO-Revision-Date: 2021-08-05 11:49\n"
"Last-Translator: \n"
"Language-Team: Russian\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=4; plural=((n%10==1 && n%100!=11) ? 0 : ((n%10 >= 2 && n%10 <=4 && (n%100 < 12 || n%100 > 14)) ? 1 : ((n%10 == 0 || (n%10 >= 5 && n%10 <=9)) || (n%100 >= 11 && n%100 <= 14)) ? 2 : 3));\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ru\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/05_torch_connector.po\n"
"X-Crowdin-File-ID: 9636\n"
"Language: ru_RU\n"

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "This page was generated from `docs/tutorials/05_torch_connector.ipynb`__."
msgstr "Страница создана на основе `docs/tutorials/05_torch_connector.ipynb`__."

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector and Hybrid QNNs"
msgstr "Torch Connector и гибридные QNN"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial introduces Qiskit’s ``TorchConnector`` class, and demonstrates how the ``TorchConnector`` allows for a natural integration of any ``NeuralNetwork`` from Qiskit Machine Learning into a PyTorch workflow. ``TorchConnector`` takes a Qiskit ``NeuralNetwork`` and makes it available as a PyTorch ``Module``. The resulting module can be seamlessly incorporated into PyTorch classical architectures and trained jointly without additional considerations, enabling the development and testing of novel **hybrid quantum-classical** machine learning architectures."
msgstr "Этот учебный материал представляет класс ``TorchConnector`` из Qiskit и демонстрирует, как ``TorchConnector`` позволяет интегрировать любую ``NeuralNetwork`` из Qiskit Machine Learning в рабочий процесс PyTorch. ``TorchConnector`` принимает Qiskit ``NeuralNetwork`` и делает его доступным как ``Module`` PyTorch. Результирующий модуль можно легко интегрировать в классические архитектуры PyTorch и обучать без дополнительных сложностей, открывая возможность разработки и тестирования **гибридных квантово-классических** архитектур машинного обучения."

#: ../../tutorials/05_torch_connector.ipynb:15
msgid "Content:"
msgstr "Содержание:"

#: ../../tutorials/05_torch_connector.ipynb:17
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__"
msgstr "`Часть 1: Простая классификация и регрессия <#Part-1:-Simple-Classification-&-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:19
msgid "The first part of this tutorial shows how quantum neural networks can be trained using PyTorch’s automatic differentiation engine (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) for simple classification and regression tasks."
msgstr "Первая часть этого урока показывает, как квантовые нейронные сети могут быть обучены с помощью механизма автоматического дифференцирования PyTorch (``torch.autograd``, ``ссылка <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) для простых задач классификации и регрессии."

#: ../../tutorials/05_torch_connector.ipynb:21
msgid "`Classification <#1.-Classification>`__"
msgstr "`Классификация <#1.-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:23
msgid "Classification with PyTorch and ``OpflowQNN``"
msgstr "Классификация с PyTorch и ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:24
msgid "Classification with PyTorch and ``CircuitQNN``"
msgstr "Классификация с PyTorch и ``CircuitQNN``"

#: ../../tutorials/05_torch_connector.ipynb:26
msgid "`Regression <#2.-Regression>`__"
msgstr "`Регрессия <#2.-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:28
msgid "Regression with PyTorch and ``OpflowQNN``"
msgstr "Регрессия с PyTorch и ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:30
msgid "`Part 2: MNIST Classification, Hybrid QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"
msgstr "`Часть 2: Классификация MNIST, гибридные QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"

#: ../../tutorials/05_torch_connector.ipynb:32
msgid "The second part of this tutorial illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow (in this case, a typical CNN architecture) to classify MNIST data in a hybrid quantum-classical manner."
msgstr "Вторая часть этого урока показывает, как встроить (квантовую) ``NeuralNetwork`` в целевой рабочий процесс PyTorch (в данном случае, типичную архитектуру CNN) для классификации данных MNIST гибридным квантово-классическим способом."

#: ../../tutorials/05_torch_connector.ipynb:74
msgid "Part 1: Simple Classification & Regression"
msgstr "Часть 1: Простая классификация и регрессия"

#: ../../tutorials/05_torch_connector.ipynb:86
msgid "1. Classification"
msgstr "1. Классификация"

#: ../../tutorials/05_torch_connector.ipynb:88
msgid "First, we show how ``TorchConnector`` allows to train a Quantum ``NeuralNetwork`` to solve a classification tasks using PyTorch’s automatic differentiation engine. In order to illustrate this, we will perform **binary classification** on a randomly generated dataset."
msgstr "Сначала мы покажем, как ``TorchConnector'' позволяет обучить Quantum ``NeuralNetwork`` для решения задач классификации с помощью механизма автоматического дифференцирования PyTorch. Чтобы проиллюстрировать это, мы выполним **бинарную классификацию** на случайно сгенерированном наборе данных."

#: ../../tutorials/05_torch_connector.ipynb:144
msgid "A. Classification with PyTorch and ``OpflowQNN``"
msgstr "A. Классификация с PyTorch и ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:146
msgid "Linking an ``OpflowQNN`` to PyTorch is relatively straightforward. Here we illustrate this using the ``TwoLayerQNN``, a sub-case of ``OpflowQNN`` introduced in previous tutorials."
msgstr "Привязать ``OpflowQNN`` к PyTorch относительно просто. Здесь мы проиллюстрируем это на примере ``TwoLayerQNN``, подслучая ``OpflowQNN``, представленного в предыдущих уроках."

#: ../../tutorials/05_torch_connector.ipynb:254
msgid "Optimizer"
msgstr "Оптимизатор"

#: ../../tutorials/05_torch_connector.ipynb:256
msgid "The choice of optimizer for training any machine learning model can be crucial in determining the success of our training’s outcome. When using ``TorchConnector``, we get access to all of the optimizer algorithms defined in the [``torch.optim``] package (`link <https://pytorch.org/docs/stable/optim.html>`__). Some of the most famous algorithms used in popular machine learning architectures include *Adam*, *SGD*, or *Adagrad*. However, for this tutorial we will be using the L-BFGS algorithm (``torch.optim.LBFGS``), one of the most well know second-order optimization algorithms for numerical optimization."
msgstr "Выбор оптимизатора для обучения любой модели машинного обучения может иметь решающее значение для определения успеха нашего обучения. При использовании ``TorchConnector``, мы получаем доступ ко всем алгоритмам оптимизатора, определенным в пакете [``torch.optim``] (`ссылка на источник <https://pytorch.org/docs/stable/optim.html>`__). Некоторые наиболее известные алгоритмы, используемые в популярных архитектурах машинного обучения, включают *Adam*, *SGD*, или *Adagrad*. Однако, для этого урока мы будем использовать алгоритм L-BFGS (``torch.optim.LBFGS``), один из наиболее известных алгоритмов оптимизации второго порядка для числовой оптимизации."

#: ../../tutorials/05_torch_connector.ipynb:260
msgid "Loss Function"
msgstr "Функция потерь"

#: ../../tutorials/05_torch_connector.ipynb:262
msgid "As for the loss function, we can also take advantage of PyTorch’s pre-defined modules from ``torch.nn``, such as the `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ or `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."
msgstr "Что касается функции потерь, то мы также можем воспользоваться предопределенными модулями PyTorch с ``torch.nn``, например, `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ или `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__."

#: ../../tutorials/05_torch_connector.ipynb:264
msgid "**💡 Clarification :** In classical machine learning, the general rule of thumb is to apply a Cross-Entropy loss to classification tasks, and MSE loss to regression tasks. However, this recommendation is given under the assumption that the output of the classification network is a class probability value in the [0,1] range (usually this is achieved through a Softmax layer). Because the following example for ``TwoLayerQNN`` does not include such layer, and we don’t apply any mapping to the output (the following section shows an example of application of parity mapping with ``CircuitQNNs``), the QNN’s output can take any value in the range [-1,1]. In case you were wondering, this is the reason why this particular example uses MSELoss for classification despite it not being the norm (but we encourage you to experiment with different loss functions and see how they can impact training results)."
msgstr "**💡 Уточнение :** В процессе классического обучения общим правилом большого пальца является применение Cross-Entropy loss к задачам классификации, и MSE loss в регрессионных задачах. Однако, эта рекомендация приводится исходя из предположения о том, что результатом работы системы классификации является значение вероятности в диапазоне [0, 1] (обычно это достигается через слой Softmax). Поскольку следующий пример ``TwoLayerQN`` не включает такой слой, и мы не применяем никакие сопоставления с результатами (следующий раздел показывает пример приложения с parity mapping для ``CircuitQNs``), вывод QNN может принимать любое значение в диапазоне [-1,1]. Именно поэтому в данном примере используется MSELoss для классификации, несмотря на то, что она не является нормой (но мы рекомендуем вам экспериментировать с различными функциями потерь и посмотреть, как они могут повлиять на результаты обучения)."

#: ../../tutorials/05_torch_connector.ipynb:442
#: ../../tutorials/05_torch_connector.ipynb:674
msgid "The red circles indicate wrongly classified data points."
msgstr "Красными кружками отмечены неверно классифицированные данные."

#: ../../tutorials/05_torch_connector.ipynb:454
msgid "B. Classification with PyTorch and ``CircuitQNN``"
msgstr "B. Классификация с PyTorch и ``CircuitQNN``"

#: ../../tutorials/05_torch_connector.ipynb:456
msgid "Linking an ``CircuitQNN`` to PyTorch requires a bit more attention than ``OpflowQNN``. Without the correct setup, backpropagation is not possible."
msgstr "Связание ``CircuitQNNN`` с PyTorch требует немного больше внимания, чем ``OpflowQNN``. Без правильной настройки использование метода обратного распространения ошибки (backpropagation) невозможно."

#: ../../tutorials/05_torch_connector.ipynb:458
msgid "In particular, we must make sure that we are returning a dense array of probabilities in the network’s forward pass (``sparse=False``). This parameter is set up to ``False`` by default, so we just have to make sure that it has not been changed."
msgstr "В частности, мы должны убедиться, что мы возвращаем плотный массив вероятностей при прямом прохождении сети (``sparse=False``). Этот параметр имеет значение ``False`` по умолчанию, поэтому мы просто должны убедиться, что он не был изменен."

#: ../../tutorials/05_torch_connector.ipynb:460
msgid "**⚠️ Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``CircuitQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."
msgstr "**⚠️ Внимание:** Если мы определим пользовательскую функцию интерпретации (в примере - ``parity``), мы должны явно предоставить желаемую форму вывода (в примере - ``2``). Для получения дополнительной информации о начальной настройке параметра ``CircuitQNN``, ознакомьтесь с `официальной документацией qiskit <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."

#: ../../tutorials/05_torch_connector.ipynb:523
#: ../../tutorials/05_torch_connector.ipynb:815
msgid "For a reminder on optimizer and loss function choices, you can go back to `this section <#Optimizer>`__."
msgstr "Для выбора оптимизатора и функции потерь вы можете вернуться к `этому разделу <#Optimizer>`__."

#: ../../tutorials/05_torch_connector.ipynb:686
msgid "2. Regression"
msgstr "2. Регрессия"

#: ../../tutorials/05_torch_connector.ipynb:688
msgid "We use a model based on the ``TwoLayerQNN`` to also illustrate how to perform a regression task. The chosen dataset in this case is randomly generated following a sine wave."
msgstr "Чтобы продемонстрировать выполнение задачи регрессии, мы также используем модель на основе ``TwoLayerQNN``. Выбранный набор данных в данном случае является случайно сгенерированным и имеет форму синусоидальной волны."

#: ../../tutorials/05_torch_connector.ipynb:730
msgid "A. Regression with PyTorch and ``OpflowQNN``"
msgstr "A. Регрессия с PyTorch ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:741
msgid "The network definition and training loop will be analogous to those of the classification task using ``TwoLayerQNN``. In this case, we define our own feature map and ansatz, instead of using the default values."
msgstr "При использовании ``TwoLayerQNN`` определение сети и цикл обучения будут аналогичны задачам классификации. В этом случае мы определяем собственную карту признаков и анзац, а не используем значения по умолчанию."

#: ../../tutorials/05_torch_connector.ipynb:963
msgid "Part 2: MNIST Classification, Hybrid QNNs"
msgstr "Часть 2: Классификация MNIST, гибридные QNN"

#: ../../tutorials/05_torch_connector.ipynb:965
msgid "In this second part, we show how to leverage a hybrid quantum-classical neural network using ``TorchConnector``, to perform a more complex image classification task on the MNIST handwritten digits dataset."
msgstr "В этой второй части мы показываем, как использовать гибридно-классическую нейронную сеть с помощью ``TorchConnector`` для выполнения более сложной задачи по классификации изображений на наборе данных с рукописными буквами MNIST."

#: ../../tutorials/05_torch_connector.ipynb:967
msgid "For a more detailed (pre-``TorchConnector``) explanation on hybrid quantum-classical neural networks, you can check out the corresponding section in the `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."
msgstr "Для более подробного (до ``TorchConnector``) объяснения гибридных кванто-классических нейронных сетей вы можете посмотреть соответствующий раздел в `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."

#: ../../tutorials/05_torch_connector.ipynb:996
msgid "Step 1: Defining Data-loaders for train and test"
msgstr "Шаг 1: Определение загрузчиков данных для обучения и тестирования"

#: ../../tutorials/05_torch_connector.ipynb:1007
msgid "We take advantage of the ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ to directly load a subset of the `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ and define torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) for train and test."
msgstr "Мы пользуемся преимуществом ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ для непосредственной загрузки подмножества `набора данных MNIST <https://en.wikipedia.org/wiki/MNIST_database>`__ и определения ``DataLoader`` (`link <https://pytorch.org/docs/stable/data.html>`__) для обучения и тестирования."

#: ../../tutorials/05_torch_connector.ipynb:1048
msgid "If we perform a quick visualization we can see that the train dataset consists of images of handwritten 0s and 1s."
msgstr "Если мы выполним быструю визуализацию, то станет видно, что набор данных для обучения состоит из изображений написанных вручную цифр 0 и 1."

#: ../../tutorials/05_torch_connector.ipynb:1120
msgid "Step 2: Defining the QNN and Hybrid Model"
msgstr "Шаг 2: Определение QNN и гибридной модели"

#: ../../tutorials/05_torch_connector.ipynb:1131
msgid "This second step shows the power of the ``TorchConnector``. After defining our quantum neural network layer (in this case, a ``TwoLayerQNN``), we can embed it into a layer in our torch ``Module`` by initializing a torch connector as ``TorchConnector(qnn)``."
msgstr "Данный второй шаг раскрывает мощь ``TorchConnector``. После определения нашего квантового слоя нейросети (в данном случае ``TwoLayerQN``), мы можем встроить его в наш ``Module``, инициализируя его как ``TorchConnector(qnn)``."

#: ../../tutorials/05_torch_connector.ipynb:1133
msgid "**⚠️ Attention:** In order to have an adequate gradient backpropagation in hybrid models, we MUST set the initial parameter ``input_gradients`` to TRUE during the qnn initialization."
msgstr "**⚠️ Внимание:** Для правильного использования метода обратного распространения ошибки (backpropagation) для градиента в гибридных моделях, НЕОБХОДИМО установить начальный параметр ``input_gradients`` в значение TRUE во время инициализации qnn."

#: ../../tutorials/05_torch_connector.ipynb:1235
msgid "Step 3: Training"
msgstr "Шаг 3: Обучение"

#: ../../tutorials/05_torch_connector.ipynb:1337
msgid "Step 4: Evaluation"
msgstr "Шаг 4: Оценка"

#: ../../tutorials/05_torch_connector.ipynb:1440
msgid "🎉🎉🎉🎉 **You are now able to experiment with your own hybrid datasets and architectures using Qiskit Machine Learning.** **Good Luck!**"
msgstr "🎉🎉🎉🎉 **Теперь вы можете экспериментировать с собственными гибридными наборами данных и архитектурами, используя Qiskit Machine Learning.** **Удачи!**"

