msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-12-15 16:59+0000\n"
"PO-Revision-Date: 2021-12-15 17:32\n"
"Last-Translator: \n"
"Language-Team: Malayalam\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ml-IN\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/01_neural_networks.po\n"
"X-Crowdin-File-ID: 9628\n"
"Language: ml_IN\n"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/01_neural_networks.ipynb`__."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "ക്വാണ്ടം ന്യൂറൽ നെറ്റ്‌വർക്കുകൾ"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "ഈ നോട്ട്ബുക്ക് ക്വിസ്കിറ്റ് മെഷീൻ ലേണിംഗിൽ നൽകിയിട്ടുള്ള വ്യത്യസ്ത ജനറിക് ക്വാണ്ടം ന്യൂറൽ നെറ്റ്‌വർക്ക് (QNN) നടപ്പാക്കലുകൾ കാണിക്കുന്നു. വ്യത്യസ്‌ത ഉപയോഗ കേസുകൾ‌ക്ക് ഉപയോഗിക്കാൻ‌ കഴിയുന്ന ആപ്ലിക്കേഷൻ‌-അജ്ഞ്ഞേയ കംപ്യൂട്ടേഷണൽ‌ യൂണിറ്റുകളാണ് നെറ്റ്‌വർ‌ക്കുകൾ‌. ആപ്ലിക്കേഷനെ ആശ്രയിച്ച്, ഒരു പ്രത്യേക തരം നെറ്റ്‌വർക്ക് കൂടുതലോ കുറവോ അനുയോജ്യമായേക്കാം, ഇവയെ ഒരു പ്രത്യേക രീതിയിൽ സജ്ജീകരിക്കേണ്ടതുണ്ട്. ലഭ്യമായ വ്യത്യസ്ത ന്യൂറൽ നെറ്റ്‌വർക്കുകൾ ഇപ്പോൾ കൂടുതൽ വിശദമായി ചർച്ചചെയ്യും:"

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks."
msgstr "``NeuralNetwork``: ന്യൂറൽ നെറ്റ്‌വർക്കുകൾക്കായുള്ള ഇന്റർഫേസ്."

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``OpflowQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr "``OpflowQNN``: ക്വാണ്ടം മെക്കാനിക്കൽ നിരീക്ഷണങ്ങളുടെ വിലയിരുത്തലിനെ അടിസ്ഥാനമാക്കിയുള്ള ഒരു നെറ്റ്‌വർക്ക്."

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``TwoLayerQNN``: A special ``OpflowQNN`` implementation for convenience."
msgstr "``TwoLayerQNN``: സൗകര്യാർത്ഥം ഒരു പ്രത്യേക ``OpflowQNN`` നടപ്പാക്കൽ."

#: ../../tutorials/01_neural_networks.ipynb:16
msgid "``CircuitQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr "``CircuitQNN``: ഒരു ക്വാണ്ടം സർക്യൂട്ട് അളക്കുന്നതിന്റെ ഫലമായ സാമ്പിളുകളെ അടിസ്ഥാനമാക്കിയുള്ള ഒരു നെറ്റ്‌വർക്ക്."

#: ../../tutorials/01_neural_networks.ipynb:66
msgid "1. ``NeuralNetwork``"
msgstr "1.``NeuralNetwork``"

#: ../../tutorials/01_neural_networks.ipynb:68
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interfaces are introduced."
msgstr "ക്വിസ്കിറ്റ് മെഷീൻ ലേണിംഗിൽ ലഭ്യമായ എല്ലാ ന്യൂറൽ നെറ്റ്‌വർക്കുകൾക്കുമായുള്ള ഇന്റർഫേസിനെ ``NeuralNetwork`` പ്രതിനിധീകരിക്കുന്നു. ഡാറ്റാ സാമ്പിളുകളും ട്രെയിനബിൾ വെയ്റ്റുകളും ഇൻപുട്ടായി എടുക്കുന്ന ഒരു ഫോർവേഡ്, ബാക്ക്വേർഡ് പാസ് ഇത് തുറന്നുകാട്ടുന്നു. ഒരു ``NeuralNetwork``യിൽ പരിശീലന ശേഷികളൊന്നും അടങ്ങിയിട്ടില്ല, ഇവയെ യഥാർത്ഥ അൽഗോരിതം / ആപ്ലിക്കേഷനുകളിലേക്ക് തള്ളപ്പെടുന്നു. അതിനാൽ, ``NeuralNetwork``ഒരുപരിശീലനയോഗ്യമായ വെയ്റ്റിംൻ്റെ മൂല്യങ്ങളൊന്നും സംഭരിക്കുന്നില്ല. ഇനിപ്പറയുന്നവയിൽ, ഈ ഇന്റർഫേസുകളുടെ വ്യത്യസ്ത നടപ്പാക്കലുകൾ അവതരിപ്പിക്കുന്നു."

#: ../../tutorials/01_neural_networks.ipynb:70
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes either flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr "``nn`` എന്ന് വിളിക്കുന്ന ഒരു ``NeuralNetwork`` കരുതുക. തുടർന്ന്, ``nn.forward(input, weights)`` പാസ് യഥാക്രമം ``nn.num_inputs``, ``nn.num_weights`` എന്നിവയുടെ വലുപ്പത്തിനും ഡാറ്റയ്‌ക്കുമുള്ള ഫ്ലാറ്റ് ഇൻ‌പുട്ടുകൾ‌ എടുക്കുന്നു. ``NeuralNetwork`` ഇൻപുട്ടുകൾ ബാച്ച് ചെയ്യുന്നതിനെ പിന്തുണയ്ക്കുകയും അനുബന്ധ ആകൃതിയുടെ (shape) ഔട്ട്‌പുട്ടിന്റെ ബാച്ചുകൾ നൽകുകയും ചെയ്യുന്നു."

#: ../../tutorials/01_neural_networks.ipynb:82
msgid "2. ``OpflowQNN``"
msgstr "2. ``OpflowQNN``"

#: ../../tutorials/01_neural_networks.ipynb:84
msgid "The ``OpflowQNN`` takes a (parametrized) operator from Qiskit and leverages Qiskit’s gradient framework to provide the backward pass. Such an operator can for instance be an expected value of a quantum mechanical observable with respect to a parametrized quantum state. The Parameters can be used to load classical data as well as represent trainable weights. The ``OpflowQNN`` also allows lists of operators and more complex structures to construct more complex QNNs."
msgstr "``OpflowQNN`` ക്വിസ്കിറ്റിൽ‌ നിന്നും ഒരു (പാരാമീറ്ററൈസ്ഡ്) ഓപ്പറേറ്ററെടുക്കുകയും ബാക്ക്‌വേർ‌ഡ് പാസ് നൽ‌കുന്നതിന് ക്വിസ്കിറ്റിന്റെ ഗ്രേഡിയൻറ് ഫ്രെയിംവർ‌ക്കിനെ പരമാവധി ഉപയോഗപെടുത്തുന്നു. അത്തരമൊരു ഓപ്പറേറ്ററിന് ഒരു പാരാമീറ്ററൈസ്ഡ് ക്വാണ്ടം അവസ്ഥയുമായി(Quantum State) ബന്ധപ്പെട്ട് നിരീക്ഷിക്കാവുന്ന ഒരു ക്വാണ്ടം മെക്കാനിക്കലിന്റെ പ്രതീക്ഷിത മൂല്യമാകാം. ക്ലാസിക്കൽ ഡാറ്റ ലോഡുചെയ്യുന്നതിനും പരിശീലിപ്പിക്കാവുന്ന ഭാരം പ്രതിനിധീകരിക്കുന്നതിനും പാരാമീറ്ററുകൾ ഉപയോഗിക്കാം. കൂടുതൽ‌ സങ്കീർ‌ണ്ണമായ QNN കൾ‌ നിർമ്മിക്കുന്നതിന് ഓപ്പറേറ്റർ‌മാരുടെ പട്ടികകളും കൂടുതൽ‌ സങ്കീർ‌ണ്ണ ഘടനകളും ``OpflowQNN`` അനുവദിക്കുന്നു."

#: ../../tutorials/01_neural_networks.ipynb:319
msgid "Combining multiple observables in a ``ListOp`` also allows to create more complex QNNs"
msgstr "``ListOp`` -ൽ ഒന്നിലധികം നിരീക്ഷണങ്ങൾ സംയോജിപ്പിക്കുന്നത് കൂടുതൽ സങ്കീർണ്ണമായ QNN- കൾ സൃഷ്ടിക്കാൻ അനുവദിക്കുന്നു"

#: ../../tutorials/01_neural_networks.ipynb:408
msgid "3. ``TwoLayerQNN``"
msgstr "3. ``TwoLayerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:410
msgid "The ``TwoLayerQNN`` is a special ``OpflowQNN`` on :math:`n` qubits that consists of first a feature map to insert data and second an ansatz that is trained. The default observable is :math:`Z^{\\otimes n}`, i.e., parity."
msgstr "``TwoLayerQNN`` എന്നത് ഒരു പ്രത്യേക ``OpflowQNN`` എന്നതിലെ :math:`n` ക്യൂബിറ്റുകൾ, അതിൽ ആദ്യം ഡാറ്റ ഉൾപ്പെടുത്തുന്നതിനുള്ള സവിശേഷത മാപ്പും രണ്ടാമത് പരിശീലനം ലഭിച്ച ഒരു അൻസാറ്റ്സും(ansatz) അടങ്ങിയിരിക്കുന്നു. സ്ഥിരസ്ഥിതിയായി നിരീക്ഷിക്കാനാകുന്നത് :math:`Z^{\\otimes n}`, അതായത്, പാരിറ്റി."

#: ../../tutorials/01_neural_networks.ipynb:607
msgid "4. ``CircuitQNN``"
msgstr "4. ``CircuitQNN``"

#: ../../tutorials/01_neural_networks.ipynb:609
msgid "The ``CircuitQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples can either be interpreted as probabilities of measuring the integer index corresponding to a bitstring or directly as a batch of binary output. In the case of probabilities, gradients can be estimated efficiently and the ``CircuitQNN`` provides a backward pass as well. In case of samples, differentiation is not possible and the backward pass returns ``(None, None)``."
msgstr "``CircuitQNN`` ഒരു (പാരാമീറ്ററൈസ്ഡ്) ``QuantumCircuit`` അടിസ്ഥാനമാക്കിയുള്ളതാണ്. ഇത് ഇൻപുട്ടുകളും വെയിറ്റ് പാരാമീറ്ററുകളും എടുക്കുകയും ഇവയുടെ അളവുകളിൽ നിന്ന് സാമ്പിളുകൾ നിർമ്മിക്കുകയും ചെയ്യും. സാമ്പിളുകളെ ഒരു ബിറ്റ്സ്ട്രിംഗിന് സമാനമായ സംഖ്യ സൂചിക അളക്കുന്നതിനുള്ള സാധ്യതകളായി അല്ലെങ്കിൽ നേരിട്ട് ഒരു ബൈനറി ഔട്ട്പുട്ടായിട്ടും വ്യാഖ്യാനിക്കാം. സാധ്യതകളുടെ കാര്യത്തിൽ, ഗ്രേഡിയന്റുകളെ കാര്യക്ഷമമായി കണക്കാക്കാം, കൂടാതെ ``CircuitQNN`` ഒരു പിന്നാക്ക പാസും നൽകുന്നു. സാമ്പിളുകളുടെ കാര്യത്തിൽ, ഡിഫ്രൻസിയേശൻ (differentiation) സാധ്യമല്ല, പിന്നോക്ക പാസ്ന ``(None, None)`` നൽകുന്നു."

#: ../../tutorials/01_neural_networks.ipynb:612
msgid "Further, the ``CircuitQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are aggregated accordingly."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:614
msgid "A ``CircuitQNN`` can be configured to return sparse as well as dense probability vectors. If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits and a sparse recommendation is usually recommended. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr "സ്പാർസും ഡെൻസ് പ്രോബബിലിറ്റി വെക്ടറുകളിലേക്കും മടങ്ങുന്നതിന് ഒരു ``CircuitQNN`` -ന് ക്രമീകരിക്കാൻ‌ കഴിയും. ``interpret`` -ൻ്റെ ഫംഗ്ഷനൊന്നും ഉപയോഗിക്കുന്നില്ലെങ്കിൽ, പ്രോബബിലിറ്റി വെക്റ്ററിന്റെ അളവ് ക്യൂബിറ്റുകളുടെ എണ്ണത്തിനനുസരിച്ച് എക്‌സ്‌പോണൻസലായി വർധിക്കുന്നു, അങ്ങനെ ഒരു സ്പാർസ് റെക്കമൻ്റേഷൻ സാധാരണയായി ശുപാർശ ചെയ്യുന്നു.ഒരു ``interpret`` ഫംഗ്ഷന്റെ കാര്യത്തിൽ അത് പ്രതീക്ഷിച്ച ഫലത്തെ ആശ്രയിച്ചിരിക്കുന്നു. ഉദാഹരണത്തിന്, ഒരു സൂചിക അനുബന്ധ ബിറ്റ്സ്ട്രിംഗിന്റെ തുല്യതയിലേക്ക് മാപ്പുചയ്തിട്ടുണ്ടെങ്കിൽ, അതായത്, 0 അല്ലെങ്കിൽ 1 ലേക്ക്, ഡെൻസ് ഔട്ട്‌പുട്ട് അർത്ഥമാക്കുന്നു, ഫലം 2 ദൈർഘ്യമുള്ള പ്രോബബിലിറ്റി വെക്ടറായിരുക്കും."

#: ../../tutorials/01_neural_networks.ipynb:657
msgid "4.1 Output: sparse integer probabilities"
msgstr "4.1 ഔട്ട്‌പുട്ട്: സ്പാർസ് സംഖ്യാ പ്രോബബിലിറ്റികൾ"

#: ../../tutorials/01_neural_networks.ipynb:754
msgid "4.2 Output: dense parity probabilities"
msgstr "4.2 ഔട്ട്‌പുട്ട്: ഡെൻസ് പാരിറ്റി പ്രോബബിലിറ്റികൾ"

#: ../../tutorials/01_neural_networks.ipynb:865
msgid "4.3 Output: Samples"
msgstr "4.3 ഔട്ട്‌പുട്ട്: സാമ്പിളുകൾ"

#: ../../tutorials/01_neural_networks.ipynb:980
msgid "4.4 Output: Parity Samples"
msgstr "4.4 ഔട്ട്‌പുട്ട്: പാരിറ്റി സാമ്പിളുകൾ"

