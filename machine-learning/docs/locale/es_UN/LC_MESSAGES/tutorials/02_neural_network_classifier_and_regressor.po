msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-02-07 03:44+0000\n"
"PO-Revision-Date: 2023-03-06 16:50\n"
"Last-Translator: \n"
"Language: es_UN\n"
"Language-Team: Spanish (United)\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: es-un\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/02_neural_network_classifier_and_regressor.po\n"
"X-Crowdin-File-ID: 9630\n"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:9
msgid "This page was generated from `docs/tutorials/02_neural_network_classifier_and_regressor.ipynb`__."
msgstr "Esta página fue generada a partir de `docs/tutorials/02_neural_network_classifier_and_regressor.ipynb`__."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:9
msgid "Neural Network Classifier & Regressor"
msgstr "Redes Neuronales de Clasificación y Regresión"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:11
msgid "In this tutorial we show how the ``NeuralNetworkClassifier`` and ``NeuralNetworkRegressor`` are used. Both take as an input a (Quantum) ``NeuralNetwork`` and leverage it in a specific context. In both cases we also provide a pre-configured variant for convenience, the Variational Quantum Classifier (``VQC``) and Variational Quantum Regressor (``VQR``). The tutorial is structured as follows:"
msgstr "En este tutorial mostramos cómo se utiliza la ``NeuralNetworkClassifier`` y la ``NeuralNetworkRegressor``. Ambas toman como entrada una ``NeuralNetwork`` (Cuántica) y la aprovechan en un contexto específico. En ambos casos, también ofrecemos una variante preconfigurada para mayor comodidad, el Clasificador Cuántico Variacional (Variational Quantum Classifier, ``VQC``) y el Regresor Cuántico Variacional (Variational Quantum Regressor, ``VQR``). El tutorial está estructurado de la siguiente manera:"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:13
msgid "`Classification <#Classification>`__"
msgstr "`Clasificación <#Classification>`__"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:15
msgid "Classification with an ``EstimatorQNN``"
msgstr "Clasificación con una ``EstimatorQNN``"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:16
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:380
msgid "Classification with a ``SamplerQNN``"
msgstr "Clasificación con una ``SamplerQNN``"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:17
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:600
msgid "Variational Quantum Classifier (``VQC``)"
msgstr "Clasificador Cuántico Variacional (Variational Quantum Classifier, ``VQC``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:19
msgid "`Regression <#Regression>`__"
msgstr "`Regresión <#Regression>`__"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:21
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1048
msgid "Regression with an ``EstimatorQNN``"
msgstr "Regresión con una ``EstimatorQNN``"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:22
msgid "Variational Quantum Regressor (``VQR``)"
msgstr "Regresor Cuántico Variacional (Variational Quantum Regressor, ``VQR``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:57
msgid "Classification"
msgstr "Clasificación"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:59
msgid "We prepare a simple classification dataset to illustrate the following algorithms."
msgstr "Preparamos un conjunto de datos de clasificación simple para ilustrar los siguientes algoritmos."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:104
msgid "Classification with the an ``EstimatorQNN``"
msgstr "Clasificación con una ``EstimatorQNN``"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:106
msgid "First we show how an ``EstimatorQNN`` can be used for classification within a ``NeuralNetworkClassifier``. In this context, the ``EstimatorQNN`` is expected to return one-dimensional output in :math:`[-1, +1]`. This only works for binary classification and we assign the two classes to :math:`\\{-1, +1\\}`."
msgstr "Primero mostramos cómo se puede usar una ``EstimatorQNN`` para la clasificación dentro de un ``NeuralNetworkClassifier``. En este contexto, se espera que ``EstimatorQNN`` devuelva una salida unidimensional en :math:`[-1, +1]`. Esto solo funciona para la clasificación binaria y asignamos las dos clases a :math:`\\{-1, +1\\}`."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:142
msgid "Create a quantum neural network"
msgstr "Crear una red neuronal cuántica"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:201
msgid "We will add a callback function called ``callback_graph``. This will be called for each iteration of the optimizer and will be passed two parameters: the current weights and the value of the objective function at those weights. For our function, we append the value of the objective function to an array so we can plot iteration versus objective function value and update the graph with each iteration. However, you can do whatever you want with a callback function as long as it gets the two parameters mentioned passed."
msgstr "Agregaremos una función de devolución de llamada nombrada ``callback_graph``. Esto se llamará para cada iteración del optimizador y se le pasarán dos parámetros: los pesos actuales y el valor de la función objetivo en esos pesos. Para nuestra función, agregamos el valor de la función objetivo a un arreglo para que podamos graficar la iteración frente al valor de la función objetivo y actualizar la gráfica con cada iteración. Sin embargo, puedes hacer lo que desees con una función de devolución de llamada siempre y cuando se pasen los dos parámetros mencionados."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:330
msgid "Now, when the model is trained, we can explore the weights of the neural network. Please note, the number of weights is defined by ansatz."
msgstr "Ahora, cuando el modelo está entrenado, podemos explorar los pesos de la red neuronal. Ten en cuenta que el número de pesos está definido por el ansatz."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:382
msgid "Next we show how a ``SamplerQNN`` can be used for classification within a ``NeuralNetworkClassifier``. In this context, the ``SamplerQNN`` is expected to return :math:`d`-dimensional probability vector as output, where :math:`d` denotes the number of classes. The underlying ``Sampler`` primitive returns quasi-distributions of bit strings and we just need to define a mapping from the measured bitstrings to the different classes. For binary classification we use the parity mapping."
msgstr "A continuación mostramos cómo se puede usar una ``SamplerQNN`` para la clasificación dentro de un ``NeuralNetworkClassifier``. En este contexto, se espera que ``SamplerQNN`` devuelva un vector de probabilidad de dimensión :math:`d` como salida, donde :math:`d` denota el número de clases. La primitiva ``Sampler`` subyacente devuelve cuasi-distribuciones de cadenas de bits y solo necesitamos definir un mapeo de las cadenas de bits medidas a las diferentes clases. Para la clasificación binaria usamos el mapeo de paridad."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:553
msgid "Again, once the model is trained we can take a look at the weights. As we set ``reps=1`` explicitly in our ansatz, we can see less parameters than in the previous model."
msgstr "Nuevamente, una vez que el modelo está entrenado, podemos echar un vistazo a los pesos. Como configuramos explícitamente ``reps=1`` en nuestro ansatz, podemos ver menos parámetros que en el modelo anterior."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:602
msgid "The ``VQC`` is a special variant of the ``NeuralNetworkClassifier`` with a ``SamplerQNN``. It applies a parity mapping (or extensions to multiple classes) to map from the bitstring to the classification, which results in a probability vector, which is interpreted as a one-hot encoded result. By default, it applies this the ``CrossEntropyLoss`` function that expects labels given in one-hot encoded format and will return predictions in that format too."
msgstr "El ``VQC`` es una variante especial del ``NeuralNetworkClassifier`` con una ``SamplerQNN``. Aplica un mapeo de paridad (o extensiones a varias clases) para mapear desde la cadena de bits hasta la clasificación, lo que da como resultado un vector de probabilidad, que se interpreta como un resultado codificado con one-hot. Por defecto, aplica esta función ``CrossEntropyLoss`` que espera etiquetas dadas en el formato codificado con one-hot y devolverá predicciones en ese formato también."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:721
msgid "Multiple classes with VQC"
msgstr "Clases múltiples con VQC"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:723
msgid "In this section we generate an artificial dataset that contains samples of three classes and show how to train a model to classify this dataset. This example shows how to tackle more interesting problems in machine learning. Of course, for a sake of short training time we prepare a tiny dataset. We employ ``make_classification`` from SciKit-Learn to generate a dataset. There 10 samples in the dataset, 2 features, that means we can still have a nice plot of the dataset, as well as no redundant features, these are features are generated as a combinations of the other features. Also, we have 3 different classes in the dataset, each classes one kind of centroid and we set class separation to ``2.0``, a slight increase from the default value of ``1.0`` to ease the classification problem."
msgstr "En esta sección generamos un conjunto de datos artificial que contiene muestras de tres clases y mostramos cómo entrenar un modelo para clasificar este conjunto de datos. Este ejemplo muestra cómo abordar problemas más interesantes en el machine learning. Por supuesto, en aras del corto tiempo de entrenamiento, preparamos un pequeño conjunto de datos. Empleamos ``make_classification`` de SciKit-Learn para generar un conjunto de datos. Hay 10 muestras en el conjunto de datos, con 2 características, lo que significa que todavía podemos tener una buena gráfica del conjunto de datos, así como características redundantes, estas características se generan como una combinación de las otras. Además, tenemos 3 clases diferentes en el conjunto de datos, cada clase tiene un tipo de centroide y establecemos la separación de clases en ``2.0``, un ligero aumento del valor predeterminado de ``1.0`` para facilitar el problema de clasificación."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:726
msgid "Once the dataset is generated we scale the features into the range ``[0, 1]``."
msgstr "Una vez que el conjunto de datos es generado, escalamos las características en el rango ``[0, 1]``."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:759
msgid "Let’s see how our dataset looks like."
msgstr "Veamos cómo se ve nuestro conjunto de datos."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:814
msgid "We also transform labels and make them categorical."
msgstr "También transformamos las etiquetas y las convertimos en categóricas."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:863
msgid "We create an instance of ``VQC`` similar to the previous example, but in this case we pass a minimal set of parameters. Instead of feature map and ansatz we pass just the number of qubits that is equal to the number of features in the dataset, an optimizer with a low number of iteration to reduce training time, a quantum instance, and a callback to observe progress."
msgstr "Creamos una instancia de ``VQC`` similar al ejemplo anterior, pero en este caso pasamos un conjunto mínimo de parámetros. En lugar de un mapa de características y un ansatz, pasamos solo la cantidad de qubits que es igual a la cantidad de características en el conjunto de datos, un optimizador con un bajo número de iteraciones para reducir el tiempo de entrenamiento, una instancia cuántica (quantum instance) y una devolución de llamada (callback) para observar el progreso."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:888
msgid "Start the training process in the same way as in previous examples."
msgstr "Inicia el proceso de entrenamiento de la misma forma que en los ejemplos anteriores."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:954
msgid "Despite we had the low number of iterations, we achieved quite a good score. Let see the output of the ``predict`` method and compare the output with the ground truth."
msgstr "A pesar de que tuvimos el bajo número de iteraciones, logramos una puntuación bastante buena. Veamos el resultado del método ``predict`` y comparemos el resultado con la verdad fundamental."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1005
msgid "Regression"
msgstr "Regresión"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1007
msgid "We prepare a simple regression dataset to illustrate the following algorithms."
msgstr "Preparamos un conjunto de datos de regresión simple para ilustrar los siguientes algoritmos."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1050
msgid "Here we restrict to regression with an ``EstimatorQNN`` that returns values in :math:`[-1, +1]`. More complex and also multi-dimensional models could be constructed, also based on ``SamplerQNN`` but that exceeds the scope of this tutorial."
msgstr "Aquí restringimos la regresión con una ``EstimatorQNN`` que devuelve valores entre :math:`[-1, +1]`. Se podrían construir modelos más complejos y también multidimensionales, así como basados en ``SamplerQNN``, pero eso excede el alcance de este tutorial."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1187
msgid "Similarly to the classification models, we can obtain an array of trained weights by querying a corresponding property of the model. In this model we have only one parameter defined as ``param_y`` above."
msgstr "De manera similar a los modelos de clasificación, podemos obtener una matriz de pesos entrenados consultando una propiedad correspondiente del modelo. En este modelo solo tenemos un parámetro arriba definido como ``param_y``."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1234
msgid "Regression with the Variational Quantum Regressor (``VQR``)"
msgstr "Regresión con el Regresor Cuántico Variacional (Variational Quantum Regressor, ``VQR``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1236
msgid "Similar to the ``VQC`` for classification, the ``VQR`` is a special variant of the ``NeuralNetworkRegressor`` with a ``EstimatorQNN``. By default it considers the ``L2Loss`` function to minimize the mean squared error between predictions and targets."
msgstr "Similar al ``VQC`` para la clasificación, el ``VQR`` es una variante especial del ``NeuralNetworkRegressor`` con una ``EstimatorQNN``. De forma predeterminada, considera la función ``L2Loss`` para minimizar el error cuadrático medio entre las predicciones y los objetivos."

