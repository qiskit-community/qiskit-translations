msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-03-28 08:39+0000\n"
"PO-Revision-Date: 2023-03-28 10:56\n"
"Last-Translator: \n"
"Language: es_UN\n"
"Language-Team: Spanish (United)\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: es-un\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/01_neural_networks.po\n"
"X-Crowdin-File-ID: 9628\n"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/01_neural_networks.ipynb`__."
msgstr "Esta página fue generada a partir de `docs/tutorials/01_neural_networks.ipynb`__."

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "Redes Neuronales Cuánticas"

#: ../../tutorials/01_neural_networks.ipynb:12
msgid "Overview"
msgstr "Descripción General"

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "This notebook demonstrates different quantum neural network (QNN) implementations provided in ``qiskit-machine-learning``, and how they can be integrated into basic quantum machine learning (QML) workflows."
msgstr "Este cuaderno muestra diferentes implementaciones de redes neuronales cuánticas (quantum neural network, QNN) proporcionadas en ``qiskit-machine-learning``, y cómo se pueden integrar en flujos de trabajo básicos de machine learning cuántico (quantum machine learning, QML)."

#: ../../tutorials/01_neural_networks.ipynb:16
msgid "The tutorial is structured as follows:"
msgstr "El tutorial está estructurado de la siguiente manera:"

#: ../../tutorials/01_neural_networks.ipynb:18
msgid "`Introduction <#1.-Introduction>`__"
msgstr "`Introducción <#1.-Introducción>`__"

#: ../../tutorials/01_neural_networks.ipynb:19
msgid "`How to Instantiate QNNs <#2.-How-to-Instantiate-QNNs>`__"
msgstr "`Cómo Instanciar QNNs <#2.-Cómo-Instanciar-QNNs>`__"

#: ../../tutorials/01_neural_networks.ipynb:20
msgid "`How to Run a Forward Pass <#3.-How-to-Run-a-Forward-Pass>`__"
msgstr "`Cómo Ejecutar un Paso hacia Adelante <#3.-Cómo-Ejecutar-un-Paso-hacia-Adelante>`__"

#: ../../tutorials/01_neural_networks.ipynb:21
msgid "`How to Run a Backward Pass <#4.-How-to-Run-a-Backward-Pass>`__"
msgstr "`Cómo Ejecutar un Paso hacia Atrás <#4.-Cómo-Ejecutar-un-Paso-hacia-Atrás>`__"

#: ../../tutorials/01_neural_networks.ipynb:22
msgid "`Advanced Functionality <#5.-Advanced-Functionality>`__"
msgstr "`Funcionalidad Avanzada <#5.-Funcionalidad-Avanzada>`__"

#: ../../tutorials/01_neural_networks.ipynb:23
msgid "`Conclusion <#6.-Conclusion>`__"
msgstr "`Conclusión <#6.-Conclusión>`__"

#: ../../tutorials/01_neural_networks.ipynb:35
msgid "1. Introduction"
msgstr "1. Introducción"

#: ../../tutorials/01_neural_networks.ipynb:38
msgid "1.1. Quantum vs. Classical Neural Networks"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:40
msgid "Classical neural networks are algorithmic models inspired by the human brain that can be trained to recognize patterns in data and learn to solve complex problems. They are based on a series of interconnected nodes, or *neurons*, organized in a layered structure, with parameters that can be learned by applying machine or deep learning training strategies."
msgstr "Las redes neuronales clásicas son modelos algorítmicos inspirados en el cerebro humano que se pueden entrenar para reconocer patrones en los datos y aprender a resolver problemas complejos. Se basan en una serie de nodos interconectados, o *neuronas*, organizados en una estructura en capas, con parámetros que se pueden aprender aplicando estrategias de entrenamiento de machine learning o deep learning."

#: ../../tutorials/01_neural_networks.ipynb:42
msgid "The motivation behind quantum machine learning (QML) is to integrate notions from quantum computing and classical machine learning to open the way for new and improved learning schemes. QNNs apply this generic principle by combining classical neural networks and parametrized quantum circuits. Because they lie at an intersection between two fields, QNNs can be viewed from two perspectives:"
msgstr "La motivación detrás del machine learning cuántico (QML) es integrar nociones de computación cuántica y de machine learning clásico para abrir el camino a esquemas de aprendizaje nuevos y mejorados. Las QNNs aplican este principio genérico al combinar redes neuronales clásicas y circuitos cuánticos parametrizados. Debido a que se encuentran en una intersección entre dos campos, las QNNs se pueden ver desde dos perspectivas:"

#: ../../tutorials/01_neural_networks.ipynb:44
msgid "From a **machine learning perspective**, QNNs are, once again, algorithmic models that can be trained to find hidden patterns in data in a similar manner to their classical counterparts. These models can **load** classical data (**inputs**) into a quantum state, and later **process** it with quantum gates parametrized by **trainable weights**. Figure 1 shows a generic QNN example including the data loading and processing steps. The output from measuring this state can then be plugged into a loss function to train the weights through backpropagation."
msgstr "Desde una **perspectiva de machine learning**, las QNNs son, una vez más, modelos algorítmicos que se pueden entrenar para encontrar patrones ocultos en los datos de manera similar a sus contrapartes clásicas. Estos modelos pueden **cargar** datos clásicos (**entradas**) en un estado cuántico, y luego **procesarlos** con compuertas cuánticas parametrizadas por **pesos entrenables**. La Figura 1 muestra un ejemplo genérico de QNN que incluye los pasos de carga y procesamiento de datos. La salida de la medición de este estado se puede conectar a una función de pérdida para entrenar los pesos (ponderaciones) a través de la retropropagación."

#: ../../tutorials/01_neural_networks.ipynb:47
msgid "From a **quantum computing perspective**, QNNs are quantum algorithms based on parametrized quantum circuits that can be trained in a variational manner using classical optimizers. These circuits contain a **feature map** (with input parameters) and an **ansatz** (with trainable weights), as seen in Figure 1."
msgstr "Desde la **perspectiva de la computación cuántica**, las QNNs son algoritmos cuánticos basados en circuitos cuánticos parametrizados que se pueden entrenar de forma variacional utilizando optimizadores clásicos. Estos circuitos contienen un **mapa de características** (con parámetros de entrada) y un **ansatz** (con pesos entrenables), como se ve en la Figura 1."

#: ../../tutorials/01_neural_networks.ipynb:49
msgid "|new_qnn-3.jpg|"
msgstr "|new_qnn-3.jpg|"

#: ../../tutorials/01_neural_networks.ipynb:53
msgid "new_qnn-3.jpg"
msgstr "new_qnn-3.jpg"

#: ../../tutorials/01_neural_networks.ipynb:51
msgid "*Figure 1. Generic quantum neural network (QNN) structure.*"
msgstr "*Figura 1. Estructura genérica de una red neuronal cuántica (QNN).*"

#: ../../tutorials/01_neural_networks.ipynb:64
msgid "As you can see, these two perspectives are complementary, and do not necessarily rely on strict definitions of concepts such as \"quantum neuron\" or what constitutes a QNN's \"layer\"."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:67
msgid "1.2. Implementation in ``qiskit-machine-learning``"
msgstr "1.2. Implementación en ``qiskit-machine-learning``"

#: ../../tutorials/01_neural_networks.ipynb:69
msgid "The QNNs in ``qiskit-machine-learning`` are meant as application-agnostic computational units that can be used for different use cases, and their setup will depend on the application they are needed for. The module contains an interface for the QNNs and two specific implementations:"
msgstr "Las QNNs en ``qiskit-machine-learning`` están pensadas como unidades computacionales independientes de la aplicación en las que se pueden usar para diferentes casos de uso, y su configuración dependerá de la aplicación para la que se necesiten. El módulo contiene una interfaz para las QNNs y dos implementaciones específicas:"

#: ../../tutorials/01_neural_networks.ipynb:71
msgid "`NeuralNetwork <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.NeuralNetwork.html>`__: The interface for neural networks. This is an abstract class all QNNs inherit from."
msgstr "`NeuralNetwork <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.NeuralNetwork.html>`__: La interfaz para redes neuronales. Esta es una clase abstracta de la que heredan todas las QNN."

#: ../../tutorials/01_neural_networks.ipynb:72
msgid "`EstimatorQNN <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.EstimatorQNN.html>`__: A network based on the evaluation of quantum mechanical observables."
msgstr "`EstimatorQNN <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.EstimatorQNN.html>`__: Una red basada en la evaluación de observables mecánicos cuánticos."

#: ../../tutorials/01_neural_networks.ipynb:73
msgid "`SamplerQNN <https://qiskit.org/documentation/machine-learning/locale/fr_FR/stubs/qiskit_machine_learning.neural_networks.SamplerQNN.html>`__: A network based on the samples resulting from measuring a quantum circuit."
msgstr "`SamplerQNN <https://qiskit.org/documentation/machine-learning/locale/fr_FR/stubs/qiskit_machine_learning.neural_networks.SamplerQNN.html>`__: Una red basada en las muestras resultantes de medir un circuito cuántico."

#: ../../tutorials/01_neural_networks.ipynb:75
msgid "These implementations are based on the `qiskit primitives <https://qiskit.org/documentation/apidoc/primitives.html>`__. The primitives are the entry point to run QNNs on either a simulator or real quantum hardware. Each implementation, ``EstimatorQNN`` and ``SamplerQNN``, takes in an optional instance of its corresponding primitive, which can be any subclass of ``BaseEstimator`` and ``BaseSampler``, respectively."
msgstr "Estas implementaciones se basan en las `primitivas de qiskit <https://qiskit.org/documentation/apidoc/primitives.html>`__. Las primitivas son el punto de entrada para ejecutar QNNs en un simulador o en hardware cuántico real. Cada implementación, ``EstimatorQNN`` y ``SamplerQNN``, toma una instancia opcional de su primitiva correspondiente, que puede ser cualquier subclase de ``BaseEstimator`` y ``BaseSampler``, respectivamente."

#: ../../tutorials/01_neural_networks.ipynb:77
msgid "The ``qiskit.primitives`` module provides a reference implementation for the ``Sampler`` and ``Estimator`` classes to run statevector simulations. By default, if no instance is passed to a QNN class, an instance of the corresponding reference primitive (``Sampler`` or ``Estimator``) is created automatically by the network. For more information about primitives please refer to the `primitives documentation <https://qiskit.org/documentation/apidoc/primitives.html>`__."
msgstr "El módulo ``qiskit.primitives`` proporciona una implementación de referencia para las clases ``Sampler`` y ``Estimator`` para ejecutar simulaciones de vectores de estado. De forma predeterminada, si no se pasa ninguna instancia a una clase QNN, la red crea automáticamente una instancia de la primitiva de referencia correspondiente (``Sampler`` o ``Estimator``). Para obtener más información sobre las primitivas, consulta la `documentación de las primitivas <https://qiskit.org/documentation/apidoc/primitives.html>`__."

#: ../../tutorials/01_neural_networks.ipynb:79
msgid "The ``NeuralNetwork`` class is the interface for all QNNs available in ``qiskit-machine-learning``. It exposes a forward and a backward pass that take data samples and trainable weights as input."
msgstr "La clase ``NeuralNetwork`` es la interfaz para todas las QNNs disponibles en ``qiskit-machine-learning``. Expone un paso hacia adelante y hacia atrás que toman muestras de datos y pesos entrenables como entrada."

#: ../../tutorials/01_neural_networks.ipynb:81
msgid "It's important to note that ``NeuralNetwork``\\ s are \"stateless\". They do not contain any training capabilities (these are pushed to the actual algorithms or applications: `classifiers <https://qiskit.org/documentation/machine-learning/apidocs/qiskit_machine_learning.algorithms.html#classifiers>`__, `regressors <https://qiskit.org/documentation/machine-learning/apidocs/qiskit_machine_learning.algorithms.html#regressors>`__, etc), nor do they store the values for trainable weights."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:94
msgid "Let's now look into specific examples for the two ``NeuralNetwork`` implementations. But first, let's set the algorithmic seed to ensure that the results don't change between runs."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:118
msgid "2. How to Instantiate QNNs"
msgstr "2. Cómo Instanciar QNNs"

#: ../../tutorials/01_neural_networks.ipynb:121
msgid "2.1. ``EstimatorQNN``"
msgstr "2.1. ``EstimatorQNN``"

#: ../../tutorials/01_neural_networks.ipynb:123
msgid "The ``EstimatorQNN`` takes in a parametrized quantum circuit as input, as well as an optional quantum mechanical observable, and outputs expectation value computations for the forward pass. The ``EstimatorQNN`` also accepts lists of observables to construct more complex QNNs."
msgstr "La ``EstimatorQNN`` toma como entrada un circuito cuántico parametrizado, así como un observable mecánico cuántico opcional, y genera cálculos de valor esperado para el paso hacia adelante. La ``EstimatorQNN`` también acepta listas de observables para construir QNNs más complejas."

#: ../../tutorials/01_neural_networks.ipynb:125
msgid "Let's see an ``EstimatorQNN`` in action with a simple example. We start by constructing the parametrized circuit. This quantum circuit has two parameters, one represents a QNN input and the other represents a trainable weight:"
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:163
msgid "We can now create an observable to define the expectation value computation. If not set, then the ``EstimatorQNN`` will automatically create the default observable :math:`Z^{\\otimes n}`. Here, :math:`n` is the number of qubits of the quantum circuit."
msgstr "Ahora podemos crear un observable para definir el cálculo del valor esperado. Si no se establece, ``EstimatorQNN`` creará automáticamente el observable predeterminado :math:`Z^{\\otimes n}`. Aquí, :math:`n` es el número de qubits del circuito cuántico."

#: ../../tutorials/01_neural_networks.ipynb:165
msgid "In this example, we will change things up and use the :math:`Y^{\\otimes n}` observable:"
msgstr "En este ejemplo, cambiaremos las cosas y usaremos el observable :math:`Y^{\\otimes n}`:"

#: ../../tutorials/01_neural_networks.ipynb:188
msgid "Together with the quantum circuit defined above, and the observable we have created, the ``EstimatorQNN`` constructor takes in the following keyword arguments:"
msgstr "Junto con el circuito cuántico definido anteriormente y el observable que hemos creado, el constructor de ``EstimatorQNN`` toma los siguientes argumentos de palabras clave:"

#: ../../tutorials/01_neural_networks.ipynb:190
msgid "``estimator``: optional primitive instance"
msgstr "``estimator``: instancia primitiva opcional"

#: ../../tutorials/01_neural_networks.ipynb:191
msgid "``input_params``: list of quantum circuit parameters that should be treated as \"network inputs\""
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:192
msgid "``weight_params``: list of quantum circuit parameters that should be treated as \"network weights\""
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:194
msgid "In this example, we previously decided that the first parameter of ``params1`` should be the input, while the second should be the weight. As we are performing a local statevector simulation, we will not set the ``estimator`` parameter; the network will create an instance of the reference ``Estimator`` primitive for us. If we needed to access cloud resources or ``Aer`` simulators, we would have to define the respective ``Estimator`` instances and pass them to the ``EstimatorQNN``."
msgstr "En este ejemplo, previamente decidimos que el primer parámetro de ``params1`` debería ser la entrada, mientras que el segundo debería ser el peso. Como estamos realizando una simulación de vector de estado local, no estableceremos el parámetro ``estimator``; la red creará una instancia de la primitiva ``Estimator`` de referencia para nosotros. Si necesitáramos acceder a recursos en la nube o simuladores ``Aer``, tendríamos que definir las respectivas instancias de ``Estimator`` y pasarlas al ``EstimatorQNN``."

#: ../../tutorials/01_neural_networks.ipynb:245
msgid "We'll see how to use the QNN in the following sections, but before that, let's check out the ``SamplerQNN`` class."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:257
msgid "2.2. ``SamplerQNN``"
msgstr "2.2. ``SamplerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:259
msgid "The ``SamplerQNN`` is instantiated in a similar way to the ``EstimatorQNN``, but because it directly consumes samples from measuring the quantum circuit, it does not require a custom observable."
msgstr "La ``SamplerQNN`` se instancia de manera similar a la ``EstimatorQNN``, pero debido a que consume muestras directamente al medir el circuito cuántico, no requiere un observable personalizado."

#: ../../tutorials/01_neural_networks.ipynb:261
msgid "These output samples are interpreted by default as the probabilities of measuring the integer index corresponding to a bitstring. However, the ``SamplerQNN`` also allows us to specify an ``interpret`` function to post-process the samples. This function should be defined so that it takes a measured integer (from a bitstring) and maps it to a new value, i.e. non-negative integer."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:263
msgid "**(!)** It's important to note that if a custom ``interpret`` function is defined, the ``output_shape`` cannot be inferred by the network, and **needs to be provided explicitly**."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:265
msgid "**(!)** It's also important to keep in mind that if no ``interpret`` function is used, the dimension of the probability vector will scale exponentially with the number of qubits. With a custom ``interpret`` function, this scaling can change. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, the result will be a probability vector of length 2 independently of the number of qubits."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:276
msgid "Let's create a different quantum circuit for the ``SamplerQNN``. In this case, we will have two input parameters and four trainable weights that parametrize a two-local circuit."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:351
msgid "Similarly to the ``EstimatorQNN``, we must specify inputs and weights when instantiating the ``SamplerQNN``. In this case, the keyword arguments will be: - ``sampler``: optional primitive instance - ``input_params``: list of quantum circuit parameters that should be treated as \"network inputs\" - ``weight_params``: list of quantum circuit parameters that should be treated as \"network weights\""
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:353
msgid "Please note that, once again, we are choosing not to set the ``Sampler`` instance to the QNN and relying on the default."
msgstr "Ten en cuenta que, una vez más, estamos eligiendo no configurar la instancia de ``Sampler`` en la QNN y confiando en el valor predeterminado."

#: ../../tutorials/01_neural_networks.ipynb:402
msgid "In addition to the basic arguments shown above, the ``SamplerQNN`` accepts three more settings: ``input_gradients``, ``interpret``, and ``output_shape``. These will be introduced in sections 4 and 5."
msgstr "Además de los argumentos básicos que se muestran arriba, la ``SamplerQNN`` acepta tres configuraciones más: ``input_gradients``, ``interpret``, y ``output_shape``. Estos se introducirán en las secciones 4 y 5."

#: ../../tutorials/01_neural_networks.ipynb:414
msgid "3. How to Run a Forward Pass"
msgstr "3. Cómo Ejecutar un Paso hacia Adelante"

#: ../../tutorials/01_neural_networks.ipynb:426
msgid "3.1. Set-Up"
msgstr "3.1. Configuración"

#: ../../tutorials/01_neural_networks.ipynb:428
msgid "In a real setting, the inputs would be defined by the dataset, and the weights would be defined by the training algorithm or as part of a pre-trained model. However, for the sake of this tutorial, we will specify random sets of input and weights of the right dimension:"
msgstr "En un entorno real, las entradas estarían definidas por el conjunto de datos y los pesos estarían definidos por el algoritmo de entrenamiento o como parte de un modelo preentrenado. Sin embargo, por el bien de este tutorial, especificaremos conjuntos aleatorios de entrada y pesos de la dimensión correcta:"

#: ../../tutorials/01_neural_networks.ipynb:440
msgid "3.1.1. ``EstimatorQNN`` Example"
msgstr "3.1.1. Ejemplo de ``EstimatorQNN``"

#: ../../tutorials/01_neural_networks.ipynb:511
msgid "3.1.2. ``SamplerQNN`` Example"
msgstr "3.1.2. Ejemplo de ``SamplerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:581
msgid "Once we have the inputs and the weights, let's see the results for batched and non-batched passes."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:593
msgid "3.2. Non-batched Forward Pass"
msgstr "3.2. Paso hacia Adelante Sin Lotes"

#: ../../tutorials/01_neural_networks.ipynb:605
msgid "3.2.1. ``EstimatorQNN`` Example"
msgstr "3.2.1. Ejemplo de ``EstimatorQNN``"

#: ../../tutorials/01_neural_networks.ipynb:616
msgid "For the ``EstimatorQNN``, the expected output shape for the forward pass is ``(1, num_qubits * num_observables)`` where ``1`` in our case is the number of samples:"
msgstr "Para la ``EstimatorQNN``, la forma de salida esperada para el paso hacia adelante es ``(1, num_qubits * num_observables)`` donde ``1`` en nuestro caso es el número de muestras:"

#: ../../tutorials/01_neural_networks.ipynb:669
msgid "3.2.2. ``SamplerQNN`` Example"
msgstr "3.2.2. Ejemplo de ``SamplerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:680
msgid "For the ``SamplerQNN`` (without a custom interpret function), the expected output shape for the forward pass is ``(1, 2**num_qubits)``. With a custom interpret function, the output shape will be ``(1, output_shape)``, where ``1`` in our case is the number of samples:"
msgstr "Para la ``SamplerQNN`` (sin una función de interpretación personalizada), la forma de salida esperada para el paso hacia adelante es ``(1, 2**num_qubits)``. Con una función de interpretación personalizada, la forma de salida será ``(1, output_shape)``, donde ``1`` en nuestro caso es el número de muestras:"

#: ../../tutorials/01_neural_networks.ipynb:733
msgid "3.3. Batched Forward Pass"
msgstr "3.3. Paso hacia Adelante Con Lotes"

#: ../../tutorials/01_neural_networks.ipynb:745
msgid "3.3.1. ``EstimatorQNN`` Example"
msgstr "3.3.1. Ejemplo de ``EstimatorQNN``"

#: ../../tutorials/01_neural_networks.ipynb:756
msgid "For the ``EstimatorQNN``, the expected output shape for the forward pass is ``(batch_size, num_qubits * num_observables)``:"
msgstr "Para el ``EstimatorQNN``, la forma de salida esperada para el paso hacia adelante es ``(batch_size, num_qubits * num_observables)``:"

#: ../../tutorials/01_neural_networks.ipynb:814
msgid "3.3.2. ``SamplerQNN`` Example"
msgstr "3.3.2. Ejemplo de ``SamplerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:825
msgid "For the ``SamplerQNN`` (without custom interpret function), the expected output shape for the forward pass is ``(batch_size, 2**num_qubits)``. With a custom interpret function, the output shape will be ``(batch_size, output_shape)``."
msgstr "Para la ``SamplerQNN`` (sin la función de interpretación personalizada), la forma de salida esperada para el paso hacia adelante es ``(batch_size, 2**num_qubits)``. Con una función de interpretación personalizada, la forma de salida será ``(batch_size, output_shape)``."

#: ../../tutorials/01_neural_networks.ipynb:883
msgid "4. How to Run a Backward Pass"
msgstr "4. Cómo Ejecutar un Paso hacia Atrás"

#: ../../tutorials/01_neural_networks.ipynb:885
msgid "Let's take advantage of the inputs and weights defined above to show how the backward pass works. This pass returns a tuple ``(input_gradients, weight_gradients)``. By default, the backward pass will only calculate gradients with respect to the weight parameters."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:887
msgid "If you want to enable gradients with respect to the input parameters, you should set the following flag during the QNN instantiation:"
msgstr "Si deseas habilitar gradientes con respecto a los parámetros de entrada, debes configurar el siguiente indicador durante la instanciación de la QNN:"

#: ../../tutorials/01_neural_networks.ipynb:893
msgid "Please remember that input gradients are **required** for the use of ``TorchConnector`` for PyTorch integration."
msgstr "Recuerda que los gradientes de entrada son **requeridos** para el uso de ``TorchConnector`` para la integración de PyTorch."

#: ../../tutorials/01_neural_networks.ipynb:905
msgid "4.1. Backward Pass without Input Gradients"
msgstr "4.1. Paso hacia Atrás sin Gradientes de Entrada"

#: ../../tutorials/01_neural_networks.ipynb:917
msgid "4.1.1. ``EstimatorQNN`` Example"
msgstr "4.1.1. Ejemplo de ``EstimatorQNN``"

#: ../../tutorials/01_neural_networks.ipynb:928
msgid "For the ``EstimatorQNN``, the expected output shape for the weight gradients is ``(batch_size, num_qubits * num_observables, num_weights)``:"
msgstr "Para ``EstimatorQNN``, la forma de salida esperada para los gradientes de peso es ``(batch_size, num_qubits * num_observables, num_weights)``:"

#: ../../tutorials/01_neural_networks.ipynb:992
msgid "4.1.2. ``SamplerQNN`` Example"
msgstr "4.1.2. Ejemplo de ``SamplerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:1003
msgid "For the ``SamplerQNN`` (without custom interpret function), the expected output shape for the forward pass is ``(batch_size, 2**num_qubits, num_weights)``. With a custom interpret function, the output shape will be ``(batch_size, output_shape, num_weights)``.:"
msgstr "Para la ``SamplerQNN`` (sin la función de interpretación personalizada), la forma de salida esperada para el paso hacia adelante es ``(batch_size, 2**num_qubits, num_weights)``. Con una función de interpretación personalizada, la forma de salida será ``(batch_size, output_shape, num_weights)``.:"

#: ../../tutorials/01_neural_networks.ipynb:1076
msgid "4.2. Backward Pass with Input Gradients"
msgstr "4.2. Paso hacia Atrás con Gradientes de Entrada"

#: ../../tutorials/01_neural_networks.ipynb:1078
msgid "Let's enable the ``input_gradients`` to show what the expected output sizes are for this option."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:1101
msgid "4.2.1. ``EstimatorQNN`` Example"
msgstr "4.2.1. Ejemplo de ``EstimatorQNN``"

#: ../../tutorials/01_neural_networks.ipynb:1112
msgid "For the ``EstimatorQNN``, the expected output shape for the input gradients is ``(batch_size, num_qubits * num_observables, num_inputs)``:"
msgstr "Para la ``EstimatorQNN``, la forma de salida esperada para los gradientes de entrada es ```(batch_size, num_qubits * num_observables, num_inputs)``:"

#: ../../tutorials/01_neural_networks.ipynb:1176
msgid "4.2.2. ``SamplerQNN`` Example"
msgstr "4.2.2. Ejemplo de ``SamplerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:1187
msgid "For the ``SamplerQNN`` (without custom interpret function), the expected output shape for the input gradients is ``(batch_size, 2**num_qubits, num_inputs)``. With a custom interpret function, the output shape will be ``(batch_size, output_shape, num_inputs)``."
msgstr "Para la ``SamplerQNN`` (sin función de interpretación personalizada), la forma de salida esperada para los gradientes de entrada es ``(batch_size, 2**num_qubits, num_inputs)``. Con una función de interpretación personalizada, la forma de salida será ``(batch_size, output_shape, num_inputs)``."

#: ../../tutorials/01_neural_networks.ipynb:1269
msgid "5. Advanced Functionality"
msgstr "5. Funcionalidad Avanzada"

#: ../../tutorials/01_neural_networks.ipynb:1281
msgid "5.1. ``EstimatorQNN`` with Multiple Observables"
msgstr "5.1. ``EstimatorQNN`` con Múltiples Observables"

#: ../../tutorials/01_neural_networks.ipynb:1292
msgid "The ``EstimatorQNN`` allows to pass lists of observables for more complex QNN architectures. For example (note the change in output shape):"
msgstr "La ``EstimatorQNN`` permite pasar listas de observables para arquitecturas QNN más complejas. Por ejemplo (ten en cuenta el cambio en la forma de salida):"

#: ../../tutorials/01_neural_networks.ipynb:1372
msgid "5.2. ``SamplerQNN`` with custom ``interpret``"
msgstr "5.2. ``SamplerQNN`` con ``interpret`` personalizado"

#: ../../tutorials/01_neural_networks.ipynb:1383
msgid "One common ``interpret`` method for ``SamplerQNN`` is the ``parity`` function, which allows it to perform binary classification. As explained in the instantiation section, using interpret functions will modify the output shape of the forward and backward passes. In the case of the parity interpret function, ``output_shape`` is fixed to ``2``. Therefore, the expected forward and weight gradient shapes are ``(batch_size, 2)`` and ``(batch_size, 2, num_weights)``, respectively:"
msgstr "Un método ``interpret`` común para ``SamplerQNN`` es la función ``parity``, que le permite realizar una clasificación binaria. Como se explicó en la sección de creación de instancias, el uso de funciones de interpretación modificará la forma de salida de los pasos hacia adelante y hacia atrás. En el caso de la función de interpretación de paridad, ``output_shape`` se fija en ``2``. Por lo tanto, las formas esperadas del gradiente de peso y gradiente hacia adelante son ``(batch_size, 2)`` y ``(batch_size, 2, num_weights)``, respectivamente:"

#: ../../tutorials/01_neural_networks.ipynb:1465
msgid "6. Conclusion"
msgstr "6. Conclusión"

#: ../../tutorials/01_neural_networks.ipynb:1467
msgid "In this tutorial, we introduced the two neural networks classes provided by ``qiskit-machine-learning``, namely the ``EstimatorQNN`` and ``SamplerQNN``, which extend the base ``NeuralNetwork`` class. We provided some theoretical background, the key steps for QNN initialization, basic use in forward and backward passes, and advanced functionality."
msgstr "En este tutorial, presentamos las dos clases de redes neuronales proporcionadas por ``qiskit-machine-learning``, es decir, ``EstimatorQNN`` y ``SamplerQNN``, que amplían la clase base ``NeuralNetwork``. Brindamos algunos antecedentes teóricos, los pasos clave para la inicialización de QNN, el uso básico en pasos hacia adelante y hacia atrás y funcionalidad avanzada."

#: ../../tutorials/01_neural_networks.ipynb:1469
msgid "We now encourage you to play around with the problem setup and see how different circuit sizes, input, and weight parameter lengths influence the output shapes."
msgstr "Ahora te alentamos a que juegues con la configuración del problema y veas cómo los diferentes tamaños de circuito, la entrada y las longitudes de los parámetros de peso influyen en las formas de salida."

