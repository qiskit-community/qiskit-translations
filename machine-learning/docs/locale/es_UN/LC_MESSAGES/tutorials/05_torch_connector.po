msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-04-04 19:59+0000\n"
"PO-Revision-Date: 2023-04-04 21:28\n"
"Last-Translator: \n"
"Language: es_UN\n"
"Language-Team: Spanish (United)\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: es-un\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/05_torch_connector.po\n"
"X-Crowdin-File-ID: 9636\n"

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "This page was generated from `docs/tutorials/05_torch_connector.ipynb`__."
msgstr "Esta página fue generada a partir de `docs/tutorials/05_torch_connector.ipynb`__."

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector and Hybrid QNNs"
msgstr "Conector Torch y QNNs Híbridas"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial introduces Qiskit's ``TorchConnector`` class, and demonstrates how the ``TorchConnector`` allows for a natural integration of any ``NeuralNetwork`` from Qiskit Machine Learning into a PyTorch workflow. ``TorchConnector`` takes a Qiskit ``NeuralNetwork`` and makes it available as a PyTorch ``Module``. The resulting module can be seamlessly incorporated into PyTorch classical architectures and trained jointly without additional considerations, enabling the development and testing of novel **hybrid quantum-classical** machine learning architectures."
msgstr "Este tutorial presenta la clase ``TorchConnector`` de Qiskit y demuestra cómo el ``TorchConnector`` permite una integración natural de cualquier ``NeuralNetwork`` de Qiskit Machine Learning en un flujo de trabajo PyTorch. ``TorchConnector`` toma una ``NeuralNetwork`` de Qiskit y la pone a disposición como un ``Module`` de PyTorch. El módulo resultante se puede incorporar a la perfección a las arquitecturas clásicas de PyTorch y se puede entrenar de forma conjunta sin consideraciones adicionales, permitiendo el desarrollo y pruebas de arquitecturas de machine learning **híbridas cuánticas-clásicas** novedosas."

#: ../../tutorials/05_torch_connector.ipynb:15
msgid "Content:"
msgstr "Contenido:"

#: ../../tutorials/05_torch_connector.ipynb:17
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__"
msgstr "`Parte 1: Clasificación y Regresión Simples <#Part-1:-Simple-Classification-&-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:19
msgid "The first part of this tutorial shows how quantum neural networks can be trained using PyTorch's automatic differentiation engine (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) for simple classification and regression tasks."
msgstr "La primera parte de este tutorial muestra cómo se pueden entrenar las redes neuronales cuánticas utilizando el motor de diferenciación automática de PyTorch (``torch.autograd``, `enlace \n"
"<https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) para tareas simples de clasificación y regresión."

#: ../../tutorials/05_torch_connector.ipynb:21
msgid "`Classification <#1.-Classification>`__"
msgstr "`Clasificación <#1.-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:23
msgid "Classification with PyTorch and ``EstimatorQNN``"
msgstr "Clasificación con PyTorch y ``EstimatorQNN``"

#: ../../tutorials/05_torch_connector.ipynb:24
msgid "Classification with PyTorch and ``SamplerQNN``"
msgstr "Clasificación con PyTorch y ``SamplerQNN``"

#: ../../tutorials/05_torch_connector.ipynb:26
msgid "`Regression <#2.-Regression>`__"
msgstr "`Regresión <#2.-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:28
msgid "Regression with PyTorch and ``SamplerQNN``"
msgstr "Regresión con PyTorch y ``SamplerQNN``"

#: ../../tutorials/05_torch_connector.ipynb:30
msgid "`Part 2: MNIST Classification, Hybrid QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"
msgstr "`Parte 2: Clasificación MNIST, QNNs Híbridas <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"

#: ../../tutorials/05_torch_connector.ipynb:32
msgid "The second part of this tutorial illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow (in this case, a typical CNN architecture) to classify MNIST data in a hybrid quantum-classical manner."
msgstr "La segunda parte de este tutorial ilustra cómo incrustar una ``NeuralNetwork`` (Cuántica) en un flujo de trabajo PyTorch de destino (en este caso, una arquitectura CNN típica) para clasificar los datos MNIST de una manera híbrida cuántica-clásica."

#: ../../tutorials/05_torch_connector.ipynb:73
msgid "Part 1: Simple Classification & Regression"
msgstr "Parte 1: Clasificación y Regresión Simples"

#: ../../tutorials/05_torch_connector.ipynb:85
msgid "1. Classification"
msgstr "1. Clasificación"

#: ../../tutorials/05_torch_connector.ipynb:87
msgid "First, we show how ``TorchConnector`` allows to train a Quantum ``NeuralNetwork`` to solve a classification tasks using PyTorch's automatic differentiation engine. In order to illustrate this, we will perform **binary classification** on a randomly generated dataset."
msgstr "Primero, mostramos cómo ``TorchConnector`` permite entrenar una ``NeuralNetwork`` Cuántica para resolver tareas de clasificación utilizando el motor de diferenciación automática de PyTorch. Para ilustrar esto, realizaremos una **clasificación binaria** en un conjunto de datos generado aleatoriamente."

#: ../../tutorials/05_torch_connector.ipynb:140
msgid "A. Classification with PyTorch and ``EstimatorQNN``"
msgstr "A. Clasificación con PyTorch y ``EstimatorQNN``"

#: ../../tutorials/05_torch_connector.ipynb:142
msgid "Linking an ``EstimatorQNN`` to PyTorch is relatively straightforward. Here we illustrate this by using the ``EstimatorQNN`` constructed from a feature map and an ansatz."
msgstr "Vincular un ``EstimatorQNN`` a PyTorch es relativamente sencillo. Aquí ilustramos esto usando el ``EstimatorQNN`` construido a partir de un mapa de características y un ansatz."

#: ../../tutorials/05_torch_connector.ipynb:262
msgid "Optimizer"
msgstr "Optimizador"

#: ../../tutorials/05_torch_connector.ipynb:264
msgid "The choice of optimizer for training any machine learning model can be crucial in determining the success of our training's outcome. When using ``TorchConnector``, we get access to all of the optimizer algorithms defined in the [``torch.optim``] package (`link <https://pytorch.org/docs/stable/optim.html>`__). Some of the most famous algorithms used in popular machine learning architectures include *Adam*, *SGD*, or *Adagrad*. However, for this tutorial we will be using the L-BFGS algorithm (``torch.optim.LBFGS``), one of the most well know second-order optimization algorithms for numerical optimization."
msgstr "La elección del optimizador para entrenar cualquier modelo de machine learning puede ser crucial para determinar el éxito del resultado de nuestro entrenamiento. Cuando usamos ``TorchConnector``, obtenemos acceso a todos los algoritmos del optimizador definidos en el paquete [``torch.optim``] (`enlace <https://pytorch.org/docs/stable/optim.html>`__). Algunos de los algoritmos más famosos utilizados en las arquitecturas de machine learning populares incluyen *Adam*, *SGD*, o *Adagrad*. Sin embargo, para este tutorial usaremos el algoritmo L-BFGS (``torch.optim.LBFGS``), uno de los algoritmos de optimización de segundo orden más conocidos para la optimización numérica."

#: ../../tutorials/05_torch_connector.ipynb:268
msgid "Loss Function"
msgstr "Función de Pérdida"

#: ../../tutorials/05_torch_connector.ipynb:270
msgid "As for the loss function, we can also take advantage of PyTorch's pre-defined modules from ``torch.nn``, such as the `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ or `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."
msgstr "En cuanto a la función de pérdida, también podemos aprovechar los módulos predefinidos de PyTorch desde ``torch.nn``, como las pérdidas `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ o `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__."

#: ../../tutorials/05_torch_connector.ipynb:272
msgid "**💡 Clarification :** In classical machine learning, the general rule of thumb is to apply a Cross-Entropy loss to classification tasks, and MSE loss to regression tasks. However, this recommendation is given under the assumption that the output of the classification network is a class probability value in the :math:`[0, 1]` range (usually this is achieved through a Softmax layer). Because the following example for ``EstimatorQNN`` does not include such layer, and we don't apply any mapping to the output (the following section shows an example of application of parity mapping with ``SamplerQNN``\\ s), the QNN's output can take any value in the range :math:`[-1, 1]`. In case you were wondering, this is the reason why this particular example uses MSELoss for classification despite it not being the norm (but we encourage you to experiment with different loss functions and see how they can impact training results)."
msgstr "**💡 Aclaración:** En machine learning clásico, la regla general es aplicar una pérdida de entropía cruzada (Cross-Entropy) a las tareas de clasificación y una pérdida de MSE a las tareas de regresión. Sin embargo, esta recomendación se da bajo el supuesto de que la salida de la red de clasificación es un valor de probabilidad de clase en el rango :math:`[0, 1]` (generalmente esto se logra a través de una capa Softmax). Debido a que el siguiente ejemplo para ``EstimatorQNN`` no incluye dicha capa, y no aplicamos ningún mapeo a la salida (la siguiente sección muestra un ejemplo de aplicación de mapeo de paridad con ``SamplerQNN``\\ s), la salida de la QNN puede tomar cualquier valor en el rango :math:`[-1, 1]`. En caso de que te lo preguntes, esta es la razón por la que este ejemplo en particular usa MSELoss para la clasificación a pesar de que no es la norma (pero te alentamos a experimentar con diferentes funciones de pérdida y ver cómo pueden afectar los resultados del entrenamiento)."

#: ../../tutorials/05_torch_connector.ipynb:482
#: ../../tutorials/05_torch_connector.ipynb:752
msgid "The red circles indicate wrongly classified data points."
msgstr "Los círculos rojos indican puntos de datos clasificados incorrectamente."

#: ../../tutorials/05_torch_connector.ipynb:494
msgid "B. Classification with PyTorch and ``SamplerQNN``"
msgstr "B. Clasificación con PyTorch y ``SamplerQNN``"

#: ../../tutorials/05_torch_connector.ipynb:496
msgid "Linking a ``SamplerQNN`` to PyTorch requires a bit more attention than ``EstimatorQNN``. Without the correct setup, backpropagation is not possible."
msgstr "Vincular una ``SamplerQNN``a PyTorch requiere un poco más de atención que con ``EstimatorQNN``. Sin la configuración correcta, la propagación hacia atrás (backpropagation) no es posible."

#: ../../tutorials/05_torch_connector.ipynb:498
msgid "In particular, we must make sure that we are returning a dense array of probabilities in the network's forward pass (``sparse=False``). This parameter is set up to ``False`` by default, so we just have to make sure that it has not been changed."
msgstr "En particular, debemos asegurarnos de que estamos devolviendo un arreglo denso de probabilidades en el paso hacia adelante de la red (``sparse=False``). Este parámetro está configurado en ``False`` de forma predeterminada, por lo que solo debemos asegurarnos de que no haya sido modificado."

#: ../../tutorials/05_torch_connector.ipynb:500
msgid "**⚠️ Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``SamplerQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.SamplerQNN.html>`__."
msgstr "**⚠️ Atención:** Si definimos una función de interpretación personalizada (en el ejemplo: ``parity``), debemos recordar proporcionar explícitamente la forma de salida deseada (en el ejemplo: ``2``). Para obtener más información sobre la configuración inicial de parámetros para ``SamplerQNN``, consulta la `documentación oficial de qiskit <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.SamplerQNN.html>`__."

#: ../../tutorials/05_torch_connector.ipynb:571
#: ../../tutorials/05_torch_connector.ipynb:860
msgid "For a reminder on optimizer and loss function choices, you can go back to `this section <#Optimizer>`__."
msgstr "Para obtener un recordatorio sobre el optimizador y las opciones de funciones de pérdida, puedes volver a `esta sección <#Optimizer>`__."

#: ../../tutorials/05_torch_connector.ipynb:764
msgid "2. Regression"
msgstr "2. Regresión"

#: ../../tutorials/05_torch_connector.ipynb:766
msgid "We use a model based on the ``EstimatorQNN`` to also illustrate how to perform a regression task. The chosen dataset in this case is randomly generated following a sine wave."
msgstr "Usamos un modelo basado en la ``EstimatorQNN`` para ilustrar también cómo realizar una tarea de regresión. El conjunto de datos elegido en este caso se genera aleatoriamente siguiendo una onda sinusoidal."

#: ../../tutorials/05_torch_connector.ipynb:807
msgid "A. Regression with PyTorch and ``EstimatorQNN``"
msgstr "A. Regresión con PyTorch y ``EstimatorQNN``"

#: ../../tutorials/05_torch_connector.ipynb:818
msgid "The network definition and training loop will be analogous to those of the classification task using ``EstimatorQNN``. In this case, we define our own feature map and ansatz, but let's do it a little different."
msgstr "La definición de la red y el ciclo de entrenamiento serán análogos a los de la tarea de clasificación usando ``EstimatorQNN``. En este caso, definimos nuestro propio mapa de características y ansatz, pero hagámoslo un poco diferente."

#: ../../tutorials/05_torch_connector.ipynb:999
msgid "Part 2: MNIST Classification, Hybrid QNNs"
msgstr "Parte 2: Clasificación MNIST, QNNs Híbridas"

#: ../../tutorials/05_torch_connector.ipynb:1001
msgid "In this second part, we show how to leverage a hybrid quantum-classical neural network using ``TorchConnector``, to perform a more complex image classification task on the MNIST handwritten digits dataset."
msgstr "En esta segunda parte, mostramos cómo aprovechar una red neuronal híbrida cuántica-clásica utilizando ``TorchConnector``, para realizar una tarea de clasificación de imágenes más compleja en el conjunto de datos de dígitos manuscritos del MNIST."

#: ../../tutorials/05_torch_connector.ipynb:1003
msgid "For a more detailed (pre-``TorchConnector``) explanation on hybrid quantum-classical neural networks, you can check out the corresponding section in the `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."
msgstr "Para obtener una explicación más detallada (pre-``TorchConnector``) sobre las redes neuronales híbridas cuánticas-clásicas, puedes consultar la sección correspondiente en el `Libro de texto de Qiskit <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."

#: ../../tutorials/05_torch_connector.ipynb:1042
msgid "Step 1: Defining Data-loaders for train and test"
msgstr "Paso 1: Definición de cargadores de datos para entrenamiento y prueba"

#: ../../tutorials/05_torch_connector.ipynb:1053
msgid "We take advantage of the ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ to directly load a subset of the `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ and define torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) for train and test."
msgstr "Aprovechamos la `API <https://pytorch.org/vision/stable/datasets.html>`__ de ``torchvision`` para cargar directamente un subconjunto del `conjunto de datos MNIST <https://en.wikipedia.org/wiki/MNIST_database>`__ y definir los ``DataLoader``\\ s de torch (`enlace <https://pytorch.org/docs/stable/data.html>`__) para entrenar y probar."

#: ../../tutorials/05_torch_connector.ipynb:1398
msgid "If we perform a quick visualization we can see that the train dataset consists of images of handwritten 0s and 1s."
msgstr "Si realizamos una visualización rápida, podemos ver que el conjunto de datos de entrenamiento consta de imágenes de 0s y 1s escritos a mano."

#: ../../tutorials/05_torch_connector.ipynb:1472
msgid "Step 2: Defining the QNN and Hybrid Model"
msgstr "Paso 2: Definición del Modelo Híbrido y de la QNN"

#: ../../tutorials/05_torch_connector.ipynb:1483
msgid "This second step shows the power of the ``TorchConnector``. After defining our quantum neural network layer (in this case, a ``EstimatorQNN``), we can embed it into a layer in our torch ``Module`` by initializing a torch connector as ``TorchConnector(qnn)``."
msgstr "Este segundo paso muestra el poder del ``TorchConnector``. Después de definir nuestra capa de red neuronal cuántica (en este caso, una ``EstimatorQNN``), podemos incrustarla en una capa en nuestro ``Module`` de torch, al inicializar un conector torch como ``TorchConnector(qnn)``."

#: ../../tutorials/05_torch_connector.ipynb:1485
msgid "**⚠️ Attention:** In order to have an adequate gradient backpropagation in hybrid models, we MUST set the initial parameter ``input_gradients`` to TRUE during the qnn initialization."
msgstr "**⚠️ Atención:** Para tener un gradiente de propagación hacia atrás (backpropagation) adecuado en modelos híbridos, DEBEMOS establecer el parámetro inicial ``input_gradients`` en TRUE durante la inicialización de la qnn."

#: ../../tutorials/05_torch_connector.ipynb:1564
msgid "Step 3: Training"
msgstr "Paso 3: Entrenamiento"

#: ../../tutorials/05_torch_connector.ipynb:1678
msgid "Now we'll save the trained model, just to show how a hybrid model can be saved and re-used later for inference. To save and load hybrid models, when using the TorchConnector, follow the PyTorch recommendations of saving and loading the models."
msgstr "Ahora guardaremos el modelo entrenado, solo para mostrar cómo se puede guardar un modelo híbrido y reutilizarlo más tarde para la inferencia. Para guardar y cargar modelos híbridos, al usar TorchConnector, sigue las recomendaciones de PyTorch para guardar y cargar los modelos."

#: ../../tutorials/05_torch_connector.ipynb:1700
msgid "Step 4: Evaluation"
msgstr "Paso 4: Evaluación"

#: ../../tutorials/05_torch_connector.ipynb:1711
msgid "We start from recreating the model and loading the state from the previously saved file. You create a QNN layer using another simulator or a real hardware. So, you can train a model on real hardware available on the cloud and then for inference use a simulator or vice verse. For a sake of simplicity we create a new quantum neural network in the same way as above."
msgstr "Partimos de recrear el modelo y cargar el estado desde el archivo previamente guardado. Creaste una capa QNN usando otro simulador o un hardware real. Por lo tanto, puedes entrenar un modelo en hardware real disponible en la nube y luego, para la inferencia, usar un simulador o viceversa. En aras de la simplicidad, creamos una nueva red neuronal cuántica de la misma manera que arriba."

#: ../../tutorials/05_torch_connector.ipynb:1859
msgid "🎉🎉🎉🎉 **You are now able to experiment with your own hybrid datasets and architectures using Qiskit Machine Learning.** **Good Luck!**"
msgstr "🎉🎉🎉🎉 **Ahora puedes experimentar con tus propios conjuntos de datos y arquitecturas híbridas utilizando Qiskit Machine Learning.** **¡Buena suerte!**"

