msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-03-28 08:39+0000\n"
"PO-Revision-Date: 2023-03-28 10:57\n"
"Last-Translator: \n"
"Language: es_UN\n"
"Language-Team: Spanish (United)\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: es-un\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/11_quantum_convolutional_neural_networks.po\n"
"X-Crowdin-File-ID: 9840\n"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/11_quantum_convolutional_neural_networks.ipynb`__."
msgstr "Esta página fue generada a partir de `docs/tutorials/11_quantum_convolutional_neural_networks.ipynb`__."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:9
msgid "The Quantum Convolution Neural Network"
msgstr "La Red Neuronal Convolucional Cuántica"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:21
msgid "1. Introduction"
msgstr "1. Introducción"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:32
msgid "Throughout this tutorial, we discuss a Quantum Convolutional Neural Network (QCNN), first proposed by Cong et. al. [1]. We implement such a QCNN on Qiskit by modeling both the convolutional layers and pooling layers using a quantum circuit. After building such a network, we train it to differentiate horizontal and vertical lines from a pixelated image. The following tutorial is thus divided accordingly;"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:34
msgid "Differences between a QCNN and CCNN"
msgstr "Diferencias entre una QCNN y una CCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:35
msgid "Components of a QCNN"
msgstr "Componentes de una QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:36
msgid "Data Generation"
msgstr "Generación de Datos"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:37
msgid "Building a QCNN"
msgstr "Construir una QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:38
msgid "Training our QCNN"
msgstr "Entrenar nuestra QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:39
msgid "Testing our QCNN"
msgstr "Probar nuestra QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:40
msgid "References"
msgstr "Referencias"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:42
msgid "We first begin by importing the libraries and packages we will need for this tutorial."
msgstr "Primero comenzamos importando las bibliotecas y los paquetes que necesitaremos para este tutorial."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:78
msgid "1. Differences between a QCNN and CCNN"
msgstr "1. Diferencias entre una QCNN y una CCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:90
msgid "1.1 Classical Convolutional Neural Networks"
msgstr "1.1 Redes Neuronales Convolucionales Clásicas"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:101
msgid "Classical Convolutional Neural Networks (CCNNs) are a subclass of artificial neural networks which have the ability to determine particular features and patterns of a given input. Because of this, they are commonly used in image recognition and audio processing."
msgstr "Las Redes Neuronales Convolucionales Clásicas (Classical Convolutional Neural Networks, CCNN) son una subclase de redes neuronales artificiales que tienen la capacidad de determinar características y patrones particulares de una entrada determinada. Debido a esto, se utilizan comúnmente en el reconocimiento de imágenes y el procesamiento de audio."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:103
msgid "The capability of determining features is a result of the two types of layers used in a CCNN, the convolutional layer and pooling layer."
msgstr "La capacidad de determinar características es el resultado de los dos tipos de capas que se utilizan en una CCNN, la capa convolucional y la capa de reducción (pooling)."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:105
msgid "An example of a CCNN can be seen in Figure 1, where a CCNN is trained to determine whether an input image either contains a cat or a dog. To do so, the input image passes through a series of alternating convolutional (C) and pooling layers (P), all of which detect patterns and associate each pattern to a cat or a dog. The fully connected layer (FC) provides us with an output which allows us to determine whether the input image was a cat or dog."
msgstr "Se puede ver un ejemplo de CCNN en la Figura 1, donde se entrena a una CCNN para determinar si una imagen de entrada contiene un gato o un perro. Para hacerlo, la imagen de entrada pasa a través de una serie de capas alternas convolucionales (C) y de reducción (P), todas las cuales detectan patrones y asocian cada patrón a un gato o un perro. La capa totalmente conectada (FC) nos proporciona una salida que nos permite determinar si la imagen de entrada era un gato o un perro."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:107
msgid "The convolutional layer makes use of a kernel, which can determine features and patterns of a particular input. An example of this is feature detection in an image, where different layers detect particular patterns in the input image. This is demonstrated in Figure 1, where the :math:`l^{th}` layer recognizes features and patterns along the :math:`ij` plane. It can then associate such features with a given output in the training process, and can use this process to train the dataset."
msgstr "La capa convolucional utiliza un kernel, que puede determinar características y patrones de una entrada en particular. Un ejemplo de esto es la detección de características en una imagen, donde diferentes capas detectan patrones particulares en la imagen de entrada. Esto se demuestra en la Figura 1, donde la capa :math:`l^{th}` reconoce características y patrones a lo largo del plano :math:`ij`. Luego, puede asociar dichas características con un resultado dado en el proceso de entrenamiento y puede usar este proceso para entrenar el conjunto de datos."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:109
msgid "On the other hand, a pooling layer reduces the dimensionality of the input data, reducing the computational cost and amount of learning parameters in the CCNN. A schematic of a CCNN can be seen below."
msgstr "Por otro lado, una capa de reducción (pooling) reduce la dimensionalidad de los datos de entrada, reduciendo el costo computacional y la cantidad de parámetros de aprendizaje en la CCNN. A continuación se puede ver un esquema de una CCNN."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:111
msgid "For further information on CCNN, see [2]."
msgstr "Para obtener más información sobre CCNN, consulta [2]."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:122
msgid "|Screenshot%202022-08-09%20at%2017.03.09.png| Figure 1. A schematic demonstration of the use of a CCNN to classify between images of a cat and dog. Here, we see the several convolutional and pooling layers being applied, all of which are decreasing in dimensionality due to the use of the pooling layers. The output of the CCNN determines whether the input image was a cat or dog. Image obtained form [1]."
msgstr "|Screenshot%202022-08-09%20at%2017.03.09.png| Figura 1. Una demostración esquemática del uso de una CCNN para clasificar entre imágenes de un gato y un perro. Aquí, vemos que se aplican varias capas convolucionales y de reducción, todas están disminuyendo en dimensionalidad debido al uso de las capas de reducción. La salida de la CCNN determina si la imagen de entrada era un gato o un perro. Imagen obtenida de [1]."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:124
msgid "Screenshot%202022-08-09%20at%2017.03.09.png"
msgstr "Screenshot%202022-08-09%20at%2017.03.09.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:136
msgid "1.2 Quantum Convolutional Neural Networks"
msgstr "1.2 Redes Neuronales Convolucionales Cuánticas"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:147
msgid "Quantum Convolutional Neural Networks (QCNN) behave in a similar manner to CCNNs. First, we encode our pixelated image into a quantum circuit using a given feature map, such Qiskit's ZFeatureMap or ZZFeatureMap or others available in the circuit library."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:149
msgid "After encoding our image, we apply alternating convolutional and pooling layers, as defined in the next section. By applying these alternating layers, we reduce the dimensionality of our circuit until we are left with one qubit. We can then classify our input image by measuring the output of this one remaining qubit."
msgstr "Después de codificar nuestra imagen, aplicamos capas convolucionales y de reducción (pooling) alternas, como se define en la siguiente sección. Al aplicar estas capas alternas, reducimos la dimensionalidad de nuestro circuito hasta que nos quedamos con un qubit. Luego podemos clasificar nuestra imagen de entrada midiendo la salida de este qubit restante."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:151
msgid "The Quantum Convolutional Layer will consist of a series of two qubit unitary operators, which recognize and determine relationships between the qubits in our circuit. This unitary gates are defined below in the next section."
msgstr "La Capa Convolucional Cuántica consistirá en una serie de operadores unitarios de dos qubits, que reconocen y determinan las relaciones entre los qubits en nuestro circuito. Estas compuertas unitarias se definen a continuación en la siguiente sección."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:153
msgid "For the Quantum Pooling Layer, we cannot do the same as is done classically to reduce the dimension, i.e. the number of qubits in our circuit. Instead, we reduce the number of qubits by performing operations upon each until a specific point and then disregard certain qubits in a specific layer. It is these layers where we stop performing operations on certain qubits that we call our 'pooling layer'. Details of the pooling layer is discussed further in the next section."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:155
msgid "In the QCNN, each layer contains parametrized circuits, meaning we alter our output result by adjusting the parameters of each layer. When training our QCNN, it is these parameters that are adjusted to reduce the loss function of our QCNN."
msgstr "En QCNN, cada capa contiene circuitos parametrizados, lo que significa que alteramos nuestro resultado de salida ajustando los parámetros de cada capa. Al entrenar nuestra QCNN, son estos parámetros los que se ajustan para reducir la función de pérdida de nuestra QCNN."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:166
msgid "A simple example of four qubit QCNN can be seen below."
msgstr "A continuación se puede ver un ejemplo simple de QCNN de cuatro qubits."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:177
msgid "|figure2.png|"
msgstr "|figure2.png|"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:179
msgid "figure2.png"
msgstr "figure2.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:190
msgid "Figure 2: Example QCNN containing four qubits. The first Convolutional Layer acts on all the qubits. This is followed by the first pooling layer, which reduces the dimensionality of the QCNN from four qubits to two qubits by disregarding the first two. The second Convolutional layer then detects features between the two qubits still in use in the QCNN, followed by another pooling layer, which reduces the dimensionality from two qubits to one, which will be our output qubit."
msgstr "Figura 2: Ejemplo de QCNN que contiene cuatro qubits. La primera Capa Convolucional actúa sobre todos los qubits. A esto le sigue la primera capa de reducción, que disminuye la dimensionalidad de la QCNN de cuatro qubits a dos qubits al ignorar los dos primeros. Luego, la segunda Capa Convolucional detecta características entre los dos qubits que aún están en uso en la QCNN, seguida de otra capa de reducción, que disminuye la dimensionalidad de dos qubits a uno, que será nuestro qubit de salida."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:202
msgid "2. Components of a QCNN"
msgstr "2. Componentes de una QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:213
msgid "As discussed in Section 1 of this tutorial, a CCNN will contain both convolutional and pooling layers. Here, we define these layers for the QCNN in terms of gates applied to a Quantum Circuit and demonstrate an example for each layer for 4 qubits."
msgstr "Como se discutió en la Sección 1 de este tutorial, una CCNN contendrá capas convolucionales y de reducción (agrupación). Aquí, definimos estas capas para la QCNN en términos de compuertas aplicadas a un circuito cuántico y demostramos un ejemplo para cada capa para 4 qubits."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:215
msgid "Each of these layers will contain parameters which are tuned throughout the training process to minimize the loss function and train the QCNN to classify between horizontal and vertical lines."
msgstr "Cada una de estas capas contendrá parámetros que se ajustan a lo largo del proceso de entrenamiento para minimizar la función de pérdida y entrenar a la QCNN para clasificar entre líneas horizontales y verticales."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:217
msgid "In theory, one could apply any parametrized circuit for both the convolutional and pooling layers of our network. For example in [2], the Gellmann Matrices (which are the three dimensional generalization of the Pauli Matrices) are used as generators for each unitary gate acting on a pair of qubits."
msgstr "En teoría, se podría aplicar cualquier circuito parametrizado para las capas convolucional y de reducción de nuestra red. Por ejemplo, en [2], las Matrices de Gellmann (que son la generalización tridimensional de las Matrices de Pauli) se utilizan como generadores para cada compuerta unitaria que actúa sobre un par de qubits."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:219
msgid "Here, we take a different approach and form our parametrized circuit based on the two qubit unitary as proposed in [3]. This states that every unitary matrix in :math:`U(4)` can be decomposed such that"
msgstr "Aquí, tomamos un enfoque diferente y formamos nuestro circuito parametrizado basado en la unitaria de dos qubits como se propone en [3]. Esto establece que cada matriz unitaria en :math:`U(4)` se puede descomponer de tal manera que"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:221
msgid "U = (A_1 \\otimes A_2) \\cdot N(\\alpha, \\beta, \\gamma) \\cdot (A_3 \\otimes A_4)\n\n"
msgstr "U = (A_1 \\otimes A_2) \\cdot N(\\alpha, \\beta, \\gamma) \\cdot (A_3 \\otimes A_4)\n\n"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:223
msgid "where :math:`A_j \\in \\text{SU}(2)`, :math:`\\otimes` is the tensor product, and :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])`, where :math:`\\alpha, \\beta, \\gamma` are the parameters that we can adjust."
msgstr "donde :math:`A_j \\in \\text{SU}(2)`, :math:`\\otimes` es el producto tensorial, y :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])`, donde :math:`\\alpha, \\beta, \\gamma` son los parámetros que podemos ajustar."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:225
msgid "From this, it is evident that each unitary depends on 15 parameters and implies that in order for the QCNN to be able to span the whole Hilbert space, each unitary in our QCNN must contain 15 parameters each."
msgstr "A partir de esto, es evidente que cada unitaria depende de 15 parámetros e implica que para que la QCNN pueda abarcar todo el espacio de Hilbert, cada unitaria en nuestra QCNN debe contener 15 parámetros cada una."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:227
msgid "Tuning this large amount of parameters would be difficult and would lead to long training times. To overcome this problem, we restrict our ansatz to a particular subspace of the Hilbert space and define the two qubit unitary gate as :math:`N(\\alpha, \\beta, \\gamma)`. These two qubit unitaries, as seen in [3] can be seen below and are applied to all neighboring qubits each of the layers in the QCNN."
msgstr "Ajustar esta gran cantidad de parámetros sería difícil y daría lugar a largos tiempos de entrenamiento. Para superar este problema, restringimos nuestro ansatz a un subespacio particular del espacio de Hilbert y definimos la compuerta unitaria de dos qubits como :math:`N(\\alpha, \\beta, \\gamma)`. Estas unitarias dos qubits, como se muestra en [3], se pueden ver a continuación y se aplican a todos los qubits vecinos de cada una de las capas de la QCNN."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:229
msgid "Note that by only using :math:`N(\\alpha, \\beta, \\gamma)` as our two qubit unitary for the parametrized layers, we are restricting our QCNN to a particular subspace, one in which the optimal solution may not be contained in and reducing the accuracy of the QCNN. For the purpose of this tutorial, we will use this parametrized circuit to decrease the training time of our QCNN."
msgstr "Ten en cuenta que al usar solo :math:`N(\\alpha, \\beta, \\gamma)` como nuestra unitaria de dos qubits para las capas parametrizadas, estamos restringiendo nuestra QCNN a un subespacio particular, uno en el que la solución óptima puede no estar contenida y reduciendo la precisión de la QCNN. A los efectos de este tutorial, utilizaremos este circuito parametrizado para disminuir el tiempo de entrenamiento de nuestra QCNN."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:240
msgid "|circuit2.png|"
msgstr "|circuit2.png|"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:242
msgid "circuit2.png"
msgstr "circuit2.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:253
msgid "Figure 3: Parametrized two qubit unitary circuit for :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])` as seen in [3], where :math:`\\alpha = \\frac{\\pi}{2} - 2\\theta`, :math:`\\beta = 2\\phi - \\frac{\\pi}{2}` and :math:`\\gamma = \\frac{\\pi}{2} - 2\\lambda` as seen in the circuit. This two qubit unitary will be applied to all neighboring qubits in our feature map."
msgstr "Figura 3: Circuito unitario parametrizado de dos qubits para :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])` como se ve en [3], donde :math:`\\alpha = \\frac{\\pi}{2} - 2\\theta`, :math:`\\beta = 2\\phi - \\frac{\\pi}{2}` y :math:`\\gamma = \\frac{\\pi}{2} - 2\\lambda` como se ve en el circuito. Esta unitaria de dos qubits se aplicará a todos los qubits vecinos en nuestro mapa de funciones."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:265
msgid "2.1 Convolutional Layer"
msgstr "2.1 Capa Convolucional"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:276
msgid "The next step in this tutorial is to define the Convolutional Layers of our QCNN. These layers are then applied to the qubits after the data has been encoded through use of the feature map."
msgstr "El siguiente paso en este tutorial es definir las Capas Convolucionales de nuestra QCNN. Luego, estas capas se aplican a los qubits después de que los datos se hayan codificado mediante el uso del mapa de características."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:278
msgid "To do so we first need to determine a parametrized unitary gate, which will be used to create our convolutional and pooling layers."
msgstr "Para hacerlo, primero debemos determinar una compuerta unitaria parametrizada, que se utilizará para crear nuestras capas convolucionales y de reducción."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:325
msgid "Now that we have defined these unitaries, it is time to create a function for the convolutional layer in our QCNN. To do so, we apply the two qubit unitary to neighboring qubits as seen in the ``conv_layer`` function below."
msgstr "Ahora que hemos definido estas unitarias, es hora de crear una función para la capa convolucional en nuestra QCNN. Para hacerlo, aplicamos la unitaria de dos qubits a los qubits vecinos como se ve en la función ``conv_layer`` a continuación."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:327
msgid "Note that we first apply the two qubit unitary to all even pairs of qubits followed by applying to odd pairs of qubits in a circular coupling manner, i.e. the as well as neighboring qubits being coupled, the first and final qubit are also coupled through a unitary gate."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:329
msgid "Note that we add barriers into our quantum circuits for convenience when plotting, however they are not required for the actual QCNN and can be extracted from the following circuits."
msgstr "Ten en cuenta que agregamos barreras en nuestros circuitos cuánticos por conveniencia al graficar, sin embargo, no son necesarias para la QCNN real y se pueden extraer de los siguientes circuitos."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:382
msgid "2.2 Pooling Layer"
msgstr "2.2 Capa de Reducción"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:393
msgid "The purpose of a pooling layer is to reduce the dimensions of our Quantum Circuit, i.e. reduce the number of qubits in our circuit, while retaining as much information as possible from previously learned data. Reducing the amount of qubits also reduces the computational cost of the overall circuit, as the number of parameters that the QCNN needs to learn decreases."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:395
msgid "However, one cannot simply decrease the amount of qubits in our quantum circuit. Because of this, we must define the pooling layer in a different manner compared with the classical approach."
msgstr "Sin embargo, uno no puede simplemente disminuir la cantidad de qubits en nuestro circuito cuántico. Debido a esto, debemos definir la capa de reducción de una manera diferente en comparación con el enfoque clásico."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:397
msgid "To 'artificially' reduce the number of qubits in our circuit, we first begin by creating pairs of the :math:`N` qubits in our system."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:399
msgid "After initially pairing all the qubits, we apply our generalized 2 qubit unitary to each pair, as described previously. After applying this two qubit unitary, we then ignore one qubit from each pair of qubits for the remainder of the neural network."
msgstr "Después de emparejar inicialmente todos los qubits, aplicamos nuestra unitaria generalizada de 2 qubits a cada par, como se describió anteriormente. Después de aplicar esta unitaria de dos qubits, ignoramos un qubit de cada par de qubits para el resto de la red neuronal."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:401
msgid "This layer therefore has the overall effect of 'combining' the information of the two qubits into one qubit by first applying the unitary circuit, encoding information from one qubit into another, before disregarding one of qubits for the remainder of the circuit and not performing any operations or measurements on it."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:403
msgid "We note that one could also apply a dynamic circuit to reduce the dimensionality in the pooling layers. This would involve performing measurements on certain qubits in the circuit and having an intermediate classical feedback loop in our pooling layers. By applying these measurements, one would also be reducing the dimensionality of the circuit."
msgstr "Observamos que también se podría aplicar un circuito dinámico para reducir la dimensionalidad en las capas de reducción. Esto implicaría realizar mediciones en ciertos qubits en el circuito y tener un ciclo de retroalimentación clásico intermedio en nuestras capas de reducción. Al aplicar estas mediciones, también se estaría reduciendo la dimensionalidad del circuito."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:405
msgid "In this tutorial, we apply the former approach, and disregard qubits in each pooling layer. Using this approach, we thus create a QCNN Pooling Layer which transforms the dimensions of our :math:`N` qubit Quantum Circuit to :math:`N/2`."
msgstr "En este tutorial, aplicamos el enfoque anterior e ignoramos los qubits en cada capa de reducción. Con este enfoque, creamos una Capa de Reducción de la QCNN que transforma las dimensiones de nuestro circuito cuántico de :math:`N` qubits en :math:`N/2`."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:407
msgid "To do so, we first define a two qubit unitary, which transforms the two qubit system to one."
msgstr "Para hacerlo, primero definimos una unitaria de dos qubits, que transforma el sistema de dos qubits en uno."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:451
msgid "After applying this two qubit unitary circuit, we neglect the first qubit (q0) in future layers and only use the second qubit (q1) in our QCNN"
msgstr "Después de aplicar este circuito unitario de dos qubits, ignoramos el primer qubit (q0) en capas futuras y solo usamos el segundo qubit (q1) en nuestra QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:453
msgid "We apply this two qubit pooling layer to different pairs of qubits to create our pooling layer for N qubits. As an example we then plot it for four qubits."
msgstr "Aplicamos esta capa de reducción de dos qubits a diferentes pares de qubits para crear nuestra capa de reducción para N qubits. Como ejemplo, lo graficamos para cuatro qubits."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:503
msgid "In this particular example, we reduce the dimensionality of our four qubit circuit to the last two qubits, i.e. the last two qubits in this particular example. These qubits are then used in the next layer, while the first two are neglected for the remainder of the QCNN."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:515
msgid "3. Data Generation"
msgstr "3. Generación de Datos"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:526
msgid "One common use of a CCNN is an image classifier, where a CCNN detects particular features and patterns (such as straight lines or curves) of the pixelated images through the use of the feature maps in the convolutional layer. By learning the relationship between these features, it can then classify and label handwritten digits with ease."
msgstr "Un uso común de una CCNN es un clasificador de imágenes, donde una CCNN detecta características y patrones particulares (como líneas rectas o curvas) de las imágenes pixeladas mediante el uso de mapas de características en la capa convolucional. Al aprender la relación entre estas características, puede clasificar y etiquetar los dígitos escritos a mano con facilidad."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:528
msgid "Because of a classical CNN's ability to recognize features and patterns easily, we will train our QCNN to also determine patterns and features of a given set of pixelated images, and classify between two different patterns."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:530
msgid "To simplify the dataset, we only consider 2 x 4 pixelated images. The patterns we will train the QCNN to distinguish will be a horizontal or vertical line, which can be placed anywhere in the image, alongside a noisy background."
msgstr "Para simplificar el conjunto de datos, solo consideramos imágenes pixeladas de 2 x 4. Los patrones que entrenaremos en la QCNN para distinguir serán una línea horizontal o vertical, que se puede colocar en cualquier lugar de la imagen, junto con un fondo ruidoso."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:532
msgid "We first begin by generating this dataset. To create a 'horizontal' or 'vertical' line, we assign pixels value to be :math:`\\frac{\\pi}{2}` which will represent the line in our pixelated image. We create a noisy background by assigning every other pixel a random value between :math:`0` and :math:`\\frac{\\pi}{4}` which will create a noisy background."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:534
msgid "Note that when we create our dataset, we need to split it into the training set and testing set of images, the datasets we train and test our neural network respectively."
msgstr "Ten en cuenta que cuando creamos nuestro conjunto de datos, debemos dividirlo en el conjunto de imágenes de entrenamiento y en el conjunto de imágenes de prueba, los conjuntos de datos con los que entrenamos y probamos nuestra red neuronal, respectivamente."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:536
msgid "We also need to label our datasets such that the QCNN can learn to differentiate between the two patterns. In this example we label images with a horizontal line with -1 and images with a vertical line +1."
msgstr "También necesitamos etiquetar nuestros conjuntos de datos de manera que la QCNN pueda aprender a diferenciar entre los dos patrones. En este ejemplo, etiquetamos las imágenes con una línea horizontal con -1 y las imágenes con una línea vertical +1."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:591
msgid "Let's now create our dataset below and split it into our test and training datasets."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:616
msgid "Let's see some examples in our dataset"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:651
msgid "As we can see each image contains either a vertical or horizontal line, that the QCNN will learn how to differentiate. Now that we have built our dataset, it is time to discuss the components of the QCNN and build our model."
msgstr "Como podemos ver, cada imagen contiene una línea vertical u horizontal, que la QCNN aprenderá a diferenciar. Ahora que hemos construido nuestro conjunto de datos, es hora de discutir los componentes de la QCNN y construir nuestro modelo."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:663
msgid "4. Modeling our QCNN"
msgstr "4. Modelar nuestra QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:674
msgid "Now that we have defined both the convolutional layers it is now time to build our QCNN, which will consist of alternating pooling and convolutional layers."
msgstr "Ahora que hemos definido ambas capas convolucionales, es el momento de construir nuestra QCNN, que consistirá en capas alternas de reducción y convolucionales."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:676
msgid "As the images in our dataset contains 8 pixels, we will use 8 qubits in our QCNN."
msgstr "Como las imágenes en nuestro conjunto de datos contienen 8 píxeles, usaremos 8 qubits en nuestra QCNN."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:678
msgid "We encode our dataset into our QCNN by applying a feature map. One can create a feature map using one of Qiskit's built in feature maps, such as ZFeatureMap or ZZFeatureMap."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:680
msgid "After analyzing several different Feature maps for this dataset, it was found that QCNN obtains the greatest accuracy when the Z feature map is used. Therefore, throughout the remainder of the tutorial we will use the Z feature Map, of which can be seen below."
msgstr "Después de analizar varios mapas de características diferentes para este conjunto de datos, se encontró que la QCNN obtiene la mayor precisión cuando se usa el mapa de características Z. Por lo tanto, durante el resto del tutorial utilizaremos el mapa de características Z, como se puede ver a continuación."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:711
msgid "We create a function for our QCNN, which will contain three sets of alternating convolutional and pooling layers, which can be seen in the schematic below. Through the use of the pooling layers, we thus reduce the dimensionality of our QCNN from eight qubits to one."
msgstr "Creamos una función para nuestra QCNN, que contendrá tres conjuntos de capas convolucionales y de reducción alternas, que se pueden ver en el siguiente esquema. Mediante el uso de las capas de agrupación (pooling), reducimos la dimensionalidad de nuestra QCNN de ocho qubits a uno."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:722
msgid "|Screenshot%202022-08-10%20at%2021.42.39.png|"
msgstr "|Screenshot%202022-08-10%20at%2021.42.39.png|"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:724
msgid "Screenshot%202022-08-10%20at%2021.42.39.png"
msgstr "Screenshot%202022-08-10%20at%2021.42.39.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:735
msgid "To classify our image dataset of horizontal and vertical lines, we measure the expectation value of the Pauli Z operator of the final qubit. Based on the obtained value being +1 or -1, we can conclude that the input image contained either a horizontal or vertical line."
msgstr "Para clasificar nuestro conjunto de datos de imágenes de líneas horizontales y verticales, medimos el valor esperado del operador de Pauli Z del qubit final. Según el valor obtenido +1 o -1, podemos concluir que la imagen de entrada contenía una línea horizontal o vertical."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:747
msgid "5. Training our QCNN"
msgstr "5. Entrenar nuestra QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:758
msgid "The next step is to build our model using our training data."
msgstr "El siguiente paso es construir nuestro modelo usando nuestros datos de entrenamiento."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:760
msgid "To classify our system, we perform a measurement from the output circuit. The value we obtain will thus classify whether our input data contains either a vertical line or horizontal line."
msgstr "Para clasificar nuestro sistema, realizamos una medición desde el circuito de salida. El valor que obtengamos clasificará si nuestros datos de entrada contienen una línea vertical o una línea horizontal."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:762
msgid "The measurement we have chosen in this tutorial is :math:`<Z>`, i.e. the expectation value of the Pauli Z qubit for the final qubit. Measuring this expectation value, we obtain +1 or -1, which correspond to a vertical or horizontal line respectively."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:837
msgid "We will also define a callback function to use when training our model. This allows us to view and plot the loss function per each iteration in our training process."
msgstr "También definiremos una función de devolución de llamada para usar al entrenar nuestro modelo. Esto nos permite ver y graficar la función de pérdida por cada iteración en nuestro proceso de entrenamiento."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:865
msgid "In this example, we will use the COBYLA optimizer to train our classifier, which is a numerical optimization method commonly used for classification machine learning algorithms."
msgstr "En este ejemplo, usaremos el optimizador COBYLA para entrenar nuestro clasificador, que es un método de optimización numérica comúnmente utilizado para clasificar algoritmos de machine learning."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:867
msgid "We then place the the callback function, optimizer and operator of our QCNN created above into Qiskit's built in Neural Network Classifier, which we can then use to train our model."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:869
msgid "Since model training may take a long time we have already pre-trained the model for some iterations and saved the pre-trained weights. We'll continue training from that point by setting ``initial_point`` to a vector of pre-trained weights."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:898
msgid "After creating this classifier, we can train our QCNN using our training dataset and each image's corresponding label. Because we previously defined the callback function, we plot the overall loss of our system per iteration."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:900
msgid "It may take some time to train the QCNN so be patient!"
msgstr "¡Puede tomar algún tiempo entrenar la QCNN, así que ten paciencia!"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:962
msgid "As we can see from above, the QCNN converges slowly, hence our ``initial_point`` was already close to an optimal solution. The next step is to determine whether our QCNN can classify data seen in our test image data set."
msgstr "Como podemos ver desde arriba, la QCNN converge lentamente, por lo que nuestro ``initial_point`` ya estaba cerca de una solución óptima. El siguiente paso es determinar si nuestra QCNN puede clasificar los datos vistos en nuestro conjunto de datos de imágenes de prueba."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:974
msgid "6. Testing our QCNN"
msgstr "6. Probar nuestra QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:985
msgid "After building and training our dataset we now test whether our QCNN can predict images that are not from our test data set."
msgstr "Después de construir y entrenar nuestro conjunto de datos, ahora probamos si nuestra QCNN puede predecir imágenes que no son de nuestro conjunto de datos de prueba."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1052
msgid "From above, we can indeed see that our QCNN can classify horizontal and vertical lines! Congratulations! Through the use of quantum circuits and quantum convolutional and pooling layers, you have built a Quantum Convolutional Neural Network!"
msgstr "¡De lo anterior, podemos ver que nuestra QCNN puede clasificar líneas horizontales y verticales! ¡Felicidades! Mediante el uso de circuitos cuánticos y capas cuánticas convolucionales y de reducción (pooling), ¡has creado una Red Neuronal Cuántica Convolucional!"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1064
msgid "7. References"
msgstr "7. Referencias"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1075
msgid "[1] Cong, I., Choi, S. & Lukin, M.D. Quantum convolutional neural networks. Nat. Phys. 15, 1273–1278 (2019). https://doi.org/10.1038/s41567-019-0648-8"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1077
msgid "[2] IBM Convolutional Neural Networks https://www.ibm.com/cloud/learn/convolutional-neural-networks"
msgstr "[2] IBM Convolutional Neural Networks https://www.ibm.com/cloud/learn/convolutional-neural-networks"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1079
msgid "[3] Vatan, Farrokh, and Colin Williams. \"Optimal quantum circuits for general two-qubit gates.\" Physical Review A 69.3 (2004): 032315."
msgstr ""

