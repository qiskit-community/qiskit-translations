msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-08 23:29+0000\n"
"PO-Revision-Date: 2022-12-13 08:46\n"
"Last-Translator: \n"
"Language-Team: Korean\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ko\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/09_saving_and_loading_models.po\n"
"X-Crowdin-File-ID: 9887\n"
"Language: ko_KR\n"

#: ../../tutorials/09_saving_and_loading_models.ipynb:9
msgid "This page was generated from `docs/tutorials/09_saving_and_loading_models.ipynb`__."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:9
msgid "Saving, Loading Qiskit Machine Learning Models and Continuous Training"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:11
msgid "In this tutorial we will show how to save and load Qiskit machine learning models. Ability to save a model is very important, especially when a significant amount of time is invested in training a model on a real hardware. Also, we will show how to resume training of the previously saved model."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:13
msgid "In this tutorial we will cover how to:"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:15
msgid "Generate a simple dataset, split it into training/test datasets and plot them"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:16
msgid "Train and save a model"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:17
msgid "Load a saved model and resume training"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:18
msgid "Evaluate performance of models"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:19
msgid "PyTorch hybrid models"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:30
msgid "First off, we start from the required imports. We’ll heavily use SciKit-Learn on the data preparation step. In the next cell we also fix a random seed for reproducibility purposes."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:64
msgid "We will be using two quantum simulators, in particular, two instances of the ``Sampler`` primitive. We’ll start training on the first one, then will resume training on the second one. The approach shown in this tutorial can be used to train a model on a real hardware available on the cloud and then re-use the model for inference on a local simulator."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:88
msgid "1. Prepare a dataset"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:90
msgid "Next step is to prepare a dataset. Here, we generate some data in the same way as in other tutorials. The difference is that we apply some transformations to the generated data. We generates ``40`` samples, each sample has ``2`` features, so our features is an array of shape ``(40, 2)``. Labels are obtained by summing up features by columns and if the sum is more than ``1`` then this sample is labeled as ``1`` and ``0`` otherwise."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:114
msgid "Then, we scale down our features into a range of ``[0, 1]`` by applying ``MinMaxScaler`` from SciKit-Learn. Model training convergence is better when this transformation is applied."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:161
msgid "Let’s take a look at the features of the first ``5`` samples of our dataset after the transformation."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:219
msgid "We choose ``VQC`` or Variational Quantum Classifier as a model we will train. This model, by default, takes one-hot encoded labels, so we have to transform the labels that are in the set of ``{0, 1}`` into one-hot representation. We employ SciKit-Learn for this transformation as well. Please note that the input array must be reshaped to ``(num_samples, 1)`` first. The ``OneHotEncoder`` encoder does not work with 1D arrays and our labels is a 1D array. In this case a user must decide either an array has only one feature(our case!) or has one sample. Also, by default the encoder returns sparse arrays, but for dataset plotting it is easier to have dense arrays, so we set ``sparse`` to ``False``."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:267
msgid "Let’s take a look at the labels of the first ``5`` labels of the dataset. The labels should be one-hot encoded."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:325
#, python-format
msgid "Now we split our dataset into two parts: a training dataset and a test one. As a rule of thumb, 80% of a full dataset should go into a training part and 20% into a test one. Our training dataset has ``30`` samples. The test dataset should be used only once, when a model is trained to verify how well the model behaves on unseen data. We employ ``train_test_split`` from SciKit-Learn."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:374
msgid "Now it is time to see how our dataset looks like. Let’s plot it."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:441
msgid "On the plot above we see:"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:443
msgid "Solid blue dots are the samples from the training dataset labeled as ``0``"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:444
msgid "Empty blue dots are the samples from the test dataset labeled as ``0``"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:445
msgid "Solid green dots are the samples from the training dataset labeled as ``1``"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:446
msgid "Empty green dots are the samples from the test dataset labeled as ``1``"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:448
msgid "We’ll train our model using solid dots and verify it using empty dots."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:460
msgid "2. Train a model and save it"
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:462
msgid "We’ll train our model in two steps. On the first step we train our model in ``20`` iterations."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:483
msgid "Create an empty array for callback to store values of the objective function."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:504
msgid "We re-use a callback function from the Neural Network Classifier & Regressor tutorial to plot iteration versus objective function value with some minor tweaks to plot objective values at each step."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:547
msgid "As mentioned above we train a ``VQC`` model and set ``COBYLA`` as an optimizer with a chosen value of the ``maxiter`` parameter. Then we evaluate performance of the model to see how well it was trained. Then we save this model for a file. On the second step we load this model and will continue to work with it."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:549
msgid "Here, we manually construct an ansatz to fix an initial point where to start optimization from."
msgstr "여기에서,  최적화를 시작할 초기 지점을 조정하기 위해 직접 ansatz를 구성한다."

#: ../../tutorials/09_saving_and_loading_models.ipynb:573
msgid "We create a model and set a sampler to the first sampler we created earlier."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:596
msgid "Now it is time to train the model."
msgstr "이제 우리의 모델을 학습해보자."

#: ../../tutorials/09_saving_and_loading_models.ipynb:651
msgid "Let’s see how well our model performs after the first step of training."
msgstr "첫 학습 후에 우리의 모델이 얼마나 잘 수행되는지 보도록 하자."

#: ../../tutorials/09_saving_and_loading_models.ipynb:700
msgid "Next, we save the model. You may choose any file name you want. Please note that the ``save`` method does not append an extension if it is not specified in the file name."
msgstr "다음으로 모델을 저장한다. 원하는 파일 이름을 선택할 수 있다. 파일 이름이 지정되지 않은 경우 ``save`` 메소드는 확장자를 추가하지 않는다."

#: ../../tutorials/09_saving_and_loading_models.ipynb:722
msgid "3. Load a model and continue training"
msgstr "3. 모델을 불러오고 계속 학습하기"

#: ../../tutorials/09_saving_and_loading_models.ipynb:724
msgid "To load a model a user have to call a class method ``load`` of the corresponding model class. In our case it is ``VQC``. We pass the same file name we used in the previous section where we saved our model."
msgstr "모델을 불러오려면 사용자가 해당 모델 클래스의 ``load`` 클래스 메소드를 호출해야 한다. 우리의 경우에는 ``VQC`` 이다. 우리는 이전 섹션에서 사용한 것과 같은 파일 이름을 사용하여 모델을 저장했다."

#: ../../tutorials/09_saving_and_loading_models.ipynb:745
msgid "Next, we want to alter the model in a way it can be trained further and on another simulator. To do so, we set the ``warm_start`` property. When it is set to ``True`` and ``fit()`` is called again the model uses weights from previous fit to start a new fit. We also set the ``sampler`` property of the underlying network to the second instance of the ``Sampler`` primitive we created in the beginning of the tutorial. Finally, we create and set a new optimizer with ``maxiter`` is set to ``80``, so the total number of iterations is ``100``."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:769
msgid "Now we continue training our model from the state we finished in the previous section."
msgstr "이제 이전 섹션을 완료한 상태에서 모델을 계속 학습한다."

#: ../../tutorials/09_saving_and_loading_models.ipynb:862
msgid "Let’s see which data points were misclassified. First, we call ``predict`` to infer predicted values from the training and test features."
msgstr "어떤 데이터 포인트가 잘못 분류되었는지 살펴보자. 우선, 우리는 ``predict`` 를 호출하여 학습 및 테스트 기능으로부터 예측된 값을 추론한다."

#: ../../tutorials/09_saving_and_loading_models.ipynb:884
msgid "Plot the whole dataset and the highlight the points that were classified incorrectly."
msgstr "전체 데이터 세트의 그래프를 그리고, 잘못 분류된 점을 강조 표시한다."

#: ../../tutorials/09_saving_and_loading_models.ipynb:960
msgid "So, if you have a large dataset or a large model you can train it in multiple steps as shown in this tutorial."
msgstr "따라서 거대한 데이터 세트가 있거나 거대한 모델이 있는 경우, 이 튜토리얼에 표시된 여러 단계를 거쳐 학습할 수 있다."

#: ../../tutorials/09_saving_and_loading_models.ipynb:972
msgid "4. PyTorch hybrid models"
msgstr "4. PyTorch 하이브리드 모델"

#: ../../tutorials/09_saving_and_loading_models.ipynb:974
msgid "To save and load hybrid models, when using the TorchConnector, follow the PyTorch recommendations of saving and loading the models. For more details please refer to the PyTorch Connector tutorial `here <https://qiskit.org/documentation/machine-learning/tutorials/05_torch_connector.html>`__ where a short snippet shows how to do it."
msgstr "하이브리드 모델을 저장 및 로드하려면 TorchConnector를 사용하여 모델을 저장 및 로드하는 PyTorch 권장사항을 따른다. 자세한 내용은 PyTorch Connector 지침서 `여기 <https://qiskit.org/documentation/machine-learning/tutorials/05_torch_connector.html>`__ 를 참조하시오. 여기서 짧은 스니펫(snippet)을 통해 이를 수행하는 방법을 알 수 있다."

#: ../../tutorials/09_saving_and_loading_models.ipynb:976
msgid "Take a look at this pseudo-like code to get the idea:"
msgstr "아이디어를 얻기 위해서 다음의 준 유사 코드를 살펴보자."

