msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-08 23:29+0000\n"
"PO-Revision-Date: 2022-11-08 23:45\n"
"Last-Translator: \n"
"Language-Team: Korean\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ko\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/05_torch_connector.po\n"
"X-Crowdin-File-ID: 9636\n"
"Language: ko_KR\n"

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "This page was generated from `docs/tutorials/05_torch_connector.ipynb`__."
msgstr "이 페이지는 `docs/tutorials/05_torch_connector.ipynb`__ 에서 생성되었다."

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector and Hybrid QNNs"
msgstr "토치 커넥터 및 하이브리드 QNN"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial introduces Qiskit’s ``TorchConnector`` class, and demonstrates how the ``TorchConnector`` allows for a natural integration of any ``NeuralNetwork`` from Qiskit Machine Learning into a PyTorch workflow. ``TorchConnector`` takes a Qiskit ``NeuralNetwork`` and makes it available as a PyTorch ``Module``. The resulting module can be seamlessly incorporated into PyTorch classical architectures and trained jointly without additional considerations, enabling the development and testing of novel **hybrid quantum-classical** machine learning architectures."
msgstr "이 튜토리얼에서는 Qiskit의 ``TorchConnector`` 클래스를 소개하고 ``TorchConnector`` 가 Qiskit Machine Learning 에서 PyTorch 워크플로우로 ``NeuralNetwork`` 를 자연스럽게 통합하는 방법을 설명합니다.``TorchConnector`` 는 Qiskit의 ``NeuralNetwork`` 을 받아 PyTorch의 ``Module`` 로 사용할 수 있도록 한다. 결과 모듈은 PyTorch 클래식 아키텍처에 완벽하게 통합되어 추가적인 고려사항 없이 공동으로 train될 수 있으며, 새로운 **양자-고전 하이브리드** 기계 학습 아키텍처를 개발하고 테스트할 수 있다."

#: ../../tutorials/05_torch_connector.ipynb:15
msgid "Content:"
msgstr "내용:"

#: ../../tutorials/05_torch_connector.ipynb:17
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__"
msgstr "`파트 1: 단순 분류 및 회귀 <#Part-1:-Simple-Classification-&-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:19
msgid "The first part of this tutorial shows how quantum neural networks can be trained using PyTorch’s automatic differentiation engine (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) for simple classification and regression tasks."
msgstr "이 튜토리얼의 첫 번째 부분에서는 양자신경망을 간단한 분류 및 회귀 작업을 위해 PyTorch의 자동 분화 엔진 (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) 을 사용하여 어떻게 훈련시킬 수 있는지를 보여 준다."

#: ../../tutorials/05_torch_connector.ipynb:21
msgid "`Classification <#1.-Classification>`__"
msgstr "`분류 <#1.-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:23
msgid "Classification with PyTorch and ``EstimatorQNN``"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:24
msgid "Classification with PyTorch and ``SamplerQNN``"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:26
msgid "`Regression <#2.-Regression>`__"
msgstr "`회귀 <#2.-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:28
msgid "Regression with PyTorch and ``SamplerQNN``"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:30
msgid "`Part 2: MNIST Classification, Hybrid QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"
msgstr "`Part 2: MNIST 분류, 하이브리드 QNN <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"

#: ../../tutorials/05_torch_connector.ipynb:32
msgid "The second part of this tutorial illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow (in this case, a typical CNN architecture) to classify MNIST data in a hybrid quantum-classical manner."
msgstr "이 튜토리얼의 두 번째 부분에서는 하이브리드 양자-고전 방식으로 MNIST 데이터를 분류하기 위해 (이 경우에는 전형적인 CNN 아키텍처인) 대상 PyTorch 워크플로에 (양자) ``NeuralNetwork`` 를 삽입하는 방법을 설명한다."

#: ../../tutorials/05_torch_connector.ipynb:73
msgid "Part 1: Simple Classification & Regression"
msgstr "파트 1: 단순 분류 및 회귀"

#: ../../tutorials/05_torch_connector.ipynb:85
msgid "1. Classification"
msgstr "1. 분류"

#: ../../tutorials/05_torch_connector.ipynb:87
msgid "First, we show how ``TorchConnector`` allows to train a Quantum ``NeuralNetwork`` to solve a classification tasks using PyTorch’s automatic differentiation engine. In order to illustrate this, we will perform **binary classification** on a randomly generated dataset."
msgstr "먼저, 우리는 ``TorchConnector`` 가 PyTorch의 자동 분화엔진을 사용하여 분류 작업을 해결하기 위해 양자 ``NeuralNetwork`` 를 훈련시키는 방법을 설명한다. 이를 설명하기 위해 무작위로 생성된 데이터 세트에 **이진 분류** 를 수행한다."

#: ../../tutorials/05_torch_connector.ipynb:140
msgid "A. Classification with PyTorch and ``EstimatorQNN``"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:142
msgid "Linking an ``EstimatorQNN`` to PyTorch is relatively straightforward. Here we illustrate this by using the ``EstimatorQNN`` constructed from a feature map and an ansatz."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:262
msgid "Optimizer"
msgstr "최적화 도구"

#: ../../tutorials/05_torch_connector.ipynb:264
msgid "The choice of optimizer for training any machine learning model can be crucial in determining the success of our training’s outcome. When using ``TorchConnector``, we get access to all of the optimizer algorithms defined in the [``torch.optim``] package (`link <https://pytorch.org/docs/stable/optim.html>`__). Some of the most famous algorithms used in popular machine learning architectures include *Adam*, *SGD*, or *Adagrad*. However, for this tutorial we will be using the L-BFGS algorithm (``torch.optim.LBFGS``), one of the most well know second-order optimization algorithms for numerical optimization."
msgstr "시스템 학습 모델을 훈련하기 위한 최적화 프로그램을 선택하는 것은 훈련 결과의 성공 여부를 결정하는 데 중요할 수 있다. ``TorchConnector`` 를 사용할 때에는 [``torch.optim``] 패키지 (`link <https://pytorch.org/docs/stable/optim.html>`__) 에서 정의한 모든 최적화 프로그램 알고리즘에 액세스할 수 있다. 인기있는 기계 학습 아키텍처에서 사용되는 가장 유명한 알고리즘들에는 *Adam*, *SGD*, 또는 *Adagrad* 이 포함된다. 그러나 이 튜토리얼에서는 수치 최적화를 위한 가장 잘 알려진 2차 최적화 알고리즘 중 하나인 L-BFGS 알고리즘 (``torch.optim.LBFGS``) 을 사용하게 된다."

#: ../../tutorials/05_torch_connector.ipynb:268
msgid "Loss Function"
msgstr "손실 함수"

#: ../../tutorials/05_torch_connector.ipynb:270
msgid "As for the loss function, we can also take advantage of PyTorch’s pre-defined modules from ``torch.nn``, such as the `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ or `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."
msgstr "손실 함수에 대해서는 `크로스 엔트로피 <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ 또는 `평균 제곱 오차 <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ 손실과 같은 PyTorch ``torch.nn`` 의 사전 정의된 모듈을 이용할 수도 있다."

#: ../../tutorials/05_torch_connector.ipynb:272
msgid "**💡 Clarification :** In classical machine learning, the general rule of thumb is to apply a Cross-Entropy loss to classification tasks, and MSE loss to regression tasks. However, this recommendation is given under the assumption that the output of the classification network is a class probability value in the :math:`[0, 1]` range (usually this is achieved through a Softmax layer). Because the following example for ``EstimatorQNN`` does not include such layer, and we don’t apply any mapping to the output (the following section shows an example of application of parity mapping with ``SamplerQNN``\\ s), the QNN’s output can take any value in the range :math:`[-1, 1]`. In case you were wondering, this is the reason why this particular example uses MSELoss for classification despite it not being the norm (but we encourage you to experiment with different loss functions and see how they can impact training results)."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:482
#: ../../tutorials/05_torch_connector.ipynb:752
msgid "The red circles indicate wrongly classified data points."
msgstr "빨간색 원은 잘못 분류된 데이터 포인트들을 나타낸다."

#: ../../tutorials/05_torch_connector.ipynb:494
msgid "B. Classification with PyTorch and ``SamplerQNN``"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:496
msgid "Linking a ``SamplerQNN`` to PyTorch requires a bit more attention than ``EstimatorQNN``. Without the correct setup, backpropagation is not possible."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:498
msgid "In particular, we must make sure that we are returning a dense array of probabilities in the network’s forward pass (``sparse=False``). This parameter is set up to ``False`` by default, so we just have to make sure that it has not been changed."
msgstr "특히, 우리는 네트워크의 포워드 패스(``sparse=False``) 에서 고밀도의 확률 배열을 반환하고 있는지 확인해야 한다. 이 매개변수는 기본적으로 ``False`` 로 설정되어 있으므로 변경되지 않았는지 확인하기만 하면 된다."

#: ../../tutorials/05_torch_connector.ipynb:500
msgid "**⚠️ Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``SamplerQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.SamplerQNN.html>`__."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:571
#: ../../tutorials/05_torch_connector.ipynb:860
msgid "For a reminder on optimizer and loss function choices, you can go back to `this section <#Optimizer>`__."
msgstr "최적화 함수 및 손실 함수에 대한 자세한 사항은 `최적화 함수 <https://qiskit.org/documentation/machine-learning/tutorials/05_torch_connector.html#Optimizer>`__ 를 통해 확인할 수 있다."

#: ../../tutorials/05_torch_connector.ipynb:764
msgid "2. Regression"
msgstr "2. 회귀"

#: ../../tutorials/05_torch_connector.ipynb:766
msgid "We use a model based on the ``EstimatorQNN`` to also illustrate how to perform a regression task. The chosen dataset in this case is randomly generated following a sine wave."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:807
msgid "A. Regression with PyTorch and ``EstimatorQNN``"
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:818
msgid "The network definition and training loop will be analogous to those of the classification task using ``EstimatorQNN``. In this case, we define our own feature map and ansatz, but let’s do it a little different."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:999
msgid "Part 2: MNIST Classification, Hybrid QNNs"
msgstr "파트 2: MNIST 분류, 하이브리드 QNN"

#: ../../tutorials/05_torch_connector.ipynb:1001
msgid "In this second part, we show how to leverage a hybrid quantum-classical neural network using ``TorchConnector``, to perform a more complex image classification task on the MNIST handwritten digits dataset."
msgstr "이 두 번째 부분에서는 ``TorchConnector`` 를 사용하여 하이브리드 양자-고전 신경망을 활용하여 MNIST 자필 숫자 데이터 셋에 보다 복잡한 이미지 분류 작업을 수행하는 방법을 설명한다."

#: ../../tutorials/05_torch_connector.ipynb:1003
msgid "For a more detailed (pre-``TorchConnector``) explanation on hybrid quantum-classical neural networks, you can check out the corresponding section in the `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."
msgstr "하이브리드 양자-고전 신경망에 대한 보다 자세한 설명 (pre-``TorchConnector``) 에 대해서는 `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__의 해당 섹션을 확인할 수 있다."

#: ../../tutorials/05_torch_connector.ipynb:1042
msgid "Step 1: Defining Data-loaders for train and test"
msgstr "1단계: 훈련 및 테스트를 위한 데이터 로더 정의"

#: ../../tutorials/05_torch_connector.ipynb:1053
msgid "We take advantage of the ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ to directly load a subset of the `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ and define torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) for train and test."
msgstr "우리는 ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ 를 이용하여 `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ 의 서브셋을 직접 로드하고, torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__)를 훈련과 테스트에 사용할 수 있도록 한다."

#: ../../tutorials/05_torch_connector.ipynb:1096
msgid "If we perform a quick visualization we can see that the train dataset consists of images of handwritten 0s and 1s."
msgstr "빠른 시각화를 수행하는 경우 훈련 데이터 셋이 손으로 쓴 0과 1의 이미지로 구성되어 있음을 알 수 있다."

#: ../../tutorials/05_torch_connector.ipynb:1170
msgid "Step 2: Defining the QNN and Hybrid Model"
msgstr "단계 2: QNN및 하이브리드 모델 정의"

#: ../../tutorials/05_torch_connector.ipynb:1181
msgid "This second step shows the power of the ``TorchConnector``. After defining our quantum neural network layer (in this case, a ``EstimatorQNN``), we can embed it into a layer in our torch ``Module`` by initializing a torch connector as ``TorchConnector(qnn)``."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:1183
msgid "**⚠️ Attention:** In order to have an adequate gradient backpropagation in hybrid models, we MUST set the initial parameter ``input_gradients`` to TRUE during the qnn initialization."
msgstr "**⚠️ 주의:** 하이브리드 모델에서 적절한 그라디언트 역전파를 수행하려면 qnn 초기화 중에 초기 매개변수 ``input_gradients`` 를 TRUE로 설정해야 한다."

#: ../../tutorials/05_torch_connector.ipynb:1262
msgid "Step 3: Training"
msgstr "단계 3: 훈련"

#: ../../tutorials/05_torch_connector.ipynb:1376
msgid "Now we’ll save the trained model, just to show how a hybrid model can be saved and re-used later for inference. To save and load hybrid models, when using the TorchConnector, follow the PyTorch recommendations of saving and loading the models."
msgstr "이제 훈련된 모델을 저장하여, 이후 하이브리드 모델이 어떻게 저장되고 재사용되어 추론에 사용되는지 알아볼 것이다. TorchConnector을 사용하는 경우, 하이브리드 모델을 저장 및 불러오려면 PyTorch의 모델 저장 및 불러오기 권고 사항을 따른다."

#: ../../tutorials/05_torch_connector.ipynb:1398
msgid "Step 4: Evaluation"
msgstr "단계 4: 평가"

#: ../../tutorials/05_torch_connector.ipynb:1409
msgid "We start from recreating the model and loading the state from the previously saved file. You create a QNN layer using another simulator or a real hardware. So, you can train a model on real hardware available on the cloud and then for inference use a simulator or vice verse. For a sake of simplicity we create a new quantum neural network in the same way as above."
msgstr "모델을 다시 생성하고 이전에 저장된 파일에서 상태를 불러오는 것부터 시작한다. 다른 시뮬레이터나 실제 하드웨어로 QNN 계층을 만든다. 그리고 클라우드에서 사용할 수 있는 실제 하드웨어에서 모델을 훈련시키고 추론은 시뮬레이터로 하거나 또는 반대로 할 수도 있다. 간단하게, 위와 같이 새로운 양자 신경망을 만든다."

#: ../../tutorials/05_torch_connector.ipynb:1557
msgid "🎉🎉🎉🎉 **You are now able to experiment with your own hybrid datasets and architectures using Qiskit Machine Learning.** **Good Luck!**"
msgstr "🎉🎉🎉🎉 **이제 Qiskit Machine Learning을 사용하여 자체 하이브리드 데이터 세트 및 아키텍처를 실험할 수 있다. ** **행운을 빈다!**"

