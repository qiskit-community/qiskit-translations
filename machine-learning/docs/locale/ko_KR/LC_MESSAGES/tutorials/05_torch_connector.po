msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-08 17:14-0400\n"
"PO-Revision-Date: 2021-07-13 19:51\n"
"Last-Translator: \n"
"Language-Team: Korean\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ko\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/05_torch_connector.po\n"
"X-Crowdin-File-ID: 9636\n"
"Language: ko_KR\n"

#: ../../tutorials/05_torch_connector.ipynb:13
msgid "Run interactively in jupyter notebook."
msgstr "Jupyter 노트북에서 대화식으로 실행하라."

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector and Hybrid QNNs"
msgstr "토치 커넥터 및 하이브리드 QNN"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial introduces Qiskit’s ``TorchConnector`` class, and demonstrates how the ``TorchConnector`` allows for a natural integration of any ``NeuralNetwork`` from Qiskit Machine Learning into a PyTorch workflow. ``TorchConnector`` takes a Qiskit ``NeuralNetwork`` and makes it available as a PyTorch ``Module``. The resulting module can be seamlessly incorporated into PyTorch classical architectures and trained jointly without additional considerations, enabling the development and testing of novel **hybrid quantum-classical** machine learning architectures."
msgstr "이 튜토리얼에서는 Qiskit의 ``TorchConnector`` 클래스를 소개하고 ``TorchConnector`` 가 Qiskit Machine Learning 에서 PyTorch 워크플로우로 ``NeuralNetwork`` 를 자연스럽게 통합하는 방법을 설명합니다.``TorchConnector`` 는 Qiskit의 ``NeuralNetwork`` 을 받아 PyTorch의 ``Module`` 로 사용할 수 있도록 한다. 결과 모듈은 PyTorch 클래식 아키텍처에 완벽하게 통합되어 추가적인 고려사항 없이 공동으로 train될 수 있으며, 새로운 **양자-고전 하이브리드** 기계 학습 아키텍처를 개발하고 테스트할 수 있다."

#: ../../tutorials/05_torch_connector.ipynb:15
msgid "Content:"
msgstr "내용:"

#: ../../tutorials/05_torch_connector.ipynb:17
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__"
msgstr "`파트 1: 단순 분류 및 회귀 <#Part-1:-Simple-Classification-&-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:19
msgid "The first part of this tutorial shows how quantum neural networks can be trained using PyTorch’s automatic differentiation engine (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) for simple classification and regression tasks."
msgstr "이 튜토리얼의 첫 번째 부분에서는 양자신경망을 간단한 분류 및 회귀 작업을 위해 PyTorch의 자동 분화 엔진 (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) 을 사용하여 어떻게 훈련시킬 수 있는지를 보여 준다."

#: ../../tutorials/05_torch_connector.ipynb:21
msgid "`Classification <#1.-Classification>`__"
msgstr "`분류 <#1.-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:23
msgid "Classification with PyTorch and ``OpflowQNN``"
msgstr "PyTorch와 ``OpflowQNN`` 을 이용한 분류"

#: ../../tutorials/05_torch_connector.ipynb:24
msgid "Classification with PyTorch and ``CircuitQNN``"
msgstr "PyTorch와 ``CircuitQNN`` 을 이용한 분류"

#: ../../tutorials/05_torch_connector.ipynb:26
msgid "`Regression <#2.-Regression>`__"
msgstr "`회귀 <#2.-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:28
msgid "Regression with PyTorch and ``OpflowQNN``"
msgstr "PyTorch와 ``OpflowQNN`` 을 통한 회귀"

#: ../../tutorials/05_torch_connector.ipynb:30
msgid "`Part 2: MNIST Classification, Hybrid QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"
msgstr "`Part 2: MNIST 분류, 하이브리드 QNN <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"

#: ../../tutorials/05_torch_connector.ipynb:32
msgid "The second part of this tutorial illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow (in this case, a typical CNN architecture) to classify MNIST data in a hybrid quantum-classical manner."
msgstr "이 튜토리얼의 두 번째 부분에서는 하이브리드 양자-고전 방식으로 MNIST 데이터를 분류하기 위해 (이 경우에는 전형적인 CNN 아키텍처인) 대상 PyTorch 워크플로에 (양자) ``NeuralNetwork`` 를 삽입하는 방법을 설명한다."

#: ../../tutorials/05_torch_connector.ipynb:74
msgid "Part 1: Simple Classification & Regression"
msgstr "파트 1: 단순 분류 및 회귀"

#: ../../tutorials/05_torch_connector.ipynb:86
msgid "1. Classification"
msgstr "1. 분류"

#: ../../tutorials/05_torch_connector.ipynb:88
msgid "First, we show how ``TorchConnector`` allows to train a Quantum ``NeuralNetwork`` to solve a classification tasks using PyTorch’s automatic differentiation engine. In order to illustrate this, we will perform **binary classification** on a randomly generated dataset."
msgstr "먼저, 우리는 ``TorchConnector`` 가 PyTorch의 자동 분화엔진을 사용하여 분류 작업을 해결하기 위해 양자 ``NeuralNetwork`` 를 훈련시키는 방법을 설명한다. 이를 설명하기 위해 무작위로 생성된 데이터 세트에 **이진 분류** 를 수행한다."

#: ../../tutorials/05_torch_connector.ipynb:144
msgid "A. Classification with PyTorch and ``OpflowQNN``"
msgstr "A. PyTorch와 ``OpflowQNN`` 을 이용한 분류"

#: ../../tutorials/05_torch_connector.ipynb:146
msgid "Linking an ``OpflowQNN`` to PyTorch is relatively straightforward. Here we illustrate this using the ``TwoLayerQNN``, a sub-case of ``OpflowQNN`` introduced in previous tutorials."
msgstr "``OpflowQNN`` 을 PyTorch로 연결하는 것은 비교적 간단하다. 여기에서는 이전 튜토리얼에서 소개한 ``OpflowQNN`` 의 서브 케이스인 ``TwoLayerQNN``을 사용하여 이를 설명한다."

#: ../../tutorials/05_torch_connector.ipynb:254
msgid "Optimizer"
msgstr "최적화 도구"

#: ../../tutorials/05_torch_connector.ipynb:256
msgid "The choice of optimizer for training any machine learning model can be crucial in determining the success of our training’s outcome. When using ``TorchConnector``, we get access to all of the optimizer algorithms defined in the [``torch.optim``] package (`link <https://pytorch.org/docs/stable/optim.html>`__). Some of the most famous algorithms used in popular machine learning architectures include *Adam*, *SGD*, or *Adagrad*. However, for this tutorial we will be using the L-BFGS algorithm (``torch.optim.LBFGS``), one of the most well know second-order optimization algorithms for numerical optimization."
msgstr "시스템 학습 모델을 훈련하기 위한 최적화 프로그램을 선택하는 것은 훈련 결과의 성공 여부를 결정하는 데 중요할 수 있다. ``TorchConnector`` 를 사용할 때에는 [``torch.optim``] 패키지 (`link <https://pytorch.org/docs/stable/optim.html>`__) 에서 정의한 모든 최적화 프로그램 알고리즘에 액세스할 수 있다. 인기있는 기계 학습 아키텍처에서 사용되는 가장 유명한 알고리즘들에는 *Adam*, *SGD*, 또는 *Adagrad* 이 포함된다. 그러나 이 튜토리얼에서는 수치 최적화를 위한 가장 잘 알려진 2차 최적화 알고리즘 중 하나인 L-BFGS 알고리즘 (``torch.optim.LBFGS``) 을 사용하게 된다."

#: ../../tutorials/05_torch_connector.ipynb:260
msgid "Loss Function"
msgstr "손실 함수"

#: ../../tutorials/05_torch_connector.ipynb:262
msgid "As for the loss function, we can also take advantage of PyTorch’s pre-defined modules from ``torch.nn``, such as the `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ or `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."
msgstr "손실 함수에 대해서는 `크로스 엔트로피<https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>` 또는 `평균 제곱 오차 <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ 손실과 같은 PyTorch ``torch.nn`` 의 사전 정의된 모듈을 이용할 수도 있다."

#: ../../tutorials/05_torch_connector.ipynb:264
msgid "**💡 Clarification :** In classical machine learning, the general rule of thumb is to apply a Cross-Entropy loss to classification tasks, and MSE loss to regression tasks. However, this recommendation is given under the assumption that the output of the classification network is a class probability value in the [0,1] range (usually this is achieved through a Softmax layer). Because the following example for ``TwoLayerQNN`` does not include such layer, and we don’t apply any mapping to the output (the following section shows an example of application of parity mapping with ``CircuitQNNs``), the QNN’s output can take any value in the range [-1,1]. In case you were wondering, this is the reason why this particular example uses MSELoss for classification despite it not being the norm (but we encourage you to experiment with different loss functions and see how they can impact training results)."
msgstr "**💡 설명: ** 고전적인 머신러닝에서 일반적으로는 분류 작업에 교차 엔트로피 손실을 적용하고 MSE 손실을 회귀 작업에 적용한다. 그러나, 이것은 분류 네트워크의 출력이 [0, 1] 범위 내의 클래스 확률 값이라는 가정 하에 추천하는 사항이다 (보통 이것은 Softmax 층을 통해 달성된다). ``TwoLayerQNN`` 에 대한 다음 예제는 이러한 레이어를 포함하지 않고, 출력에 어떠한 매핑도 적용하지 않기 때문에 (다음 섹션에서는 ``CircuitQNNs`` 를 사용한 패리티 매핑을 적용한 예를 보여준다), QNN의 출력은 [-1, 1] 범위의 값을 취할 수 있다. 여러분이 궁금해할 경우를 대비해, 이것이 노름(norm) 이 아닌데도 불구하고 MSELoss를 사용하는 이유라는 것을 밝혀둔다 (하지만 우리는 당신이 다른 손실 함수를 사용하여 실험하고 훈련 결과에 어떤 영향을 미칠 수 있는지 알아보는 것을 권장한다)."

#: ../../tutorials/05_torch_connector.ipynb:442
#: ../../tutorials/05_torch_connector.ipynb:674
msgid "The red circles indicate wrongly classified data points."
msgstr "빨간색 원은 잘못 분류된 데이터 포인트들을 나타낸다."

#: ../../tutorials/05_torch_connector.ipynb:454
msgid "B. Classification with PyTorch and ``CircuitQNN``"
msgstr "B. Pytorch와 ``CircuitQNN`` 를 이용한 분류"

#: ../../tutorials/05_torch_connector.ipynb:456
msgid "Linking an ``CircuitQNN`` to PyTorch requires a bit more attention than ``OpflowQNN``. Without the correct setup, backpropagation is not possible."
msgstr "``CircuitQNN`` 을 PyTorch에 연결하는 것은 ``OpflowQNN`` 보다 좀 더 주의를 요하는 것이다. 정확한 설정이 없다면, 역전파는 불가능하다."

#: ../../tutorials/05_torch_connector.ipynb:458
msgid "In particular, we must make sure that we are returning a dense array of probabilities in the network’s forward pass (``sparse=False``). This parameter is set up to ``False`` by default, so we just have to make sure that it has not been changed."
msgstr "특히, 우리는 네트워크의 포워드 패스(``sparse=False``) 에서 고밀도의 확률 배열을 리턴하고 있는지 확인해야 한다. 이 매개변수는 기본적으로 ``False`` 로 설정되어 있으므로 변경되지 않았는지 확인하기만 하면 된다."

#: ../../tutorials/05_torch_connector.ipynb:460
msgid "**⚠️ Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``CircuitQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."
msgstr "**⚠️ 주의: ** 사용자 정의 해석 함수를 정의하는 경우 (예: ``parity``), 원하는 출력 형태를 명시적으로 제공해야 한다 (예:``2``). ``CircuitQNN`` 에 대한 초기 매개변수 설정에 대한 자세한 정보는`공식 Qiskit 문서 <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__를 참고하여라."

#: ../../tutorials/05_torch_connector.ipynb:523
#: ../../tutorials/05_torch_connector.ipynb:815
msgid "For a reminder on optimizer and loss function choices, you can go back to `this section <#Optimizer>`__."
msgstr "옵티마이저 및 손실 함수 선택사항에 대해서는 `이 섹션 <#Optimizer>`__으로 돌아갈 수 있음을 기억해라."

#: ../../tutorials/05_torch_connector.ipynb:686
msgid "2. Regression"
msgstr "2. 회귀"

#: ../../tutorials/05_torch_connector.ipynb:688
msgid "We use a model based on the ``TwoLayerQNN`` to also illustrate how to perform a regression task. The chosen dataset in this case is randomly generated following a sine wave."
msgstr "회귀 작업을 수행하는 방법을 설명하기 위해 ``TwoLayerQNN`` 을 기반으로 한 모델을 사용한다. 이 경우 선택한 데이터 셋은 사인파를 따라 무작위로 생성된다."

#: ../../tutorials/05_torch_connector.ipynb:730
msgid "A. Regression with PyTorch and ``OpflowQNN``"
msgstr "A. PyTorch와 ``OpflowQNN`` 을 통한 회귀"

#: ../../tutorials/05_torch_connector.ipynb:741
msgid "The network definition and training loop will be analogous to those of the classification task using ``TwoLayerQNN``. In this case, we define our own feature map and ansatz, instead of using the default values."
msgstr "네트워크 정의와 훈련 루프는 ``TwoLayerQNN`` 을 사용하는 분류작업과 유사하게 될 것이다. 이 경우에 우리는 기본 값들을 사용하는 대신 우리만의 feature map과 ansatz를 정의한다."

#: ../../tutorials/05_torch_connector.ipynb:963
msgid "Part 2: MNIST Classification, Hybrid QNNs"
msgstr "파트 2: MNIST 분류, 하이브리드 QNN"

#: ../../tutorials/05_torch_connector.ipynb:965
msgid "In this second part, we show how to leverage a hybrid quantum-classical neural network using ``TorchConnector``, to perform a more complex image classification task on the MNIST handwritten digits dataset."
msgstr "이 두 번째 부분에서는 ``TorchConnector`` 를 사용하여 하이브리드 양자-고전 신경망을 활용하여 MNIST 자필 숫자 데이터 셋에 보다 복잡한 이미지 분류 작업을 수행하는 방법을 설명한다."

#: ../../tutorials/05_torch_connector.ipynb:967
msgid "For a more detailed (pre-``TorchConnector``) explanation on hybrid quantum-classical neural networks, you can check out the corresponding section in the `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."
msgstr "하이브리드 양자-고전 신경망에 대한 보다 자세한 설명 (pre-``TorchConnector``) 에 대해서는 `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__의 해당 섹션을 확인할 수 있다."

#: ../../tutorials/05_torch_connector.ipynb:996
msgid "Step 1: Defining Data-loaders for train and test"
msgstr "1단계: 훈련 및 테스트를 위한 데이터 로더 정의"

#: ../../tutorials/05_torch_connector.ipynb:1007
msgid "We take advantage of the ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ to directly load a subset of the `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ and define torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) for train and test."
msgstr "우리는 ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ 를 이용하여 `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ 의 서브셋을 직접 로드하고, torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__)를 훈련과 테스트에 사용할 수 있도록 한다."

#: ../../tutorials/05_torch_connector.ipynb:1048
msgid "If we perform a quick visualization we can see that the train dataset consists of images of handwritten 0s and 1s."
msgstr "빠른 시각화를 수행하는 경우 훈련 데이터 셋이 손으로 쓴 0과 1의 이미지로 구성되어 있음을 알 수 있다."

#: ../../tutorials/05_torch_connector.ipynb:1120
msgid "Step 2: Defining the QNN and Hybrid Model"
msgstr "단계 2: QNN및 하이브리드 모델 정의"

#: ../../tutorials/05_torch_connector.ipynb:1131
msgid "This second step shows the power of the ``TorchConnector``. After defining our quantum neural network layer (in this case, a ``TwoLayerQNN``), we can embed it into a layer in our torch ``Module`` by initializing a torch connector as ``TorchConnector(qnn)``."
msgstr "이 두 번째 단계는 ``TorchConnector`` 의 힘을 보여주고 있다. 우리의 양자신경망 (이 경우에는 ``TwoLayerQNN`` )을 정의한 후 torch connector를 ``TorchConnector(qnn)`` 로 초기화함으로써 우리는 Torch의 ``Module`` 에 있는 레이어에 끼워 넣을 수 있다."

#: ../../tutorials/05_torch_connector.ipynb:1133
msgid "**⚠️ Attention:** In order to have an adequate gradient backpropagation in hybrid models, we MUST set the initial parameter ``input_gradients`` to TRUE during the qnn initialization."
msgstr "**⚠️ 주의:** 하이브리드 모델에서 적절한 그라디언트 역전파를 수행하려면 qnn 초기화 중에 초기 매개변수 ``input_gradients`` 를 TRUE로 설정해야 한다."

#: ../../tutorials/05_torch_connector.ipynb:1235
msgid "Step 3: Training"
msgstr "단계 3: 훈련"

#: ../../tutorials/05_torch_connector.ipynb:1337
msgid "Step 4: Evaluation"
msgstr "단계 4: 평가"

#: ../../tutorials/05_torch_connector.ipynb:1440
msgid "🎉🎉🎉🎉 **You are now able to experiment with your own hybrid datasets and architectures using Qiskit Machine Learning.** **Good Luck!**"
msgstr "🎉🎉🎉🎉 **이제 Qiskit Machine Learning을 사용하여 자체 하이브리드 데이터 세트 및 아키텍처를 실험할 수 있다. ** **행운을 빈다!**"

