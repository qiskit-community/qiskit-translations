msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-08 23:29+0000\n"
"PO-Revision-Date: 2022-11-08 23:46\n"
"Last-Translator: \n"
"Language-Team: Korean\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ko\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/11_quantum_convolutional_neural_networks.po\n"
"X-Crowdin-File-ID: 9840\n"
"Language: ko_KR\n"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/11_quantum_convolutional_neural_networks.ipynb`__."
msgstr "이 페이지는 `docs/tutorials/11_quantum_convolutional_neural_networks.ipynb`__ 에서 생성되었다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:9
msgid "The Quantum Convolution Neural Network"
msgstr "양자 합성곱 신경망"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:21
msgid "1. Introduction"
msgstr "1. 소개"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:32
msgid "Throughout this tutorial, we discuss a Quantum Convolutional Neural Network (QCNN), first proposed by Cong et. al. [1]. We implement such a QCNN on Qiskit by modeling both the convolutional layers and pooling layers using a quantum circuit. After building such a network, we train it to differentiate horizontal and vertical lines from a pixelated image. The following tutorial is thus divided accordingly;"
msgstr "이 튜토리얼을 통해 Cong et, al. [1] 에서 처음 제안한 양자 합성곱 신경망(QCNN)에 대해 다뤄볼 것이다. 양자 회로를 사용하여 합성곱 층과 풀링 층을 모델링하여 Qiskit에 QCNN을 구현한다. 이러한 네트워크를 구축한 후 픽셀화된 이미지에서 수평선과 수직선을 구별하도록 훈련한다. 다음의 튜토리얼은 아래 목차와 같이 구성되어있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:34
msgid "Differences between a QCNN and CCNN"
msgstr "QCNN과 CCNN의 차이점"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:35
msgid "Components of a QCNN"
msgstr "QCNN의 구성 요소"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:36
msgid "Data Generation"
msgstr "데이터 생성"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:37
msgid "Building a QCNN"
msgstr "QCNN 구축"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:38
msgid "Training our QCNN"
msgstr "QCNN 학습"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:39
msgid "Testing our QCNN"
msgstr "QCNN 테스트"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:40
msgid "References"
msgstr "참고문헌"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:42
msgid "We first begin by importing the libraries and packages we will need for this tutorial."
msgstr "먼저 이 튜토리얼에 필요한 라이브러리와 패키지를 불러온다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:78
msgid "1. Differences between a QCNN and CCNN"
msgstr "1. QCNN과 CCNN의 차이점"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:90
msgid "1.1 Classical Convolutional Neural Networks"
msgstr "1.1 고전 합성곱 신경망"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:101
msgid "Classical Convolutional Neural Networks (CCNNs) are a subclass of artificial neural networks which have the ability to determine particular features and patterns of a given input. Because of this, they are commonly used in image recognition and audio processing."
msgstr "고전 합성곱 신경망(CCNN)은 입력의 특정한 특징과 패턴을 결정할 수 있는 인공 신경망의 하위 개념이다. 이 같은 이유로 이미지 인식 및 오디오 처리에 일반적으로 사용된다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:103
msgid "The capability of determining features is a result of the two types of layers used in a CCNN, the convolutional layer and pooling layer."
msgstr "CCNN에서 사용되는 합성곱 층과 풀링 층을 이용해서 입력데이터의 특징을 추출할 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:105
msgid "An example of a CCNN can be seen in Figure 1, where a CCNN is trained to determine whether an input image either contains a cat or a dog. To do so, the input image passes through a series of alternating convolutional (C) and pooling layers (P), all of which detect patterns and associate each pattern to a cat or a dog. The fully connected layer (FC) provides us with an output which allows us to determine whether the input image was a cat or dog."
msgstr "그림 1의 CCNN 모델은 입력 이미지가 고양이 혹은 개를 포함하는지 판단하도록 학습되었다. 이를 위해 입력 이미지는 일련의 합성곱 층(C)과 풀링 층(P)을 교대로 통과한하고, 모든 층에서 패턴을 감지되고 각 패턴이 고양이 또는 개와 연결한다. 전결합 층(FC)은 입력 이미지가 고양이인지 개인지를 결정할 수 있는 출력을 제공한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:107
msgid "The convolutional layer makes use of a kernel, which can determine features and patterns of a particular input. An example of this is feature detection in an image, where different layers detect particular patterns in the input image. This is demonstrated in Figure 1, where the :math:`l^{th}` layer recognizes features and patterns along the :math:`ij` plane. It can then associate such features with a given output in the training process, and can use this process to train the dataset."
msgstr "합성곱 층은 특정 입력의 특징 및 패턴을 판단할 수 있는 커널을 사용한다. 이것의 예는 이미지에서의 특징 검출이며, 여기서 각각의 층들은 입력 이미지 내의 특정 패턴들을 검출한다. 이는 :math:`ij` 평면을 따라 특징 및 패턴을 인식하는  :math:`l^{th}` 층이 있는 그림 1에 도시되어 있다. 그런 다음 이러한 특징을 학습 과정에서 주어진 출력과 연관시킬 수 있으며, 이러한 과정을 통해 데이터셋을 학습할 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:109
msgid "On the other hand, a pooling layer reduces the dimensionality of the input data, reducing the computational cost and amount of learning parameters in the CCNN. A schematic of a CCNN can be seen below."
msgstr "한편, 풀링 층은 입력 데이터의 차원수를 감소시키고, CCNN 에서 학습 매개변수의 양과 연산 비용을 감소시킨다. CCNN의 개략도는 아래에서 볼 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:111
msgid "For further information on CCNN, see [2]."
msgstr "CCNN에 대한 추가 정보는 [2]를 참조하십시오."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:122
msgid "|Screenshot%202022-08-09%20at%2017.03.09.png| Figure 1. A schematic demonstration of the use of a CCNN to classify between images of a cat and dog. Here, we see the several convolutional and pooling layers being applied, all of which are decreasing in dimensionality due to the use of the pooling layers. The output of the CCNN determines whether the input image was a cat or dog. Image obtained form [1]."
msgstr "|Screenshot%202022-08-09%20at%2017.03.09.png| Figure 1. CCNN을 사용하여 고양이와 개의 이미지를 분류하는 개략적인 시연이다. 풀링 층의 사용으로 인해 차원수가 감소하는 여러 합성곱 층과 풀링 층이 적용되는 것을 볼 수 있다. CCNN의 출력을 통해 입력 이미지가 고양이인지 개인지를 결정한다. [1] 에서 가져온 이미지이다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:124
msgid "Screenshot%202022-08-09%20at%2017.03.09.png"
msgstr "Screenshot%202022-08-09%20at%2017.03.09.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:136
msgid "1.2 Quantum Convolutional Neural Networks"
msgstr "1.2 양자 합성곱 신경망"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:147
msgid "Quantum Convolutional Neural Networks (QCNN) behave in a similar manner to CCNNs. First, we encode our pixelated image into a quantum circuit using a given feature map, such Qiskit’s ZFeatureMap or ZZFeatureMap or others available in the circuit library."
msgstr "양자 합성곱 신경망(QCNN)은 CCNN과 유사한 방식으로 동작한다. Qiskit의 ZFeatureMap 또는 ZZFeatureMap과 같은 주어진 특성 지도를 사용하여 이미지의 픽셀 값을 양자 회로로 인코딩한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:149
msgid "After encoding our image, we apply alternating convolutional and pooling layers, as defined in the next section. By applying these alternating layers, we reduce the dimensionality of our circuit until we are left with one qubit. We can then classify our input image by measuring the output of this one remaining qubit."
msgstr "이미지를 인코딩한 후 다음 섹션에서 정의된 대로 합성곱 층과 풀링 층을 교대로 적용한다. 이러한 층들을 교대로 적용함으로써, 회로의 차원을 큐비트가 한개만 남을 때까지 감소시킨다. 그런 다음 이 남은 큐비트의 출력을 측정하여 입력 이미지를 분류할 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:151
msgid "The Quantum Convolutional Layer will consist of a series of two qubit unitary operators, which recognize and determine relationships between the qubits in our circuit. This unitary gates are defined below in the next section."
msgstr "양자 합성곱 층은 회로의 큐비트 간의 관계를 인식하고 결정하는 두 개의 큐비트 유니타리 연산자로 구성된다. 이 유니타리 게이트는 다음 섹션에서 아래에 정의된다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:153
msgid "For the Quantum Pooling Layer, we cannot do the same as is done classically to reduce the dimension, i.e. the number of qubits in our circuit. Instead, we reduce the number of qubits by performing operations upon each until a specific point and then disregard certain qubits in a specific layer. It is these layers where we stop performing operations on certain qubits that we call our ‘pooling layer’. Details of the pooling layer is discussed further in the next section."
msgstr "양자 풀링 층의 경우, 회로의 큐비트 수와 같은 차원수를 줄이기 위해 고전적으로 행해진 것과 같은 것을 할 수 없다. 대신, 특정 지점까지 각각에 대한 작업을 수행한 다음 특정 층의 특정 큐비트를 무시함으로써 큐비트의 수를 줄인다. 이러한 것을 '풀링 층'이라고 부르고 특정 큐비트에서 작업을 수행하는 것을 중단하는 층이다. 풀링 층에 대한 자세한 내용은 다음 섹션에서 자세히 설명한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:155
msgid "In the QCNN, each layer contains parametrized circuits, meaning we alter our output result by adjusting the parameters of each layer. When training our QCNN, it is these parameters that are adjusted to reduce the loss function of our QCNN."
msgstr "QCNN에서 각 층은 매개 변수화된 회로를 포함하며, 각 층의 매개 변수를 조정하여 출력 결과를 변경한다는 것을 의미한다. QCNN을 학습할 때 이러한 매개 변수는 QCNN의 손실 함수를 줄이기 위해 조정된다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:166
msgid "A simple example of four qubit QCNN can be seen below."
msgstr "4개의 큐비트 QCNN의 간단한 예는 아래에서 볼 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:177
msgid "|figure2.png|"
msgstr "|figure2.png|"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:179
msgid "figure2.png"
msgstr "figure2.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:190
msgid "Figure 2: Example QCNN containing four qubits. The first Convolutional Layer acts on all the qubits. This is followed by the first pooling layer, which reduces the dimensionality of the QCNN from four qubits to two qubits by disregarding the first two. The second Convolutional layer then detects features between the two qubits still in use in the QCNN, followed by another pooling layer, which reduces the dimensionality from two qubits to one, which will be our output qubit."
msgstr "그림 2: 4개의 큐비트를 포함하는 QCNN의 예시. 첫 번째 합성곱 층은 모든 큐비트에 작용한다. 이는 첫 번째 풀링 층에 이어 첫 번째 두 개를 무시하여 QCNN의 차원수를 4개의 큐비트에서 2개의 큐비트로 감소시킨다. 그런 다음 두 번째 합성곱 층 QCNN에서 여전히 사용 중인 두 큐비트 사이의 특징을 감지하고 이어서 다른 풀링 층을 감지하여 2개의 큐비트에서 출력 큐비트가 되는 1개의 큐비트로 차원수를 감소시킨다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:202
msgid "2. Components of a QCNN"
msgstr "2. QCNN의 구성요소"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:213
msgid "As discussed in Section 1 of this tutorial, a CCNN will contain both convolutional and pooling layers. Here, we define these layers for the QCNN in terms of gates applied to a Quantum Circuit and demonstrate an example for each layer for 4 qubits."
msgstr "이 튜토리얼의 섹션 1에서 논의한 바와 같이, CCNN은 합성곱 층과 풀링 층을 모두 포함할 것이다. 여기서, 양자 회로에 적용되는 게이트의 관점에서 QCNN에 대한 이러한 층을 정의하고 4개의 큐비트에 대한 각 층의 예를 보여준다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:215
msgid "Each of these layers will contain parameters which are tuned throughout the training process to minimize the loss function and train the QCNN to classify between horizontal and vertical lines."
msgstr "이러한 각 층에는 손실 함수를 최소화하고 QCNN이 수평선과 수직선 사이를 분류하도록 학습하기 위해 학습 과정 전반에 걸쳐 조정된 매개 변수가 포함된다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:217
msgid "In theory, one could apply any parametrized circuit for both the convolutional and pooling layers of our network. For example in [2], the Gellmann Matrices (which are the three dimensional generalization of the Pauli Matrices) are used as generators for each unitary gate acting on a pair of qubits."
msgstr "이론적으로, 네트워크의 합성곱 층과 풀링 층 모두에 매개 변수화된 회로를 적용할 수 있다. 예를 들어 [2] 에서 (파울리 행렬의 3차원 일반화인) Gellmann 행렬은 한 쌍의 큐비트에 작용하는 각 유니타리 게이트의 생성기로 사용된다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:219
msgid "Here, we take a different approach and form our parametrized circuit based on the two qubit unitary as proposed in [3]. This states that every unitary matrix in :math:`U(4)` can be decomposed such that"
msgstr "여기서, 다른 접근법을 취하고 [3] 에서 제안된 것처럼 두 개의 큐비트 유니타리를 기반으로 매개 변수화된 회로를 형성한다. 이것은 :math:`U(4)` 의 모든 유니타리 행렬이 다음과 같이 분해될 수 있음을 나타낸다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:221
msgid "U = (A_1 \\otimes A_2) \\cdot N(\\alpha, \\beta, \\gamma) \\cdot (A_3 \\otimes A_4)\n\n"
msgstr "U = (A_1 \\otimes A_2) \\cdot N(\\alpha, \\beta, \\gamma) \\cdot (A_3 \\otimes A_4)\n\n"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:223
msgid "where :math:`A_j \\in \\text{SU}(2)`, :math:`\\otimes` is the tensor product, and :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])`, where :math:`\\alpha, \\beta, \\gamma` are the parameters that we can adjust."
msgstr "여기서 :math:`A_j \\in \\text{SU}(2)` 이고, :math:`\\otimes` 는 텐서 곱이며 :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])` 에서의 :math:`\\alpha, \\beta, \\gamma` 는 조절할 수 있는 매개 변수이다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:225
msgid "From this, it is evident that each unitary depends on 15 parameters and implies that in order for the QCNN to be able to span the whole Hilbert space, each unitary in our QCNN must contain 15 parameters each."
msgstr "이로부터, 각 유니타리는 15개의 매개 변수에 의존한다는 것이 분명하며, QCNN이 전체 힐베르트 공간을 포괄할 수 있으려면 QCNN의 각 유니타리가 각각 15개의 매개 변수를 포함해야 한다는 것을 암시한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:227
msgid "Tuning this large amount of parameters would be difficult and would lead to long training times. To overcome this problem, we restrict our ansatz to a particular subspace of the Hilbert space and define the two qubit unitary gate as :math:`N(\\alpha, \\beta, \\gamma)`. These two qubit unitaries, as seen in [3] can be seen below and are applied to all neighboring qubits each of the layers in the QCNN."
msgstr "이렇게 많은 양의 매개변수를 조정하는 것은 어렵고 긴 학습 시간이 필요할 것이다. 이 문제를 극복하기 위해, ansatz를 힐베르트 공간의 특정 하위 공간으로 제한하고 2 큐비트 유니타리 게이트를 :math:`N(\\alpha, \\beta, \\gamma)` 로 정의한다. [3] 에서 볼 수 있는 이 2 큐비트 유니타리들은 아래에서 볼 수 있으며 QCNN의 각 층에 대한 모든 인접 큐비트에 적용된다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:229
msgid "Note that by only using :math:`N(\\alpha, \\beta, \\gamma)` as our two qubit unitary for the parametrized layers, we are restricting our QCNN to a particular subspace, one in which the optimal solution may not be contained in and reducing the accuracy of the QCNN. For the purpose of this tutorial, we will use this parametrized circuit to decrease the training time of our QCNN."
msgstr ":math:`N(\\alpha, \\beta, \\gamma)` 를 매개 변수화된 층에 대한 2 큐비트 유니타리로만 사용함으로써, QCNN을 최적의 솔루션이 포함되지 않을 수 있는 특정 하위 공간으로 제한하고 QCNN의 정확도를 감소시킨다는 점에 유의한다. 이 튜토리얼의 의도대로 이 매개 변수화된 회로를 사용하여 QCNN의 학습 시간을 단축할 것이다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:240
msgid "|circuit2.png|"
msgstr "|circuit2.png|"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:242
msgid "circuit2.png"
msgstr "circuit2.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:253
msgid "Figure 3: Parametrized two qubit unitary circuit for :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])` as seen in [3], where :math:`\\alpha = \\frac{\\pi}{2} - 2\\theta`, :math:`\\beta = 2\\phi - \\frac{\\pi}{2}` and :math:`\\gamma = \\frac{\\pi}{2} - 2\\lambda` as seen in the circuit. This two qubit unitary will be applied to all neighboring qubits in our feature map."
msgstr "그림 3: [3] 에서 보는 바와 같이 :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])` 에 대한 2 큐비트 유니타리 회로를 매개 변수화하였으며, 여기서 :math:`\\alpha = \\frac{\\pi}{2} - 2\\theta`, :math:`\\beta = 2\\phi - \\frac{\\pi}{2}`, :math:`\\gamma = \\frac{\\pi}{2} - 2\\lambda` 는 회로에서 보는 바와 같다. 이러한 2 큐비트 유니타리는 특징 지도의 모든 인접한 큐비트에 적용할 것이다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:265
msgid "2.1 Convolutional Layer"
msgstr "2.1 합성곱 층"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:276
msgid "The next step in this tutorial is to define the Convolutional Layers of our QCNN. These layers are then applied to the qubits after the data has been encoded through use of the feature map."
msgstr "이 튜토리얼의 다음 단계는 QCNN의 합성곱 층을 정의한다. 이러한 층은 특징 지도를 사용하여 데이터를 인코딩한 후 큐비트에 적용된다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:278
msgid "To do so we first need to determine a parametrized unitary gate, which will be used to create our convolutional and pooling layers."
msgstr "먼저 합성곱 및 풀링 층을 만드는 데 사용될 매개 변수화된 유니타리 게이트를 결정해야 한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:325
msgid "Now that we have defined these unitaries, it is time to create a function for the convolutional layer in our QCNN. To do so, we apply the two qubit unitary to neighboring qubits as seen in the ``conv_layer`` function below."
msgstr "유니타리를 정의했으므로 QCNN에서 합성곱 층에 대한 함수를 생성해야 한다. 아래 ``conv_layer`` 함수에 표시된 것처럼 두 개의 큐비트 유니타리를 인접한 큐비트에 적용한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:327
msgid "Note that we first apply the two qubit unitary to all even pairs of qubits followed by applying to odd pairs of qubits in a circular coupling manner, i.e. the as well as neighboring qubits being coupled, the first and final qubit are also coupled through a unitary gate."
msgstr "먼저 2 큐비트 유니타리를 모든 짝수 큐비트 쌍에 적용한 후 원형 커플링 방식으로 홀수 큐비트 쌍에 적용한다. 즉, 커플링 중인 인접하는 큐비트뿐만 아니라 첫 번째 큐비트와 마지막 큐비트도 유니타리 게이트를 통해 커플링된다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:329
msgid "Note that we add barriers into our quantum circuits for convenience when plotting, however they are not required for the actual QCNN and can be extracted from the following circuits."
msgstr "그래프를 그릴때 편의를 위해 양자 회로에 배리어를 추가하지만 실제 QCNN에는 필요하지 않으며 다음 회로에서 추출할 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:382
msgid "2.2 Pooling Layer"
msgstr "2.2 풀링 층"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:393
msgid "The purpose of a pooling layer is to reduce the dimensions of our Quantum Circuit, i.e. reduce the number of qubits in our circuit, while retaining as much information as possible from previously learned data. Reducing the amount of qubits also reduces the computational cost of the overall circuit, as the number of parameters that the QCNN needs to learn decreases."
msgstr "풀링 층의 목적은 이전에 학습한 데이터에서 가능한 많은 정보를 유지하면서 양자 회로의 차원수를 줄이는 것이다. 큐비트의 수를 줄이면 QCNN이 학습해야 하는 매개 변수의 수가 줄어들기 때문에 전체 회로의 계산 비용도 감소한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:395
msgid "However, one cannot simply decrease the amount of qubits in our quantum circuit. Because of this, we must define the pooling layer in a different manner compared with the classical approach."
msgstr "그러나 양자 회로의 큐비트의 양을 단순히 줄일 수는 없다. 이 때문에 풀링 층을 기존의 접근 방식과 다른 방식으로 정의해야 한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:397
msgid "To ‘artificially’ reduce the number of qubits in our circuit, we first begin by creating pairs of the :math:`N` qubits in our system."
msgstr "회로의 큐비트 수를 '인위적으로' 줄이기 위해 먼저 시스템에서 :math:`N` 큐비트 쌍을 만드는 것으로 시작한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:399
msgid "After initially pairing all the qubits, we apply our generalized 2 qubit unitary to each pair, as described previously. After applying this two qubit unitary, we then ignore one qubit from each pair of qubits for the remainder of the neural network."
msgstr "처음에 모든 큐비트를 쌍으로 구성한 후 앞에서 설명한 것처럼 일반화된 2 큐비트 유니타리를 각 쌍에 적용한다. 이 2 큐비트 유니타리를 적용한 후, 신경망의 나머지 부분에는 각 큐비트 쌍마다 하나의 큐비트를 무시한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:401
msgid "This layer therefore has the overall effect of ‘combining’ the information of the two qubits into one qubit by first applying the unitary circuit, encoding information from one qubit into another, before disregarding one of qubits for the remainder of the circuit and not performing any operations or measurements on it."
msgstr "따라서 이 층은 먼저 유니타리 회로를 적용하여 두개의 큐비트의 정보를 하나의 큐비트로 '결합'하는 전반적인 효과를 가지고 있으며, 나머지 회로에 대해 큐비트 중 하나를 무시하고 어떠한 연산이나 측정을 수행하지 않는다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:403
msgid "We note that one could also apply a dynamic circuit to reduce the dimensionality in the pooling layers. This would involve performing measurements on certain qubits in the circuit and having an intermediate classical feedback loop in our pooling layers. By applying these measurements, one would also be reducing the dimensionality of the circuit."
msgstr "풀링 층에서 차원수를 줄이기 위해 동적 회로를 적용할 수도 있다. 회로의 특정 큐비트에 대한 측정을 수행하고 풀링 층에서 중간의 고전적 피드백 루프를 갖는 것을 포함한다. 이러한 측정을 적용함으로써 회로의 차원수도 줄일 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:405
msgid "In this tutorial, we apply the former approach, and disregard qubits in each pooling layer. Using this approach, we thus create a QCNN Pooling Layer which transforms the dimensions of our :math:`N` qubit Quantum Circuit to :math:`N/2`."
msgstr "이 튜토리얼에서는 이전 접근 방식을 적용하고 각 풀링 층의 큐비트를 무시한다. 따라서 이 접근 방식을 사용하여 :math:`N` 큐비트 양자 회로의 차원수를 :math:`N/2` 로 변환하는 QCNN 풀링 층을 만든다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:407
msgid "To do so, we first define a two qubit unitary, which transforms the two qubit system to one."
msgstr "이를 위해 먼저 2 큐비트 시스템을 하나로 변환하는 2 큐비트 유니타리를 정의한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:451
msgid "After applying this two qubit unitary circuit, we neglect the first qubit (q0) in future layers and only use the second qubit (q1) in our QCNN"
msgstr "이 2 큐비트 유니타리 회로를 적용한 후, 다음층에서 첫 번째 큐비트(q0)를 무시하고 QCNN에서 두 번째 큐비트(q1)만 사용한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:453
msgid "We apply this two qubit pooling layer to different pairs of qubits to create our pooling layer for N qubits. As an example we then plot it for four qubits."
msgstr "2 큐비트 풀링 층을 다른 큐비트 쌍에 적용하여 N 큐비트에 대한 풀링 층을 생성한다. 4개의 큐비트에 대해 그래프를 그려 예를 들어보겠다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:503
msgid "In this particular example, we reduce the dimensionality of our four qubit circuit to the last two qubits, i.e. the last two qubits in this particular example. These qubits are then used in the next layer, while the first two are neglected for the remainder of the QCNN."
msgstr "이 특정 예제에서는 4개의 큐비트 회로의 차원수를 마지막 2개의 큐비트로 줄인다. 이러한 큐비트는 다음 층에서 사용되는 반면 처음 두 개는 나머지 QCNN에서 무시된다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:515
msgid "3. Data Generation"
msgstr "3. 데이터 생성"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:526
msgid "One common use of a CCNN is an image classifier, where a CCNN detects particular features and patterns (such as straight lines or curves) of the pixelated images through the use of the feature maps in the convolutional layer. By learning the relationship between these features, it can then classify and label handwritten digits with ease."
msgstr "CCNN의 일반적인 용도는 이미지 분류기로, CCNN은 합성곱 층에서 특징 지도를 사용하여 픽셀화된 이미지의 (직선 또는 곡선 등)특정 특징과 패턴을 감지한다. 이러한 특징간의 관계를 학습함으로써 손으로 쓴 숫자를 쉽게 분류하고 라벨을 지정 할 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:528
msgid "Because of a classical CNN’s ability to recognize features and patterns easily, we will train our QCNN to also determine patterns and features of a given set of pixelated images, and classify between two different patterns."
msgstr "특징과 패턴을 쉽게 인식하는 고전적인 CNN의 능력으로 인해, QCNN을 학습시켜 주어진 픽셀화된 이미지 세트의 패턴과 특징을 결정하고 두 개의 다른 패턴을 분류한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:530
msgid "To simplify the dataset, we only consider 2 x 4 pixelated images. The patterns we will train the QCNN to distinguish will be a horizontal or vertical line, which can be placed anywhere in the image, alongside a noisy background."
msgstr "데이터셋을 단순화하기 위해 2 x 4 픽셀 이미지만 고려한다. QCNN을 학습하여 구별하는 패턴은 노이즈가 많은 배경과 동시에 이미지 어디에나 놓일 수 있는 수평 또는 수직선이 될 것이다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:532
msgid "We first begin by generating this dataset. To create a ‘horizontal’ or ‘vertical’ line, we assign pixels value to be :math:`\\frac{\\pi}{2}` which will represent the line in our pixelated image. We create a noisy background by assigning every other pixel a random value between :math:`0` and :math:`\\frac{\\pi}{4}` which will create a noisy background."
msgstr "먼저 이 데이터셋을 생성하는 것으로 시작한다. '수평' 또는 '수직' 선을 생성하기 위해 픽셀 값을 픽셀화된 이미지에서 선을 나타낼 :math:`\\frac{\\pi}{2}` 로 할당한다. 모든 다른 픽셀을 :math:`0` 과 :math:`\\frac{\\pi}{4}` 사이에 임의의 값을 할당하여 노이즈가 많은 배경을 만든다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:534
msgid "Note that when we create our dataset, we need to split it into the training set and testing set of images, the datasets we train and test our neural network respectively."
msgstr "데이터셋을 만들 때 신경망을 각각 훈련하고 테스트하는 데이터셋인 학습 세트와 테스트 이미지 세트로 분할해야 한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:536
msgid "We also need to label our datasets such that the QCNN can learn to differentiate between the two patterns. In this example we label images with a horizontal line with -1 and images with a vertical line +1."
msgstr "또한 QCNN이 두 패턴을 구별하는 방법을 배울 수 있도록 데이터셋에 레이블을 지정해야 한다. 이 예제에서는 이미지에서의 수평선을 -1, 이미지에서의 수직선을 +1로 레이블 하였다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:591
msgid "Let’s now create our dataset below and split it into our test and training datasets."
msgstr "이제 아래에 데이터셋을 만들고 테스트 및 학습 데이터셋으로 나눠보자."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:616
msgid "Let’s see some examples in our dataset"
msgstr "데이터셋에서 몇 가지 예를 살펴보자."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:651
msgid "As we can see each image contains either a vertical or horizontal line, that the QCNN will learn how to differentiate. Now that we have built our dataset, it is time to discuss the components of the QCNN and build our model."
msgstr "각 이미지에는 수직 또는 수평선이 포함되어 있으므로 QCNN은 구별하는 방법을 학습한다. 데이터셋을 구축했으므로 이제 QCNN의 구성 요소에 대해 논의하고 모델을 구축해보자."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:663
msgid "4. Modeling our QCNN"
msgstr "4. QCNN 모델링"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:674
msgid "Now that we have defined both the convolutional layers it is now time to build our QCNN, which will consist of alternating pooling and convolutional layers."
msgstr "이제 두 합성곱 층을 모두 정의했으므로 이제 풀링 층과 합성곱 층이 교대로 구성될 QCNN을 구축해보자."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:676
msgid "As the images in our dataset contains 8 pixels, we will use 8 qubits in our QCNN."
msgstr "데이터셋의 이미지는 8개의 픽셀을 포함하므로 QCNN에서 8개의 큐비트를 사용한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:678
msgid "We encode our dataset into our QCNN by applying a feature map. One can create a feature map using one of Qiskit’s built in feature maps, such as ZFeatureMap or ZZFeatureMap."
msgstr "특징 지도를 적용하여 데이터셋을 QCNN으로 인코딩한다. ZFeatureMap 또는 ZZFeatureMap과 같은 Qiskit에 내장된 특징 지도 중 하나를 사용하여 특징 지도를 생성할 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:680
msgid "After analyzing several different Feature maps for this dataset, it was found that QCNN obtains the greatest accuracy when the Z feature map is used. Therefore, throughout the remainder of the tutorial we will use the Z feature Map, of which can be seen below."
msgstr "이 데이터셋에 대해 여러 가지 다른 기능 맵을 분석한 결과, Z 특징 지도를 사용할 때 QCNN이 가장 높은 정확도를 얻는 것으로 나타났다. 따라서 나머지 튜토리얼에서는 Z 특징 지도를 사용할 것이며 아래에서 확인할 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:711
msgid "We create a function for our QCNN, which will contain three sets of alternating convolutional and pooling layers, which can be seen in the schematic below. Through the use of the pooling layers, we thus reduce the dimensionality of our QCNN from eight qubits to one."
msgstr "아래 개략도에서 볼 수 있는 것처럼 3개 세트의 합성곱 및 풀링 층이 교대로 배치된 QCNN에 대한 함수를 만든다. 따라서 풀링 층을 사용하여 QCNN의 차원수를 8개의 큐비트에서 1개의 큐비트로 줄인다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:722
msgid "|Screenshot%202022-08-10%20at%2021.42.39.png|"
msgstr "|Screenshot%202022-08-10%20at%2021.42.39.png|"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:724
msgid "Screenshot%202022-08-10%20at%2021.42.39.png"
msgstr "Screenshot%202022-08-10%20at%2021.42.39.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:735
msgid "To classify our image dataset of horizontal and vertical lines, we measure the expectation value of the Pauli Z operator of the final qubit. Based on the obtained value being +1 or -1, we can conclude that the input image contained either a horizontal or vertical line."
msgstr "수평선과 수직선의 이미지 데이터셋을 분류하기 위해 최종 큐비트의 파울리 Z 연산자의 기댓값을 측정한다. 얻어진 값이 +1 또는 -1인지에 따라 입력 이미지가 수평선 또는 수직선을 포함하였다고 결론지을 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:747
msgid "5. Training our QCNN"
msgstr "5. QCNN 학습"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:758
msgid "The next step is to build our model using our training data."
msgstr "다음 단계는 학습 데이터를 사용하여 모델을 구축하는 것이다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:760
msgid "To classify our system, we perform a measurement from the output circuit. The value we obtain will thus classify whether our input data contains either a vertical line or horizontal line."
msgstr "시스템을 분류하기 위해 출력 회로에서 측정을 수행한다. 따라서 얻은 값은 입력 데이터에 수직선이 포함되는지 수평선이 포함되는지 여부를 분류할 것이다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:762
msgid "The measurement we have chosen in this tutorial is :math:`<Z>`, i.e. the expectation value of the Pauli Z qubit for the final qubit. Measuring this expectation value, we obtain +1 or -1, which correspond to a vertical or horizontal line respectively."
msgstr "이 튜토리얼에서 선택한 측정은 최종 큐비트에 대한 파울리 Z 큐비트의 기대값인 :math:`<Z>` 이다. 이 기댓값을 측정하면 각각 수직선과 수평선에 해당하는 +1 또는 -1을 얻을 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:837
msgid "We will also define a callback function to use when training our model. This allows us to view and plot the loss function per each iteration in our training process."
msgstr "또한 모델을 학습할 때 사용할 콜백 함수를 정의한다. 이를 통해 학습 과정의 각 회차당 손실 함수를 보고 표시 할 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:865
msgid "In this example, we will use the COBYLA optimizer to train our classifier, which is a numerical optimization method commonly used for classification machine learning algorithms."
msgstr "이 예에서, 분류 기계 학습 알고리즘에 일반적으로 사용되는 수치 최적화 방법인 분류기를 학습하기 위해 COBYLA 최적화기를 사용한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:867
msgid "We then place the the callback function, optimizer and operator of our QCNN created above into Qiskit’s built in Neural Network Classifier, which we can then use to train our model."
msgstr "그런 다음 위에서 생성된 QCNN의 콜백 함수, 옵티마이저, 연산자를 Qiskit의 신경망 분류기에 배치하여 모델을 학습하는 데 사용할 수 있다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:869
msgid "Since model training may take a long time we have already pre-trained the model for some iterations and saved the pre-trained weights. We’ll continue training from that point by setting ``initial_point`` to a vector of pre-trained weights."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:898
msgid "After creating this classifier, we can train our QCNN using our training dataset and each image’s corresponding label. Because we previously defined the callback function, we plot the overall loss of our system per iteration."
msgstr "이 분류기를 생성한 후, 학습 데이터 세트와 각 이미지의 해당 레이블을 사용하여 QCNN을 학습시킬 수 있다. 이전에 콜백 함수를 정의했기 때문에 반복당 전체 시스템 손실을 그래프로 표시한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:900
msgid "It may take some time to train the QCNN so be patient!"
msgstr "QCNN을 학습하는 데 시간이 걸릴 수 있으므로 인내심이 필요하다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:962
msgid "As we can see from above, the QCNN converges slowly, hence our ``initial_point`` was already close to an optimal solution. The next step is to determine whether our QCNN can classify data seen in our test image data set."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:974
msgid "6. Testing our QCNN"
msgstr "6. QCNN 테스트"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:985
msgid "After building and training our dataset we now test whether our QCNN can predict images that are not from our test data set."
msgstr "데이터셋을 구축하고 학습한 후, QCNN이 테스트 데이터셋에 없는 이미지를 예측할 수 있는지 테스트한다."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1052
msgid "From above, we can indeed see that our QCNN can classify horizontal and vertical lines! Congratulations! Through the use of quantum circuits and quantum convolutional and pooling layers, you have built a Quantum Convolutional Neural Network!"
msgstr "위에서 보면, QCNN이 수평선과 수직선을 분류할 수 있다는 것을 알 수 있다. 드디어 양자 회로와 양자 합성곱 및 풀링 층을 사용하여 양자 합성곱 신경망을 구축하는데 성공했다!"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1064
msgid "7. References"
msgstr "7. 참조"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1075
msgid "[1] Cong, I., Choi, S. & Lukin, M.D. Quantum convolutional neural networks. Nat. Phys. 15, 1273–1278 (2019). https://doi.org/10.1038/s41567-019-0648-8"
msgstr "[1] Cong, I., Choi, S. & Lukin, M.D. Quantum convolutional neural networks. Nat. Phys. 15, 1273–1278 (2019). https://doi.org/10.1038/s41567-019-0648-8"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1077
msgid "[2] IBM Convolutional Neural Networks https://www.ibm.com/cloud/learn/convolutional-neural-networks"
msgstr "[2] IBM Convolutional Neural Networks https://www.ibm.com/cloud/learn/convolutional-neural-networks"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1079
msgid "[3] Vatan, Farrokh, and Colin Williams. “Optimal quantum circuits for general two-qubit gates.” Physical Review A 69.3 (2004): 032315."
msgstr "[3] Vatan, Farrokh, and Colin Williams. “Optimal quantum circuits for general two-qubit gates.” Physical Review A 69.3 (2004): 032315."

