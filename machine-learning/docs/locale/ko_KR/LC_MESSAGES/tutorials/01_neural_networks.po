msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-12-15 16:59+0000\n"
"PO-Revision-Date: 2021-12-15 17:19\n"
"Last-Translator: \n"
"Language-Team: Korean\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ko\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/01_neural_networks.po\n"
"X-Crowdin-File-ID: 9628\n"
"Language: ko_KR\n"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/01_neural_networks.ipynb`__."
msgstr "이 페이지는 `docs/tutorials/01_neural_networks.ipynb`__ 에서 생성되었다."

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "양자 신경망"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "이 노트북은 Qiskit Machine Learning에서 제공하는 여러 가지 QNN (일반적인 양자 신경망)을 시연한다. 네트워크는 애플리케이션에 구애받지 않는 컴퓨터적인 단위로써 다양한 예제에 사용될 수 있다 . 애플리케이션에 따라 특정 유형의 네트워크가 더 적합하거나 적합하지 않을 수 있으며,  경우에 따라 네트워크를 특별한 방식으로 설정해야 할 수도 있다. 이제 다음과 같은 다른 사용 가능한 신경망을 자세히 설명한다."

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks."
msgstr "``NeuralNetwork`` : 신경망을 위한 인터페이스."

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``OpflowQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr "``OpflowQNN`` : 양자역학적 관측 수행을 기반으로 한 네트워크."

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``TwoLayerQNN``: A special ``OpflowQNN`` implementation for convenience."
msgstr "``TwoLayerQNN`` : 편의를 위한 특수한 ``OpflowQNN`` 구현."

#: ../../tutorials/01_neural_networks.ipynb:16
msgid "``CircuitQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr "``CircuitQNN`` : 양자회로 측정으로 얻은 샘플을 기반으로 한 네트워크."

#: ../../tutorials/01_neural_networks.ipynb:66
msgid "1. ``NeuralNetwork``"
msgstr "1. ``NeuralNetwork``"

#: ../../tutorials/01_neural_networks.ipynb:68
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interfaces are introduced."
msgstr "``NeuralNetwork`` 은 Qiskit Machine Learning에서 사용할 수 있는 모든 신경망에 대한 인터페이스를 나타낸다. 신경망은 데이터 샘플과 학습 가능한 가중치를 입력으로하는 정방향 및 역방향 경로를 나타낸다. ``NeuralNetwork`` 에는 훈련 기능이 포함되어 있지 않으며 실제 알고리즘/애플리케이션으로 푸시된다. 이와 같이 ``NeuralNetwork`` 은 학습 가능한 가중치를 저장하지 않는다. 다음은 이 인터페이스의 다양한 구현 예제가 소개한다."

#: ../../tutorials/01_neural_networks.ipynb:70
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes either flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr "``NeuralNetwork`` 을 ``nn`` 이라 부르자. 그러면 ``nn.forward(input, weights)`` 경로는 데이터의 입력과 가중치를 ``nn.num_inputs`` 과 ``nn.num_weights`` 로 받는다. ``NeuralNetwork`` 는 입력의 배치처리를 지원하고 해당 형상의 출력 배치를 반환한다."

#: ../../tutorials/01_neural_networks.ipynb:82
msgid "2. ``OpflowQNN``"
msgstr "2. ``OpflowQNN``"

#: ../../tutorials/01_neural_networks.ipynb:84
msgid "The ``OpflowQNN`` takes a (parametrized) operator from Qiskit and leverages Qiskit’s gradient framework to provide the backward pass. Such an operator can for instance be an expected value of a quantum mechanical observable with respect to a parametrized quantum state. The Parameters can be used to load classical data as well as represent trainable weights. The ``OpflowQNN`` also allows lists of operators and more complex structures to construct more complex QNNs."
msgstr "``OpflowQNN`` 은 Qiskit의 (매개 변수화된) 연산자를 취하여 Qiskit의 기울기 프레임워크를 활용해 역방향 경로를 제공한다. 예를 들어, 이러한 연산자는 매개 변수화된 양자 상태에 관한 양자 기계적 관찰의 기댓값이 될 수 있다. 매개변수를 사용하여 훈련 가능한 가중치를 표시할 뿐만 아니라 고전적 데이터를 불러오는데 사용할 수 있다. 또한 ``OpflowQNN`` 은 더욱 복잡한 QNN을 구성하기 위한 연산자 목록과 복잡한 구조를 가능하게 한다."

#: ../../tutorials/01_neural_networks.ipynb:319
msgid "Combining multiple observables in a ``ListOp`` also allows to create more complex QNNs"
msgstr "``ListOp`` 에서 여러 관측 자료를 결합하면 보다 복잡한 QNN을 생성할 수 있다."

#: ../../tutorials/01_neural_networks.ipynb:408
msgid "3. ``TwoLayerQNN``"
msgstr "3. ``TwoLayerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:410
msgid "The ``TwoLayerQNN`` is a special ``OpflowQNN`` on :math:`n` qubits that consists of first a feature map to insert data and second an ansatz that is trained. The default observable is :math:`Z^{\\otimes n}`, i.e., parity."
msgstr "``TwoLayerQNN`` 은 :math:`n` 큐비트에 작용하는 특별한 종류의 ``OpflowQNN`` 으로서 두 가지 요소로 구성되어 있다. 첫 번째는 데이터를 삽입하기 위한 feature map이고 두 번째는 훈련된 ansatz이다. 기본 관측값은 :math:`Z^{\\otimes n}`, 즉 parity이다."

#: ../../tutorials/01_neural_networks.ipynb:607
msgid "4. ``CircuitQNN``"
msgstr "4. ``CircuitQNN``"

#: ../../tutorials/01_neural_networks.ipynb:609
msgid "The ``CircuitQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples can either be interpreted as probabilities of measuring the integer index corresponding to a bitstring or directly as a batch of binary output. In the case of probabilities, gradients can be estimated efficiently and the ``CircuitQNN`` provides a backward pass as well. In case of samples, differentiation is not possible and the backward pass returns ``(None, None)``."
msgstr "``CircuitQNN`` 은 (파라미터화된) ``QuantumCircuit`` 에 기반으로 한다. 이것은 가중치뿐만 아니라 입력을 취할 수 있고, 측정을 통해 샘플을 생성할 수 있다. 샘플들은 비트열에 대응하는 정수 인덱스를 측정하는 확률 또는 이진 출력의 배치(batch) 로서 직접적으로 해석될 수 있다. 확률의 경우 기울기는 효율적으로 추정될 수 있고, ``CircuitQNN`` 은 역방향 경로 또한 제공된다. 샘플의 경우에는 미분이 가능하지 않으며 역방향 경로는 ``(None, None)`` 을 반환한다."

#: ../../tutorials/01_neural_networks.ipynb:612
msgid "Further, the ``CircuitQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are aggregated accordingly."
msgstr "또한, ``CircuitQNN`` 은 샘플들을 후처리하기 위한 ``interpret`` 함수를 설정할 수 있다. 이것은 비트열에서 측정된 정수를 가져와 새로운 인덱스 (예를 들면, 음이 아닌 정수)에 mapping 하게 된다. 이 경우, 출력 형태가 제공되어야 하며 이에 따라 확률이 집계되어야 한다."

#: ../../tutorials/01_neural_networks.ipynb:614
msgid "A ``CircuitQNN`` can be configured to return sparse as well as dense probability vectors. If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits and a sparse recommendation is usually recommended. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr "``CircuitQNN`` 은 밀집 확률 벡터뿐만 아니라, 희소 확률 벡터를 반환하도록 조정될 수 있다. ``interpret`` 함수가 사용되지 않는 경우, 확률 벡터의 차원은 큐비트의 수에 지수적으로 비례하고, 보통 희소 방식이 권장된다. ``interpret`` 함수의 경우, 이는 기대되는 출력값에 의존한다. 예를 들어, 만약 index가 해당 비트열의 패리티에 mapping되었을 경우 (예를 들면 0 or 1), 밀집 출력이 알맞으며 그 결과는 길이가 2인 확률 벡터가 될 것이다."

#: ../../tutorials/01_neural_networks.ipynb:657
msgid "4.1 Output: sparse integer probabilities"
msgstr "4.1 출력: 희소 정수 확률"

#: ../../tutorials/01_neural_networks.ipynb:754
msgid "4.2 Output: dense parity probabilities"
msgstr "4.2 출력: 조밀한 패리티 확률"

#: ../../tutorials/01_neural_networks.ipynb:865
msgid "4.3 Output: Samples"
msgstr "4.3 출력: 샘플"

#: ../../tutorials/01_neural_networks.ipynb:980
msgid "4.4 Output: Parity Samples"
msgstr "4.4 출력: 패리티 샘플"

