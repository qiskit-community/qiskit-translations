msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-02-07 03:44+0000\n"
"PO-Revision-Date: 2023-02-07 05:25\n"
"Last-Translator: \n"
"Language: sw\n"
"Language-Team: Swahili\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: sw\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/12_quantum_autoencoder.po\n"
"X-Crowdin-File-ID: 9929\n"

#: ../../tutorials/12_quantum_autoencoder.ipynb:9
msgid "This page was generated from `docs/tutorials/12_quantum_autoencoder.ipynb`__."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:22
#: ../../tutorials/12_quantum_autoencoder.ipynb:52
msgid "The Quantum Autoencoder"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:33
msgid "The goal of this tutorial is to build an Quantum Autoencoder, a circuit which can compress a quantum state onto a smaller amount of qubits, while retaining the information from the initial state."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:35
msgid "Throughout this tutorial, we explain the architecture of a Quantum Autoencoder and how one can design and train such a system to compress and encode information. Following this discussion, we give two examples to demonstrate the capabilities of such a system to compress different quantum states, as well as the ability to compress images of zeros and ones."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:47
msgid "Contents"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:49
msgid "The following tutorial is broken down as follows:"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:51
msgid "What is an Autoencoder?"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:53
msgid "Components of a Quantum Autoencoder"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:54
msgid "Choosing a Loss Function"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:55
msgid "Building our Autoencoder"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:56
msgid "A Simple Example: The Domain Wall"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:57
msgid "A Quantum Autoencoder for Noisy Images of Digits"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:58
msgid "Applications of a Quantum Autoencoder"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:59
msgid "References"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:71
msgid "1. What is an Autoencoder?"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:82
msgid "A classical autoencoder (CAE) is a type of neural network architecture that is commonly used to efficiently compress and encode information from the input using of representation learning. Following compression, one can then uncompress the data through the use of a decoder."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:84
msgid "Typical autoencoders are commonly divided into three layers, as seen in Figure 1."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:95
msgid "|qae_fig1_wide.png| Figure 1: Example of a Classical Autoencoder which includes the input, bottleneck and output layer."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:97
msgid "qae_fig1_wide.png"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:108
msgid "The first layer is called the Input Layer (1) and is the layer of which we input our data of length :math:`n`."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:110
msgid "The input data then passes through an encoder and travels to the next layer, which has less nodes or is reduced in dimensions and is known as the Bottleneck Layer (2). The input layer is compressed through this process. Common CAEs may have several layers."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:112
msgid "The final layer is called the Output Layer (3). Here the compressed data is reconstructed to its original size, :math:`n`, from the compressed data through the process of a decoder."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:114
msgid "By passing our input data through a CAE, we are therefore able to reduce the dimensionality of our input data, as seen in the bottleneck layer, while retaining as much information as possible from the input data. Because of this feature, common uses of CAE are Image Denoising, Anomaly Detection and Facial Recognition devices. For more information on classical autoencoders, see [1]."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:126
msgid "2. The Quantum Autoencoder"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:137
msgid "We can also define a quantum counterpart to the CAE, the Quantum Autoencoder. Much like the CAE, the Quantum Autoencoder aims to reduce the dimensionality of the input of the neural network, in this case a quantum state. A pictorial representation of this can be seen in Figure 2."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:148
msgid "|qae_fig2_wide.png| Figure 2: Pictorial Representation of a Quantum Autoencoder. Here one can see the similarities with the CAE, with the circuit having an input state, bottleneck state and an output state."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:150
msgid "qae_fig2_wide.png"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:161
msgid "Much like its classical counterpart, our circuit contains three layers. We first input our state :math:`|\\psi>` (which contains :math:`n` qubits), of which we wish to compress. This is our input layer (1)."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:163
msgid "We then apply our parametrized circuit on our input state, which will act as our encoder and ‘compresses’ our quantum state, reducing the dimensionality of our state to :math:`n-k` qubits. Our new compressed state is of the form :math:`|\\psi_{comp}> \\otimes |0>^{\\otimes k}`, where :math:`|\\psi_{comp}>` contains :math:`n-k` qubits."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:165
msgid "This parametrized circuit will depend on a set of parameters, which will be the nodes of our Quantum Autoencoder. Throughout the training process, these parameters will be updated to optimize the loss function."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:167
msgid "We disregard the remaining :math:`k` qubits for the remainder of the circuit. This is our bottleneck layer (2) and our input state is now compressed."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:169
msgid "The final layer consists of the addition of :math:`k` qubits (all in the state :math:`|0\\rangle`) and applying another parametrized circuit between the compressed state and the new qubits. This parametrized circuit acts as our decoder and reconstructs the input state from the compressed state using the new qubits. After the decoder, we retain the original state as the state travels to the output layer (3)."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:181
msgid "3. Components of a Quantum Autoencoder"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:192
msgid "Before building our Quantum Autoencoder, we must note a few subtleties."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:194
msgid "We first note that we cannot introduce or disregard qubits in the middle of a Quantum Circuit when implementing an autoencoder using Qiskit."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:196
msgid "Because of this we must include our reference state as well as our auxiliary qubits (whose role will be described in later sections) at the beginning of the circuit."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:198
msgid "Therefore our input state will consist of our input state, reference state and one auxiliary qubit, as well as a classical register to perform measurements (which will be described in the next section). A pictorial representation of this can be seen in Figure 3."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:209
msgid "|qae_fig3_wide.png| Figure 3: Pictorial Representation of input state of Quantum Autoencoder. Note that we must also include an auxiliary qubit, the reference state and classical register at the beginning of the circuit, even though they are not used until later in the circuit."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:211
msgid "qae_fig3_wide.png"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:223
msgid "4. Choosing a Loss Function"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:234
msgid "We now define our cost function, which we will use to train our Quantum Autoencoder, to return the input state. There’s a bit of math involved here, so skip this section if you’re not interested!"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:236
msgid "We take the cost function as defined in [2], which tries to maximize the fidelity between the input and output state of our Quantum Autoencoder."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:238
msgid "We first define subsystems :math:`A` and :math:`B` to contain :math:`n` and :math:`k` qubits respectively, while :math:`B'` is the space which will contain our reference space. We call the subsystem :math:`A` our latent space, which will contain the compressed qubit state, and :math:`B` our trash space, which contain the qubits of which we disregard throughout compression."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:240
msgid "Our input state therefore :math:`|\\psi_{AB}>` contains :math:`n + k` qubits. We define the reference space :math:`B'` which contains the reference state :math:`|a>_{B'}`. This space will contain the additional :math:`k` qubits we use in the decoder. All of these subsystems can be seen in Figure 3."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:242
msgid "We define the parameterized circuit as :math:`U(\\theta)` which we will use as our encoder. However the structure and parameters of our parametrized circuit is currently unknown to us and may vary for different input states. To determine the parameters to compress our input state, we must train our device to maximally compress the state by adjusting the values of the parameters :math:`\\theta`. For the decoder we will use :math:`U^{\\dagger}(\\theta)`."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:244
msgid "Our goal therefore is to maximize the fidelity between the input and output states, i.e."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:246
msgid "\\text{max }F(\\psi_{AB}, \\rho_{out})\n\n"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:248
msgid "where"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:250
msgid "\\rho_{out} = U^{\\dagger}(\\theta)_{AB'} \\text{Tr}_{B} [U(\\theta)_{AB}[\\psi_{AB} \\otimes a_{B'}]U^{\\dagger}(\\theta)_{AB}]U(\\theta)_{AB'}\n\n"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:252
msgid "We can maximize this fidelity by tuning the parameters :math:`\\theta` in our parametrized circuit. However, this fidelity can at times be complicated to determine and may require a large amount of gates needed to calculate the fidelity between two states, i.e. the larger the number of qubits, the more gates required which results to deeper circuits. Therefore we look for alternative means of comparing the input and output states."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:254
msgid "As shown in [2] a simpler way of determining an optimally compressed state is to perform a swap gate between the trash state and reference state. These states usually have a smaller number of qubits and are therefore easier to compare, due to the smaller amount of gates required. As shown in [2] maximizing the fidelity of such these two states is equivalent to maximizing the fidelity of the input and output state and thus determining an optimal compression of our input circuit."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:256
msgid "Keeping our reference state fixed, our cost function will now be a function of the trash state and is denoted as;"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:258
msgid "\\text{max }F(\\text{Tr}_{A} [ U(\\theta)_{AB}\\psi_{AB} U^{\\dagger}(\\theta)_{AB}], a_{B'})\n\n"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:260
msgid "Throughout the training process, we adjust the parameters :math:`\\theta` in our encoder and perform a swap test (as described below) to determine the fidelity between these trash and reference states. In doing so, we must include an additional qubit, our auxiliary qubit, which will be used throughout the swap test and measured to determine the overall fidelity of the trash and reference states. This is the reason why we included both an auxiliary qubit and classical register in the previous section when initializing our circuit."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:273
msgid "The SWAP Test"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:284
msgid "The SWAP Test is a procedure commonly used to compare two states by applying CNOT gates to each qubit (for further information see [3]). By running the circuit :math:`M` times, and applying the SWAP test, we then measure the auxiliary qubit. We use the number of states in the state :math:`|1\\rangle` to compute:"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:286
msgid "S = 1 - \\frac{2}{M}L\n\n"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:288
msgid "where :math:`L` is the count for the states in the :math:`|1\\rangle` state. As shown in [3], maximizing this function corresponds to the two states of which we are comparing being identical. We therefore aim to maximize this function, i.e. minimize :math:`\\frac{2}{M}L`. This value will be therefore be our cost function."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:300
msgid "5. Building the Quantum Autoencoder Ansatz"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:311
msgid "First, we implement IBM’s Qiskit to build our Quantum Autoencoder. We first begin by importing in the necessary libraries and fixing the seed."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:349
msgid "We begin by defining our parametrized ansatz for the Quantum Autoencoder. This will be our parametrized circuit where we can tune the parameters to maximize the fidelity between the trash and reference states."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:352
msgid "The Parametrized Circuit"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:354
msgid "The parametrized circuit we will use below for our encoder is the RealAmplitude Ansatz available in Qiskit. One of the reasons why we have chosen this ansatz is because it is a 2-local circuit, the prepared quantum states will only have real amplitudes, and does not rely on full connectivity between each qubits, which is hard to implement or can lead to deep circuits."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:356
msgid "We define our parametrized circuit for our Encoder below, where we set the repetition parameter to ``reps=5``, to increase the number of parameters in our circuit allowing greater flexibility."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:378
msgid "Let’s draw this ansatz with :math:`5` qubits and see what it looks like."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:410
msgid "We now apply this Encoder to the state we wish to compress. In this example, we divide our initial :math:`5` qubit state into a :math:`3` qubit latent state (:math:`n = 3`) and :math:`2` qubit trash space (:math:`k = 2`)."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:412
msgid "As explained in the previous section, we must also include a :math:`2` qubit reference space in our circuit, as well as an auxiliary qubit to perform the swap test between the reference and trash states. We will therefore have a total of :math:`2 + 3 + 2 + 1 = 8` qubits and :math:`1` classical register in our circuit."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:414
msgid "After initializing our state, we apply our parametrized circuit."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:416
msgid "Following this, we then split our initial state into the latent space (the compressed state) and trash space (the part of the state we will disregard) and perform the swap test between the reference state and the trash space. The last qubit is then measured to determine the fidelity between the reference and trash states. A pictorial representation of this is given below in Figure 4."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:427
msgid "|qae_fig4_wide.png|"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:429
msgid "qae_fig4_wide.png"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:440
msgid "Figure 4: Example of a Quantum Autoencoder in the training process. We use the swap test to determine the fidelity between the trash and reference space."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:451
msgid "We define a function below to implement the above circuit configuration to the :math:`5` qubit domain wall state :math:`|00111\\rangle` and plot an example below. Here qubits :math:`5` and :math:`6` are the reference state, :math:`0, 1, 2, 3, 4` are the initial state we wish to compress and qubit :math:`7` is our auxiliary qubit which is used in the swap test. We also include a classical register to measure the results of qubit :math:`7` in the swap test."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:501
msgid "In order to reconstruct the original input state, we must apply the adjoint of our parametrized circuit after the swap test. However, during training, we are only interested in the trash state and the reference state. We can therefore exclude the gates following compression until we wish to reconstruct our initial input."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:503
msgid "After building our Quantum Autoencoder, the next step is to train our Quantum Autoencoder to compress the state and maximize the cost function and determine the parameters :math:`\\theta`."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:515
msgid "6. A Simple Example: The Domain Wall Autoencoder"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:526
msgid "Let’s first begin with a simple example, a state known as the Domain Wall, which for :math:`5` qubits is given by :math:`|00111\\rangle`. Here we will try and compress this state from :math:`5` qubits to :math:`3` qubits, with the remaining qubits in the trash space, in the state :math:`|00\\rangle`. We can create a function to build the domain wall state below."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:564
msgid "Now let’s train our Autoencoder to compress this state from 5 qubits to 3 qubits (qubits 0,1 and 2), with the remaining qubits in the trash space (qubits 3 and 4) being in the \\|00> state."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:575
msgid "We create a circuit to be used in the loss function, as described in Section 4, which determines the fidelity between the two states below using the swap test for our particular AutoEncoder function. For further information on the swap test, see [1]."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:609
msgid "Then, we create a quantum neural network and pass the circuit as a parameter. We note that this network must take an interpret function, which determines how we map the output of the network to the output shape. Since we measure only one qubit, the output of the network is a bit string either :math:`0` or :math:`1`, so the output shape is :math:`2`, the number of possible outcomes. Then, we introduce an identity mapping. The output of the network is a vector of probabilities of getting interpret-mapped bit strings. Thus, we get probabilities of getting :math:`0` or :math:`1` and this is exactly what we are looking for. In the cost function we make use of the probability of getting :math:`1` and penalize the outcomes that lead to :math:`1`, therefore maximizing the fidelity between the trash space and the reference space."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:642
msgid "Next we create our cost function. As described in the previous section, our aim is to minimize :math:`\\frac{2}{M}L`, which is the twice the probability of getting the final qubit in the :math:`|1\\rangle` state. We therefore wish to minimize the of getting a :math:`|1\\rangle` on qubit 7."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:644
msgid "The cost function will also plot out the objective value at each cost function evaluation."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:678
msgid "Now we will train our Autoencoder to reduce the dimension of the Hilbert space from :math:`5` qubits to :math:`3`, while leaving the trash space in the state :math:`|00\\rangle`. We initially set the parameters :math:`\\theta` to random values and tune these parameters to minimize our cost function through the use of the COBYLA optimizer."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:743
msgid "Looks like it has converged! After training our Quantum Autoencoder, let’s build it and see how well it compresses the state!"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:745
msgid "To do this, we first apply our Autoencoder to a :math:`5` qubit Domain Wall state. After applying this state, the compressed state should be of the form :math:`|00\\rangle`. Therefore resetting the last two qubits should not effect our over all state."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:747
msgid "After resetting we apply our decoder (the hermitian conjugate of our encoder) and compare it to the initial state by determining the fidelity. If our fidelity is one, then our Autoencoder has encoded all the information of the domain wall efficiently into a smaller set of qubits and when decoding, we retain the original state!"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:758
msgid "Let’s first apply our circuit to the Domain Wall State, using the parameters we obtained when training our Quantum Autoencoder. (Note we have included barriers in our circuit below, however these are not necessary for the implementation of the Quantum Autoencoder and are used to determine between different sections of our circuit)."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:798
msgid "Now we assign the parameter values obtained in the training."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:819
msgid "Now let’s get the statevectors of our Domain Wall state and output circuit and calculate the fidelity!"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:868
msgid "As you can see our fidelity is quite high and our Autoencoder has thus compressed our dataset while retaining all the information from the input state!"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:870
msgid "Now we will see if we can apply such a Quantum Autoencoder to more complicated datasets containing noise, such as images of the numbers zero and one."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:882
msgid "7. A Quantum Autoencoder for Digital Compression"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:893
msgid "One can also apply a Quantum Autoencoder to more complicated examples, such as a set of handwritten digits in order to compress the dataset. Below, we will show that we can indeed train an Quantum Autoencoder to compress such an example, giving us the ability to store data more efficiently on a Quantum Computer."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:895
msgid "For this tutorial, we will build a Quantum Autoencoder for a noisy dataset containing zeros and ones, which can be seen below."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:897
msgid "Each image contains :math:`32` pixels of which can be encoded into :math:`5` qubits by Amplitude Encoding. This can be done using Qiskit’s ``RawFeatureVector`` feature map."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1002
msgid "After encoding our image into :math:`5` qubits, we begin to train our Quantum Autoencoder to compress this state into :math:`3` qubits."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1004
msgid "We repeat the steps in the previous example and write a cost function, again based on the Swap Test between the trash and latent space. We can also use the same Autoencoder function as given in the previous example, as the input state and trash space contain the same amount of qubits."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1006
msgid "Let’s input one of our digits and see our circuit for the Autoencoder below."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1047
msgid "Again, we can see the swap test being performed on the qubits :math:`3`, :math:`4`, :math:`5` and :math:`6`, which will determine the value of our cost function."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1078
msgid "We build our cost function, based on the swap test between the reference and trash space for the digit dataset. To do this, we again use Qiskit’s CircuitQNN network and use the same interpret function as we are measuring the probability of getting the final qubit in the :math:`|1\\rangle` state."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1112
msgid "Since model training may take a long time we have already pre-trained the model for some iterations and saved the pre-trained weights. We’ll continue training from that point by setting ``initial_point`` to a vector of pre-trained weights."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1134
msgid "By minimizing this cost function, we can thus determine the required parameters to compress our noisy images. Let’s see if we can encode our images!"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1197
msgid "Looks like it has converged!"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1199
msgid "Now let’s build our Encoder and Decoder using the parameters obtained from the training period. After applying this circuit to our new dataset, we can then compare our input and output data and see if we were able to retain the images efficiently throughout the compression!"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1265
msgid "It looks like our Quantum Autoencoder can be trained to encode digits as well! Now it’s your turn to build your own Quantum Autoencoder and come up with ideas and datasets to compress!"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1277
msgid "8. Applications of a Quantum Autoencoder"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1288
msgid "Quantum Autoencoder’s can be used for various different applications, including"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1290
msgid "Digital Compression: where information can be encoded into a smaller amount of qubits. This can be hugely beneficial for near term quantum devices, as smaller systems of qubits are less prone to noise."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1291
msgid "Denoising: where one can use Quantum Autoencoder to extract relevant features from the initial quantum state or encoded data, while neglecting any additional noise."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1292
msgid "Quantum Chemistry: in which a Quantum Autoencoder can be used as an ansatz for systems, such as the Hubbard Model. This is commonly used to describe electron-electron interactions in molecules."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1304
msgid "9. References"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1315
msgid "A wikipedia page on Autoencoder: https://en.wikipedia.org/wiki/Autoencoder"
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1317
msgid "Romero, Jonathan, Jonathan P. Olson, and Alan Aspuru-Guzik. “Quantum autoencoders for efficient compression of quantum data.” Quantum Science and Technology 2.4 (2017): 045001."
msgstr ""

#: ../../tutorials/12_quantum_autoencoder.ipynb:1319
msgid "Swap Test Algorithm: https://en.wikipedia.org/wiki/Swap_test"
msgstr ""

