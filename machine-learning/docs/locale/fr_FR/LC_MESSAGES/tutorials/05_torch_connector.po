msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-22 17:47+0000\n"
"PO-Revision-Date: 2021-07-23 11:33\n"
"Last-Translator: \n"
"Language-Team: French\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: fr\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/05_torch_connector.po\n"
"X-Crowdin-File-ID: 9636\n"
"Language: fr_FR\n"

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "This page was generated from `docs/tutorials/05_torch_connector.ipynb`__."
msgstr "Cette page a √©t√© g√©n√©r√©e √† partir de `docs/tutorials/05_torch_connector.ipynb`__."

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector and Hybrid QNNs"
msgstr "Connecteur √† Torch et QNNs hybrides"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial introduces Qiskit‚Äôs ``TorchConnector`` class, and demonstrates how the ``TorchConnector`` allows for a natural integration of any ``NeuralNetwork`` from Qiskit Machine Learning into a PyTorch workflow. ``TorchConnector`` takes a Qiskit ``NeuralNetwork`` and makes it available as a PyTorch ``Module``. The resulting module can be seamlessly incorporated into PyTorch classical architectures and trained jointly without additional considerations, enabling the development and testing of novel **hybrid quantum-classical** machine learning architectures."
msgstr "Ce tutoriel pr√©sente la classe ``TorchConnector`` de Qiskit et montre comment le ``TorchConnector`` permet une int√©gration naturelle de ``NeuralNetwork`` de Qiskit Machine Learning dans un flux de travail PyTorch. ``TorchConnector`` prend un ``NeuralNetwork`` de Qiskit et le rend disponible en tant que ``Module`` de PyTorch. Le module qui en r√©sulte peut √™tre int√©gr√© de fa√ßon transparente dans les architectures classiques de PyTorch et √™tre form√© conjointement sans consid√©rations suppl√©mentaires, ce qui permet le d√©veloppement et la mise √† l'essai de nouvelles architectures **hybrides classique-quantique**."

#: ../../tutorials/05_torch_connector.ipynb:15
msgid "Content:"
msgstr "Contenu¬†:"

#: ../../tutorials/05_torch_connector.ipynb:17
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__"
msgstr "`Partie 1: Classification & R√©gression Simple <#Part-1:-Simple-Classification- &-Regression>` __"

#: ../../tutorials/05_torch_connector.ipynb:19
msgid "The first part of this tutorial shows how quantum neural networks can be trained using PyTorch‚Äôs automatic differentiation engine (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) for simple classification and regression tasks."
msgstr "La premi√®re partie de ce tutoriel montre comment les r√©seaux neuronaux quantiques peuvent √™tre form√©s √† l'aide du moteur de diff√©renciation automatique de PyTorch (``torch.autograd``, lien <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>` __) pour des t√¢ches simples de classification et de r√©gression."

#: ../../tutorials/05_torch_connector.ipynb:21
msgid "`Classification <#1.-Classification>`__"
msgstr "`Classification <#1.-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:23
msgid "Classification with PyTorch and ``OpflowQNN``"
msgstr "Classification avec PyTorch et ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:24
msgid "Classification with PyTorch and ``CircuitQNN``"
msgstr "Classification avec PyTorch et le ``CircuitQNN``"

#: ../../tutorials/05_torch_connector.ipynb:26
msgid "`Regression <#2.-Regression>`__"
msgstr "`R√©gression <#2.-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:28
msgid "Regression with PyTorch and ``OpflowQNN``"
msgstr "R√©gression avec ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:30
msgid "`Part 2: MNIST Classification, Hybrid QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"
msgstr "`Partie 2: Classification MNIST, QNNs hybrides <#Part-2: -MNIST-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:32
msgid "The second part of this tutorial illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow (in this case, a typical CNN architecture) to classify MNIST data in a hybrid quantum-classical manner."
msgstr "La seconde partie de ce tutoriel montre comment int√©grer un ``NeuralNetwork`` (Quantum) dans un workflow PyTorch cible (dans ce cas, une architecture typique de CNN) pour classer les donn√©es MNIST d'une mani√®re hybride quantique-classique."

#: ../../tutorials/05_torch_connector.ipynb:74
msgid "Part 1: Simple Classification & Regression"
msgstr "Partie 1: Classification simple et r√©gression"

#: ../../tutorials/05_torch_connector.ipynb:86
msgid "1. Classification"
msgstr "1. Classification"

#: ../../tutorials/05_torch_connector.ipynb:88
msgid "First, we show how ``TorchConnector`` allows to train a Quantum ``NeuralNetwork`` to solve a classification tasks using PyTorch‚Äôs automatic differentiation engine. In order to illustrate this, we will perform **binary classification** on a randomly generated dataset."
msgstr "Tout d'abord, nous montrons comment ``TorchConnector`` permet de former Quantum ``NeuralNetwork`` pour r√©soudre une t√¢che de classification √† l'aide du moteur de diff√©renciation automatique de PyTorch. Pour illustrer cela, nous allons effectuer une **classification binaire** sur un jeu de donn√©es g√©n√©r√© de fa√ßon al√©atoire."

#: ../../tutorials/05_torch_connector.ipynb:144
msgid "A. Classification with PyTorch and ``OpflowQNN``"
msgstr "A. Classification avec PyTorch et l' ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:146
msgid "Linking an ``OpflowQNN`` to PyTorch is relatively straightforward. Here we illustrate this using the ``TwoLayerQNN``, a sub-case of ``OpflowQNN`` introduced in previous tutorials."
msgstr "Lier un ``OpflowQNN`` √† PyTorch est relativement simple. Ici, nous l'illustrons en utilisant le ``TwoLayerQNN``, un sous-cas de ``OpflowQNN`` introduit dans des tutoriels pr√©c√©dents."

#: ../../tutorials/05_torch_connector.ipynb:254
msgid "Optimizer"
msgstr "Optimiseur"

#: ../../tutorials/05_torch_connector.ipynb:256
msgid "The choice of optimizer for training any machine learning model can be crucial in determining the success of our training‚Äôs outcome. When using ``TorchConnector``, we get access to all of the optimizer algorithms defined in the [``torch.optim``] package (`link <https://pytorch.org/docs/stable/optim.html>`__). Some of the most famous algorithms used in popular machine learning architectures include *Adam*, *SGD*, or *Adagrad*. However, for this tutorial we will be using the L-BFGS algorithm (``torch.optim.LBFGS``), one of the most well know second-order optimization algorithms for numerical optimization."
msgstr "Le choix de l'optimiseur pour la formation de n'importe quel mod√®le d'apprentissage automatique peut √™tre crucial pour d√©terminer le succ√®s du r√©sultat de notre formation. Lors de l'utilisation de ``TorchConnector``, nous avons acc√®s √† tous les algorithmes de l'optimiseur d√©finis dans le paquet [``torch.optim``] (`lien <https://pytorch.org/docs/stable/optim.html>` __). Parmi les algorithmes les plus c√©l√®bres utilis√©s dans les architectures d'apprentissage en machine populaires figurent *Adam*, *SGD* ou *Adagrad *. Cependant, pour ce tutoriel, nous utiliserons l'algorithme L-BFGS (``torch.optim.LBFGS``), l'un des algorithmes d'optimisation de second ordre les plus connu pour l'optimisation num√©rique."

#: ../../tutorials/05_torch_connector.ipynb:260
msgid "Loss Function"
msgstr "Fonction de perte"

#: ../../tutorials/05_torch_connector.ipynb:262
msgid "As for the loss function, we can also take advantage of PyTorch‚Äôs pre-defined modules from ``torch.nn``, such as the `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ or `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."
msgstr "Quant √† la fonction de perte, nous pouvons √©galement tirer profit des modules pr√©d√©finis de PyTorch de ``torch.nn``, tels que la `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>` __ ou ` Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ ."

#: ../../tutorials/05_torch_connector.ipynb:264
msgid "**üí° Clarification :** In classical machine learning, the general rule of thumb is to apply a Cross-Entropy loss to classification tasks, and MSE loss to regression tasks. However, this recommendation is given under the assumption that the output of the classification network is a class probability value in the [0,1] range (usually this is achieved through a Softmax layer). Because the following example for ``TwoLayerQNN`` does not include such layer, and we don‚Äôt apply any mapping to the output (the following section shows an example of application of parity mapping with ``CircuitQNNs``), the QNN‚Äôs output can take any value in the range [-1,1]. In case you were wondering, this is the reason why this particular example uses MSELoss for classification despite it not being the norm (but we encourage you to experiment with different loss functions and see how they can impact training results)."
msgstr "**üí° Clarification: ** Dans l'apprentissage machine automatique, la r√®gle g√©n√©rale consiste √† appliquer une perte inter-entropie aux t√¢ches de classification, et la perte MSE aux t√¢ches de r√©gression. Cependant, cette recommandation est donn√©e en partant de l'hypoth√®se que la sortie du r√©seau de classification est une valeur de probabilit√© dans la gamme [0, 1] (ce qui est g√©n√©ralement obtenu par le biais d'une couche de Softmax). Etant donn√© que l'exemple suivant pour ``TwoLayerQNN`` n'inclut pas cette couche, et que nous n'appliquons aucun mappage √† la sortie (la section suivante montre un exemple d'application du mappage de parit√© avec ``CircuitQNNs``), la sortie QNN peut prendre n'importe quelle valeur dans la plage [-1,1]. Au cas o√π vous vous poseriez la question, c'est la raison pour laquelle cet exemple particulier utilise MSELoss pour la classification alors qu'il n'est pas la norme (mais nous vous encourageons √† exp√©rimenter diff√©rentes fonctions de perte et voir comment elles peuvent avoir un impact sur les r√©sultats de l'entra√Ænement)."

#: ../../tutorials/05_torch_connector.ipynb:442
#: ../../tutorials/05_torch_connector.ipynb:674
msgid "The red circles indicate wrongly classified data points."
msgstr "Les cercles rouges indiquent des points de donn√©es mal classifi√©s."

#: ../../tutorials/05_torch_connector.ipynb:454
msgid "B. Classification with PyTorch and ``CircuitQNN``"
msgstr "B. Classification avec PyTorch et le ``CircuitQNN``"

#: ../../tutorials/05_torch_connector.ipynb:456
msgid "Linking an ``CircuitQNN`` to PyTorch requires a bit more attention than ``OpflowQNN``. Without the correct setup, backpropagation is not possible."
msgstr "La liaison d'un ``CircuitQNN`` √† PyTorch n√©cessite un peu plus d'attention que ``OpflowQNN``. Sans une configuration correcte, la r√©tropropagation n'est pas possible."

#: ../../tutorials/05_torch_connector.ipynb:458
msgid "In particular, we must make sure that we are returning a dense array of probabilities in the network‚Äôs forward pass (``sparse=False``). This parameter is set up to ``False`` by default, so we just have to make sure that it has not been changed."
msgstr "En particulier, nous devons nous assurer que nous retournons une gamme dense de probabilit√©s dans le passage direct du r√©seau (``sparse=False``). Ce param√®tre est d√©fini sur ``False`` par d√©faut, donc il suffit de s'assurer qu'il n'a pas √©t√© modifi√©."

#: ../../tutorials/05_torch_connector.ipynb:460
msgid "**‚ö†Ô∏è Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``CircuitQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."
msgstr "**‚ö†Ô∏è Attention : **Si nous d√©finissons une fonction d'interpr√©tation personnalis√©e (dans cet exemple: ``parity``), nous ne devons pas oublier de fournir explicitement la forme de sortie souhait√©e (dans l'exemple: ``2``). Pour plus d'informations sur la configuration initiale du param√®tre pour ``CircuitQNN``, veuillez consulter la `documentation officielle de qiskit <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>` __."

#: ../../tutorials/05_torch_connector.ipynb:523
#: ../../tutorials/05_torch_connector.ipynb:815
msgid "For a reminder on optimizer and loss function choices, you can go back to `this section <#Optimizer>`__."
msgstr "Pour un rappel sur les choix de fonctions d'optimisation et de perte, vous pouvez retourner √† `cette section <#Optimizer>`__."

#: ../../tutorials/05_torch_connector.ipynb:686
msgid "2. Regression"
msgstr "2. R√©gression"

#: ../../tutorials/05_torch_connector.ipynb:688
msgid "We use a model based on the ``TwoLayerQNN`` to also illustrate how to perform a regression task. The chosen dataset in this case is randomly generated following a sine wave."
msgstr "Nous utilisons un mod√®le bas√© sur le ``TwoLayerQNN`` pour illustrer la mani√®re d'effectuer une t√¢che de regression. Le jeu de donn√©es choisi dans ce cas est g√©n√©r√© de fa√ßon al√©atoire √† partir d'une onde sinuso√Ødale."

#: ../../tutorials/05_torch_connector.ipynb:730
msgid "A. Regression with PyTorch and ``OpflowQNN``"
msgstr "A. R√©gression avec PyTorch et ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:741
msgid "The network definition and training loop will be analogous to those of the classification task using ``TwoLayerQNN``. In this case, we define our own feature map and ansatz, instead of using the default values."
msgstr "La d√©finition du r√©seau et routine d'entrainement du r√©seau seront analogues √† celles de la t√¢che de classification utilisant ``TwoLayerQNN``. Dans ce cas, nous d√©finissons notre propre jeu de features et ansatz, au lieu d'utiliser les valeurs par d√©faut."

#: ../../tutorials/05_torch_connector.ipynb:963
msgid "Part 2: MNIST Classification, Hybrid QNNs"
msgstr "Partie 2 : Classification MNIST, QNNs hybrides"

#: ../../tutorials/05_torch_connector.ipynb:965
msgid "In this second part, we show how to leverage a hybrid quantum-classical neural network using ``TorchConnector``, to perform a more complex image classification task on the MNIST handwritten digits dataset."
msgstr "Dans cette seconde partie, nous montrons comment tirer parti d'un r√©seau neuronal quantique hybride √† l'aide de ``TorchConnector`` pour effectuer une t√¢che de classification d'image plus complexe sur le jeu de donn√©es des √©critures manuelles du MNIST."

#: ../../tutorials/05_torch_connector.ipynb:967
msgid "For a more detailed (pre-``TorchConnector``) explanation on hybrid quantum-classical neural networks, you can check out the corresponding section in the `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."
msgstr "Pour une explication plus d√©taill√©e (pre-``TorchConnector``) sur les r√©seaux neuronaux hybrides quantiques classiques, vous pouvez consulter la section correspondante dans le manuel `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>` __."

#: ../../tutorials/05_torch_connector.ipynb:996
msgid "Step 1: Defining Data-loaders for train and test"
msgstr "√âtape 1 : D√©finir des chargeurs de donn√©es pour l'entrainement et le test"

#: ../../tutorials/05_torch_connector.ipynb:1007
msgid "We take advantage of the ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ to directly load a subset of the `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ and define torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) for train and test."
msgstr "Nous tirons profit de l'API `torchvision<https://pytorch.org/vision/stable/datasets.html>` __ pour charger directement un sous-ensemble de l'ensemble de donn√©es MNIST <https://en.wikipedia.org/wiki/MNIST_database>` __ et d√©finir le `` DataLoader`` Torch (` link <https://pytorch.org/docs/stable/data.html>` __) pour l'entrainement et le test."

#: ../../tutorials/05_torch_connector.ipynb:1048
msgid "If we perform a quick visualization we can see that the train dataset consists of images of handwritten 0s and 1s."
msgstr "Si nous r√©alisons une visualisation rapide, nous pouvons voir que le jeu de donn√©es d'entrainement est constitu√© d'images de 0 et de 1 manuscrits."

#: ../../tutorials/05_torch_connector.ipynb:1120
msgid "Step 2: Defining the QNN and Hybrid Model"
msgstr "√âtape 2 : D√©finition du QNN et du mod√®le hybride"

#: ../../tutorials/05_torch_connector.ipynb:1131
msgid "This second step shows the power of the ``TorchConnector``. After defining our quantum neural network layer (in this case, a ``TwoLayerQNN``), we can embed it into a layer in our torch ``Module`` by initializing a torch connector as ``TorchConnector(qnn)``."
msgstr "Cette seconde √©tape montre la puissance de ``TorchConnector``. Apr√®s avoir d√©fini notre couche de r√©seau neuronal quantique (dans ce cas, un ``TwoLayerQNN``) nous pouvons l'int√©grer dans une couche de notre ``Module`` Torch en initialisant un connecteur comme ``TorchConnector(qnn)``."

#: ../../tutorials/05_torch_connector.ipynb:1133
msgid "**‚ö†Ô∏è Attention:** In order to have an adequate gradient backpropagation in hybrid models, we MUST set the initial parameter ``input_gradients`` to TRUE during the qnn initialization."
msgstr "**‚ö†Ô∏è Attention : ** Pour avoir une r√©tropropagation de gradient ad√©quate dans les mod√®les hybrides, nous DEVEZ d√©finir le param√®tre initial ``input_gradients`` √† TRUE lors de l'initialisation du qnn."

#: ../../tutorials/05_torch_connector.ipynb:1235
msgid "Step 3: Training"
msgstr "√âtape 3 : Entra√Ænement"

#: ../../tutorials/05_torch_connector.ipynb:1337
msgid "Step 4: Evaluation"
msgstr "√âtape 4 : √âvaluation"

#: ../../tutorials/05_torch_connector.ipynb:1440
msgid "üéâüéâüéâüéâ **You are now able to experiment with your own hybrid datasets and architectures using Qiskit Machine Learning.** **Good Luck!**"
msgstr "üéâüéâüéâüéâ **Vous pouvez maintenant exp√©rimenter avec vos propres jeux de donn√©es et architectures hybrides en utilisant Qiskit Machine Learning.** **Bonne chance !**"

