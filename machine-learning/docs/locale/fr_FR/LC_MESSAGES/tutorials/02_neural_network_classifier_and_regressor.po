msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-09-01 14:17+0000\n"
"PO-Revision-Date: 2023-09-01 15:23\n"
"Last-Translator: \n"
"Language: fr\n"
"Language-Team: French\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: fr\n"
"X-Crowdin-File: /main/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/02_neural_network_classifier_and_regressor.po\n"
"X-Crowdin-File-ID: 9630\n"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:9
msgid "This page was generated from `docs/tutorials/02_neural_network_classifier_and_regressor.ipynb`__."
msgstr "Cette page a été générée à partir de `docs/tutorials/02_neural_network_classifier_and_regressor.ipynb`__."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:9
msgid "Neural Network Classifier & Regressor"
msgstr "Classification et régression de réseau de neurones"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:11
msgid "In this tutorial we show how the ``NeuralNetworkClassifier`` and ``NeuralNetworkRegressor`` are used. Both take as an input a (Quantum) ``NeuralNetwork`` and leverage it in a specific context. In both cases we also provide a pre-configured variant for convenience, the Variational Quantum Classifier (``VQC``) and Variational Quantum Regressor (``VQR``). The tutorial is structured as follows:"
msgstr "Dans ce tutoriel, nous montrons comment utiliser ``NeuralNetworkClassifier`` et ``NeuralNetworkRegressor``. Les deux prennent comme entrée (Quantique) ``NeuralNetwork`` et l'exploitent dans un contexte spécifique. Dans les deux cas, nous proposons également pour plus de commodité, une variante préconfigurée : Le Classificateur Variationnel Quantique (``VQC``) et le Régresseur Variationnel Quantique (``VQR``). Le didacticiel est structuré comme suit :"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:13
msgid "`Classification <#Classification>`__"
msgstr "`Classification <#Classification>` __"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:15
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:132
msgid "Classification with an ``EstimatorQNN``"
msgstr "Classification avec ``EstimatorQNN``"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:16
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:408
msgid "Classification with a ``SamplerQNN``"
msgstr "Classification avec un ``SamplerQNN``"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:17
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:628
msgid "Variational Quantum Classifier (``VQC``)"
msgstr "Classifieur Variationnel Quantique (VQC)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:19
msgid "`Regression <#Regression>`__"
msgstr "`Régression <#Regression>` __"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:21
#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1076
msgid "Regression with an ``EstimatorQNN``"
msgstr "Classification avec ``EstimatorQNN``"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:22
msgid "Variational Quantum Regressor (``VQR``)"
msgstr "Régresseur Variationnel Quantique (``VQR``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:85
msgid "Classification"
msgstr "Classification"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:87
msgid "We prepare a simple classification dataset to illustrate the following algorithms."
msgstr "Nous préparons un ensemble de données de classification simple pour illustrer les algorithmes suivants."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:134
msgid "First we show how an ``EstimatorQNN`` can be used for classification within a ``NeuralNetworkClassifier``. In this context, the ``EstimatorQNN`` is expected to return one-dimensional output in :math:`[-1, +1]`. This only works for binary classification and we assign the two classes to :math:`\\{-1, +1\\}`."
msgstr "Premièrement, nous montrons comment ``EstimatorQNN`` peut être utilisé pour la classification dans un ``NeuralNetworkClassifier``. Dans ce contexte, ``EstimatorQNN`` est censé renvoyer une sortie unidimensionnelle dans :math:`[-1, +1]`. Cela ne fonctionne que pour la classification binaire et nous affectons les deux classes à :math:` \\{ -1, + 1\\}`."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:170
msgid "Create a quantum neural network"
msgstr "Création d'un réseau de neurones quantique"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:229
msgid "We will add a callback function called ``callback_graph``. This will be called for each iteration of the optimizer and will be passed two parameters: the current weights and the value of the objective function at those weights. For our function, we append the value of the objective function to an array so we can plot iteration versus objective function value and update the graph with each iteration. However, you can do whatever you want with a callback function as long as it gets the two parameters mentioned passed."
msgstr "Nous allons ajouter une fonction de rappel appelée ``callback_graph``. Elle sera appelée pour chaque itération de l'optimiseur et recevra deux paramètres : les poids actuels et la valeur de la fonction objectif à ces pondérations. Pour notre fonction, nous ajoutons la valeur de la fonction objectif à un tableau pour que nous puissions tracer la valeur de l'itération par rapport à la fonction objectif et mettre à jour le graphe avec chaque itération. Cependant, vous pouvez faire ce que vous voulez avec une fonction de rappel tant qu'elle obtient les deux paramètres mentionnés."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:358
msgid "Now, when the model is trained, we can explore the weights of the neural network. Please note, the number of weights is defined by ansatz."
msgstr "Maintenant, quand le modèle est entraîné, nous pouvons explorer les poids du réseau neuronal. Veuillez noter que le nombre de poids est défini par ansatz."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:410
msgid "Next we show how a ``SamplerQNN`` can be used for classification within a ``NeuralNetworkClassifier``. In this context, the ``SamplerQNN`` is expected to return :math:`d`-dimensional probability vector as output, where :math:`d` denotes the number of classes. The underlying ``Sampler`` primitive returns quasi-distributions of bit strings and we just need to define a mapping from the measured bitstrings to the different classes. For binary classification we use the parity mapping."
msgstr "Ensuite, nous montrons comment ``SamplerQNN`` peut être utilisé pour la classification à l'intérieur d'un ``NeuralNetworkClassifier``. Dans ce contexte, le ``SamplerQNN`` est censé renvoyer le vecteur de probabilité :math:`d`-dimensionnel comme sortie, où :math:`d` indique le nombre de classes. La primitive sous jacente ``Sampler`` reetourne les quasi-distributions de bit strings , et il suffit de définir une correspondance entre les bitstrings mesuré et les différeentes classes. Pour une classification binaire, nous utilisons le maaping de parité."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:581
msgid "Again, once the model is trained we can take a look at the weights. As we set ``reps=1`` explicitly in our ansatz, we can see less parameters than in the previous model."
msgstr "Encore une fois, une fois le modèle entraîné, nous pouvons examiner les poids. Comme nous avons défini ``reps=1``explicitement dans notre ansatz, nous pouvons voir moins de paramètres que dans le modèle précédent."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:630
msgid "The ``VQC`` is a special variant of the ``NeuralNetworkClassifier`` with a ``SamplerQNN``. It applies a parity mapping (or extensions to multiple classes) to map from the bitstring to the classification, which results in a probability vector, which is interpreted as a one-hot encoded result. By default, it applies this the ``CrossEntropyLoss`` function that expects labels given in one-hot encoded format and will return predictions in that format too."
msgstr "``VQC`` est une variante spéciale de ``NeuralNetworkClassifier`` avec un ``SamplerQNN``. Il applique une correspondance de parité (ou des extensions à plusieurs classes) pour mapper la chaîne de bits à la classification, ce qui donne lieu à un vecteur de probabilité, qui est interprété comme un résultat à encodage 1 parmi n (one-hot encoding). Par défaut, il applique la fonction ``CrossEntropyLoss`` qui attend les étiquettes données en un format d'encodage 1 parmi n et qui renverra également les prédictions dans ce format."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:749
msgid "Multiple classes with VQC"
msgstr "Classes multiples avec VQC"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:751
msgid "In this section we generate an artificial dataset that contains samples of three classes and show how to train a model to classify this dataset. This example shows how to tackle more interesting problems in machine learning. Of course, for a sake of short training time we prepare a tiny dataset. We employ ``make_classification`` from SciKit-Learn to generate a dataset. There 10 samples in the dataset, 2 features, that means we can still have a nice plot of the dataset, as well as no redundant features, these are features are generated as a combinations of the other features. Also, we have 3 different classes in the dataset, each classes one kind of centroid and we set class separation to ``2.0``, a slight increase from the default value of ``1.0`` to ease the classification problem."
msgstr "Dans cette section, nous générons un jeu de données artificiel contenant des échantillons de trois classes et montrant comment former un modèle pour classer ce jeu de données. Cet exemple montre comment résoudre des problèmes plus intéressants dans l'apprentissage automatique. Bien sûr, pour des raisons de durée d'entraînement, nous préparons un petit jeu de données. Nous utilisons ``make_classification`` de SciKit-Learn pour générer un jeu de données. Il y a 10 échantillons dans le jeu de données, 2 fonctionnalités, ce qui signifie que nous pouvons encore avoir un joli tracé du jeu de données, ainsi qu’aucune fonctionnalité redondante, ces fonctionnalités sont générées en tant que combinaisons des autres fonctionnalités. De plus, nous avons 3 classes différentes dans le jeu de données, chaque classe un type de centroid et nous définissons la séparation de classe à ``2. ``, une légère augmentation à partir de la valeur par défaut de ``1.0`` pour faciliter le problème de classification."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:754
msgid "Once the dataset is generated we scale the features into the range ``[0, 1]``."
msgstr "Une fois que le jeu de données est généré, nous mettons à l'échelle les fonctionnalités dans la plage ``[0, 1]``."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:787
msgid "Let's see how our dataset looks like."
msgstr ""

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:842
msgid "We also transform labels and make them categorical."
msgstr ""

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:891
msgid "We create an instance of ``VQC`` similar to the previous example, but in this case we pass a minimal set of parameters. Instead of feature map and ansatz we pass just the number of qubits that is equal to the number of features in the dataset, an optimizer with a low number of iteration to reduce training time, a quantum instance, and a callback to observe progress."
msgstr ""

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:916
msgid "Start the training process in the same way as in previous examples."
msgstr ""

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:982
msgid "Despite we had the low number of iterations, we achieved quite a good score. Let see the output of the ``predict`` method and compare the output with the ground truth."
msgstr ""

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1033
msgid "Regression"
msgstr "Régression"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1035
msgid "We prepare a simple regression dataset to illustrate the following algorithms."
msgstr "Nous préparons un ensemble de données de régression simple pour illustrer les algorithmes suivants."

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1078
msgid "Here we restrict to regression with an ``EstimatorQNN`` that returns values in :math:`[-1, +1]`. More complex and also multi-dimensional models could be constructed, also based on ``SamplerQNN`` but that exceeds the scope of this tutorial."
msgstr ""

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1215
msgid "Similarly to the classification models, we can obtain an array of trained weights by querying a corresponding property of the model. In this model we have only one parameter defined as ``param_y`` above."
msgstr ""

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1262
msgid "Regression with the Variational Quantum Regressor (``VQR``)"
msgstr "Régression avec le Régresseur Quantique Variationnel (``VQR``)"

#: ../../tutorials/02_neural_network_classifier_and_regressor.ipynb:1264
msgid "Similar to the ``VQC`` for classification, the ``VQR`` is a special variant of the ``NeuralNetworkRegressor`` with a ``EstimatorQNN``. By default it considers the ``L2Loss`` function to minimize the mean squared error between predictions and targets."
msgstr ""

