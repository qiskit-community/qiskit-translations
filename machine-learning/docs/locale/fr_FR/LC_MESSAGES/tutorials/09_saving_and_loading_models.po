msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-05-09 10:21+0000\n"
"PO-Revision-Date: 2023-08-14 19:37\n"
"Last-Translator: \n"
"Language: fr\n"
"Language-Team: French\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: fr\n"
"X-Crowdin-File: /main/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/09_saving_and_loading_models.po\n"
"X-Crowdin-File-ID: 9887\n"

#: ../../tutorials/09_saving_and_loading_models.ipynb:9
msgid "This page was generated from `docs/tutorials/09_saving_and_loading_models.ipynb`__."
msgstr "Cette page a été générée à partir de `docs/tutorials/05_uploading_program.ipynb`__."

#: ../../tutorials/09_saving_and_loading_models.ipynb:9
msgid "Saving, Loading Qiskit Machine Learning Models and Continuous Training"
msgstr "Sauvegarder, Charger les modèles Qiskit Machine Learning et Entraînement Continu"

#: ../../tutorials/09_saving_and_loading_models.ipynb:11
msgid "In this tutorial we will show how to save and load Qiskit machine learning models. Ability to save a model is very important, especially when a significant amount of time is invested in training a model on a real hardware. Also, we will show how to resume training of the previously saved model."
msgstr "Dans ce tutoriel nous montrerons comment enregistrer et charger les modèles d'apprentissage automatique Qiskit. La fonctionalité de sauvegarde d'un modèle est très importante, surtout lorsque beaucoup de temps est investi dans l'entraînment d'un modèle sur un véritable système. De plus, nous montrerons comment reprendre l'entraînment du modèle précédemment enregistré."

#: ../../tutorials/09_saving_and_loading_models.ipynb:13
msgid "In this tutorial we will cover how to:"
msgstr "Dans ce tutoriel, nous allons apprendre à :"

#: ../../tutorials/09_saving_and_loading_models.ipynb:15
msgid "Generate a simple dataset, split it into training/test datasets and plot them"
msgstr "Générer un simple ensemble de données, le diviser en ensembles d'apprentissage et de test, et les représenter graphiquement"

#: ../../tutorials/09_saving_and_loading_models.ipynb:16
msgid "Train and save a model"
msgstr "Entraînez et sauvegarder un modèle"

#: ../../tutorials/09_saving_and_loading_models.ipynb:17
msgid "Load a saved model and resume training"
msgstr "Charger un modèle sauvegardé et reprendre l'apprentissage"

#: ../../tutorials/09_saving_and_loading_models.ipynb:18
msgid "Evaluate performance of models"
msgstr "Évaluer la performance des modèles"

#: ../../tutorials/09_saving_and_loading_models.ipynb:19
msgid "PyTorch hybrid models"
msgstr "Modèles hybrides PyTorch"

#: ../../tutorials/09_saving_and_loading_models.ipynb:30
msgid "First off, we start from the required imports. We'll heavily use SciKit-Learn on the data preparation step. In the next cell we also fix a random seed for reproducibility purposes."
msgstr "Tout d'abord, nous commençons par les importations requises. Nous utiliserons beaucoup SciKit-Learn pour l'étape de préparation des données. Dans la cellule suivante, nous définissons également une graine aléatoire à des fins de reproductibilité."

#: ../../tutorials/09_saving_and_loading_models.ipynb:64
msgid "We will be using two quantum simulators, in particular, two instances of the ``Sampler`` primitive. We'll start training on the first one, then will resume training on the second one. The approach shown in this tutorial can be used to train a model on a real hardware available on the cloud and then re-use the model for inference on a local simulator."
msgstr "Nous allons utiliser deux simulateurs quantiques, plus particulièrement, deux instances de la primitive ``Sampler``. Nous débuterons la phase apprentissage sur la première, puis reprendrons l'apprentissage sur la deuxième. L'approche illustrée dans ce tutoriel peut être utilisée pour entraîner un modèle sur un véritable système disponible sur le cloud, puis réutiliser le modèle pour un simulateur local."

#: ../../tutorials/09_saving_and_loading_models.ipynb:88
msgid "1. Prepare a dataset"
msgstr "1. Préparer un ensemble de données"

#: ../../tutorials/09_saving_and_loading_models.ipynb:90
msgid "Next step is to prepare a dataset. Here, we generate some data in the same way as in other tutorials. The difference is that we apply some transformations to the generated data. We generates ``40`` samples, each sample has ``2`` features, so our features is an array of shape ``(40, 2)``. Labels are obtained by summing up features by columns and if the sum is more than ``1`` then this sample is labeled as ``1`` and ``0`` otherwise."
msgstr "L'étape suivante consiste à préparer un ensemble de données. Ici, nous générons des données de la même façon que dans d'autres tutoriels. La différence est que nous appliquons certaines transformations aux données générées. Nous générons ``40`` échantillons, chaque échantillon a ``2`` variables, donc nos variables sont un ensemble de forme ``(40, 2)``. L'étiquetage est obtenu en additionnant les variables par colonnes et si la somme est supérieure à ``1``, alors cet échantillon est marqué comme ``1`` et ``0`` autrement."

#: ../../tutorials/09_saving_and_loading_models.ipynb:114
msgid "Then, we scale down our features into a range of ``[0, 1]`` by applying ``MinMaxScaler`` from SciKit-Learn. Model training convergence is better when this transformation is applied."
msgstr "Ensuite, nous réduisons nos variables à ``[0, 1]`` en appliquant ``MinMaxScaler`` de SciKit-Learn. La convergence de l'entraînement du modèle est meilleure lorsque cette transformation est appliquée."

#: ../../tutorials/09_saving_and_loading_models.ipynb:161
msgid "Let's take a look at the features of the first ``5`` samples of our dataset after the transformation."
msgstr "Examinons les variables des premiers ``5`` échantillons de notre ensemble de données, après la transformation."

#: ../../tutorials/09_saving_and_loading_models.ipynb:219
msgid "We choose ``VQC`` or Variational Quantum Classifier as a model we will train. This model, by default, takes one-hot encoded labels, so we have to transform the labels that are in the set of ``{0, 1}`` into one-hot representation. We employ SciKit-Learn for this transformation as well. Please note that the input array must be reshaped to ``(num_samples, 1)`` first. The ``OneHotEncoder`` encoder does not work with 1D arrays and our labels is a 1D array. In this case a user must decide either an array has only one feature(our case!) or has one sample. Also, by default the encoder returns sparse arrays, but for dataset plotting it is easier to have dense arrays, so we set ``sparse`` to ``False``."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:296
msgid "Let's take a look at the labels of the first ``5`` labels of the dataset. The labels should be one-hot encoded."
msgstr "Examinons l'étiquetage des premiers ``5`` échantillons de l'ensemble de données. Les étiquettes devraient être encodées one-hot."

#: ../../tutorials/09_saving_and_loading_models.ipynb:354
#, python-format
msgid "Now we split our dataset into two parts: a training dataset and a test one. As a rule of thumb, 80% of a full dataset should go into a training part and 20% into a test one. Our training dataset has ``30`` samples. The test dataset should be used only once, when a model is trained to verify how well the model behaves on unseen data. We employ ``train_test_split`` from SciKit-Learn."
msgstr "Maintenant, nous divisons notre ensemble de données en deux parties : un ensemble de données d'entraînement et un ensemble de données de test. En règle générale, 80 % d'un ensemble de données devrait être dédié à l'entraînement et 20 % au test. Notre ensemble de données d'entraînement a ``30`` échantillons. L'ensemble de données de test ne devrait être utilisé qu'une seule fois, lorsqu'un modèle est formé pour vérifier comment le modèle se comporte sur les données nouvelles. Nous utilisons ``train_test_split`` de SciKit-Learn."

#: ../../tutorials/09_saving_and_loading_models.ipynb:403
msgid "Now it is time to see how our dataset looks like. Let's plot it."
msgstr "Maintenant, il est temps de voir à quoi ressemble notre ensemble de données. Représentons le graphiquement."

#: ../../tutorials/09_saving_and_loading_models.ipynb:470
msgid "On the plot above we see:"
msgstr "Sur le graphique ci-dessus, nous remarquons :"

#: ../../tutorials/09_saving_and_loading_models.ipynb:472
msgid "Solid blue dots are the samples from the training dataset labeled as ``0``"
msgstr "Les points bleus solides sont les échantillons de l'ensemble de données d'entraînement, annotés ``0``"

#: ../../tutorials/09_saving_and_loading_models.ipynb:473
msgid "Empty blue dots are the samples from the test dataset labeled as ``0``"
msgstr "Les points bleus vides sont les échantillons de l'ensemble de données de test, annotés ``0``"

#: ../../tutorials/09_saving_and_loading_models.ipynb:474
msgid "Solid green dots are the samples from the training dataset labeled as ``1``"
msgstr "Les points verts solides sont les échantillons de l'ensemble de données d'entraînement, annotés ``1``"

#: ../../tutorials/09_saving_and_loading_models.ipynb:475
msgid "Empty green dots are the samples from the test dataset labeled as ``1``"
msgstr "Les points verts vides sont les échantillons de l'ensemble de données de test, annotés ``1``"

#: ../../tutorials/09_saving_and_loading_models.ipynb:477
msgid "We'll train our model using solid dots and verify it using empty dots."
msgstr "Nous allons former notre modèle à l'aide de points solides et le vérifier à l'aide de points vides."

#: ../../tutorials/09_saving_and_loading_models.ipynb:489
msgid "2. Train a model and save it"
msgstr "2. Entraîner un modèle et le sauvegarder"

#: ../../tutorials/09_saving_and_loading_models.ipynb:491
msgid "We'll train our model in two steps. On the first step we train our model in ``20`` iterations."
msgstr "Nous formerons notre modèle en deux étapes. Pour la première étape, nous formons notre modèle en ``20`` itérations."

#: ../../tutorials/09_saving_and_loading_models.ipynb:512
msgid "Create an empty array for callback to store values of the objective function."
msgstr "Créez un tableau vide pour le rappel afin de stocker les valeurs de la fonction objectif."

#: ../../tutorials/09_saving_and_loading_models.ipynb:533
msgid "We re-use a callback function from the Neural Network Classifier & Regressor tutorial to plot iteration versus objective function value with some minor tweaks to plot objective values at each step."
msgstr "Nous réutiliserons une fonction de rappel à partir du tutoriel Classificateur de réseau de neurones & Regressor pour tracer la valeur de l'itération par rapport à la valeur de la fonction objectif avec quelques petits tweaks pour tracer des valeurs objectives à chaque étape."

#: ../../tutorials/09_saving_and_loading_models.ipynb:576
msgid "As mentioned above we train a ``VQC`` model and set ``COBYLA`` as an optimizer with a chosen value of the ``maxiter`` parameter. Then we evaluate performance of the model to see how well it was trained. Then we save this model for a file. On the second step we load this model and will continue to work with it."
msgstr "Comme mentionné ci-dessus, nous formons un modèle ` ` VQC ` ` et définissez ` ` COBYLA ` ` en tant qu'optimiseur avec une valeur choisie du paramètre ` ` maxiter ` `. Ensuite, nous évaluons les performances du modèle pour voir à quel point il a été formé. Ensuite, nous sauvegartons ce modèle pour un fichier. Au cours de la deuxième étape, nous chargerons ce modèle et nous continuerons à travailler avec lui."

#: ../../tutorials/09_saving_and_loading_models.ipynb:578
msgid "Here, we manually construct an ansatz to fix an initial point where to start optimization from."
msgstr "Ici, nous construisons manuellement un ansatz pour fixer un point initial où commencer l'optimisation à partir de."

#: ../../tutorials/09_saving_and_loading_models.ipynb:602
msgid "We create a model and set a sampler to the first sampler we created earlier."
msgstr "Nous créons un modèle et nous fixons un échantillonneur au premier échantillonneur que nous avons créé précédemment."

#: ../../tutorials/09_saving_and_loading_models.ipynb:625
msgid "Now it is time to train the model."
msgstr "Il est maintenant temps de former le modèle."

#: ../../tutorials/09_saving_and_loading_models.ipynb:680
msgid "Let's see how well our model performs after the first step of training."
msgstr "Voyons à quel point notre modèle fonctionne bien après la première étape de la formation."

#: ../../tutorials/09_saving_and_loading_models.ipynb:729
msgid "Next, we save the model. You may choose any file name you want. Please note that the ``save`` method does not append an extension if it is not specified in the file name."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:751
msgid "3. Load a model and continue training"
msgstr "3. Charger un modèle et poursuivre la formation"

#: ../../tutorials/09_saving_and_loading_models.ipynb:753
msgid "To load a model a user have to call a class method ``load`` of the corresponding model class. In our case it is ``VQC``. We pass the same file name we used in the previous section where we saved our model."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:774
msgid "Next, we want to alter the model in a way it can be trained further and on another simulator. To do so, we set the ``warm_start`` property. When it is set to ``True`` and ``fit()`` is called again the model uses weights from previous fit to start a new fit. We also set the ``sampler`` property of the underlying network to the second instance of the ``Sampler`` primitive we created in the beginning of the tutorial. Finally, we create and set a new optimizer with ``maxiter`` is set to ``80``, so the total number of iterations is ``100``."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:798
msgid "Now we continue training our model from the state we finished in the previous section."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:891
msgid "Let's see which data points were misclassified. First, we call ``predict`` to infer predicted values from the training and test features."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:913
msgid "Plot the whole dataset and the highlight the points that were classified incorrectly."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:989
msgid "So, if you have a large dataset or a large model you can train it in multiple steps as shown in this tutorial."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:1001
msgid "4. PyTorch hybrid models"
msgstr "4. Modèles hybrides PyTorch"

#: ../../tutorials/09_saving_and_loading_models.ipynb:1003
msgid "To save and load hybrid models, when using the TorchConnector, follow the PyTorch recommendations of saving and loading the models. For more details please refer to the PyTorch Connector tutorial `here <https://qiskit.org/documentation/machine-learning/tutorials/05_torch_connector.html>`__ where a short snippet shows how to do it."
msgstr ""

#: ../../tutorials/09_saving_and_loading_models.ipynb:1005
msgid "Take a look at this pseudo-like code to get the idea:"
msgstr ""

