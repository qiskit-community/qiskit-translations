msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-09-01 14:17+0000\n"
"PO-Revision-Date: 2023-09-01 15:24\n"
"Last-Translator: \n"
"Language: fr\n"
"Language-Team: French\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: fr\n"
"X-Crowdin-File: /main/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/11_quantum_convolutional_neural_networks.po\n"
"X-Crowdin-File-ID: 9840\n"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/11_quantum_convolutional_neural_networks.ipynb`__."
msgstr "Cette page a été générée à partir de `docs/tutorials/11_quantum_convolutional_neural_networks.ipynb`__."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:9
msgid "The Quantum Convolution Neural Network"
msgstr "Le réseau neuronal convolutif quantique"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:21
msgid "1. Introduction"
msgstr "1. Introduction"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:32
msgid "Throughout this tutorial, we discuss a Quantum Convolutional Neural Network (QCNN), first proposed by Cong et. al. [1]. We implement such a QCNN on Qiskit by modeling both the convolutional layers and pooling layers using a quantum circuit. After building such a network, we train it to differentiate horizontal and vertical lines from a pixelated image. The following tutorial is thus divided accordingly;"
msgstr "Tout au long de ce tutoriel, nous discutons d'un réseau neuronal convolutif quantique (QCNN), proposé pour la première fois par Cong et. al. [1]. Nous implémentons un tel QCNN sur Qiskit en modélisant à la fois les neurones convolutionnels et les neurones de mise en commun à l'aide d'un circuit quantique. Après avoir construit un tel réseau, nous l'entraînons pour différencier les lignes horizontales et verticales d'une image pixélisée. Le tutoriel suivant est donc divisé en conséquence;"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:34
msgid "Differences between a QCNN and CCNN"
msgstr "Différences entre un QCNN et un CCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:35
msgid "Components of a QCNN"
msgstr "Éléments d'un QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:36
msgid "Data Generation"
msgstr "Génération de données"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:37
msgid "Building a QCNN"
msgstr "Construction d'un QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:38
msgid "Training our QCNN"
msgstr "Entraîner notre QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:39
msgid "Testing our QCNN"
msgstr "Tester notre QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:40
msgid "References"
msgstr "Références"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:42
msgid "We first begin by importing the libraries and packages we will need for this tutorial."
msgstr "Nous commençons par importer les bibliothèques et les paquets dont nous aurons besoin pour ce tutoriel."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:106
msgid "1. Differences between a QCNN and CCNN"
msgstr "1. Différences entre un QCNN et un CCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:118
msgid "1.1 Classical Convolutional Neural Networks"
msgstr "1.1 Réseau neuronal convolutif classique"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:129
msgid "Classical Convolutional Neural Networks (CCNNs) are a subclass of artificial neural networks which have the ability to determine particular features and patterns of a given input. Because of this, they are commonly used in image recognition and audio processing."
msgstr "Les réseaux neuronaux convolutifs classiques (CCNNs) sont une sous-classe des réseaux de neurones artificiels qui ont la capacité de déterminer des caractéristiques et des motifs particuliers pour une entrée donnée. De ce fait, ils sont couramment utilisés pour la reconnaissance d'images et le traitement audio."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:131
msgid "The capability of determining features is a result of the two types of layers used in a CCNN, the convolutional layer and pooling layer."
msgstr "La capacité de déterminer les caractéristiques est le résultat des deux types de couches utilisées dans un CCNN, la couche convolutive et la couche de mise en commun."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:133
msgid "An example of a CCNN can be seen in Figure 1, where a CCNN is trained to determine whether an input image either contains a cat or a dog. To do so, the input image passes through a series of alternating convolutional (C) and pooling layers (P), all of which detect patterns and associate each pattern to a cat or a dog. The fully connected layer (FC) provides us with an output which allows us to determine whether the input image was a cat or dog."
msgstr "On peut voir un exemple de CCNN dans la Figure 1, où un CCNN est entraîné pour déterminer si une image contient soit un chat, soit un chien. Pour cela, l'image passe à travers une série alernante de couches convolutives (C) et de mise en commun (P), qui permettent de détecter des motifs et de les associer à un chat ou à un chien. La couche entièrement connectée (FC) nous fournit un résultat qui nous permet de déterminer si l'image était un chat ou un chien."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:135
msgid "The convolutional layer makes use of a kernel, which can determine features and patterns of a particular input. An example of this is feature detection in an image, where different layers detect particular patterns in the input image. This is demonstrated in Figure 1, where the :math:`l^{th}` layer recognizes features and patterns along the :math:`ij` plane. It can then associate such features with a given output in the training process, and can use this process to train the dataset."
msgstr "La couche convolutionnaire utilise un noyau qui peut déterminer les caractéristiques et les motifs d'une entrée particulière. Un exemple de cette fonction est la détection des fonctions dans une image, où différentes couches détectant des motifs particuliers dans l'image d'entrée. Ceci est illustré à la figure 1, où la couche :math:` l ^{th}` reconnaît les caractéristiques et les motifs le long du plan :math:` ij. Il peut ensuite associer de telles fonctions à une sortie donnée dans le processus de formation, et peut utiliser ce processus pour entraîner le jeu de données."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:137
msgid "On the other hand, a pooling layer reduces the dimensionality of the input data, reducing the computational cost and amount of learning parameters in the CCNN. A schematic of a CCNN can be seen below."
msgstr "D'autre part, une couche de mise en commun réduit la dimensionnalité des données, ce qui réduit le coût de calcul et la quantité de paramètres d'apprentissage dans le CCNN. On peut voir ci-dessous le schéma d'un CCNN."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:139
msgid "For further information on CCNN, see [2]."
msgstr "Pour plus d'informations sur les CCNN, voir [2]."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:150
msgid "|Screenshot%202022-08-09%20at%2017.03.09.png| Figure 1. A schematic demonstration of the use of a CCNN to classify between images of a cat and dog. Here, we see the several convolutional and pooling layers being applied, all of which are decreasing in dimensionality due to the use of the pooling layers. The output of the CCNN determines whether the input image was a cat or dog. Image obtained form [1]."
msgstr "|Screenshot%202022-08-09%20at%2017.03.09.png| Figure 1. Une démonstration schématique de l'utilisation d'un CCNN pour différencier les images d'un chat et d'un chien. Ici, nous voyons l'application de plusieurs couches convolutives et de mise en commun, qui diminuent en dimension à cause des couches de mise en commun. Le résultat du CCNN détermine si l'image était un chat ou un chien. Image originelle [1]."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:152
msgid "Screenshot%202022-08-09%20at%2017.03.09.png"
msgstr "Screenshot%202022-08-09%20at%2017.03.09.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:164
msgid "1.2 Quantum Convolutional Neural Networks"
msgstr "1.2. Réseau neuronal convolutif quantique"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:175
msgid "Quantum Convolutional Neural Networks (QCNN) behave in a similar manner to CCNNs. First, we encode our pixelated image into a quantum circuit using a given feature map, such Qiskit's ZFeatureMap or ZZFeatureMap or others available in the circuit library."
msgstr "Les réseaux neuronaux convolutifs quantiques (QCNN) se comportent de la même manière que les CCNNs. Tout d'abord, nous encodons notre image pixelée dans un circuit quantique à l'aide d'une carte de fonction, telle que ZFeatureMap, ZZFeatureMap ou d'autres disponibles dans la bibliothèque de circuits Qiskit."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:177
msgid "After encoding our image, we apply alternating convolutional and pooling layers, as defined in the next section. By applying these alternating layers, we reduce the dimensionality of our circuit until we are left with one qubit. We can then classify our input image by measuring the output of this one remaining qubit."
msgstr "Après avoir encodé notre image, nous appliquons des couches alternatives de convolution et de mise en commun, comme décrit dans la section suivante. En appliquant ces couches alternées, nous réduisons la dimensionnalité de notre circuit jusqu'à ce qu'il nous reste un seul qubit. Nous pouvons alors classifier notre image en mesurant le qubit restant."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:179
msgid "The Quantum Convolutional Layer will consist of a series of two qubit unitary operators, which recognize and determine relationships between the qubits in our circuit. This unitary gates are defined below in the next section."
msgstr "La couche convolutive quantique se compose d'une série de deux opérateurs quantiques unitaires, qui reconnaissent et déterminent les relations entre les qubits de notre circuit. Ces opérateurs unitaires sont défini ci-dessous dans la section suivante."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:181
msgid "For the Quantum Pooling Layer, we cannot do the same as is done classically to reduce the dimension, i.e. the number of qubits in our circuit. Instead, we reduce the number of qubits by performing operations upon each until a specific point and then disregard certain qubits in a specific layer. It is these layers where we stop performing operations on certain qubits that we call our 'pooling layer'. Details of the pooling layer is discussed further in the next section."
msgstr "Pour la couche de mise en commun quantique, nous ne pouvons pas faire de même, comme c'est fait classiquement pour réduire la dimension, c'est-à-dire le nombre de qubits dans notre circuit. Au lieu de cela, nous réduisons le nombre de qubits en effectuant des opérations sur chacun d'entre eux jusqu'à un point spécifique, puis nous ignorons certains qubits dans une couche spécifique. Ce sont ces couches où nous arrêtons les opérations sur certains qubits que nous appelons notre \"couche de mise en commun\". Les détails de la mise en commun sont discutés plus en détail dans la section suivante."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:183
msgid "In the QCNN, each layer contains parametrized circuits, meaning we alter our output result by adjusting the parameters of each layer. When training our QCNN, it is these parameters that are adjusted to reduce the loss function of our QCNN."
msgstr "Dans un QCNN, chaque couche contient des circuits paramétrés, ce qui signifie que nous modifions nos résultats en ajustant les paramètres de chaque couche. Lors de l'apprentissage de notre QCNN, ce sont ces paramètres qui sont ajustés pour réduire la fonction de perte du QCNN."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:194
msgid "A simple example of four qubit QCNN can be seen below."
msgstr "Un exemple simple d'un QCNN à quatre qubits peut être vu ci-dessous."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:205
msgid "|figure2.png|"
msgstr "|figure2.png|"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:207
msgid "figure2.png"
msgstr "figure2.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:218
msgid "Figure 2: Example QCNN containing four qubits. The first Convolutional Layer acts on all the qubits. This is followed by the first pooling layer, which reduces the dimensionality of the QCNN from four qubits to two qubits by disregarding the first two. The second Convolutional layer then detects features between the two qubits still in use in the QCNN, followed by another pooling layer, which reduces the dimensionality from two qubits to one, which will be our output qubit."
msgstr "Figure 2: Exemple QCNN contenant quatre qubits. La première couche convolutionnaire agit sur tous les qubits. Ceci est suivi par la première couche de mise en commun, ce qui réduit la dimensionnalité de QCNN de quatre qubits à deux qubits en disconcernant les deux premiers. La seconde couche Convolutionnaire détecte alors les caractéristiques entre les deux qubits toujours en cours d'utilisation sur la QCNN, suivie d'une autre couche de mise en commun, ce qui réduit la dimensionnalité de deux qubits à un, ce qui sera notre qubit de sortie."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:230
msgid "2. Components of a QCNN"
msgstr "2. Éléments d'un QCNN"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:241
msgid "As discussed in Section 1 of this tutorial, a CCNN will contain both convolutional and pooling layers. Here, we define these layers for the QCNN in terms of gates applied to a Quantum Circuit and demonstrate an example for each layer for 4 qubits."
msgstr "Comme nous l'avons vu à la section 1 de ce tutoriel, un NCCNN contiendra à la fois des couches convolutionnaires et des couches de mise en commun. Ici, nous définissons ces couches pour QCNN en termes de portes appliquées à un circuit quantique et montrons un exemple pour chaque couche pour 4 qubits."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:243
msgid "Each of these layers will contain parameters which are tuned throughout the training process to minimize the loss function and train the QCNN to classify between horizontal and vertical lines."
msgstr "Chacune de ces couches contiendra des paramètres qui seront réglés tout au long du processus de formation afin de minimiser la fonction de perte et de former la QCNN à classer entre les lignes horizontales et verticales."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:245
msgid "In theory, one could apply any parametrized circuit for both the convolutional and pooling layers of our network. For example in [2], the Gellmann Matrices (which are the three dimensional generalization of the Pauli Matrices) are used as generators for each unitary gate acting on a pair of qubits."
msgstr "En théorie, on pourrait appliquer n'importe quel circuit paramétré pour les couches conévolutionnaires et de mise en commun de notre réseau. Par exemple, en [2], les matrices de Gellmann (qui sont la généralisation tridimensionnelle des matrices de Pauli) sont utilisées comme générateurs pour chaque porte unitaire agissant sur une paire de qubits."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:247
msgid "Here, we take a different approach and form our parametrized circuit based on the two qubit unitary as proposed in [3]. This states that every unitary matrix in :math:`U(4)` can be decomposed such that"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:249
msgid "U = (A_1 \\otimes A_2) \\cdot N(\\alpha, \\beta, \\gamma) \\cdot (A_3 \\otimes A_4)\n\n"
msgstr "U = (A_1 \\otimes A_ 2) \\cdot N (\\alpha, \\beta, \\gamma) \\cdot (A_3 \\otimes A_ 4)\n\n"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:251
msgid "where :math:`A_j \\in \\text{SU}(2)`, :math:`\\otimes` is the tensor product, and :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])`, where :math:`\\alpha, \\beta, \\gamma` are the parameters that we can adjust."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:253
msgid "From this, it is evident that each unitary depends on 15 parameters and implies that in order for the QCNN to be able to span the whole Hilbert space, each unitary in our QCNN must contain 15 parameters each."
msgstr "A partir de cela, il est évident que chaque unitaire dépend de 15 paramètres et implique que pour que le QCNN puisse couvrir l'ensemble de l'espace de Hilbert, chaque unitaire de notre QCNN doit contenir 15 paramètres chacun."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:255
msgid "Tuning this large amount of parameters would be difficult and would lead to long training times. To overcome this problem, we restrict our ansatz to a particular subspace of the Hilbert space and define the two qubit unitary gate as :math:`N(\\alpha, \\beta, \\gamma)`. These two qubit unitaries, as seen in [3] can be seen below and are applied to all neighboring qubits each of the layers in the QCNN."
msgstr "L'optimisation de cette grande quantité de paramètres serait difficile et mènerait à de longues périodes de formation. Pour surmonter ce problème, nous limitons notre ansatz à un sous-espace particulier de l'espace de Hilbert et nous définissons la porte unitaire de deux qubits sous le nom de :math:` N (\\alpha, \\beta, \\gamma) `. Ces deux groupes de qubit, comme on peut le voir dans le [3] , peuvent être vus ci-dessous et sont appliqués à tous les qubits voisins de chacune des couches de la QCNN."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:257
msgid "Note that by only using :math:`N(\\alpha, \\beta, \\gamma)` as our two qubit unitary for the parametrized layers, we are restricting our QCNN to a particular subspace, one in which the optimal solution may not be contained in and reducing the accuracy of the QCNN. For the purpose of this tutorial, we will use this parametrized circuit to decrease the training time of our QCNN."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:268
msgid "|circuit2.png|"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:270
msgid "circuit2.png"
msgstr "Circuit2.png"

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:281
msgid "Figure 3: Parametrized two qubit unitary circuit for :math:`N(\\alpha, \\beta, \\gamma) = exp(i[\\alpha \\sigma_x\\sigma_x + \\beta \\sigma_y\\sigma_y + \\gamma \\sigma_z\\sigma_z ])` as seen in [3], where :math:`\\alpha = \\frac{\\pi}{2} - 2\\theta`, :math:`\\beta = 2\\phi - \\frac{\\pi}{2}` and :math:`\\gamma = \\frac{\\pi}{2} - 2\\lambda` as seen in the circuit. This two qubit unitary will be applied to all neighboring qubits in our feature map."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:293
msgid "2.1 Convolutional Layer"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:304
msgid "The next step in this tutorial is to define the Convolutional Layers of our QCNN. These layers are then applied to the qubits after the data has been encoded through use of the feature map."
msgstr "L'étape suivante de ce tutoriel est de définir les couches convolutionnelles de notre QCNN. Ces couches sont ensuite appliquées aux qubits après que les données ont été encodées à l'aide de la carte de fonction."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:306
msgid "To do so we first need to determine a parametrized unitary gate, which will be used to create our convolutional and pooling layers."
msgstr "Pour ce faire, nous devons d'abord déterminer une grille unitaire paramétrée, qui sera utilisée pour créer nos couches convolutionnaires et de mise en commun."

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:353
msgid "Now that we have defined these unitaries, it is time to create a function for the convolutional layer in our QCNN. To do so, we apply the two qubit unitary to neighboring qubits as seen in the ``conv_layer`` function below."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:355
msgid "Note that we first apply the two qubit unitary to all even pairs of qubits followed by applying to odd pairs of qubits in a circular coupling manner, i.e. the as well as neighboring qubits being coupled, the first and final qubit are also coupled through a unitary gate."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:357
msgid "Note that we add barriers into our quantum circuits for convenience when plotting, however they are not required for the actual QCNN and can be extracted from the following circuits."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:410
msgid "2.2 Pooling Layer"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:421
msgid "The purpose of a pooling layer is to reduce the dimensions of our Quantum Circuit, i.e. reduce the number of qubits in our circuit, while retaining as much information as possible from previously learned data. Reducing the amount of qubits also reduces the computational cost of the overall circuit, as the number of parameters that the QCNN needs to learn decreases."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:423
msgid "However, one cannot simply decrease the amount of qubits in our quantum circuit. Because of this, we must define the pooling layer in a different manner compared with the classical approach."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:425
msgid "To 'artificially' reduce the number of qubits in our circuit, we first begin by creating pairs of the :math:`N` qubits in our system."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:427
msgid "After initially pairing all the qubits, we apply our generalized 2 qubit unitary to each pair, as described previously. After applying this two qubit unitary, we then ignore one qubit from each pair of qubits for the remainder of the neural network."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:429
msgid "This layer therefore has the overall effect of 'combining' the information of the two qubits into one qubit by first applying the unitary circuit, encoding information from one qubit into another, before disregarding one of qubits for the remainder of the circuit and not performing any operations or measurements on it."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:431
msgid "We note that one could also apply a dynamic circuit to reduce the dimensionality in the pooling layers. This would involve performing measurements on certain qubits in the circuit and having an intermediate classical feedback loop in our pooling layers. By applying these measurements, one would also be reducing the dimensionality of the circuit."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:433
msgid "In this tutorial, we apply the former approach, and disregard qubits in each pooling layer. Using this approach, we thus create a QCNN Pooling Layer which transforms the dimensions of our :math:`N` qubit Quantum Circuit to :math:`N/2`."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:435
msgid "To do so, we first define a two qubit unitary, which transforms the two qubit system to one."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:479
msgid "After applying this two qubit unitary circuit, we neglect the first qubit (q0) in future layers and only use the second qubit (q1) in our QCNN"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:481
msgid "We apply this two qubit pooling layer to different pairs of qubits to create our pooling layer for N qubits. As an example we then plot it for four qubits."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:531
msgid "In this particular example, we reduce the dimensionality of our four qubit circuit to the last two qubits, i.e. the last two qubits in this particular example. These qubits are then used in the next layer, while the first two are neglected for the remainder of the QCNN."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:543
msgid "3. Data Generation"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:554
msgid "One common use of a CCNN is an image classifier, where a CCNN detects particular features and patterns (such as straight lines or curves) of the pixelated images through the use of the feature maps in the convolutional layer. By learning the relationship between these features, it can then classify and label handwritten digits with ease."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:556
msgid "Because of a classical CNN's ability to recognize features and patterns easily, we will train our QCNN to also determine patterns and features of a given set of pixelated images, and classify between two different patterns."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:558
msgid "To simplify the dataset, we only consider 2 x 4 pixelated images. The patterns we will train the QCNN to distinguish will be a horizontal or vertical line, which can be placed anywhere in the image, alongside a noisy background."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:560
msgid "We first begin by generating this dataset. To create a 'horizontal' or 'vertical' line, we assign pixels value to be :math:`\\frac{\\pi}{2}` which will represent the line in our pixelated image. We create a noisy background by assigning every other pixel a random value between :math:`0` and :math:`\\frac{\\pi}{4}` which will create a noisy background."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:562
msgid "Note that when we create our dataset, we need to split it into the training set and testing set of images, the datasets we train and test our neural network respectively."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:564
msgid "We also need to label our datasets such that the QCNN can learn to differentiate between the two patterns. In this example we label images with a horizontal line with -1 and images with a vertical line +1."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:619
msgid "Let's now create our dataset below and split it into our test and training datasets."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:644
msgid "Let's see some examples in our dataset"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:679
msgid "As we can see each image contains either a vertical or horizontal line, that the QCNN will learn how to differentiate. Now that we have built our dataset, it is time to discuss the components of the QCNN and build our model."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:691
msgid "4. Modeling our QCNN"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:702
msgid "Now that we have defined both the convolutional layers it is now time to build our QCNN, which will consist of alternating pooling and convolutional layers."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:704
msgid "As the images in our dataset contains 8 pixels, we will use 8 qubits in our QCNN."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:706
msgid "We encode our dataset into our QCNN by applying a feature map. One can create a feature map using one of Qiskit's built in feature maps, such as ZFeatureMap or ZZFeatureMap."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:708
msgid "After analyzing several different Feature maps for this dataset, it was found that QCNN obtains the greatest accuracy when the Z feature map is used. Therefore, throughout the remainder of the tutorial we will use the Z feature Map, of which can be seen below."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:739
msgid "We create a function for our QCNN, which will contain three sets of alternating convolutional and pooling layers, which can be seen in the schematic below. Through the use of the pooling layers, we thus reduce the dimensionality of our QCNN from eight qubits to one."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:750
msgid "|Screenshot%202022-08-10%20at%2021.42.39.png|"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:752
msgid "Screenshot%202022-08-10%20at%2021.42.39.png"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:763
msgid "To classify our image dataset of horizontal and vertical lines, we measure the expectation value of the Pauli Z operator of the final qubit. Based on the obtained value being +1 or -1, we can conclude that the input image contained either a horizontal or vertical line."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:775
msgid "5. Training our QCNN"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:786
msgid "The next step is to build our model using our training data."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:788
msgid "To classify our system, we perform a measurement from the output circuit. The value we obtain will thus classify whether our input data contains either a vertical line or horizontal line."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:790
msgid "The measurement we have chosen in this tutorial is :math:`<Z>`, i.e. the expectation value of the Pauli Z qubit for the final qubit. Measuring this expectation value, we obtain +1 or -1, which correspond to a vertical or horizontal line respectively."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:865
msgid "We will also define a callback function to use when training our model. This allows us to view and plot the loss function per each iteration in our training process."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:893
msgid "In this example, we will use the COBYLA optimizer to train our classifier, which is a numerical optimization method commonly used for classification machine learning algorithms."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:895
msgid "We then place the the callback function, optimizer and operator of our QCNN created above into Qiskit's built in Neural Network Classifier, which we can then use to train our model."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:897
msgid "Since model training may take a long time we have already pre-trained the model for some iterations and saved the pre-trained weights. We'll continue training from that point by setting ``initial_point`` to a vector of pre-trained weights."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:926
msgid "After creating this classifier, we can train our QCNN using our training dataset and each image's corresponding label. Because we previously defined the callback function, we plot the overall loss of our system per iteration."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:928
msgid "It may take some time to train the QCNN so be patient!"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:990
msgid "As we can see from above, the QCNN converges slowly, hence our ``initial_point`` was already close to an optimal solution. The next step is to determine whether our QCNN can classify data seen in our test image data set."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1002
msgid "6. Testing our QCNN"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1013
msgid "After building and training our dataset we now test whether our QCNN can predict images that are not from our test data set."
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1080
msgid "From above, we can indeed see that our QCNN can classify horizontal and vertical lines! Congratulations! Through the use of quantum circuits and quantum convolutional and pooling layers, you have built a Quantum Convolutional Neural Network!"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1092
msgid "7. References"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1103
msgid "[1] Cong, I., Choi, S. & Lukin, M.D. Quantum convolutional neural networks. Nat. Phys. 15, 1273–1278 (2019). https://doi.org/10.1038/s41567-019-0648-8"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1105
msgid "[2] IBM Convolutional Neural Networks https://www.ibm.com/cloud/learn/convolutional-neural-networks"
msgstr ""

#: ../../tutorials/11_quantum_convolutional_neural_networks.ipynb:1107
msgid "[3] Vatan, Farrokh, and Colin Williams. \"Optimal quantum circuits for general two-qubit gates.\" Physical Review A 69.3 (2004): 032315."
msgstr ""

