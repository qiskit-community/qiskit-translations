msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-22 17:47+0000\n"
"PO-Revision-Date: 2021-07-22 17:59\n"
"Last-Translator: \n"
"Language-Team: French\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: fr\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/01_neural_networks.po\n"
"X-Crowdin-File-ID: 9628\n"
"Language: fr_FR\n"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/01_neural_networks.ipynb`__."
msgstr ""

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "Réseaux de neurones quantiques"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "Ce bloc-notes illustre les différentes implémentations génériques du réseau de neurones (QNN) fournies dans Qiskit Machine Learning. Les réseaux sont conçus comme des unités de calcul qui peuvent être utilisées pour de nombreux cas d'utilisation différents. Selon l'application, un type particulier de réseau peut être plus ou moins adapté et peut nécessiter d'être mis en place d'une manière particulière. Les différents réseaux de neurones suivants sont disponible est vont être détaillés :"

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks."
msgstr "``NeuralNetwork``: L'interface pour les réseaux de neurones."

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``OpflowQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr "``OpflowQNN``: Un réseau basé sur l'évaluation des observables mécaniques quantiques."

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``TwoLayerQNN``: A special ``OpflowQNN`` implementation for convenience."
msgstr "``TwoLayerQNN``: Une implémentation spéciale de ``OpflowQNN`` pour plus de commodité."

#: ../../tutorials/01_neural_networks.ipynb:16
msgid "``CircuitQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr "``CircuitQNN``: Un réseau basé sur les échantillons résultant de la mesure d'un circuit quantique."

#: ../../tutorials/01_neural_networks.ipynb:64
msgid "1. ``NeuralNetwork``"
msgstr "1. ``NeuralNetwork``"

#: ../../tutorials/01_neural_networks.ipynb:66
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interfaces are introduced."
msgstr "``NeuralNetwork`` représente l'interface pour tous les réseaux de neurones disponibles dans Qiskit Machine Learning. Il expose une passe vers l'avant et vers l'arrière en prenant les échantillons de données et les poids entraînables en entrée. Un ``NeuralNetwork`` ne contient aucune capacité d'entraînement, les capacités d'entrainement se trouvent au niveau des algorithmes et applications. Ainsi, un ``NeuralNetwork`` ne stocke pas non plus les valeurs des poids. Dans ce qui suit, différentes implémentations de ces interfaces sont introduites."

#: ../../tutorials/01_neural_networks.ipynb:68
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes either flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr "Soit un ``NeuralNetwork`` appelé ``nn``. Alors, le ``nn.forward (input, wieghts)`` prend des entrées égales pour les données et les poids ``nn.num_inputs`` et ``nn.num_weights``, respectivement. ``NeuralNetwork`` prend en charge les entrées et renvoie les sorties selon la même forme."

#: ../../tutorials/01_neural_networks.ipynb:80
msgid "2. ``OpflowQNN``"
msgstr "2. ``OpflowQNN``"

#: ../../tutorials/01_neural_networks.ipynb:82
msgid "The ``OpflowQNN`` takes a (parametrized) operator from Qiskit and leverages Qiskit’s gradient framework to provide the backward pass. Such an operator can for instance be an expected value of a quantum mechanical observable with respect to a parametrized quantum state. The Parameters can be used to load classical data as well as represent trainable weights. The ``OpflowQNN`` also allows lists of operators and more complex structures to construct more complex QNNs."
msgstr "``OpflowQNN`` prend un opérateur (paramétrable) de Qiskit et s'appuie sur le cadre de gradient de Qiskit pour fournir le passage en arrière. Un tel opérateur peut par exemple être une valeur d'espérance d'un observable de mécanique quantique par rapport à un état quantique paramétré. Les paramètres peuvent être utilisés pour charger des données classiques ainsi que pour représenter des poids à entraîner. ``OpflowQNN`` permet également la création de listes d'opérateurs et de structures plus complexes pour construire des réseaux de neurones quantiques plus complexes."

#: ../../tutorials/01_neural_networks.ipynb:321
msgid "Combining multiple observables in a ``ListOp`` also allows to create more complex QNNs"
msgstr "La combinaison de plusieurs observables dans une ``ListOp`` permet également de créer des réseaux de neurones quantiques plus complexes"

#: ../../tutorials/01_neural_networks.ipynb:412
msgid "3. ``TwoLayerQNN``"
msgstr "3. ``TwoLayerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:414
msgid "The ``TwoLayerQNN`` is a special ``OpflowQNN`` on :math:`n` qubits that consists of first a feature map to insert data and second an ansatz that is trained. The default observable is :math:`Z^{\\otimes n}`, i.e., parity."
msgstr "``TwoLayerQNN`` est un ``OpflowQNN`` spécial sur les qubits :math:`n` qui consiste en une première carte de features pour insérer des données et un ansatz qui est entraîné. L'observable par défaut est :math:`Z^{\\otimes n}`, c'est-à-dire la parité."

#: ../../tutorials/01_neural_networks.ipynb:612
msgid "4. ``CircuitQNN``"
msgstr "4. ``CircuitQNN``"

#: ../../tutorials/01_neural_networks.ipynb:614
msgid "The ``CircuitQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples can either be interpreted as probabilities of measuring the integer index corresponding to a bitstring or directly as a batch of binary output. In the case of probabilities, gradients can be estimated efficiently and the ``CircuitQNN`` provides a backward pass as well. In case of samples, differentiation is not possible and the backward pass returns ``(None, None)``."
msgstr "``CircuitQNN`` est basé sur un ``QuantumCircuit`` (paramétré). Il admet des paramètres d'entrée ainsi que des paramètres de poids et produit des échantillons à partir de la mesure. Les échantillons peuvent être interprétés comme des probabilités de mesure de l'index correspondant à une chaîne de bits ou directement comme une valeur de sortie binaire. Dans le cas des probabilités, les gradients peuvent être estimés efficacement et ``CircuitQNN`` fournit également une retropropagation. Dans le cas d'échantillons, la différenciation n'est pas possible et la rétropropagation renvoie le résultat `` (None, None)``."

#: ../../tutorials/01_neural_networks.ipynb:617
msgid "Further, the ``CircuitQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are aggregated accordingly."
msgstr "De plus, ``CircuitQNN`` permet de spécifier une ``fonction d'interprétation`` pour le post traitement des échantillons. On s'attend à ce que cela prenne un entier mesuré (à partir d'une chaîne de bits) et le mapper à un nouvel index, c'est à dire un entier non négatif. Dans ce cas, la forme de sortie doit être fournie et les probabilités sont agrégées en conséquence."

#: ../../tutorials/01_neural_networks.ipynb:619
msgid "A ``CircuitQNN`` can be configured to return sparse as well as dense probability vectors. If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits and a sparse recommendation is usually recommended. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr "``CircuitQNN`` peut être configuré pour renvoyer des vecteurs de probabilité épars ou denses. Si aucune fonction `ìnterpret`` n'est utilisée, la dimension des vecteurs de probabilité se calcule exponentiellement avec le nombre de qubits et une recommandation éparse est généralement recommandée. Dans le cas où une fonction `ìnterpret``est utilisée, cela dépend du résultat attendu. Si, par exemple, un index est mappé à la parité de la chaîne de caractères correspondante, c'est-à-dire à 0 ou 1, une sortie dense a du sens et le résultat sera un vecteur de probabilités de longueur 2."

#: ../../tutorials/01_neural_networks.ipynb:662
msgid "4.1 Output: sparse integer probabilities"
msgstr "4.1 Sortie: probabilités entières clairsemées"

#: ../../tutorials/01_neural_networks.ipynb:761
msgid "4.2 Output: dense parity probabilities"
msgstr "4.2 Sortie: probabilités de parité denses"

#: ../../tutorials/01_neural_networks.ipynb:869
msgid "4.3 Output: Samples"
msgstr "4.3 Sortie: Exemples"

#: ../../tutorials/01_neural_networks.ipynb:985
msgid "4.4 Output: Parity Samples"
msgstr "4.4 Sortie: Exemples de parité"

