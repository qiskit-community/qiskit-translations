msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-06-29 18:01+0000\n"
"PO-Revision-Date: 2022-06-29 18:29\n"
"Last-Translator: \n"
"Language-Team: Italian\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.10.3\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: it\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/05_torch_connector.po\n"
"X-Crowdin-File-ID: 9636\n"
"Language: it_IT\n"

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "This page was generated from `docs/tutorials/05_torch_connector.ipynb`__."
msgstr "Questa pagina è stata generata da `docs/tutorials/05_torch_connector.ipynb`__."

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector and Hybrid QNNs"
msgstr "Torch Connector e QNNs Ibride"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial introduces Qiskit’s ``TorchConnector`` class, and demonstrates how the ``TorchConnector`` allows for a natural integration of any ``NeuralNetwork`` from Qiskit Machine Learning into a PyTorch workflow. ``TorchConnector`` takes a Qiskit ``NeuralNetwork`` and makes it available as a PyTorch ``Module``. The resulting module can be seamlessly incorporated into PyTorch classical architectures and trained jointly without additional considerations, enabling the development and testing of novel **hybrid quantum-classical** machine learning architectures."
msgstr "Questo tutorial introduce la classe di Qiskit ``TorchConnector`` e dimostra come essa permetta una facile integrazione di qualsiasi ``NeuralNetwork`` da Qiskit Machine Learning in un flusso di lavoro in PyTorch. ``TorchConnector`` rende disponibile una ``NeuralNetwork`` di Qiskit come un ``Module`` di PyTorch. Il modulo che ne risulta può essere perfettamente incorporato in una classica architettura PyTorch e allenato senza considerazioni addizionali, permettendo quindi lo sviluppo ed il testing di nuove architetture di machine learning **ibride quantistiche-classiche**."

#: ../../tutorials/05_torch_connector.ipynb:15
msgid "Content:"
msgstr "Contenuto:"

#: ../../tutorials/05_torch_connector.ipynb:17
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__"
msgstr "`Parte 1: Semplice Classificazione & Regressione <#Part-1:-Simple-Classification-&-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:19
msgid "The first part of this tutorial shows how quantum neural networks can be trained using PyTorch’s automatic differentiation engine (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) for simple classification and regression tasks."
msgstr "La prima parte di questo tutorial dimostra come, per semplici compiti di classificazione e regressione, si possa allenare una quantum neural network usando un motore di differenziazione automatica di PyTorch (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__)."

#: ../../tutorials/05_torch_connector.ipynb:21
msgid "`Classification <#1.-Classification>`__"
msgstr "`Classificazione <#1.-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:23
msgid "Classification with PyTorch and ``OpflowQNN``"
msgstr "Classificazione con PyTorch e ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:24
msgid "Classification with PyTorch and ``CircuitQNN``"
msgstr "Classificazione con PyTorch e ``CircuitQNN``"

#: ../../tutorials/05_torch_connector.ipynb:26
msgid "`Regression <#2.-Regression>`__"
msgstr "`Regressione <#2.-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:28
msgid "Regression with PyTorch and ``OpflowQNN``"
msgstr "Regressione con PyTorch e ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:30
msgid "`Part 2: MNIST Classification, Hybrid QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"
msgstr "`Parte 2: Classificazione su MNIST, QNNs Ibride <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"

#: ../../tutorials/05_torch_connector.ipynb:32
msgid "The second part of this tutorial illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow (in this case, a typical CNN architecture) to classify MNIST data in a hybrid quantum-classical manner."
msgstr "La seconda parte di questo tutorial mostra come incorporare una (Quantum) ``NeuralNetwork`` in un flusso di lavoro specifico di PyTorch (in questo caso una tipica architettura di CNN) al il fine di classificare i dati MNIST in modalità ibrida quantistica-classica."

#: ../../tutorials/05_torch_connector.ipynb:85
msgid "Part 1: Simple Classification & Regression"
msgstr "Parte 1: Semplice Classificazione & Regressione"

#: ../../tutorials/05_torch_connector.ipynb:97
msgid "1. Classification"
msgstr "1. Classificazione"

#: ../../tutorials/05_torch_connector.ipynb:99
msgid "First, we show how ``TorchConnector`` allows to train a Quantum ``NeuralNetwork`` to solve a classification tasks using PyTorch’s automatic differentiation engine. In order to illustrate this, we will perform **binary classification** on a randomly generated dataset."
msgstr "Per prima cosa, mostriamo come ``TorchConnector`` permetta di allenare una Quantum ``NeuralNetwork`` per risolvere i compiti di classificazione usando il motore di differenziazione automatica in PyTorch. Per illustrare ciò, eseguiremo una **classificazione binaria** su un dataset generato in modo casuale."

#: ../../tutorials/05_torch_connector.ipynb:152
msgid "A. Classification with PyTorch and ``OpflowQNN``"
msgstr "A. Classificazione con PyTorch e ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:154
msgid "Linking an ``OpflowQNN`` to PyTorch is relatively straightforward. Here we illustrate this using the ``TwoLayerQNN``, a sub-case of ``OpflowQNN`` introduced in previous tutorials."
msgstr "Collegare una ``OpflowQNN`` a PyTorch è relativamente semplice. Qui lo illustriamo usando la ``TwoLayerQNN``, un caso minore delle ``OpflowQNN`` introdotto nei tutorial precedenti."

#: ../../tutorials/05_torch_connector.ipynb:297
msgid "Optimizer"
msgstr "Optimizer"

#: ../../tutorials/05_torch_connector.ipynb:299
msgid "The choice of optimizer for training any machine learning model can be crucial in determining the success of our training’s outcome. When using ``TorchConnector``, we get access to all of the optimizer algorithms defined in the [``torch.optim``] package (`link <https://pytorch.org/docs/stable/optim.html>`__). Some of the most famous algorithms used in popular machine learning architectures include *Adam*, *SGD*, or *Adagrad*. However, for this tutorial we will be using the L-BFGS algorithm (``torch.optim.LBFGS``), one of the most well know second-order optimization algorithms for numerical optimization."
msgstr "La scelta dell'optimizer può essere cruciale per il successo dell'addestramento di qualsiasi modello di machine learning. Quando usiamo ``TorchConnector``, abbiamo accesso a tutti gli algoritmi di ottimizzazione definiti nel package [``torch.optim``] (`link <https://pytorch.org/docs/stable/optim.html>`__). Alcuni degli algoritmi più famosi usati in popolari architetture di machine learning includono *Adam*, *SGD*, o *Adagrad*. Ad ogni modo, in questo tutorial useremo l'algoritmo L-BFGS (``torch.optim.LBFGS``), che è uno uno dei più conosciuti algoritmi di ottimizzazione di secondo-ordine per compiti di ottimizzazione numerica."

#: ../../tutorials/05_torch_connector.ipynb:303
msgid "Loss Function"
msgstr "Funzione di Costo"

#: ../../tutorials/05_torch_connector.ipynb:305
msgid "As for the loss function, we can also take advantage of PyTorch’s pre-defined modules from ``torch.nn``, such as the `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ or `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."
msgstr "Per quanto riguarda la funzioni di costo (loss function), possiamo sfruttare i moduli predefiniti di PyTorch che si posso trovare in ``torch.nn``, come ad esempio le loss `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ o `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__."

#: ../../tutorials/05_torch_connector.ipynb:307
msgid "**💡 Clarification :** In classical machine learning, the general rule of thumb is to apply a Cross-Entropy loss to classification tasks, and MSE loss to regression tasks. However, this recommendation is given under the assumption that the output of the classification network is a class probability value in the [0,1] range (usually this is achieved through a Softmax layer). Because the following example for ``TwoLayerQNN`` does not include such layer, and we don’t apply any mapping to the output (the following section shows an example of application of parity mapping with ``CircuitQNNs``), the QNN’s output can take any value in the range [-1,1]. In case you were wondering, this is the reason why this particular example uses MSELoss for classification despite it not being the norm (but we encourage you to experiment with different loss functions and see how they can impact training results)."
msgstr "**💡 Chiarificazione :** Nel machine learning classico, in genere si utilizza la funzione di costo Cross-Entropy nel caso della classificazione, mentre la MSE nel caso della regressione. Tuttavia, questa raccomandazione assume che l'output della rete di classificazione sia una classe di probabilità con valori nel range [0, 1] (solitamente ottenuto tramite un layer Softmax). Poiché nell'esempio seguente per ``TwoLayerQNN`` non c'è questo layer e non applichiamo nessun mapping all'output ( la sezione successiva mostra una esempio di applicazione di un mapping di parità utilizzando ``CircuitQNNs``), l'output della QNN può assumere qualsiasi valore nel range [-1, 1]. In caso te lo stessi domandando, per quanto non sia la norma, è esattamente questa la ragione per cui la MSELoss viene utilizzata in questo esempio di classificazione (ma incoraggiamo a sperimentare con diverse funzioni di costo e vedere qual è l' impatto sui risultati sul training)."

#: ../../tutorials/05_torch_connector.ipynb:517
#: ../../tutorials/05_torch_connector.ipynb:789
msgid "The red circles indicate wrongly classified data points."
msgstr "I cerchi rossi indicano dei dati che sono stati classificati in modo errato."

#: ../../tutorials/05_torch_connector.ipynb:529
msgid "B. Classification with PyTorch and ``CircuitQNN``"
msgstr "B. Classificazione con PyTorch e ``CircuitQNN``"

#: ../../tutorials/05_torch_connector.ipynb:531
msgid "Linking an ``CircuitQNN`` to PyTorch requires a bit more attention than ``OpflowQNN``. Without the correct setup, backpropagation is not possible."
msgstr "Collegare una ``CircuitQNN`` a PyTorch richiede un po' più di attenzione rispetto alle ``OpflowQNN``. Senza il setup corretto non sarà possibile la backpropagation."

#: ../../tutorials/05_torch_connector.ipynb:533
msgid "In particular, we must make sure that we are returning a dense array of probabilities in the network’s forward pass (``sparse=False``). This parameter is set up to ``False`` by default, so we just have to make sure that it has not been changed."
msgstr "In particolare, dobbiamo assicurarci di restituire un vettore di probabilità denso nel pass forward della rete (``sparse=False``). Questo parametro è impostato a ``False`` di default, quindi dobbiamo solo essere sicuri che non venga modificato."

#: ../../tutorials/05_torch_connector.ipynb:535
msgid "**⚠️ Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``CircuitQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."
msgstr "**⚠️ Attenzione:** Se definiamo una funzione interpret personalizzata (nell'esempio ``parity``), dobbiamo ricordarci di fornire in modo esplicito la dimensione dell'output desiderato (nell'esempio ``2``). Per più informazioni sulle impostazioni dei parametri iniziali per ``CircuitQNN``, per favore far riferimento alla `documentazione ufficiale di qiskit <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."

#: ../../tutorials/05_torch_connector.ipynb:608
#: ../../tutorials/05_torch_connector.ipynb:939
msgid "For a reminder on optimizer and loss function choices, you can go back to `this section <#Optimizer>`__."
msgstr "Per un ripasso su come scegliere gli optimizer e le funzione di costo, puoi andare indietro a `questa sezione <#Optimizer>`__."

#: ../../tutorials/05_torch_connector.ipynb:801
msgid "2. Regression"
msgstr "2. Regressione"

#: ../../tutorials/05_torch_connector.ipynb:803
msgid "We use a model based on the ``TwoLayerQNN`` to also illustrate how to perform a regression task. The chosen dataset in this case is randomly generated following a sine wave."
msgstr "Utilizziamo un modello basato su ``TwoLayerQNN`` per mostrare anche un esempio su come eseguire una regressione. Il dataset scelto in questo caso è stato generato in modo casuale seguendo una funzione seno."

#: ../../tutorials/05_torch_connector.ipynb:844
msgid "A. Regression with PyTorch and ``OpflowQNN``"
msgstr "A. Regressione con PyTorch e ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:855
msgid "The network definition and training loop will be analogous to those of the classification task using ``TwoLayerQNN``. In this case, we define our own feature map and ansatz, instead of using the default values."
msgstr "La definizione della rete e il processo di allenamento saranno gli stessi del caso della classificazione con la ``TwoLayerQNN``. In questo caso definiamo la nostra feature map e l'ansatz, invece di usare valori predefiniti."

#: ../../tutorials/05_torch_connector.ipynb:1078
msgid "Part 2: MNIST Classification, Hybrid QNNs"
msgstr "Part 2: Classificazione su MNIST, QNNs Ibride"

#: ../../tutorials/05_torch_connector.ipynb:1080
msgid "In this second part, we show how to leverage a hybrid quantum-classical neural network using ``TorchConnector``, to perform a more complex image classification task on the MNIST handwritten digits dataset."
msgstr "In questa seconda parte, mostriamo come sfruttare una neural network ibrida quantistica-classica, usando ``TorchConnector``, per eseguire una complessa classificazione sul dataset MNIST che contiene immagini di numeri scritti a mano."

#: ../../tutorials/05_torch_connector.ipynb:1082
msgid "For a more detailed (pre-``TorchConnector``) explanation on hybrid quantum-classical neural networks, you can check out the corresponding section in the `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."
msgstr "Puoi leggere la sezione dedicata nel `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__. per una più dettagliata spiegazione sulle neural network ibride quantistico-classiche (pre-``TorchConnector``)."

#: ../../tutorials/05_torch_connector.ipynb:1121
msgid "Step 1: Defining Data-loaders for train and test"
msgstr "Step 1: Definire i Data-loader per train e test"

#: ../../tutorials/05_torch_connector.ipynb:1132
msgid "We take advantage of the ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ to directly load a subset of the `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ and define torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) for train and test."
msgstr "Utilizziamo la `API <https://pytorch.org/vision/stable/datasets.html>`__ ``torchvision`` per scaricare direttamente un sottoinsieme del `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ e definire un torch ``DataLoader`` (`link <https://pytorch.org/docs/stable/data.html>`__) per train e test."

#: ../../tutorials/05_torch_connector.ipynb:1175
msgid "If we perform a quick visualization we can see that the train dataset consists of images of handwritten 0s and 1s."
msgstr "Con una rapida visualizzazione, possiamo osservare che il train dataset consiste di immagini di 0 e 1 scritti a mano."

#: ../../tutorials/05_torch_connector.ipynb:1249
msgid "Step 2: Defining the QNN and Hybrid Model"
msgstr "Step 2: Definire la QNN ed il Modello Ibrido"

#: ../../tutorials/05_torch_connector.ipynb:1260
msgid "This second step shows the power of the ``TorchConnector``. After defining our quantum neural network layer (in this case, a ``TwoLayerQNN``), we can embed it into a layer in our torch ``Module`` by initializing a torch connector as ``TorchConnector(qnn)``."
msgstr "Questo secondo step mostra il potere del ``TorchConnector``. Dopo aver definito il nostro layer di quantum neural network ( in questo caso una ``TwoLayerQNN``), inizializzando un torch connector nel modo seguente ``TorchConnector(qnn)``, possiamo inglobarla in un layer ``Module`` di Torch."

#: ../../tutorials/05_torch_connector.ipynb:1262
msgid "**⚠️ Attention:** In order to have an adequate gradient backpropagation in hybrid models, we MUST set the initial parameter ``input_gradients`` to TRUE during the qnn initialization."
msgstr "**⚠️ Attenzione:** Per avere una adeguate backpropagation dei gradienti dei modelli ibridi DOBBIAMO impostare il parametro iniziale ``input_gradients`` a TRUE durante l'inializzazione della qnn."

#: ../../tutorials/05_torch_connector.ipynb:1391
msgid "Step 3: Training"
msgstr "Step 3: Addestramento (Training)"

#: ../../tutorials/05_torch_connector.ipynb:1505
msgid "Now we’ll save the trained model, just to show how a hybrid model can be saved and re-used later for inference. To save and load hybrid models, when using the TorchConnector, follow the PyTorch recommendations of saving and loading the models."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:1527
msgid "Step 4: Evaluation"
msgstr "Step 4: Valutazione del modello (Evaluation)"

#: ../../tutorials/05_torch_connector.ipynb:1538
msgid "We start from recreating the model and loading the state from the previously saved file. You create a QNN layer using another simulator or a real hardware. So, you can train a model on real hardware available on the cloud and then for inference use a simulator or vice verse. For a sake of simplicity we create a new quantum neural network in the same way as above."
msgstr ""

#: ../../tutorials/05_torch_connector.ipynb:1686
msgid "🎉🎉🎉🎉 **You are now able to experiment with your own hybrid datasets and architectures using Qiskit Machine Learning.** **Good Luck!**"
msgstr "🎉🎉🎉🎉 **Ora sei in grado di sperimentare con architetture ibride personalizzate e con nuovi dataset usando Qiskit Machine Learning.** **Buona Fortuna!**"

