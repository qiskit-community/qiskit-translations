msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-08 17:14-0400\n"
"PO-Revision-Date: 2021-07-16 11:45\n"
"Last-Translator: \n"
"Language-Team: Italian\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: it\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/05_torch_connector.po\n"
"X-Crowdin-File-ID: 9636\n"
"Language: it_IT\n"

#: ../../tutorials/05_torch_connector.ipynb:13
msgid "Run interactively in jupyter notebook."
msgstr "Esegui in maniera interattiva su un jupyter notebook."

#: ../../tutorials/05_torch_connector.ipynb:9
msgid "Torch Connector and Hybrid QNNs"
msgstr "Torch Connector e QNNs Ibride"

#: ../../tutorials/05_torch_connector.ipynb:11
msgid "This tutorial introduces Qiskit‚Äôs ``TorchConnector`` class, and demonstrates how the ``TorchConnector`` allows for a natural integration of any ``NeuralNetwork`` from Qiskit Machine Learning into a PyTorch workflow. ``TorchConnector`` takes a Qiskit ``NeuralNetwork`` and makes it available as a PyTorch ``Module``. The resulting module can be seamlessly incorporated into PyTorch classical architectures and trained jointly without additional considerations, enabling the development and testing of novel **hybrid quantum-classical** machine learning architectures."
msgstr "Questo tutorial introduce la classe di Qiskit ``TorchConnector`` e dimostra come essa permetta una facile integrazione di qualsiasi ``NeuralNetwork`` da Qiskit Machine Learning in un flusso di lavoro in PyTorch. ``TorchConnector`` rende disponibile una ``NeuralNetwork`` di Qiskit come un ``Module`` di PyTorch. Il modulo che ne risulta pu√≤ essere perfettamente incorporato in una classica architettura PyTorch e allenato senza considerazioni addizionali, permettendo quindi lo sviluppo ed il testing di nuove architetture di machine learning **ibride quantistiche-classiche**."

#: ../../tutorials/05_torch_connector.ipynb:15
msgid "Content:"
msgstr "Contenuto:"

#: ../../tutorials/05_torch_connector.ipynb:17
msgid "`Part 1: Simple Classification & Regression <#Part-1:-Simple-Classification-&-Regression>`__"
msgstr "`Parte 1: Semplice Classificazione & Regressione <#Part-1:-Simple-Classification-&-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:19
msgid "The first part of this tutorial shows how quantum neural networks can be trained using PyTorch‚Äôs automatic differentiation engine (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__) for simple classification and regression tasks."
msgstr "La prima parte di questo tutorial dimostra come, per semplici compiti di classificazione e regressione, si possa allenare una quantum neural network usando un motore di differenziazione automatica di PyTorch (``torch.autograd``, `link <https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html>`__)."

#: ../../tutorials/05_torch_connector.ipynb:21
msgid "`Classification <#1.-Classification>`__"
msgstr "`Classificazione <#1.-Classification>`__"

#: ../../tutorials/05_torch_connector.ipynb:23
msgid "Classification with PyTorch and ``OpflowQNN``"
msgstr "Classificazione con PyTorch e ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:24
msgid "Classification with PyTorch and ``CircuitQNN``"
msgstr "Classificazione con PyTorch e ``CircuitQNN``"

#: ../../tutorials/05_torch_connector.ipynb:26
msgid "`Regression <#2.-Regression>`__"
msgstr "`Regressione <#2.-Regression>`__"

#: ../../tutorials/05_torch_connector.ipynb:28
msgid "Regression with PyTorch and ``OpflowQNN``"
msgstr "Regressione con PyTorch e ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:30
msgid "`Part 2: MNIST Classification, Hybrid QNNs <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"
msgstr "`Parte 2: Classificazione su MNIST, QNNs Ibride <#Part-2:-MNIST-Classification,-Hybrid-QNNs>`__"

#: ../../tutorials/05_torch_connector.ipynb:32
msgid "The second part of this tutorial illustrates how to embed a (Quantum) ``NeuralNetwork`` into a target PyTorch workflow (in this case, a typical CNN architecture) to classify MNIST data in a hybrid quantum-classical manner."
msgstr "La seconda parte di questo tutorial mostra come incorporare una (Quantum) ``NeuralNetwork`` in un flusso di lavoro specifico di PyTorch (in questo caso una tipica architettura di CNN) al il fine di classificare i dati MNIST in modalit√† ibrida quantistica-classica."

#: ../../tutorials/05_torch_connector.ipynb:74
msgid "Part 1: Simple Classification & Regression"
msgstr "Parte 1: Semplice Classificazione & Regressione"

#: ../../tutorials/05_torch_connector.ipynb:86
msgid "1. Classification"
msgstr "1. Classificazione"

#: ../../tutorials/05_torch_connector.ipynb:88
msgid "First, we show how ``TorchConnector`` allows to train a Quantum ``NeuralNetwork`` to solve a classification tasks using PyTorch‚Äôs automatic differentiation engine. In order to illustrate this, we will perform **binary classification** on a randomly generated dataset."
msgstr "Per prima cosa, mostriamo come ``TorchConnector`` permetta di allenare una Quantum ``NeuralNetwork`` per risolvere i compiti di classificazione usando il motore di differenziazione automatica in PyTorch. Per illustrare ci√≤, eseguiremo una **classificazione binaria** su un dataset generato in modo casuale."

#: ../../tutorials/05_torch_connector.ipynb:144
msgid "A. Classification with PyTorch and ``OpflowQNN``"
msgstr "A. Classificazione con PyTorch e ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:146
msgid "Linking an ``OpflowQNN`` to PyTorch is relatively straightforward. Here we illustrate this using the ``TwoLayerQNN``, a sub-case of ``OpflowQNN`` introduced in previous tutorials."
msgstr "Collegare una ``OpflowQNN`` a PyTorch √® relativamente semplice. Qui lo illustriamo usando la ``TwoLayerQNN``, un caso minore delle ``OpflowQNN`` introdotto nei tutorial precedenti."

#: ../../tutorials/05_torch_connector.ipynb:254
msgid "Optimizer"
msgstr "Optimizer"

#: ../../tutorials/05_torch_connector.ipynb:256
msgid "The choice of optimizer for training any machine learning model can be crucial in determining the success of our training‚Äôs outcome. When using ``TorchConnector``, we get access to all of the optimizer algorithms defined in the [``torch.optim``] package (`link <https://pytorch.org/docs/stable/optim.html>`__). Some of the most famous algorithms used in popular machine learning architectures include *Adam*, *SGD*, or *Adagrad*. However, for this tutorial we will be using the L-BFGS algorithm (``torch.optim.LBFGS``), one of the most well know second-order optimization algorithms for numerical optimization."
msgstr "La scelta dell'optimizer pu√≤ essere cruciale per il successo dell'addestramento di qualsiasi modello di machine learning. Quando usiamo ``TorchConnector``, abbiamo accesso a tutti gli algoritmi di ottimizzazione definiti nel package [``torch.optim``] (`link <https://pytorch.org/docs/stable/optim.html>`__). Alcuni degli algoritmi pi√π famosi usati in popolari architetture di machine learning includono *Adam*, *SGD*, o *Adagrad*. Ad ogni modo, in questo tutorial useremo l'algoritmo L-BFGS (``torch.optim.LBFGS``), che √® uno uno dei pi√π conosciuti algoritmi di ottimizzazione di secondo-ordine per compiti di ottimizzazione numerica."

#: ../../tutorials/05_torch_connector.ipynb:260
msgid "Loss Function"
msgstr "Funzione di Costo"

#: ../../tutorials/05_torch_connector.ipynb:262
msgid "As for the loss function, we can also take advantage of PyTorch‚Äôs pre-defined modules from ``torch.nn``, such as the `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ or `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__ losses."
msgstr "Per quanto riguarda la funzioni di costo (loss function), possiamo sfruttare i moduli predefiniti di PyTorch che si posso trovare in ``torch.nn``, come ad esempio le loss `Cross-Entropy <https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html>`__ o `Mean Squared Error <https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html>`__."

#: ../../tutorials/05_torch_connector.ipynb:264
msgid "**üí° Clarification :** In classical machine learning, the general rule of thumb is to apply a Cross-Entropy loss to classification tasks, and MSE loss to regression tasks. However, this recommendation is given under the assumption that the output of the classification network is a class probability value in the [0,1] range (usually this is achieved through a Softmax layer). Because the following example for ``TwoLayerQNN`` does not include such layer, and we don‚Äôt apply any mapping to the output (the following section shows an example of application of parity mapping with ``CircuitQNNs``), the QNN‚Äôs output can take any value in the range [-1,1]. In case you were wondering, this is the reason why this particular example uses MSELoss for classification despite it not being the norm (but we encourage you to experiment with different loss functions and see how they can impact training results)."
msgstr "**üí° Chiarificazione :** Nel machine learning classico, in genere si utilizza la funzione di costo Cross-Entropy nel caso della classificazione, mentre la MSE nel caso della regressione. Tuttavia, questa raccomandazione assume che l'output della rete di classificazione sia una classe di probabilit√† con valori nel range [0, 1] (solitamente ottenuto tramite un layer Softmax). Poich√© nell'esempio seguente per ``TwoLayerQNN`` non c'√® questo layer e non applichiamo nessun mapping all'output ( la sezione successiva mostra una esempio di applicazione di un mapping di parit√† utilizzando ``CircuitQNNs``), l'output della QNN pu√≤ assumere qualsiasi valore nel range [-1, 1]. In caso te lo stessi domandando, per quanto non sia la norma, √® esattamente questa la ragione per cui la MSELoss viene utilizzata in questo esempio di classificazione (ma incoraggiamo a sperimentare con diverse funzioni di costo e vedere qual √® l' impatto sui risultati sul training)."

#: ../../tutorials/05_torch_connector.ipynb:442
#: ../../tutorials/05_torch_connector.ipynb:674
msgid "The red circles indicate wrongly classified data points."
msgstr "I cerchi rossi indicano dei dati che sono stati classificati in modo errato."

#: ../../tutorials/05_torch_connector.ipynb:454
msgid "B. Classification with PyTorch and ``CircuitQNN``"
msgstr "B. Classificazione con PyTorch e ``CircuitQNN``"

#: ../../tutorials/05_torch_connector.ipynb:456
msgid "Linking an ``CircuitQNN`` to PyTorch requires a bit more attention than ``OpflowQNN``. Without the correct setup, backpropagation is not possible."
msgstr "Collegare una ``CircuitQNN`` a PyTorch richiede un po' pi√π di attenzione rispetto alle ``OpflowQNN``. Senza il setup corretto non sar√† possibile la backpropagation."

#: ../../tutorials/05_torch_connector.ipynb:458
msgid "In particular, we must make sure that we are returning a dense array of probabilities in the network‚Äôs forward pass (``sparse=False``). This parameter is set up to ``False`` by default, so we just have to make sure that it has not been changed."
msgstr "In particolare, dobbiamo assicurarci di restituire un vettore di probabilit√† denso nel pass forward della rete (``sparse=False``). Questo parametro √® impostato a ``False`` di default, quindi dobbiamo solo essere sicuri che non venga modificato."

#: ../../tutorials/05_torch_connector.ipynb:460
msgid "**‚ö†Ô∏è Attention:** If we define a custom interpret function ( in the example: ``parity``), we must remember to explicitly provide the desired output shape ( in the example: ``2``). For more info on the initial parameter setup for ``CircuitQNN``, please check out the `official qiskit documentation <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."
msgstr "**‚ö†Ô∏è Attenzione:** Se definiamo una funzione interpret personalizzata (nell'esempio ``parity``), dobbiamo ricordarci di fornire in modo esplicito la dimensione dell'output desiderato (nell'esempio ``2``). Per pi√π informazioni sulle impostazioni dei parametri iniziali per ``CircuitQNN``, per favore far riferimento alla `documentazione ufficiale di qiskit <https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.CircuitQNN.html>`__."

#: ../../tutorials/05_torch_connector.ipynb:523
#: ../../tutorials/05_torch_connector.ipynb:815
msgid "For a reminder on optimizer and loss function choices, you can go back to `this section <#Optimizer>`__."
msgstr "Per un ripasso su come scegliere gli optimizer e le funzione di costo, puoi andare indietro a `questa sezione <#Optimizer>`__."

#: ../../tutorials/05_torch_connector.ipynb:686
msgid "2. Regression"
msgstr "2. Regressione"

#: ../../tutorials/05_torch_connector.ipynb:688
msgid "We use a model based on the ``TwoLayerQNN`` to also illustrate how to perform a regression task. The chosen dataset in this case is randomly generated following a sine wave."
msgstr "Utilizziamo un modello basato su ``TwoLayerQNN`` per mostrare anche un esempio su come eseguire una regressione. Il dataset scelto in questo caso √® stato generato in modo casuale seguendo una funzione seno."

#: ../../tutorials/05_torch_connector.ipynb:730
msgid "A. Regression with PyTorch and ``OpflowQNN``"
msgstr "A. Regressione con PyTorch e ``OpflowQNN``"

#: ../../tutorials/05_torch_connector.ipynb:741
msgid "The network definition and training loop will be analogous to those of the classification task using ``TwoLayerQNN``. In this case, we define our own feature map and ansatz, instead of using the default values."
msgstr "La definizione della rete e il processo di allenamento saranno gli stessi del caso della classificazione con la ``TwoLayerQNN``. In questo caso definiamo la nostra feature map e l'ansatz, invece di usare valori predefiniti."

#: ../../tutorials/05_torch_connector.ipynb:963
msgid "Part 2: MNIST Classification, Hybrid QNNs"
msgstr "Part 2: Classificazione su MNIST, QNNs Ibride"

#: ../../tutorials/05_torch_connector.ipynb:965
msgid "In this second part, we show how to leverage a hybrid quantum-classical neural network using ``TorchConnector``, to perform a more complex image classification task on the MNIST handwritten digits dataset."
msgstr "In questa seconda parte, mostriamo come sfruttare una neural network ibrida quantistica-classica, usando ``TorchConnector``, per eseguire una complessa classificazione sul dataset MNIST che contiene immagini di numeri scritti a mano."

#: ../../tutorials/05_torch_connector.ipynb:967
msgid "For a more detailed (pre-``TorchConnector``) explanation on hybrid quantum-classical neural networks, you can check out the corresponding section in the `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__."
msgstr "Puoi leggere la sezione dedicata nel `Qiskit Textbook <https://qiskit.org/textbook/ch-machine-learning/machine-learning-qiskit-pytorch.html>`__. per una pi√π dettagliata spiegazione sulle neural network ibride quantistico-classiche (pre-``TorchConnector``)."

#: ../../tutorials/05_torch_connector.ipynb:996
msgid "Step 1: Defining Data-loaders for train and test"
msgstr "Step 1: Definire i Data-loader per train e test"

#: ../../tutorials/05_torch_connector.ipynb:1007
msgid "We take advantage of the ``torchvision`` `API <https://pytorch.org/vision/stable/datasets.html>`__ to directly load a subset of the `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ and define torch ``DataLoader``\\ s (`link <https://pytorch.org/docs/stable/data.html>`__) for train and test."
msgstr "Utilizziamo la `API <https://pytorch.org/vision/stable/datasets.html>`__ ``torchvision`` per scaricare direttamente un sottoinsieme del `MNIST dataset <https://en.wikipedia.org/wiki/MNIST_database>`__ e definire un torch ``DataLoader`` (`link <https://pytorch.org/docs/stable/data.html>`__) per train e test."

#: ../../tutorials/05_torch_connector.ipynb:1048
msgid "If we perform a quick visualization we can see that the train dataset consists of images of handwritten 0s and 1s."
msgstr "Con una rapida visualizzazione, possiamo osservare che il train dataset consiste di immagini di 0 e 1 scritti a mano."

#: ../../tutorials/05_torch_connector.ipynb:1120
msgid "Step 2: Defining the QNN and Hybrid Model"
msgstr "Step 2: Definire la QNN ed il Modello Ibrido"

#: ../../tutorials/05_torch_connector.ipynb:1131
msgid "This second step shows the power of the ``TorchConnector``. After defining our quantum neural network layer (in this case, a ``TwoLayerQNN``), we can embed it into a layer in our torch ``Module`` by initializing a torch connector as ``TorchConnector(qnn)``."
msgstr "Questo secondo step mostra il potere del ``TorchConnector``. Dopo aver definito il nostro layer di quantum neural network ( in questo caso una ``TwoLayerQNN``), inizializzando un torch connector nel modo seguente ``TorchConnector(qnn)``, possiamo inglobarla in un layer ``Module`` di Torch."

#: ../../tutorials/05_torch_connector.ipynb:1133
msgid "**‚ö†Ô∏è Attention:** In order to have an adequate gradient backpropagation in hybrid models, we MUST set the initial parameter ``input_gradients`` to TRUE during the qnn initialization."
msgstr "**‚ö†Ô∏è Attenzione:** Per avere una adeguate backpropagation dei gradienti dei modelli ibridi DOBBIAMO impostare il parametro iniziale ``input_gradients`` a TRUE durante l'inializzazione della qnn."

#: ../../tutorials/05_torch_connector.ipynb:1235
msgid "Step 3: Training"
msgstr "Step 3: Addestramento (Training)"

#: ../../tutorials/05_torch_connector.ipynb:1337
msgid "Step 4: Evaluation"
msgstr "Step 4: Valutazione del modello (Evaluation)"

#: ../../tutorials/05_torch_connector.ipynb:1440
msgid "üéâüéâüéâüéâ **You are now able to experiment with your own hybrid datasets and architectures using Qiskit Machine Learning.** **Good Luck!**"
msgstr "üéâüéâüéâüéâ **Ora sei in grado di sperimentare con architetture ibride personalizzate e con nuovi dataset usando Qiskit Machine Learning.** **Buona Fortuna!**"

