msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-02-06 22:00+0000\n"
"PO-Revision-Date: 2023-02-06 22:27\n"
"Last-Translator: \n"
"Language: ko\n"
"Language-Team: Korean\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ko\n"
"X-Crowdin-File: /master/optimization/docs/locale/en/LC_MESSAGES/tutorials/05_admm_optimizer.po\n"
"X-Crowdin-File-ID: 9650\n"

#: ../../tutorials/05_admm_optimizer.ipynb:9
msgid "This page was generated from `docs/tutorials/05_admm_optimizer.ipynb`__."
msgstr "이 페이지는 `docs/tutorials/05_admm_optimizer.ipynb`__ 에서 생성되었다."

#: ../../tutorials/05_admm_optimizer.ipynb:9
msgid "ADMM Optimizer"
msgstr "ADMM 옵티마이저"

#: ../../tutorials/05_admm_optimizer.ipynb:21
msgid "Introduction"
msgstr "소개"

#: ../../tutorials/05_admm_optimizer.ipynb:32
msgid "The ADMM Optimizer can solve classes of mixed-binary constrained optimization problems, hereafter (MBCO), which often appear in logistic, finance, and operation research. In particular, the ADMM Optimizer here designed can tackle the following optimization problem :math:`(P)`:"
msgstr "ADMM 옵티마이저는 물류, 재무 및 운영 과학에서 종종 발생하는 혼합-이진 제약 최적화 문제 (이하 MBCO) 의 클래스를 해결할 수 있다. 특히 ADMM 옵티마이저는 다음과 같은 최적화 문제 :math:`(P)` 를 해결할 수 있다."

#: ../../tutorials/05_admm_optimizer.ipynb:34
msgid "\\min_{x \\in \\mathcal{X},u\\in\\mathcal{U} \\subseteq \\mathbb{R}^l } \\quad q(x) + \\varphi(u),"
msgstr "\\min_{x \\in \\mathcal{X},u\\in\\mathcal{U} \\subseteq \\mathbb{R}^l } \\quad q(x) + \\varphi(u),"

#: ../../tutorials/05_admm_optimizer.ipynb:39
msgid "subject to the constraints:"
msgstr "다음과 같은 제약 조건이 따른다:"

#: ../../tutorials/05_admm_optimizer.ipynb:41
msgid "\\mathrm{s.t.:~} \\quad G x = b, \\quad  g(x) \\leq 0, \\quad \\ell(x, u) \\leq 0,"
msgstr "\\mathrm{s.t.:~} \\quad G x = b, \\quad  g(x) \\leq 0, \\quad \\ell(x, u) \\leq 0,"

#: ../../tutorials/05_admm_optimizer.ipynb:46
msgid "with the corresponding functional assumptions."
msgstr "해당 기능적 가정과 함께"

#: ../../tutorials/05_admm_optimizer.ipynb:48
msgid "Function :math:`q: \\mathbb{R}^n \\to \\mathbb{R}` is quadratic, i.e., :math:`q(x) = x^{\\intercal} Q x + a^{\\intercal} x` for a given symmetric squared matrix :math:`Q \\in \\mathbb{R}^n \\times \\mathbb{R}^n, Q = Q^{\\intercal}`, and vector :math:`a \\in \\mathbb{R}^n`;"
msgstr "함수 :math:`q: \\mathbb{R}^n \\to \\mathbb{R}` 은 2차, 즉 주어진 대칭 제곱 행렬 :math:`Q \\in \\mathbb{R}^n \\times \\mathbb{R}^n, Q = Q^{\\intercal}` 에 대한 :math:`q(x) = x^{\\intercal} Q x + a^{\\intercal} x` 와 :math:`a \\in \\mathbb{R}^n` 이다."

#: ../../tutorials/05_admm_optimizer.ipynb:49
msgid "The set :math:`\\mathcal{X} = \\{0,1\\}^n = \\{x_{(i)} (1-x_{(i)}) = 0, \\forall i\\}` enforces the binary constraints;"
msgstr "세트 :math:`\\mathcal{X} = \\{0,1\\}^n = \\{x_{(i)} (1-x_{(i)}) = 0, \\forall i\\}` 는 2진 제약 조건을 강제한다."

#: ../../tutorials/05_admm_optimizer.ipynb:50
msgid "Matrix :math:`G\\in\\mathbb{R}^n \\times \\mathbb{R}^{n'}`, vector :math:`b \\in \\mathbb{R}^{n'}`, and function :math:`g: \\mathbb{R}^n \\to \\mathbb{R}` is convex;"
msgstr "행렬 :math:`G\\in\\mathbb{R}^n \\times \\mathbb{R}^{n'}`, 벡터 :math:`b \\in \\mathbb{R}^{n'}`, :math:`g: \\mathbb{R}^n \\to \\mathbb{R}` 함수는 볼록(convex) 하고;"

#: ../../tutorials/05_admm_optimizer.ipynb:51
msgid "Function :math:`\\varphi: \\mathbb{R}^l \\to \\mathbb{R}` is convex and :math:`\\mathcal{U}` is a convex set;"
msgstr "함수 :math:`\\varphi: \\mathbb{R}^l \\to \\mathbb{R}` 는 볼록(convex) 이고 :math:`\\mathcal{U}` 는 볼록 세트이며;"

#: ../../tutorials/05_admm_optimizer.ipynb:52
msgid "Function :math:`\\ell: \\mathbb{R}^n\\times \\mathbb{R}^l \\to \\mathbb{R}` is *jointly* convex in :math:`x, u`."
msgstr "기능 :math:`\\ell: \\mathbb{R}^n\\times \\mathbb{R}^l \\to \\mathbb{R}` 는 :math:`x, u` 에서 *공동* 볼록(convex) 합니다."

#: ../../tutorials/05_admm_optimizer.ipynb:63
msgid "In order to solve MBO problems, [1] proposed heuristics for :math:`(P)` based on the Alternating Direction Method of Multipliers (ADMM) [2]. ADMM is an operator splitting algorithm with a long history in convex optimization, and it is known to have residual, objective and dual variable convergence properties, provided that convexity assumptions are holding."
msgstr "MBO 문제를 해결하기 위해 [1]은 Alternating Direction Method of Multipliers (ADMM) [2]에 기초한 :math:`(P)` 에 대한 발견적 교수법을 제안했다. ADMM은 convex optimzation의 오랜 이력을 지닌 연산자 분할 알고리즘이며, 볼록부 가정이 유지된다는 전제 하에 잔류, 객관 및 이중 변수 수렴 특성을 갖는 것으로 알려져 있다."

#: ../../tutorials/05_admm_optimizer.ipynb:65
msgid "The method of [1] (referred to as 3-ADMM-H) leverages the ADMM operator-splitting procedure to devise a decomposition for certain classes of MBOs into:"
msgstr "[1] 의 방법(3-ADMM-H라고 함) 은 ADMM 연산자 분할 절차를 활용하여 특정 클래스의 MBO를 다음과 같이 분해한다:"

#: ../../tutorials/05_admm_optimizer.ipynb:67
msgid "a QUBO subproblem to be solved by on the quantum device via variational algorithms, such as VQE or QAOA;"
msgstr "VQE 또는 QAOA와 같은 다양한 알고리즘들을 통해 양자 장치에서 해결해야 할 QUBO 하위 문제;"

#: ../../tutorials/05_admm_optimizer.ipynb:68
msgid "continuous convex constrained subproblem, which can be efficiently solved with classical optimization solvers."
msgstr "고전적인 최적화 해석기(Solver)로 효율적으로 해결될 수 있는 연속적인 볼록 제약(convex constrained) 부분문제(subproblem)"

#: ../../tutorials/05_admm_optimizer.ipynb:70
msgid "The algorithm 3-ADMM-H works as follows:"
msgstr "알고리즘 3-ADMM-H는 다음과 같이 작동한다:"

#: ../../tutorials/05_admm_optimizer.ipynb:72
msgid "Initialization phase (set the parameters and the QUBO and convex solvers);"
msgstr "초기화 단계(매개변수, QUBO 및 convex solver 설정)"

#: ../../tutorials/05_admm_optimizer.ipynb:73
msgid "For each ADMM iterations ($k = 1, 2, :nbsphinx-math:`\\ldots`, $) until termination:"
msgstr "계산이 종료될때까지 각 ADMM 반복에 대해 ($k = 1, 2, :nbsphinx-math:`\\ldots`, $):"

#: ../../tutorials/05_admm_optimizer.ipynb:75
msgid "Solve a properly defined QUBO subproblem (with a classical or quantum solver);"
msgstr "적절히 정의된 QUBO 하위 문제를 (고전적 또는 양자 solver) 로 해결;"

#: ../../tutorials/05_admm_optimizer.ipynb:76
msgid "Solve properly defined convex problems (with a classical solver);"
msgstr "적절히 정의된 convex 문제 (고전적 solver) 로 해결;"

#: ../../tutorials/05_admm_optimizer.ipynb:77
msgid "Update the dual variables."
msgstr "이중 변수를 업데이트한다."

#: ../../tutorials/05_admm_optimizer.ipynb:79
msgid "Return optimizers and cost."
msgstr "옵티마이저 및 비용을 반환한다."

#: ../../tutorials/05_admm_optimizer.ipynb:81
msgid "A comprehensive discussion on the conditions for convergence, feasibility and optimality of the algorithm can be found in [1]. A variant with 2 ADMM blocks, namely a QUBO subproblem, and a continuous convex constrained subproblem, is also introduced in [1]."
msgstr "알고리즘의 수렴, 실현 가능성 및 최적성에 대한 포괄적인 논의는 [1] 에서 확인할 수 있다. 2개의 ADMM 블록, 즉, QUBO 하위 문제와 연속 convex 제약 하위 문제를 가진 변형 모델도 [1] 에 도입된다."

#: ../../tutorials/05_admm_optimizer.ipynb:84
msgid "References"
msgstr "참조"

#: ../../tutorials/05_admm_optimizer.ipynb:86
msgid "[1] `C. Gambella and A. Simonetto, Multi-block ADMM heuristics for mixed-binary optimization, on classical and quantum computers, arXiv preprint arXiv:2001.02069 (2020). <https://arxiv.org/abs/2001.02069>`__"
msgstr "[1] `C. Gambella and A. Simonetto, Multi-block ADMM heuristics for mixed-binary optimization, on classical and quantum computers, arXiv preprint arXiv:2001.02069 (2020). <https://arxiv.org/abs/2001.02069>`__"

#: ../../tutorials/05_admm_optimizer.ipynb:88
msgid "[2] `S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, Distributed optimization and statistical learning via the alternating direction method of multipliers, Foundations and Trends in Machine learning, 3, 1–122 (2011). <https://web.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf>`__"
msgstr "[2] `S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, Distributed optimization and statistical learning via the alternating direction method of multipliers, Foundations and Trends in Machine learning, 3, 1–122 (2011). <https://web.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf>`__"

#: ../../tutorials/05_admm_optimizer.ipynb:100
msgid "Initialization"
msgstr "초기화"

#: ../../tutorials/05_admm_optimizer.ipynb:102
msgid "First of all we load all the packages that we need."
msgstr "가장 우선적으로 필요한 패키지를 모두 로드한다."

#: ../../tutorials/05_admm_optimizer.ipynb:138
msgid "We first initialize all the algorithms we plan to use later in this tutorial."
msgstr "이 튜토리얼의 후반부에서 사용하려는 모든 알고리즘을 먼저 초기화한다."

#: ../../tutorials/05_admm_optimizer.ipynb:140
msgid "To solve the QUBO problems we can choose between"
msgstr "QUBO 문제를 해결하기 위해 다음 중 하나를 선택할 수 있다."

#: ../../tutorials/05_admm_optimizer.ipynb:142
msgid "``MinimumEigenOptimizer`` using different ``MinimumEigensolver``, such as ``SamplingVQE``, ``QAOA`` or ``NumpyMinimumEigensolver`` (classical)"
msgstr ""

#: ../../tutorials/05_admm_optimizer.ipynb:143
msgid "``GroverOptimizer``"
msgstr "``GroverOptimizer``"

#: ../../tutorials/05_admm_optimizer.ipynb:144
msgid "``CplexOptimizer`` (classical, if CPLEX is installed)"
msgstr "``CplexOptimizer`` (고전적, CPLEX가 설치된 경우)"

#: ../../tutorials/05_admm_optimizer.ipynb:146
msgid "and to solve the convex continuous problems we can choose between the following classical solvers:"
msgstr "그리고 볼록한(convex) 연속 함수 문제를 풀기 위해 다음의 해석기(solver)중에서 선택할 수 있다:"

#: ../../tutorials/05_admm_optimizer.ipynb:148
msgid "``CplexOptimizer`` (if CPLEX is installed)"
msgstr "``CplexOptimizer`` (CPLEX가 설치된 경우)"

#: ../../tutorials/05_admm_optimizer.ipynb:149
msgid "``CobylaOptimizer``"
msgstr "``CobylaOptimizer``"

#: ../../tutorials/05_admm_optimizer.ipynb:151
msgid "In case CPLEX is not available, the ``CobylaOptimizer`` (for convex continuous problems) and the ``MinimumEigenOptimizer`` using the ``NumpyMinimumEigensolver`` (for QUBOs) can be used as classical alternatives to CPLEX for testing, validation, and benchmarking."
msgstr "CPLEX를 사용할 수 없는 경우, ``CobylaOptimizer`` (볼록 연속 문제의 경우) 와 ``NumpyMinimumEigensolver`` (QUBO의 경우) 를 사용하는 ``MinimumEigenOptimizer`` 를 테스트, 검증 및 벤치마킹을 위해 CPLEX의 고전적인 대안으로 사용할 수 있다."

#: ../../tutorials/05_admm_optimizer.ipynb:185
msgid "Example"
msgstr "예제"

#: ../../tutorials/05_admm_optimizer.ipynb:187
msgid "We test 3-ADMM-H algorithm on a simple Mixed-Binary Quadratic Problem with equality and inequality constraints (Example 6 reported in [1]). We first construct a docplex problem and then load it into a ``QuadraticProgram``."
msgstr "우리는 평등과 불평등 제약 조건을 가진 단순한 혼합 이항 2차 문제에 대해 3-ADMM-H 알고리즘을 테스트 한다 (예 6은 [1] 에 보고되었다). 우리는 먼저 복잡한 문제를 구성한 다음 그것을 ``QuadraticProgram`` 에 로드한다."

#: ../../tutorials/05_admm_optimizer.ipynb:296
msgid "Classical Solution"
msgstr "고전적인 솔루션"

#: ../../tutorials/05_admm_optimizer.ipynb:298
msgid "3-ADMM-H needs a QUBO optimizer to solve the QUBO subproblem, and a continuous optimizer to solve the continuous convex constrained subproblem. We first solve the problem classically: we use the ``MinimumEigenOptimizer`` with the ``NumPyMinimumEigenSolver`` as a classical and exact QUBO solver and we use the ``CobylaOptimizer`` as a continuous convex solver. 3-ADMM-H supports any other suitable solver available in Qiskit. For instance, ``SamplingVQE``, ``QAOA``, and ``GroverOptimizer`` can be invoked as quantum solvers, as demonstrated later. If CPLEX is installed, the ``CplexOptimizer`` can also be used as both, a QUBO and convex solver."
msgstr ""

#: ../../tutorials/05_admm_optimizer.ipynb:311
msgid "Parameters"
msgstr "매개변수"

#: ../../tutorials/05_admm_optimizer.ipynb:313
msgid "The 3-ADMM-H are wrapped in class ``ADMMParameters``. Customized parameter values can be set as arguments of the class. In this example, parameters :math:`\\rho, \\beta` are initialized to :math:`1001` and :math:`1000`, respectively. The penalization ``factor_c`` of equality constraints :math:`Gx = b` is set to :math:`900`. The tolerance ``tol`` for primal residual convergence is set to ``1.e-6``. In this case, the 3-block implementation is guaranteed to converge for Theorem 4 of [1], because the inequality constraint with the continuous variable is always active. The 2-block implementation can be run by setting ``three_block=False``, and practically converges to a feasible not optimal solution."
msgstr "3-ADMM-H는 클래스 ``ADMMParameters`` 로 포장되어 있다. 사용자 정의된 매개 변수 값은 클래스의 인수로 설정할 수 있다. 이 예에서 매개 변수 :math:`\\rho, \\beta` 는 각각 :math:`1001` 과 :math:`1000` 으로 초기화된다. 평등 제약 조건 :math:`Gx = b` 의 벌칙 ``factor_c`` 는 :math:`900` 로 설정되었다. 기본 잔차 수렴에 대한 공차 ``tol`` 는 ``1.e-6`` 로 설정된다. 이 경우, 연속 변수와 불평등 제약 조건이 항상 활성 상태이기 때문에, 3-블록 구현은 [1]의 정리 4에 대해 수렴할 것을 보장한다. 2-블록 구현은 ``three_block=False`` 을 설정하여 실행할 수 있으며, 실현 가능 하지 않은 최적의 솔루션을 실질적으로 수렴된다."

#: ../../tutorials/05_admm_optimizer.ipynb:338
msgid "Calling 3-ADMM-H algorithm"
msgstr "3-ADMM-H 알고리즘 호출"

#: ../../tutorials/05_admm_optimizer.ipynb:340
msgid "To invoke the 3-ADMM-H algorithm, an instance of the ``ADMMOptimizer`` class needs to be created. This takes ADMM-specific parameters and the subproblem optimizers separately into the constructor. The solution returned is an instance of ``OptimizationResult`` class."
msgstr "3-ADMM-H 알고리즘을 호출하기 위해 ``ADMMOptimizer`` 클래스의 인스턴스를 만들어야 한다. 이는 ADMM-특정 파라미터 및 하위 문제점 최적화 프로그램을 컨스트럭터에 개별적으로 취한다. 반환된 솔루션은 ``OptimizationResult`` 클래스의 인스턴스이다."

#: ../../tutorials/05_admm_optimizer.ipynb:384
msgid "Classical Solver Result"
msgstr "고전적인 해석기(Solver) 결과"

#: ../../tutorials/05_admm_optimizer.ipynb:386
msgid "The 3-ADMM-H solution can be then printed and visualized. The ``x`` attribute of the solution contains respectively, the values of the binary decision variables and the values of the continuous decision variables. The ``fval`` is the objective value of the solution."
msgstr "이어서, 3-ADMM-H 용액을 인쇄하고 가시화할 수 있다. 솔루션의 ``x`` 속성은 각각, 2진 결정 변수들의 값들 및 연속적인 결정 변수들의 값들을 포함한다. ``fval`` 은 해법의 객관적 가치이다."

#: ../../tutorials/05_admm_optimizer.ipynb:437
msgid "Solution statistics can be accessed in the ``state`` field and visualized. We here display the convergence of 3-ADMM-H, in terms of primal residuals."
msgstr "솔루션 통계는 ``state`` 필드에서 액세스할 수 있으며 시각화할 수 있다. 여기서는 3-ADMM-H의 수렴을 원시 잔차(primal residual) 로 표시한다."

#: ../../tutorials/05_admm_optimizer.ipynb:470
msgid "Quantum Solution"
msgstr "양자 솔루션"

#: ../../tutorials/05_admm_optimizer.ipynb:472
msgid "We now solve the same optimization problem with QAOA as QUBO optimizer, running on simulated quantum device. First, one need to select the classical optimizer of the eigensolver QAOA. Then, the simulation backend is set. Finally, the eigensolver is wrapped into the ``MinimumEigenOptimizer`` class. A new instance of ``ADMMOptimizer`` is populated with QAOA as QUBO optimizer."
msgstr "이제 QAOA와 같은 최적화 문제점을 QAOA 최적화 프로그램으로 해결하여 시뮬레이트된 양자 디바이스에서 실행한다. 첫 번째로, 고유 해결사 QAOA의 전형적인 최적화 프로그램을 선택해야 한다. 그런 다음, 시뮬레이션 백엔드가 설정된다. 마지막으로 고유해결자(eigensolver) 는 ``MinimumEigenOptimizer`` 클래스로 포장된다. ``ADMMOptimizer`` 의 새로운 인스턴스는 QUBO 최적기로서 QAOA로 채워져있다."

#: ../../tutorials/05_admm_optimizer.ipynb:515
msgid "Quantum Solver Results"
msgstr "양자 해석기(Solver) 결과"

#: ../../tutorials/05_admm_optimizer.ipynb:517
msgid "Here we present the results obtained from the quantum solver. As in the example above ``x`` stands for the solution, the ``fval`` is for objective value."
msgstr "여기서 우리는 양자 해결기로부터 얻어진 결과를 제공한다. 위의 예에서 보듯이 ``x`` 는 해법을 뜻하기 때문에 ``fval`` 은 객관적인 가치를 위한 것이다."

