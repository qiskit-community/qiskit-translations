msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-04-29 18:58+0000\n"
"PO-Revision-Date: 2021-04-29 19:35\n"
"Last-Translator: \n"
"Language-Team: Japanese\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ja\n"
"X-Crowdin-File: /master/docs/locale/en/LC_MESSAGES/tutorials/machine_learning/01_qsvm_classification.po\n"
"X-Crowdin-File-ID: 9464\n"
"Language: ja_JP\n"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:10
msgid "This page was generated from `tutorials/machine_learning/01_qsvm_classification.ipynb`__."
msgstr "このページは、 `tutorials/machine_learning/01_qsvm_classification.ipynb`__ から生成されました。"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:12
msgid "Run interactively in the `IBM Quantum lab <https://quantum-computing.ibm.com/jupyter/tutorial/machine_learning/01_qsvm_classification.ipynb>`_."
msgstr "`IBM Quantum lab <https://quantum-computing.ibm.com/jupyter/tutorial/machine_learning/01_qsvm_classification.ipynb>`_ でインタラクティブに実行します。"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:9
msgid "Quantum-enhanced Support Vector Machine (QSVM)"
msgstr "量子サポート・ベクター・マシン (QSVM)"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:11
msgid "Classification algorithms and methods for machine learning are essential for pattern recognition and data mining applications. Well known techniques such as support vector machines and neural networks have blossomed over the last two decades as a result of the spectacular advances in classical hardware computational capabilities and speed. This progress in computer power made it possible to apply techniques, that were theoretically developed towards the middle of the 20th century, on classification problems that were becoming increasingly challenging."
msgstr "機械学習の分類アルゴリズムや手法は、パターン認識やデータマイニングの応用に不可欠です。サポート・ベクター・マシンやニューラル・ネットワークなどのよく知られた技術は、古典的なハードウェアの計算能力の目覚ましい進歩の結果として、過去二十年の間に開花しました。こうした計算能力の進歩によって、二十世紀半ばに理論的に開発された技術を、より難しい分類問題にも適用することが可能となってきました。"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:14
msgid "A key concept in classification methods is that of a kernel. Data cannot typically be separated by a hyperplane in its original space. A common technique used to find such a hyperplane consists of applying a non-linear transformation function to the data. This function is called a feature map, as it transforms the raw features, or measurable properties, of the phenomenon or subject under study. Classifying in this new feature space -and, as a matter of fact, also in any other space, including the raw original one- is nothing more than seeing how close data points are to each other. This is the same as computing the inner product for each pair of data points in the set. So, in fact we do not need to compute the non-linear feature map for each datum, but only the inner product of each pair of data points in the new feature space. This collection of inner products is called the kernel and it is perfectly possible to have feature maps that are hard to compute but whose kernels are not."
msgstr "分類における重要な概念は、カーネルです。データは通常、元の空間では超平面で分離することができません。このような超平面を得るために用いられる一般的な手法は、データに対する非線形変換関数の適用からなります。この関数は、研究対象の特徴量や測定量を変換することから、特徴マップと呼ばれます。この新しい特徴空間で分類を行うことは、データ点が互いにどれだけ近いかを見ることに他なりません。これは実は、元の空間を含む他の空間においても同様です。これは、集合内の各データ点の組に対して内積を計算するのと同じです。つまり実際には、各データの非線形特徴マップを計算する必要はなく、新たな特徴空間の各データ点の組に対して内積を計算するだけで十分です。この内積の集合はカーネルと呼ばれます。特徴マップを計算するのは困難だが、カーネルは計算できるという場合はありえます。"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:17
msgid "In this notebook we provide an example of a classification problem that requires a feature map for which computing the kernel is not efficient classically -this means that the required computational resources are expected to scale exponentially with the size of the problem. We show how this can be solved in a quantum processor by a direct estimation of the kernel in the feature space. The method we used falls in the category of what is called supervised learning, consisting of a training phase (where the kernel is calculated and the support vectors obtained) and a test or classification phase (where new unlabeled data is classified according to the solution found in the training phase)."
msgstr "このノートブックでは、カーネルの計算が古典手法では効率的でない特徴マップを要する分類問題の例を示します。効率的でないとは、必要な計算リソースが問題のサイズに対して指数関数的に大きくなることを意味しています。量子プロセッサで特徴空間のカーネルを直接的に推定することで、この問題を解決する方法を紹介します。用いた手法は、学習段階 (カーネルを計算し、サポート・ベクトルを得る段階) と、テストあるいは分類段階 (学習段階で得られた解に基づき、ラベルされていない新たなデータを分類する段階) からなる、いわゆる教師あり学習として分類されるものです。"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:20
msgid "References and additional details:"
msgstr "参考文献と追加資料："

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:22
msgid "[1] Vojtech Havlicek, Antonio D. C´orcoles, Kristan Temme, Aram W. Harrow, Abhinav Kandala, Jerry M. Chow, and Jay M. Gambetta1, “Supervised learning with quantum enhanced feature spaces,” `arXiv: 1804.11326 <https://arxiv.org/pdf/1804.11326.pdf>`__"
msgstr "[1] Vojtech Havlicek, Antonio D. C´orcoles, Kristan Temme, Aram W. Harrow, Abhinav Kandala, Jerry M. Chow, and Jay M. Gambetta1, “Supervised learning with quantum enhanced feature spaces,” `arXiv: 1804.11326 <https://arxiv.org/pdf/1804.11326.pdf>`__"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:54
msgid "The ad hoc data set"
msgstr "アドホック・データセット"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:56
msgid "As a first example we will use the ad hoc dataset as described in the above referenced paper. From the dataset we take samples for use as training, testing and the final prediction (datapoints)."
msgstr "最初の例として、上記の参考文献に記載されているアドホック・データセットを用います。このデータセットから、訓練・テスト・最終予測 (データ点) として使用するためのサンプルを取ります。"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:117
msgid "With the dataset ready we can setup the `QSVM <https://qiskit.org/documentation/stubs/qiskit.aqua.algorithms.QSVM.html>`__ algorithm to do a classification. Here we use the `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__ data encoding circuit from the Qiskit circuit library."
msgstr "データセットの準備ができたので、 `QSVM <https://qiskit.org/documentation/stubs/qiskit.aqua.algorithms.QSVM.html>`__ アルゴリズムを設定して、分類を行います。ここでは `Qiskit circuit` ライブラリの `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__ データ符号化回路を用います。"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:119
msgid "Here the BasicAer ``qasm_simulator`` is used with 1024 shots."
msgstr "今回は BasicAer の ``qasm_simulator`` を1024ショットで使用します。"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:121
msgid "For the testing, the result includes the details and the success ratio. For the prediction, the result includes the predicted labels."
msgstr "テストの結果には、詳細と成功率が含まれています。予測の結果には、予測ラベルが含まれています。"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:185
msgid "The following shows the kernel matrix that was built from the training sample of the dataset."
msgstr "データセットの訓練サンプルから作成したカーネル行列を以下に示します。"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:215
msgid "Qiskit also has a classical SVM implementation that takes the same input data for classification. Let’s run this and do a comparison. Now the ad hoc data set was created to show that there can be datasets where quantum could give an advantage."
msgstr "Qiskit には、同じ入力データを取る古典的な SVM の実装もあります。これを実行して、比較を行ってみましょう。このアドホック・データは、量子が有利となるデータセットが存在していることを示すために作成されました。"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:288
msgid "The breast cancer dataset"
msgstr "乳がんデータセット"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:290
msgid "Now we run our algorithm with a real-world dataset: the breast cancer dataset, we use the first two principal components as features."
msgstr "次に、実データでアルゴリズムを実行します。乳がんデータセットの第一主成分と第二主成分を特徴量として用います。"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:364
msgid "The kernel matrix that was built from the training sample of the dataset."
msgstr "データセットの訓練サンプルから作成されたカーネル行列"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:394
msgid "Again we are able to compare the result to a classical approach."
msgstr "ここでも、古典的なアプローチと結果を比較することができます。"

