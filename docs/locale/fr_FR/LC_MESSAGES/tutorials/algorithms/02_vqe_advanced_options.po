msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-03-02 21:04+0000\n"
"PO-Revision-Date: 2023-03-03 09:48\n"
"Last-Translator: \n"
"Language: fr\n"
"Language-Team: French\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: fr\n"
"X-Crowdin-File: /master/docs/locale/en/LC_MESSAGES/tutorials/algorithms/02_vqe_advanced_options.po\n"
"X-Crowdin-File-ID: 9931\n"

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:10
msgid "This page was generated from `tutorials/algorithms/02_vqe_advanced_options.ipynb`__."
msgstr "Cette page a été générée à partir de `tutorials/algorithms/02_vqe_advanced.ipynb`__."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:9
msgid "Advanced VQE Options"
msgstr "Options Avancées de VQE"

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:11
msgid "In the first algorithms tutorial, you learned how to set up a basic `VQE <https://qiskit.org/documentation/stubs/qiskit.algorithms.minimum_eigensolvers.VQE.html>`__ algorithm. Now, you will see how to provide more advanced configuration parameters to explore the full range of capabilities of Qiskit’s variational algorithms: `VQE <https://qiskit.org/documentation/stubs/qiskit.algorithms.minimum_eigensolvers.VQE.html>`__, `QAOA <https://qiskit.org/documentation/stubs/qiskit.algorithms.minimum_eigensolvers.QAOA.html>`__ and `VQD <https://qiskit.org/documentation/stubs/qiskit.algorithms.eigensolvers.VQD.html>`__ among others. In particular, this tutorial will cover how to set up a ``callback`` to monitor convergence and the use of custom ``initial point``\\ s and ``gradient``\\ s."
msgstr "Dans le premier tutoriel d'algorithmes, vous avez appris comment mettre en place un algorithme basique `VQE <https://qiskit.org/documentation/stubs/qiskit.algorithms.minimum_eigensolvers.VQE.html>`__. Maintenant, vous allez voir comment fournir des paramètres de configuration plus avancés pour explorer toute la gamme de capacités des algorithmes variationnels de Qiskit : `VQE <https://qiskit.org/documentation/stubs/qiskit.algorithms.minimum_eigensolvers.VQE.html>`__, `QAOA <https://qiskit.org/documentation/stubs/qiskit.algorithms.minimum_eigensolvers.QAOA.html>`__ et `VQD <https://qiskit.org/documentation/stubs/qiskit.algorithms.eigensolvers.VQD.html>`__ entre autres. En particulier, ce tutoriel couvrira comment configurer un ``callback`` pour surveiller la convergence et l'utilisation des ``initial point``\\ s personnalisés et des ``gradient``\\ s."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:24
msgid "Callback"
msgstr "Procédure de rappel (callback)"

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:35
msgid "Callback methods can be used to monitor optimization progress as the algorithm runs and converges to the minimum. The callback is invoked for each functional evaluation by the optimizer and provides the current optimizer value, evaluation count, current optimizer parameters etc. Note that, depending on the specific optimizer this may not be each iteration (step) of the optimizer, so for example if the optimizer is calling the cost function to compute a finite difference based gradient this will be visible via the callback."
msgstr "Les méthodes de rappel peuvent être utilisées pour surveiller la progression de l'optimisation au fur et à mesure que l'algorithme s'exécute et converge au minimum. Le callback est appelé pour chaque évaluation fonctionnelle par l'optimiseur et fournit la valeur actuelle de l'optimiseur, le nombre d'évaluations, les paramètres actuels de l'optimiseur, etc. Notez que, selon l'optimiseur spécifique, cela peut ne pas être chaque itération (étape) de l'optimisateur, donc par exemple si l'optimiseur appelle la fonction coût pour calculer un gradient de différence finie, cela sera visible via le callback."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:38
msgid "This section demonstrates how to leverage callbacks in ``VQE`` to plot the convergence path to the ground state energy with a selected set of optimizers."
msgstr "Cette section montre comment tirer parti des callbacks dans ``VQE`` pour tracer le chemin de convergence vers l'énergie de l'état fondamental avec un ensemble sélectionné d'optimiseurs."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:49
msgid "First, you need a qubit operator for VQE. For this example, you can use the same operator as used in the algorithms introduction, which was originally computed by Qiskit Nature for an H2 molecule."
msgstr "Tout d'abord, nous créons un opérateur quantique pour VQE. Ici nous utiliserons le même opérateur que celui qui a été utilisé dans l'introduction aux algorithmes, et initialement calculé par Qiskit Nature pour une molécule H2."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:80
msgid "The next step is to instantiate the ``Estimator`` of choice for the evaluation of expectation values within ``VQE``. For simplicity, you can select the ``qiskit.primitives.Estimator`` shipped with the default Qiskit Terra installation."
msgstr "L'étape suivante consiste à instancier l' `` Estimateur`` de choix pour l'évaluation des valeurs attendues dans ``VQE``. Pour simplifier, vous pouvez sélectionner ``qiskit.primitives.Estimator`` livré avec l'installation Qiskit Terra par défaut."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:103
msgid "You are now ready to compare a set of optimizers through the ``VQE`` callback. The minimum energy of the H2 Hamiltonian can be found quite easily, so the maximum number of iterations (``maxiter``) does not have to be very large. You can once again use ``TwoLocal`` as the selected trial wavefunction (i.e. ansatz)."
msgstr "Vous êtes maintenant prêt à comparer un ensemble d'optimisateurs à travers le callback ``VQE``. L'énergie minimale du Hamiltonien de H2 peut être trouvée assez facilement, donc le nombre maximum d'itérations (``maxiter``) ne doit pas être très grand. Vous pouvez à nouveau utiliser ``TwoLocal`` comme fonction d'essai sélectionnée (i.e. ansatz)."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:176
msgid "Now, from the callback data you stored, you can plot the energy value at each objective function call each optimizer makes. An optimizer using a finite difference method for computing gradient has that characteristic step-like plot where for a number of evaluations it is computing the value for close by points to establish a gradient (the close by points having very similar values whose difference cannot be seen on the scale of the graph here)."
msgstr "Maintenant, à partir des données de callback que nous avons stockées, nous pouvons tracer la valeur d'énergie à chaque appel de fonction objectif que chaque optimiseur fait. Un optimiseur utilisant une méthode de différence finie pour le calcul du gradient a ce tracé avec des plateaux caractéristique où, pour un certain nombre d'évaluations consécutives, il calcule la valeur d'énergie pour des points très proches (les points très proches ayant des valeurs d'énergie très similaires, la différence ne peut être vue sur l'échelle du graphique)."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:213
msgid "Finally, since the above problem is still easily tractable classically, you can use ``NumPyMinimumEigensolver`` to compute a reference value for the solution."
msgstr "Enfin, puisque le problème ci-dessus est toujours facilement tractable classiquement, vous pouvez utiliser ``NumPyMinimumEigensolver`` pour calculer une valeur de référence pour la solution."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:264
msgid "You can now plot the difference between the ``VQE`` solution and this exact reference value as the algorithm converges towards the minimum energy."
msgstr "Vous pouvez maintenant tracer la différence entre la solution ``VQE`` et cette valeur de référence exacte lorsque l'algorithme converge vers l'énergie minimale."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:305
msgid "Gradients"
msgstr "Gradients"

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:307
msgid "In Qiskit’s variational algorithms, if the provided optimizer uses a gradient-based technique, the default gradient method will be finite differences. However, these classes include an option to pass custom gradients via the ``gradient`` parameter, which can be any of the provided methods within Qiskit’s `gradient <https://qiskit.org/documentation/stubs/qiskit.algorithms.gradients.html>`__ framework, which fully supports the use of primitives. This section shows how to use custom gradients in the VQE workflow."
msgstr "Dans les algorithmes variationnels de Qiskit, si l'optimiseur fourni utilise une technique basée sur un gradient, la méthode par défaut du gradient sera les différences finies. Cependant, ces classes incluent une option pour passer des gradients personnalisés via le paramètre ``gradient``, qui peut être n'importe laquelle des méthodes fournies dans le cadre Qiskit `gradient <https://qiskit.org/documentation/stubs/qiskit.algorithms.gradients.html>` __, qui supporte entièrement l'utilisation des primitives. Cette section explique comment utiliser des gradients personnalisés dans le flux de travaux VQE."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:310
msgid "The first step is to initialize both the corresponding primitive and primitive gradient:"
msgstr "La première étape consiste à initialiser la primitive et la primitive de gradient correspondante :"

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:334
msgid "Now, you can inspect an SLSQP run using the ``FiniteDiffEstimatorGradient`` from above:"
msgstr "A présent, vous pouvez inspecter une exécution SLSQP à l'aide de ``FiniteDiffEstimatorGradient`` comme ci-dessus :"

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:422
msgid "Initial point"
msgstr "Point de départ"

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:424
msgid "By default, the optimization begins at a random point within the bounds defined by the ansatz. The ``initial_point`` option allows to override this point with a custom list of values that match the number of ansatz parameters."
msgstr "Par défaut, l'optimisation commence à un point aléatoire dans les limites définies par l'ansatz. L'option ``initial_point`` permet de remplacer ce point par une liste personnalisée de valeurs qui correspondent au nombre de paramètres ansatz."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:426
msgid "You might wonder… *Why set a custom initial point?* Well, this option can come in handy if you have a guess for a reasonable starting point for the problem, or perhaps know information from a prior experiment."
msgstr "Vous pourriez vous demander… *Pourquoi définir un point initial personnalisé ? Eh bien, cette option peut vous être utile si vous avez une estimation pour un point de départ raisonnable pour le problème, ou peut-être parce que vous connaissez des informations d'une expérience antérieure."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:428
msgid "To demonstrate this feature, let’s look at the results from our previous VQE run:"
msgstr "Pour illustrer cette fonctionnalité, regardons les résultats de notre précédente exécution VQE:"

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:525
msgid "Now, you can take the ``optimal_point`` from the above result and use it as the ``initial_point`` for a follow-up computation."
msgstr "Maintenant, vous pouvez prendre le ``optimal_point`` du résultat ci-dessus et l'utiliser comme ``initial_point`` pour un calcul ultérieur."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:527
msgid "**Note:** ``initial_point`` is now a keyword-only argument of the ``VQE`` class (i.e, it must be set following the ``keyword=value`` syntax)."
msgstr "** Note:** ``initial_point`` est maintenant un argument de type mot clé de la classe ``VQE`` (c'est-à-dire qu'il doit être défini à la suite de la syntaxe ``mot clé = valeur``)."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:676
msgid "By looking at the ``cost_function_evals`` you can notice how the initial point helped the algorithm converge faster (in just 1 iteration, as we already provided the optimal solution)."
msgstr "En regardant les ``cost_function_evals`` vous pouvez remarquer comment le point initial a aidé l'algorithme à converger plus rapidement (en une seule itération, comme nous avons déjà fourni la solution optimale)."

#: ../../tutorials/algorithms/02_vqe_advanced_options.ipynb:678
msgid "This can be particularly useful in cases where we have two closely related problems, and the solution to one problem can be used to guess the other’s. A good example might be plotting dissociation profiles in chemistry, where we change the inter-atomic distances of a molecule and compute its minimum eigenvalue for each distance. When the distance changes are small, we expect the solution to still be close to the prior one. Thus, a popular technique is to simply use the optimal point from one solution as the starting point for the next step. There also exist more complex techniques, where we can apply extrapolation to compute an initial position based on prior solution(s) rather than directly use the prior solution."
msgstr "Cela peut être particulièrement utile dans les cas où nous avons deux problèmes étroitement liés, et la solution à un problème peut être utilisée pour deviner les autres. Un bon exemple pourrait être le tracé de profils de dissociation en chimie, où nous changeons les distances interatomiques d'une molécule et calculons sa valeur propre minimale pour chaque distance. Lorsque les changements de distance sont faibles, nous nous attendons à ce que la solution soit encore proche de la solution précédente. Ainsi, une technique populaire consiste à utiliser simplement le point optimal d'une solution comme point de départ pour l'étape suivante. Il existe également des techniques plus complexes, où nous pouvons appliquer une extrapolation pour calculer une position initiale basée sur une ou des solutions antérieures plutôt que d'utiliser directement la solution précédente."

