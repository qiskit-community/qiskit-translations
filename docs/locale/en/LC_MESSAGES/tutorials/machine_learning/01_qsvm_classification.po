# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, Qiskit Development Team
# This file is distributed under the same license as the Qiskit package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Qiskit \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-05-19 18:39+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:10
msgid ""
"This page was generated from "
"`tutorials/machine_learning/01_qsvm_classification.ipynb`__."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:12
msgid ""
"Run interactively in the `IBM Quantum lab <https://quantum-"
"computing.ibm.com/jupyter/tutorial/machine_learning/01_qsvm_classification.ipynb>`_."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:9
msgid "Quantum-enhanced Support Vector Machine (QSVM)"
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:11
msgid ""
"Classification algorithms and methods for machine learning are essential "
"for pattern recognition and data mining applications. Well known "
"techniques such as support vector machines and neural networks have "
"blossomed over the last two decades as a result of the spectacular "
"advances in classical hardware computational capabilities and speed. This"
" progress in computer power made it possible to apply techniques, that "
"were theoretically developed towards the middle of the 20th century, on "
"classification problems that were becoming increasingly challenging."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:14
msgid ""
"A key concept in classification methods is that of a kernel. Data cannot "
"typically be separated by a hyperplane in its original space. A common "
"technique used to find such a hyperplane consists of applying a non-"
"linear transformation function to the data. This function is called a "
"feature map, as it transforms the raw features, or measurable properties,"
" of the phenomenon or subject under study. Classifying in this new "
"feature space -and, as a matter of fact, also in any other space, "
"including the raw original one- is nothing more than seeing how close "
"data points are to each other. This is the same as computing the inner "
"product for each pair of data points in the set. So, in fact we do not "
"need to compute the non-linear feature map for each datum, but only the "
"inner product of each pair of data points in the new feature space. This "
"collection of inner products is called the kernel and it is perfectly "
"possible to have feature maps that are hard to compute but whose kernels "
"are not."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:17
msgid ""
"In this notebook we provide an example of a classification problem that "
"requires a feature map for which computing the kernel is not efficient "
"classically -this means that the required computational resources are "
"expected to scale exponentially with the size of the problem. We show how"
" this can be solved in a quantum processor by a direct estimation of the "
"kernel in the feature space. The method we used falls in the category of "
"what is called supervised learning, consisting of a training phase (where"
" the kernel is calculated and the support vectors obtained) and a test or"
" classification phase (where new unlabeled data is classified according "
"to the solution found in the training phase)."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:20
msgid "References and additional details:"
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:22
msgid ""
"[1] Vojtech Havlicek, Antonio D. C´orcoles, Kristan Temme, Aram W. "
"Harrow, Abhinav Kandala, Jerry M. Chow, and Jay M. Gambetta1, “Supervised"
" learning with quantum enhanced feature spaces,” `arXiv: 1804.11326 "
"<https://arxiv.org/pdf/1804.11326.pdf>`__"
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:54
msgid "The ad hoc data set"
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:56
msgid ""
"As a first example we will use the ad hoc dataset as described in the "
"above referenced paper. From the dataset we take samples for use as "
"training, testing and the final prediction (datapoints)."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:117
msgid ""
"With the dataset ready we can setup the `QSVM "
"<https://qiskit.org/documentation/stubs/qiskit.aqua.algorithms.QSVM.html>`__"
" algorithm to do a classification. Here we use the `ZZFeatureMap "
"<https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__"
" data encoding circuit from the Qiskit circuit library."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:119
msgid "Here the BasicAer ``qasm_simulator`` is used with 1024 shots."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:121
msgid ""
"For the testing, the result includes the details and the success ratio. "
"For the prediction, the result includes the predicted labels."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:185
msgid ""
"The following shows the kernel matrix that was built from the training "
"sample of the dataset."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:215
msgid ""
"Qiskit also has a classical SVM implementation that takes the same input "
"data for classification. Let’s run this and do a comparison. Now the ad "
"hoc data set was created to show that there can be datasets where quantum"
" could give an advantage."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:288
msgid "The breast cancer dataset"
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:290
msgid ""
"Now we run our algorithm with a real-world dataset: the breast cancer "
"dataset, we use the first two principal components as features."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:364
msgid "The kernel matrix that was built from the training sample of the dataset."
msgstr ""

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:394
msgid "Again we are able to compare the result to a classical approach."
msgstr ""

