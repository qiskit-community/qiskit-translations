msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-04-29 18:58+0000\n"
"PO-Revision-Date: 2021-05-06 17:33\n"
"Last-Translator: \n"
"Language-Team: Spanish (United)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: es-un\n"
"X-Crowdin-File: /master/docs/locale/en/LC_MESSAGES/tutorials/machine_learning/01_qsvm_classification.po\n"
"X-Crowdin-File-ID: 9464\n"
"Language: es_UN\n"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:10
msgid "This page was generated from `tutorials/machine_learning/01_qsvm_classification.ipynb`__."
msgstr "Esta página fue generada a partir de `tutorials/machine_learning/01_qsvm_classification.ipynb`__."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:12
msgid "Run interactively in the `IBM Quantum lab <https://quantum-computing.ibm.com/jupyter/tutorial/machine_learning/01_qsvm_classification.ipynb>`_."
msgstr "Puedes correr esta sección de manera interactiva en el `IBM Quantum lab <https://quantum-computing.ibm.com/jupyter/tutorial/machine_learning/01_qsvm_classification.ipynb>`_."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:9
msgid "Quantum-enhanced Support Vector Machine (QSVM)"
msgstr "Máquina de Vectores de Soporte Mejorada Cuánticamente (QSVM)"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:11
msgid "Classification algorithms and methods for machine learning are essential for pattern recognition and data mining applications. Well known techniques such as support vector machines and neural networks have blossomed over the last two decades as a result of the spectacular advances in classical hardware computational capabilities and speed. This progress in computer power made it possible to apply techniques, that were theoretically developed towards the middle of the 20th century, on classification problems that were becoming increasingly challenging."
msgstr "Los algoritmos y métodos de clasificación para aprendizaje automático son esenciales para reconocimiento de patrones y aplicaciones de minería de datos. Técnicas bien conocidas como máquinas de vectores de soporte y redes neuronales han florecido en las últimas dos décadas como resultado de los espectaculares avances en las capacidades computacionales y la velocidad del hardware clásico. Este progreso en el poder de cómputo hizo posible aplicar técnicas, que fueron teóricamente desarrolladas hacia mediados del siglo XX, en problemas de clasificación que se estaban volviendo cada vez más desafiantes."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:14
msgid "A key concept in classification methods is that of a kernel. Data cannot typically be separated by a hyperplane in its original space. A common technique used to find such a hyperplane consists of applying a non-linear transformation function to the data. This function is called a feature map, as it transforms the raw features, or measurable properties, of the phenomenon or subject under study. Classifying in this new feature space -and, as a matter of fact, also in any other space, including the raw original one- is nothing more than seeing how close data points are to each other. This is the same as computing the inner product for each pair of data points in the set. So, in fact we do not need to compute the non-linear feature map for each datum, but only the inner product of each pair of data points in the new feature space. This collection of inner products is called the kernel and it is perfectly possible to have feature maps that are hard to compute but whose kernels are not."
msgstr "Un concepto clave en los métodos de clasificación es el de kernel. Los datos típicamente no pueden ser separados por un hiperplano en su espacio original. Una técnica común utilizada para encontrar dicho hiperplano consiste en aplicar una función de transformación no lineal a los datos. Esta función se llama mapa de características, ya que transforma las características crudas, o propiedades medibles, del fenómeno o tema bajo estudio. Clasificar en este nuevo espacio de características —y, de hecho, también en cualquier otro espacio incluyendo el original en crudo— no es más que ver qué tan cerca se encuentran los puntos de datos unos a otros. Esto es lo mismo que calcular el producto interno para cada par de puntos de datos en el conjunto. Por lo tanto, de hecho no necesitamos calcular el mapa de características no linear para cada dato, sino solo el producto interno de cada par de puntos de datos en el nuevo espacio de características. Esta colección de productos internos se llama kernel y es perfectamente posible tener mapas de características que son difíciles de calcular pero cuyos kernels no lo son."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:17
msgid "In this notebook we provide an example of a classification problem that requires a feature map for which computing the kernel is not efficient classically -this means that the required computational resources are expected to scale exponentially with the size of the problem. We show how this can be solved in a quantum processor by a direct estimation of the kernel in the feature space. The method we used falls in the category of what is called supervised learning, consisting of a training phase (where the kernel is calculated and the support vectors obtained) and a test or classification phase (where new unlabeled data is classified according to the solution found in the training phase)."
msgstr "En este cuaderno proveemos un ejemplo de un problema de clasificación que requiere un mapa de características para el cual calcular el kernel no es eficiente clásicamente —esto significa que se espera que los recursos computacionales requeridos escalen exponencialmente con el tamaño del problema. Mostramos cómo se puede resolver esto en un procesador cuántico mediante una estimación directa del kernel en el espacio de características. El método que usamos cae en la categoría de lo que se llama aprendizaje supervisado, que consiste de una fase de entrenamiento (donde se calcula el kernel y se obtienen los vectores de soporte) y una fase de prueba o clasificación (donde los nuevos datos no etiquetados se clasifican de acuerdo a la solución encontrada en la fase de entrenamiento)."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:20
msgid "References and additional details:"
msgstr "Referencias y detalles adicionales:"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:22
msgid "[1] Vojtech Havlicek, Antonio D. C´orcoles, Kristan Temme, Aram W. Harrow, Abhinav Kandala, Jerry M. Chow, and Jay M. Gambetta1, “Supervised learning with quantum enhanced feature spaces,” `arXiv: 1804.11326 <https://arxiv.org/pdf/1804.11326.pdf>`__"
msgstr "[1] Vojtech Havlicek, Antonio D. C´orcoles, Kristan Temme, Aram W. Harrow, Abhinav Kandala, Jerry M. Chow, y Jay M. Gambetta1, “Supervised learning with quantum enhanced feature spaces,” `arXiv: 1804.11326 <https://arxiv.org/pdf/1804.11326.pdf>`__"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:54
msgid "The ad hoc data set"
msgstr "El conjunto de datos ad hoc"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:56
msgid "As a first example we will use the ad hoc dataset as described in the above referenced paper. From the dataset we take samples for use as training, testing and the final prediction (datapoints)."
msgstr "Como primer ejemplo utilizaremos el conjunto de datos ad hoc tal como se describe en el articulo referenciado anteriormente. Del conjunto de datos tomamos muestras para usarlas como entrenamiento, prueba y la predicción final (puntos de datos)."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:117
msgid "With the dataset ready we can setup the `QSVM <https://qiskit.org/documentation/stubs/qiskit.aqua.algorithms.QSVM.html>`__ algorithm to do a classification. Here we use the `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__ data encoding circuit from the Qiskit circuit library."
msgstr "Con el conjunto de datos listo podemos configurar el algoritmo `QSVM <https://qiskit.org/documentation/stubs/qiskit.aqua.algorithms.QSVM.html>`__ (Quantum-enhanced Support Vector Machine) para hacer una clasificación. Aquí utilizamos el circuito de codificación de datos `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__ de la librería de circuitos Qiskit."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:119
msgid "Here the BasicAer ``qasm_simulator`` is used with 1024 shots."
msgstr "Aquí se usa el ``qasm_simulator`` de BasicAer con 1024 iteraciones."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:121
msgid "For the testing, the result includes the details and the success ratio. For the prediction, the result includes the predicted labels."
msgstr "Para las pruebas, el resultado incluye los detalles y la tasa de éxito. Para la predicción, el resultado incluye las etiquetas predichas."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:185
msgid "The following shows the kernel matrix that was built from the training sample of the dataset."
msgstr "A continuación se muestra la matriz de kernel que se creó a partir de la muestra de entrenamiento del conjunto de datos."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:215
msgid "Qiskit also has a classical SVM implementation that takes the same input data for classification. Let’s run this and do a comparison. Now the ad hoc data set was created to show that there can be datasets where quantum could give an advantage."
msgstr "Qiskit también tiene una implementación clásica de SVM que toma los mismos datos de entrada para la clasificación. Vamos a correr esto y hacer una comparación. Ahora el conjunto de datos ad hoc fue creado para mostrar que puede haber conjuntos de datos donde la cuántica podría dar una ventaja."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:288
msgid "The breast cancer dataset"
msgstr "El conjunto de datos del cáncer de mama"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:290
msgid "Now we run our algorithm with a real-world dataset: the breast cancer dataset, we use the first two principal components as features."
msgstr "Ahora ejecutamos nuestro algoritmo con un conjunto de datos del mundo real: el conjunto de datos del cáncer de mama, usamos los dos primeros componentes principales como características."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:364
msgid "The kernel matrix that was built from the training sample of the dataset."
msgstr "La matriz de kernel que se creó a partir de la muestra de entrenamiento del conjunto de datos."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:394
msgid "Again we are able to compare the result to a classical approach."
msgstr "De nuevo, podemos comparar el resultado contra el enfoque clásico."

