msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-04-29 18:58+0000\n"
"PO-Revision-Date: 2021-06-21 16:18\n"
"Last-Translator: \n"
"Language-Team: Korean\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ko\n"
"X-Crowdin-File: /master/docs/locale/en/LC_MESSAGES/tutorials/machine_learning/01_qsvm_classification.po\n"
"X-Crowdin-File-ID: 9464\n"
"Language: ko_KR\n"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:10
msgid "This page was generated from `tutorials/machine_learning/01_qsvm_classification.ipynb`__."
msgstr "이 페이지는 `tutorials/machine_learning/01_qsvm_classification.ipynb`__ 에서 생성되었다."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:12
msgid "Run interactively in the `IBM Quantum lab <https://quantum-computing.ibm.com/jupyter/tutorial/machine_learning/01_qsvm_classification.ipynb>`_."
msgstr "`IBM 퀀텀 랩 <https://quantum-computing.ibm.com/jupyter/tutorial/machine_learning/01_qsvm_classification.ipynb>`_ 에서 대화식으로 실행하십시오."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:9
msgid "Quantum-enhanced Support Vector Machine (QSVM)"
msgstr "QSVM (Quantum-enhanced Support Vector Machine)"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:11
msgid "Classification algorithms and methods for machine learning are essential for pattern recognition and data mining applications. Well known techniques such as support vector machines and neural networks have blossomed over the last two decades as a result of the spectacular advances in classical hardware computational capabilities and speed. This progress in computer power made it possible to apply techniques, that were theoretically developed towards the middle of the 20th century, on classification problems that were becoming increasingly challenging."
msgstr "기계 학습을 위한 고전 분류 알고리즘 및 방법들은 패턴 인식과 데이터 마이닝 애플리케이션에 필수적이다. 지원 벡터 기계 및 신경망과 같이 잘 알려진 기술들은 고전적인 하드웨어 계산 능력 및 속도의 극적인 발전의 결과로서 지난 20년에 걸쳐 꽃을 피웠다. 이러한 컴퓨터 파워의 진보는 20세기 중반까지 이론적으로만 발달되었던 기술들을 점점 더 어려워지는 분류 문제들에 적용하는 것을 가능하게 만들었다."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:14
msgid "A key concept in classification methods is that of a kernel. Data cannot typically be separated by a hyperplane in its original space. A common technique used to find such a hyperplane consists of applying a non-linear transformation function to the data. This function is called a feature map, as it transforms the raw features, or measurable properties, of the phenomenon or subject under study. Classifying in this new feature space -and, as a matter of fact, also in any other space, including the raw original one- is nothing more than seeing how close data points are to each other. This is the same as computing the inner product for each pair of data points in the set. So, in fact we do not need to compute the non-linear feature map for each datum, but only the inner product of each pair of data points in the new feature space. This collection of inner products is called the kernel and it is perfectly possible to have feature maps that are hard to compute but whose kernels are not."
msgstr "분류 메소드의 핵심 개념은 커널에 대한 개념이다. 데이터는 일반적으로 원래 공간에서는 초평면(hyperplane)에 의해 분리될 수 없다. 이러한 초평면을 찾는 데 사용되는 일반적인 기술은 데이터에 비선형 변환 함수를 적용하는 것으로 구성된다. 이 함수는 연구 중인 현상 또는 주제의 원시 기능 또는 측정 가능한 특성을 변환하기 때문에 특징 맵(feature map)이라고 불린다. 이 새 특징 공간에서의 -당연히 원본을 포함하여 다른 어떤 공간에서도- 분류는 데이터 점들이 서로 얼마나 근접해 있는지 확인하는 것에 불과하다. 이는 세트의 각 데이터 점 쌍에 대한 내적을 계산하는 것과 동일하다. 따라서, 사실상 우리는 각각의 데이터에 대해 비선형 특징 맵을 계산할 필요가 없고, 새로운 특징 공간에서 각각의 데이터 점 쌍에 대한 내적만 구해주면 된다. 이 내적들의 콜렉션을 커널이라고 하며, 특징 맵 그 자체는 계산하기 어렵지만 이의 커널은 그렇지 않은 경우도 충분히 가능하다."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:17
msgid "In this notebook we provide an example of a classification problem that requires a feature map for which computing the kernel is not efficient classically -this means that the required computational resources are expected to scale exponentially with the size of the problem. We show how this can be solved in a quantum processor by a direct estimation of the kernel in the feature space. The method we used falls in the category of what is called supervised learning, consisting of a training phase (where the kernel is calculated and the support vectors obtained) and a test or classification phase (where new unlabeled data is classified according to the solution found in the training phase)."
msgstr "이 노트북에서는 커널이 효율적으로 효율적이지 않은 기능 맵을 필요로 하는 분류 문제의 예를 제공한다. 이는 필요한 계산 자원이 문제의 크기에 따라 기하급수적으로 확장될 것으로 예상됨을 의미한다. 우리는 이것이 특징 공간에서 커널의 직접적인 추정에 의해 양자 프로세서에서 어떻게 해결될 수 있는지를 보여준다. 사용한 방법은 훈련 단계 (커널이 계산되고 지원되는 지원 벡터) 와 테스트 또는 분류 단계 (새로운 비레이블 데이터는 훈련 단계에서 찾은 솔루션에 따라 분류되는 경우) 로 구성되는, 감독 학습이라고 하는 항목의 범주에 속한다."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:20
msgid "References and additional details:"
msgstr "참조 및 추가 세부사항:"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:22
msgid "[1] Vojtech Havlicek, Antonio D. C´orcoles, Kristan Temme, Aram W. Harrow, Abhinav Kandala, Jerry M. Chow, and Jay M. Gambetta1, “Supervised learning with quantum enhanced feature spaces,” `arXiv: 1804.11326 <https://arxiv.org/pdf/1804.11326.pdf>`__"
msgstr "[1] Vojtech Havlicek, Antonio D. C´orcoles, Kristan Temme, Aram W. Harrow, Abhinav Kandala, Jerry M. Chow, and Jay M. Gambetta1, “Supervised learning with quantum enhanced feature spaces,” `arXiv: 1804.11326 <https://arxiv.org/pdf/1804.11326.pdf>`__"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:54
msgid "The ad hoc data set"
msgstr "임시 데이터 세트"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:56
msgid "As a first example we will use the ad hoc dataset as described in the above referenced paper. From the dataset we take samples for use as training, testing and the final prediction (datapoints)."
msgstr "첫 번째 예로, 위에서 참조된 논문에 설명된 대로 임시 데이터 세트를 사용할 것이다. 데이터 세트에서 학습, 테스트 및 최종 예측(데이터 지점)으로 사용하기 위해 표본들을 추출한다."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:117
msgid "With the dataset ready we can setup the `QSVM <https://qiskit.org/documentation/stubs/qiskit.aqua.algorithms.QSVM.html>`__ algorithm to do a classification. Here we use the `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__ data encoding circuit from the Qiskit circuit library."
msgstr "데이터 세트를 사용하여 `QSVM <https://qiskit.org/documentation/stubs/qiskit.aqua.algorithms.QSVM.html>`__ 알고리즘을 설정하여 분류를 수행할 수 있다. 여기에서는 Qiskit 회로 라이브러리의 `ZZFeatureMap <https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html>`__ 데이터 인코딩 회로를 사용한다."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:119
msgid "Here the BasicAer ``qasm_simulator`` is used with 1024 shots."
msgstr "여기에는 1024샷을 넣은 'BasicAer' 의 'qasm_시뮬레이터' 가 사용된다."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:121
msgid "For the testing, the result includes the details and the success ratio. For the prediction, the result includes the predicted labels."
msgstr "테스트의 경우, 결과에는 세부사항 및 성공 비율이 포함된다. 예측에 대해, 결과에는 예측된 레이블이 포함된다."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:185
msgid "The following shows the kernel matrix that was built from the training sample of the dataset."
msgstr "다음은 데이터 세트의 훈련 표본에서 빌드된 커널 매트릭스를 나타다."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:215
msgid "Qiskit also has a classical SVM implementation that takes the same input data for classification. Let’s run this and do a comparison. Now the ad hoc data set was created to show that there can be datasets where quantum could give an advantage."
msgstr "또한, Qiskit은 분류를 위해 동일한 입력 데이터를 취하는 고전적인 SVM 구현을 갖는다. 이것을 실행하고 비교해 보자. 이제 임시 데이터 세트가 작성되어 퀀텀이 장점을 제공할 수 있는 데이터 세트가 있음을 표시한다."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:288
msgid "The breast cancer dataset"
msgstr "유방암 데이터 세트"

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:290
msgid "Now we run our algorithm with a real-world dataset: the breast cancer dataset, we use the first two principal components as features."
msgstr "이제 실제 데이터 세트를 사용하여 알고리즘을 실행한다. 유방암 데이터 세트에서는 처음 두 개의 주요 구성요소를 기능으로 사용한다."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:364
msgid "The kernel matrix that was built from the training sample of the dataset."
msgstr "데이터 세트의 훈련 표본에서 빌드된 커널 행렬이다."

#: ../../tutorials/machine_learning/01_qsvm_classification.ipynb:394
msgid "Again we are able to compare the result to a classical approach."
msgstr "우리는 그 결과를 고전적인 접근 방식과 비교할 수 있다."

