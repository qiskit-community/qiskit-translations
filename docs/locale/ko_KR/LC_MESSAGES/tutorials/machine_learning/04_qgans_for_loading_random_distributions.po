msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-12-07 16:27+0000\n"
"PO-Revision-Date: 2020-12-20 03:37\n"
"Last-Translator: \n"
"Language-Team: Korean\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ko\n"
"X-Crowdin-File: /master/docs/locale/en/LC_MESSAGES/tutorials/machine_learning/04_qgans_for_loading_random_distributions.po\n"
"X-Crowdin-File-ID: 9470\n"
"Language: ko_KR\n"

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:10
msgid "This page was generated from `tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb`__."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:12
msgid "Run interactively in the `IBM Quantum lab <https://quantum-computing.ibm.com/jupyter/tutorial/machine_learning/04_qgans_for_loading_random_distributions.ipynb>`_."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:9
msgid "qGANs for Loading Random Distributions"
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:11
msgid "Given :math:`k`-dimensional data samples, we employ a quantum Generative Adversarial Network (qGAN) to learn the data’s underlying random distribution and to load it directly into a quantum state:"
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:13
msgid "$ :nbsphinx-math:`\\big`\\| g_{:nbsphinx-math:`\\theta`}:nbsphinx-math:`\\rangle `= :nbsphinx-math:`\\sum`\\_{j=0}\\ :sup:`{2`\\ n-1} :nbsphinx-math:`\\sqrt{p_{\\theta}^{j}}`:nbsphinx-math:`\\big`\\| j :nbsphinx-math:`\\rangle `$"
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:15
msgid "where :math:`p_{\\theta}^{j}` describe the occurrence probabilities of the basis states :math:`\\big| j\\rangle`."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:17
msgid "The aim of the qGAN training is to generate a state :math:`\\big| g_{\\theta}\\rangle` where :math:`p_{\\theta}^{j}`, for :math:`j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}`, describe a probability distribution that is close to the distribution underlying the training data :math:`X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}`."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:19
msgid "For further details please refer to `Quantum Generative Adversarial Networks for Learning and Loading Random Distributions <https://arxiv.org/abs/1904.00043>`__ *Zoufal, Lucchi, Woerner* [2019]."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:21
msgid "For an example of how to use a trained qGAN in an application, the pricing of financial derivatives, please see the `Option Pricing with qGANs <../finance/10_qgan_option_pricing.ipynb>`__ tutorial."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:57
msgid "Load the Training Data"
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:59
msgid "First, we need to load the :math:`k`-dimensional training data samples (here k=1)."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:61
msgid "Next, the data resolution is set, i.e. the min/max data values and the number of qubits used to represent each data dimension."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:96
msgid "Initialize the qGAN"
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:98
msgid "The qGAN consists of a quantum generator :math:`G_{\\theta}`, a variational quantum circuit, and a classical discriminator :math:`D_{\\phi}`, a neural network."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:100
msgid "To implement the quantum generator, we choose a depth-\\ :math:`1` variational form that implements :math:`R_Y` rotations and :math:`CZ` gates which takes a uniform distribution as an input state. Notably, for :math:`k>1` the generator’s parameters must be chosen carefully. For example, the circuit depth should be :math:`>1` because higher circuit depths enable the representation of more complex structures."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:102
msgid "The classical discriminator used here is based on a neural network implementation using NumPy. There is also a discriminator based on PyTorch which is not installed by default when installing Qiskit - see `Optional Install <https://github.com/Qiskit/qiskit-aqua#optional-installs>`__ for more information."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:104
msgid "Here, both networks are updated with the ADAM optimization algorithm (ADAM is qGAN optimizer default)."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:165
msgid "Run the qGAN Training"
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:167
msgid "During the training the discriminator’s and the generator’s parameters are updated alternately w.r.t the following loss functions:"
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:169
msgid "L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right]\n\n"
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:171
msgid "and"
msgstr "그리고"

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:173
msgid "L_D\\left(\\phi, \\theta\\right) =\n"
"  \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],"
msgstr "L_D\\left(\\phi, \\theta\\right) =\n"
"  \\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right],"

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:178
msgid "with :math:`m` denoting the batch size and :math:`g^l` describing the data samples generated by the quantum generator."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:180
msgid "Please note that the training, for the purpose of this notebook, has been kept briefer by the selection of a known initial point (``init_params``). Without such prior knowledge be aware training may take some while."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:246
msgid "Training Progress & Outcome"
msgstr "교육 진행 및 결과"

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:248
msgid "Now, we plot the evolution of the generator’s and the discriminator’s loss functions during the training, as well as the progress in the relative entropy between the trained and the target distribution."
msgstr ""

#: ../../tutorials/machine_learning/04_qgans_for_loading_random_distributions.ipynb:250
msgid "Finally, we also compare the cumulative distribution function (CDF) of the trained distribution to the CDF of the target distribution."
msgstr ""

